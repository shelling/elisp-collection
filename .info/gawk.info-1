This is gawk.info, produced by makeinfo version 4.13 from
/d/home/arnold/Gnu/gawk/gendocs/gawk-4.0.0/doc/gawk.texi.

INFO-DIR-SECTION Text creation and manipulation
START-INFO-DIR-ENTRY
* Gawk: (gawk).                 A text scanning and processing language.
END-INFO-DIR-ENTRY
INFO-DIR-SECTION Individual utilities
START-INFO-DIR-ENTRY
* awk: (gawk)Invoking gawk.                     Text scanning and processing.
END-INFO-DIR-ENTRY

   Copyright (C) 1989, 1991, 1992, 1993, 1996, 1997, 1998, 1999, 2000,
2001, 2002, 2003, 2004, 2005, 2007, 2009, 2010, 2011 Free Software
Foundation, Inc.


   This is Edition 4 of `GAWK: Effective AWK Programming: A User's
Guide for GNU Awk', for the 4.0.0 (or later) version of the GNU
implementation of AWK.

   Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with the
Invariant Sections being "GNU General Public License", the Front-Cover
texts being (a) (see below), and with the Back-Cover Texts being (b)
(see below).  A copy of the license is included in the section entitled
"GNU Free Documentation License".

  a. "A GNU Manual"

  b. "You have the freedom to copy and modify this GNU manual.  Buying
     copies from the FSF supports it in developing GNU and promoting
     software freedom."


File: gawk.info,  Node: Top,  Next: Foreword,  Up: (dir)

General Introduction
********************

This file documents `awk', a program that you can use to select
particular records in a file and perform operations upon them.

   Copyright (C) 1989, 1991, 1992, 1993, 1996, 1997, 1998, 1999, 2000,
2001, 2002, 2003, 2004, 2005, 2007, 2009, 2010, 2011 Free Software
Foundation, Inc.


   This is Edition 4 of `GAWK: Effective AWK Programming: A User's
Guide for GNU Awk', for the 4.0.0 (or later) version of the GNU
implementation of AWK.

   Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with the
Invariant Sections being "GNU General Public License", the Front-Cover
texts being (a) (see below), and with the Back-Cover Texts being (b)
(see below).  A copy of the license is included in the section entitled
"GNU Free Documentation License".

  a. "A GNU Manual"

  b. "You have the freedom to copy and modify this GNU manual.  Buying
     copies from the FSF supports it in developing GNU and promoting
     software freedom."

* Menu:

* Foreword::                       Some nice words about this
                                   Info file.
* Preface::                        What this Info file is about; brief
                                   history and acknowledgments.
* Getting Started::                A basic introduction to using
                                   `awk'. How to run an `awk'
                                   program. Command-line syntax.
* Invoking Gawk::                  How to run `gawk'.
* Regexp::                         All about matching things using regular
                                   expressions.
* Reading Files::                  How to read files and manipulate fields.
* Printing::                       How to print using `awk'. Describes
                                   the `print' and `printf'
                                   statements. Also describes redirection of
                                   output.
* Expressions::                    Expressions are the basic building blocks
                                   of statements.
* Patterns and Actions::           Overviews of patterns and actions.
* Arrays::                         The description and use of arrays. Also
                                   includes array-oriented control statements.
* Functions::                      Built-in and user-defined functions.
* Internationalization::           Getting `gawk' to speak your
                                   language.
* Advanced Features::              Stuff for advanced users, specific to
                                   `gawk'.
* Library Functions::              A Library of `awk' Functions.
* Sample Programs::                Many `awk' programs with complete
                                   explanations.
* Debugger::                       The `dgawk' debugger.
* Language History::               The evolution of the `awk'
                                   language.
* Installation::                   Installing `gawk' under various
                                   operating systems.
* Notes::                          Notes about `gawk' extensions and
                                   possible future work.
* Basic Concepts::                 A very quick introduction to programming
                                   concepts.
* Glossary::                       An explanation of some unfamiliar terms.
* Copying::                        Your right to copy and distribute
                                   `gawk'.
* GNU Free Documentation License:: The license for this Info file.
* Index::                          Concept and Variable Index.

* History::                            The history of `gawk' and
                                       `awk'.
* Names::                              What name to use to find `awk'.
* This Manual::                        Using this Info file. Includes
                                       sample input files that you can use.
* Conventions::                        Typographical Conventions.
* Manual History::                     Brief history of the GNU project and
                                       this Info file.
* How To Contribute::                  Helping to save the world.
* Acknowledgments::                    Acknowledgments.
* Running gawk::                       How to run `gawk' programs;
                                       includes command-line syntax.
* One-shot::                           Running a short throwaway `awk'
                                       program.
* Read Terminal::                      Using no input files (input from
                                       terminal instead).
* Long::                               Putting permanent `awk'
                                       programs in files.
* Executable Scripts::                 Making self-contained `awk'
                                       programs.
* Comments::                           Adding documentation to `gawk'
                                       programs.
* Quoting::                            More discussion of shell quoting
                                       issues.
* DOS Quoting::                        Quoting in Windows Batch Files.
* Sample Data Files::                  Sample data files for use in the
                                       `awk' programs illustrated in
                                       this Info file.
* Very Simple::                        A very simple example.
* Two Rules::                          A less simple one-line example using
                                       two rules.
* More Complex::                       A more complex example.
* Statements/Lines::                   Subdividing or combining statements
                                       into lines.
* Other Features::                     Other Features of `awk'.
* When::                               When to use `gawk' and when to
                                       use other things.
* Command Line::                       How to run `awk'.
* Options::                            Command-line options and their
                                       meanings.
* Other Arguments::                    Input file names and variable
                                       assignments.
* Naming Standard Input::              How to specify standard input with
                                       other files.
* Environment Variables::              The environment variables
                                       `gawk' uses.
* AWKPATH Variable::                   Searching directories for `awk'
                                       programs.
* Other Environment Variables::        The environment variables.
* Exit Status::                        `gawk''s exit status.
* Include Files::                      Including other files into your
                                       program.
* Obsolete::                           Obsolete Options and/or features.
* Undocumented::                       Undocumented Options and Features.
* Regexp Usage::                       How to Use Regular Expressions.
* Escape Sequences::                   How to write nonprinting characters.
* Regexp Operators::                   Regular Expression Operators.
* Bracket Expressions::                What can go between `[...]'.
* GNU Regexp Operators::               Operators specific to GNU software.
* Case-sensitivity::                   How to do case-insensitive matching.
* Leftmost Longest::                   How much text matches.
* Computed Regexps::                   Using Dynamic Regexps.
* Records::                            Controlling how data is split into
                                       records.
* Fields::                             An introduction to fields.
* Nonconstant Fields::                 Nonconstant Field Numbers.
* Changing Fields::                    Changing the Contents of a Field.
* Field Separators::                   The field separator and how to change
                                       it.
* Default Field Splitting::            How fields are normally separated.
* Regexp Field Splitting::             Using regexps as the field separator.
* Single Character Fields::            Making each character a separate field.
* Command Line Field Separator::       Setting `FS' from the
                                       command-line.
* Field Splitting Summary::            Some final points and a summary table.
* Constant Size::                      Reading constant width data.
* Splitting By Content::               Defining Fields By Content
* Multiple Line::                      Reading multi-line records.
* Getline::                            Reading files under explicit program
                                       control using the `getline'
                                       function.
* Plain Getline::                      Using `getline' with no arguments.
* Getline/Variable::                   Using `getline' into a variable.
* Getline/File::                       Using `getline' from a file.
* Getline/Variable/File::              Using `getline' into a variable
                                       from a file.
* Getline/Pipe::                       Using `getline' from a pipe.
* Getline/Variable/Pipe::              Using `getline' into a variable
                                       from a pipe.
* Getline/Coprocess::                  Using `getline' from a coprocess.
* Getline/Variable/Coprocess::         Using `getline' into a variable
                                       from a coprocess.
* Getline Notes::                      Important things to know about
                                       `getline'.
* Getline Summary::                    Summary of `getline' Variants.
* Command line directories::           What happens if you put a directory on
                                       the command line.
* Print::                              The `print' statement.
* Print Examples::                     Simple examples of `print'
                                       statements.
* Output Separators::                  The output separators and how to change
                                       them.
* OFMT::                               Controlling Numeric Output With
                                       `print'.
* Printf::                             The `printf' statement.
* Basic Printf::                       Syntax of the `printf' statement.
* Control Letters::                    Format-control letters.
* Format Modifiers::                   Format-specification modifiers.
* Printf Examples::                    Several examples.
* Redirection::                        How to redirect output to multiple
                                       files and pipes.
* Special Files::                      File name interpretation in
                                       `gawk'. `gawk' allows
                                       access to inherited file descriptors.
* Special FD::                         Special files for I/O.
* Special Network::                    Special files for network
                                       communications.
* Special Caveats::                    Things to watch out for.
* Close Files And Pipes::              Closing Input and Output Files and
                                       Pipes.
* Values::                             Constants, Variables, and Regular
                                       Expressions.
* Constants::                          String, numeric and regexp constants.
* Scalar Constants::                   Numeric and string constants.
* Nondecimal-numbers::                 What are octal and hex numbers.
* Regexp Constants::                   Regular Expression constants.
* Using Constant Regexps::             When and how to use a regexp constant.
* Variables::                          Variables give names to values for
                                       later use.
* Using Variables::                    Using variables in your programs.
* Assignment Options::                 Setting variables on the command-line
                                       and a summary of command-line syntax.
                                       This is an advanced method of input.
* Conversion::                         The conversion of strings to numbers
                                       and vice versa.
* All Operators::                      `gawk''s operators.
* Arithmetic Ops::                     Arithmetic operations (`+',
                                       `-', etc.)
* Concatenation::                      Concatenating strings.
* Assignment Ops::                     Changing the value of a variable or a
                                       field.
* Increment Ops::                      Incrementing the numeric value of a
                                       variable.
* Truth Values and Conditions::        Testing for true and false.
* Truth Values::                       What is ``true'' and what is ``false''.
* Typing and Comparison::              How variables acquire types and how
                                       this affects comparison of numbers and
                                       strings with `<', etc.
* Variable Typing::                    String type versus numeric type.
* Comparison Operators::               The comparison operators.
* POSIX String Comparison::            String comparison with POSIX rules.
* Boolean Ops::                        Combining comparison expressions using
                                       boolean operators `||' (``or''),
                                       `&&' (``and'') and `!'
                                       (``not'').
* Conditional Exp::                    Conditional expressions select between
                                       two subexpressions under control of a
                                       third subexpression.
* Function Calls::                     A function call is an expression.
* Precedence::                         How various operators nest.
* Locales::                            How the locale affects things.
* Pattern Overview::                   What goes into a pattern.
* Regexp Patterns::                    Using regexps as patterns.
* Expression Patterns::                Any expression can be used as a
                                       pattern.
* Ranges::                             Pairs of patterns specify record
                                       ranges.
* BEGIN/END::                          Specifying initialization and cleanup
                                       rules.
* Using BEGIN/END::                    How and why to use BEGIN/END rules.
* I/O And BEGIN/END::                  I/O issues in BEGIN/END rules.
* BEGINFILE/ENDFILE::                  Two special patterns for advanced
                                       control.
* Empty::                              The empty pattern, which matches every
                                       record.
* Using Shell Variables::              How to use shell variables with
                                       `awk'.
* Action Overview::                    What goes into an action.
* Statements::                         Describes the various control
                                       statements in detail.
* If Statement::                       Conditionally execute some
                                       `awk' statements.
* While Statement::                    Loop until some condition is satisfied.
* Do Statement::                       Do specified action while looping until
                                       some condition is satisfied.
* For Statement::                      Another looping statement, that
                                       provides initialization and increment
                                       clauses.
* Switch Statement::                   Switch/case evaluation for conditional
                                       execution of statements based on a
                                       value.
* Break Statement::                    Immediately exit the innermost
                                       enclosing loop.
* Continue Statement::                 Skip to the end of the innermost
                                       enclosing loop.
* Next Statement::                     Stop processing the current input
                                       record.
* Nextfile Statement::                 Stop processing the current file.
* Exit Statement::                     Stop execution of `awk'.
* Built-in Variables::                 Summarizes the built-in variables.
* User-modified::                      Built-in variables that you change to
                                       control `awk'.
* Auto-set::                           Built-in variables where `awk'
                                       gives you information.
* ARGC and ARGV::                      Ways to use `ARGC' and
                                       `ARGV'.
* Array Basics::                       The basics of arrays.
* Array Intro::                        Introduction to Arrays
* Reference to Elements::              How to examine one element of an array.
* Assigning Elements::                 How to change an element of an array.
* Array Example::                      Basic Example of an Array
* Scanning an Array::                  A variation of the `for'
                                       statement. It loops through the indices
                                       of an array's existing elements.
* Delete::                             The `delete' statement removes an
                                       element from an array.
* Numeric Array Subscripts::           How to use numbers as subscripts in
                                       `awk'.
* Uninitialized Subscripts::           Using Uninitialized variables as
                                       subscripts.
* Multi-dimensional::                  Emulating multidimensional arrays in
                                       `awk'.
* Multi-scanning::                     Scanning multidimensional arrays.
* Arrays of Arrays::                   True multidimensional arrays.
* Built-in::                           Summarizes the built-in functions.
* Calling Built-in::                   How to call built-in functions.
* Numeric Functions::                  Functions that work with numbers,
                                       including `int()', `sin()'
                                       and `rand()'.
* String Functions::                   Functions for string manipulation, such
                                       as `split()', `match()' and
                                       `sprintf()'.
* Gory Details::                       More than you want to know about
                                       `\' and `&' with
                                       `sub()', `gsub()', and
                                       `gensub()'.
* I/O Functions::                      Functions for files and shell commands.
* Time Functions::                     Functions for dealing with timestamps.
* Bitwise Functions::                  Functions for bitwise operations.
* Type Functions::                     Functions for type information.
* I18N Functions::                     Functions for string translation.
* User-defined::                       Describes User-defined functions in
                                       detail.
* Definition Syntax::                  How to write definitions and what they
                                       mean.
* Function Example::                   An example function definition and what
                                       it does.
* Function Caveats::                   Things to watch out for.
* Calling A Function::                 Don't use spaces.
* Variable Scope::                     Controlling variable scope.
* Pass By Value/Reference::            Passing parameters.
* Return Statement::                   Specifying the value a function
                                       returns.
* Dynamic Typing::                     How variable types can change at
                                       runtime.
* Indirect Calls::                     Choosing the function to call at
                                       runtime.
* I18N and L10N::                      Internationalization and Localization.
* Explaining gettext::                 How GNU `gettext' works.
* Programmer i18n::                    Features for the programmer.
* Translator i18n::                    Features for the translator.
* String Extraction::                  Extracting marked strings.
* Printf Ordering::                    Rearranging `printf' arguments.
* I18N Portability::                   `awk'-level portability issues.
* I18N Example::                       A simple i18n example.
* Gawk I18N::                          `gawk' is also
                                       internationalized.
* Nondecimal Data::                    Allowing nondecimal input data.
* Array Sorting::                      Facilities for controlling array
                                       traversal and sorting arrays.
* Controlling Array Traversal::        How to use PROCINFO["sorted_in"].
* Controlling Scanning With A Function:: Using a function to control scanning.
* Controlling Scanning::               Controlling the order in which arrays
                                       are scanned.
* Array Sorting Functions::            How to use `asort()' and
                                       `asorti()'.
* Two-way I/O::                        Two-way communications with another
                                       process.
* TCP/IP Networking::                  Using `gawk' for network
                                       programming.
* Profiling::                          Profiling your `awk' programs.
* Library Names::                      How to best name private global
                                       variables in library functions.
* General Functions::                  Functions that are of general use.
* Strtonum Function::                  A replacement for the built-in
                                       `strtonum()' function.
* Assert Function::                    A function for assertions in
                                       `awk' programs.
* Round Function::                     A function for rounding if
                                       `sprintf()' does not do it
                                       correctly.
* Cliff Random Function::              The Cliff Random Number Generator.
* Ordinal Functions::                  Functions for using characters as
                                       numbers and vice versa.
* Join Function::                      A function to join an array into a
                                       string.
* Gettimeofday Function::              A function to get formatted times.
* Data File Management::               Functions for managing command-line
                                       data files.
* Filetrans Function::                 A function for handling data file
                                       transitions.
* Rewind Function::                    A function for rereading the current
                                       file.
* File Checking::                      Checking that data files are readable.
* Empty Files::                        Checking for zero-length files.
* Ignoring Assigns::                   Treating assignments as file names.
* Getopt Function::                    A function for processing command-line
                                       arguments.
* Passwd Functions::                   Functions for getting user information.
* Group Functions::                    Functions for getting group
                                       information.
* Walking Arrays::                     A function to walk arrays of arrays.
* Running Examples::                   How to run these examples.
* Clones::                             Clones of common utilities.
* Cut Program::                        The `cut' utility.
* Egrep Program::                      The `egrep' utility.
* Id Program::                         The `id' utility.
* Split Program::                      The `split' utility.
* Tee Program::                        The `tee' utility.
* Uniq Program::                       The `uniq' utility.
* Wc Program::                         The `wc' utility.
* Miscellaneous Programs::             Some interesting `awk'
                                       programs.
* Dupword Program::                    Finding duplicated words in a document.
* Alarm Program::                      An alarm clock.
* Translate Program::                  A program similar to the `tr'
                                       utility.
* Labels Program::                     Printing mailing labels.
* Word Sorting::                       A program to produce a word usage
                                       count.
* History Sorting::                    Eliminating duplicate entries from a
                                       history file.
* Extract Program::                    Pulling out programs from Texinfo
                                       source files.
* Simple Sed::                         A Simple Stream Editor.
* Igawk Program::                      A wrapper for `awk' that
                                       includes files.
* Anagram Program::                    Finding anagrams from a dictionary.
* Signature Program::                  People do amazing things with too much
                                       time on their hands.
* Debugging::                          Introduction to `dgawk'.
* Debugging Concepts::                 Debugging In General.
* Debugging Terms::                    Additional Debugging Concepts.
* Awk Debugging::                      Awk Debugging.
* Sample dgawk session::               Sample `dgawk' session.
* dgawk invocation::                   `dgawk' Invocation.
* Finding The Bug::                    Finding The Bug.
* List of Debugger Commands::          Main `dgawk' Commands.
* Breakpoint Control::                 Control of breakpoints.
* Dgawk Execution Control::            Control of execution.
* Viewing And Changing Data::          Viewing and changing data.
* Dgawk Stack::                        Dealing with the stack.
* Dgawk Info::                         Obtaining information about the program
                                       and the debugger state.
* Miscellaneous Dgawk Commands::       Miscellaneous Commands.
* Readline Support::                   Readline Support.
* Dgawk Limitations::                  Limitations and future plans.
* V7/SVR3.1::                          The major changes between V7 and System
                                       V Release 3.1.
* SVR4::                               Minor changes between System V Releases
                                       3.1 and 4.
* POSIX::                              New features from the POSIX standard.
* BTL::                                New features from Brian Kernighan's
                                       version of `awk'.
* POSIX/GNU::                          The extensions in `gawk' not in
                                       POSIX `awk'.
* Common Extensions::                  Common Extensions Summary.
* Ranges and Locales::                 How locales used to affect regexp
                                       ranges.
* Contributors::                       The major contributors to
                                       `gawk'.
* Gawk Distribution::                  What is in the `gawk'
                                       distribution.
* Getting::                            How to get the distribution.
* Extracting::                         How to extract the distribution.
* Distribution contents::              What is in the distribution.
* Unix Installation::                  Installing `gawk' under various
                                       versions of Unix.
* Quick Installation::                 Compiling `gawk' under Unix.
* Additional Configuration Options::   Other compile-time options.
* Configuration Philosophy::           How it's all supposed to work.
* Non-Unix Installation::              Installation on Other Operating
                                       Systems.
* PC Installation::                    Installing and Compiling `gawk'
                                       on MS-DOS and OS/2.
* PC Binary Installation::             Installing a prepared distribution.
* PC Compiling::                       Compiling `gawk' for MS-DOS,
                                       Windows32, and OS/2.
* PC Testing::                         Testing `gawk' on PC systems.
* PC Using::                           Running `gawk' on MS-DOS,
                                       Windows32 and OS/2.
* Cygwin::                             Building and running `gawk' for
                                       Cygwin.
* MSYS::                               Using `gawk' In The MSYS
                                       Environment.
* VMS Installation::                   Installing `gawk' on VMS.
* VMS Compilation::                    How to compile `gawk' under
                                       VMS.
* VMS Installation Details::           How to install `gawk' under
                                       VMS.
* VMS Running::                        How to run `gawk' under VMS.
* VMS Old Gawk::                       An old version comes with some VMS
                                       systems.
* Bugs::                               Reporting Problems and Bugs.
* Other Versions::                     Other freely available `awk'
                                       implementations.
* Compatibility Mode::                 How to disable certain `gawk'
                                       extensions.
* Additions::                          Making Additions To `gawk'.
* Accessing The Source::               Accessing the Git repository.
* Adding Code::                        Adding code to the main body of
                                       `gawk'.
* New Ports::                          Porting `gawk' to a new
                                       operating system.
* Dynamic Extensions::                 Adding new built-in functions to
                                       `gawk'.
* Internals::                          A brief look at some `gawk'
                                       internals.
* Plugin License::                     A note about licensing.
* Sample Library::                     A example of new functions.
* Internal File Description::          What the new functions will do.
* Internal File Ops::                  The code for internal file operations.
* Using Internal File Ops::            How to use an external extension.
* Future Extensions::                  New features that may be implemented
                                       one day.
* Basic High Level::                   The high level view.
* Basic Data Typing::                  A very quick intro to data types.
* Floating Point Issues::              Stuff to know about floating-point
                                       numbers.
* String Conversion Precision::        The String Value Can Lie.
* Unexpected Results::                 Floating Point Numbers Are Not Abstract
                                       Numbers.
* POSIX Floating Point Problems::      Standards Versus Existing Practice.

                  To Miriam, for making me complete.

                  To Chana, for the joy you bring us.

                To Rivka, for the exponential increase.

                  To Nachum, for the added dimension.

                   To Malka, for the new beginning.

File: gawk.info,  Node: Foreword,  Next: Preface,  Prev: Top,  Up: Top

Foreword
********

Arnold Robbins and I are good friends. We were introduced in 1990 by
circumstances--and our favorite programming language, AWK.  The
circumstances started a couple of years earlier. I was working at a new
job and noticed an unplugged Unix computer sitting in the corner.  No
one knew how to use it, and neither did I.  However, a couple of days
later it was running, and I was `root' and the one-and-only user.  That
day, I began the transition from statistician to Unix programmer.

   On one of many trips to the library or bookstore in search of books
on Unix, I found the gray AWK book, a.k.a. Aho, Kernighan and
Weinberger, `The AWK Programming Language', Addison-Wesley, 1988.
AWK's simple programming paradigm--find a pattern in the input and then
perform an action--often reduced complex or tedious data manipulations
to few lines of code.  I was excited to try my hand at programming in
AWK.

   Alas,  the `awk' on my computer was a limited version of the
language described in the AWK book.  I discovered that my computer had
"old `awk'" and the AWK book described "new `awk'."  I learned that
this was typical; the old version refused to step aside or relinquish
its name.  If a system had a new `awk', it was invariably called
`nawk', and few systems had it.  The best way to get a new `awk' was to
`ftp' the source code for `gawk' from `prep.ai.mit.edu'.  `gawk' was a
version of new `awk' written by David Trueman and Arnold, and available
under the GNU General Public License.

   (Incidentally, it's no longer difficult to find a new `awk'. `gawk'
ships with GNU/Linux, and you can download binaries or source code for
almost any system; my wife uses `gawk' on her VMS box.)

   My Unix system started out unplugged from the wall; it certainly was
not plugged into a network.  So, oblivious to the existence of `gawk'
and the Unix community in general, and desiring a new `awk', I wrote my
own, called `mawk'.  Before I was finished I knew about `gawk', but it
was too late to stop, so I eventually posted to a `comp.sources'
newsgroup.

   A few days after my posting, I got a friendly email from Arnold
introducing himself.   He suggested we share design and algorithms and
attached a draft of the POSIX standard so that I could update `mawk' to
support language extensions added after publication of the AWK book.

   Frankly, if our roles had been reversed, I would not have been so
open and we probably would have never met.  I'm glad we did meet.  He
is an AWK expert's AWK expert and a genuinely nice person.  Arnold
contributes significant amounts of his expertise and time to the Free
Software Foundation.

   This book is the `gawk' reference manual, but at its core it is a
book about AWK programming that will appeal to a wide audience.  It is
a definitive reference to the AWK language as defined by the 1987 Bell
Laboratories release and codified in the 1992 POSIX Utilities standard.

   On the other hand, the novice AWK programmer can study a wealth of
practical programs that emphasize the power of AWK's basic idioms: data
driven control-flow, pattern matching with regular expressions, and
associative arrays.  Those looking for something new can try out
`gawk''s interface to network protocols via special `/inet' files.

   The programs in this book make clear that an AWK program is
typically much smaller and faster to develop than a counterpart written
in C.  Consequently, there is often a payoff to prototype an algorithm
or design in AWK to get it running quickly and expose problems early.
Often, the interpreted performance is adequate and the AWK prototype
becomes the product.

   The new `pgawk' (profiling `gawk'), produces program execution
counts.  I recently experimented with an algorithm that for n lines of
input, exhibited ~ C n^2 performance, while theory predicted ~ C n log n
behavior. A few minutes poring over the `awkprof.out' profile
pinpointed the problem to a single line of code.  `pgawk' is a welcome
addition to my programmer's toolbox.

   Arnold has distilled over a decade of experience writing and using
AWK programs, and developing `gawk', into this book.  If you use AWK or
want to learn how, then read this book.

     Michael Brennan
     Author of `mawk'
     March, 2001


File: gawk.info,  Node: Preface,  Next: Getting Started,  Prev: Foreword,  Up: Top

Preface
*******

Several kinds of tasks occur repeatedly when working with text files.
You might want to extract certain lines and discard the rest.  Or you
may need to make changes wherever certain patterns appear, but leave
the rest of the file alone.  Writing single-use programs for these
tasks in languages such as C, C++, or Java is time-consuming and
inconvenient.  Such jobs are often easier with `awk'.  The `awk'
utility interprets a special-purpose programming language that makes it
easy to handle simple data-reformatting jobs.

   The GNU implementation of `awk' is called `gawk'; it is fully
compatible with the POSIX(1) specification of the `awk' language and
with the Unix version of `awk' maintained by Brian Kernighan.  This
means that all properly written `awk' programs should work with `gawk'.
Thus, we usually don't distinguish between `gawk' and other `awk'
implementations.

   Using `awk' allows you to:

   * Manage small, personal databases

   * Generate reports

   * Validate data

   * Produce indexes and perform other document preparation tasks

   * Experiment with algorithms that you can adapt later to other
     computer languages

   In addition, `gawk' provides facilities that make it easy to:

   * Extract bits and pieces of data for processing

   * Sort data

   * Perform simple network communications

   This Info file teaches you about the `awk' language and how you can
use it effectively.  You should already be familiar with basic system
commands, such as `cat' and `ls',(2) as well as basic shell facilities,
such as input/output (I/O) redirection and pipes.

   Implementations of the `awk' language are available for many
different computing environments.  This Info file, while describing the
`awk' language in general, also describes the particular implementation
of `awk' called `gawk' (which stands for "GNU awk").  `gawk' runs on a
broad range of Unix systems, ranging from Intel(R)-architecture
PC-based computers up through large-scale systems, such as Crays.
`gawk' has also been ported to Mac OS X, Microsoft Windows (all
versions) and OS/2 PCs, and VMS.  (Some other, obsolete systems to
which `gawk' was once ported are no longer supported and the code for
those systems has been removed.)

* Menu:

* History::                     The history of `gawk' and
                                `awk'.
* Names::                       What name to use to find `awk'.
* This Manual::                 Using this Info file. Includes sample
                                input files that you can use.
* Conventions::                 Typographical Conventions.
* Manual History::              Brief history of the GNU project and this
                                Info file.
* How To Contribute::           Helping to save the world.
* Acknowledgments::             Acknowledgments.

   ---------- Footnotes ----------

   (1) The 2008 POSIX standard can be found online at
`http://www.opengroup.org/onlinepubs/9699919799/'.

   (2) These commands are available on POSIX-compliant systems, as well
as on traditional Unix-based systems. If you are using some other
operating system, you still need to be familiar with the ideas of I/O
redirection and pipes.


File: gawk.info,  Node: History,  Next: Names,  Up: Preface

History of `awk' and `gawk'
===========================

                   Recipe For A Programming Language

          1 part  `egrep'   1 part  `snobol'
          2 parts `ed'      3 parts C

     Blend all parts well using `lex' and `yacc'.  Document minimally
     and release.

     After eight years, add another part `egrep' and two more parts C.
     Document very well and release.

   The name `awk' comes from the initials of its designers: Alfred V.
Aho, Peter J. Weinberger and Brian W. Kernighan.  The original version
of `awk' was written in 1977 at AT&T Bell Laboratories.  In 1985, a new
version made the programming language more powerful, introducing
user-defined functions, multiple input streams, and computed regular
expressions.  This new version became widely available with Unix System
V Release 3.1 (1987).  The version in System V Release 4 (1989) added
some new features and cleaned up the behavior in some of the "dark
corners" of the language.  The specification for `awk' in the POSIX
Command Language and Utilities standard further clarified the language.
Both the `gawk' designers and the original Bell Laboratories `awk'
designers provided feedback for the POSIX specification.

   Paul Rubin wrote the GNU implementation, `gawk', in 1986.  Jay
Fenlason completed it, with advice from Richard Stallman.  John Woods
contributed parts of the code as well.  In 1988 and 1989, David
Trueman, with help from me, thoroughly reworked `gawk' for compatibility
with the newer `awk'.  Circa 1994, I became the primary maintainer.
Current development focuses on bug fixes, performance improvements,
standards compliance, and occasionally, new features.

   In May of 1997, Ju"rgen Kahrs felt the need for network access from
`awk', and with a little help from me, set about adding features to do
this for `gawk'.  At that time, he also wrote the bulk of `TCP/IP
Internetworking with `gawk'' (a separate document, available as part of
the `gawk' distribution).  His code finally became part of the main
`gawk' distribution with `gawk' version 3.1.

   John Haque rewrote the `gawk' internals, in the process providing an
`awk'-level debugger. This version became available as `gawk' version
4.0, in 2011.

   *Note Contributors::, for a complete list of those who made
important contributions to `gawk'.


File: gawk.info,  Node: Names,  Next: This Manual,  Prev: History,  Up: Preface

A Rose by Any Other Name
========================

The `awk' language has evolved over the years. Full details are
provided in *note Language History::.  The language described in this
Info file is often referred to as "new `awk'" (`nawk').

   Because of this, there are systems with multiple versions of `awk'.
Some systems have an `awk' utility that implements the original version
of the `awk' language and a `nawk' utility for the new version.  Others
have an `oawk' version for the "old `awk'" language and plain `awk' for
the new one.  Still others only have one version, which is usually the
new one.(1)

   All in all, this makes it difficult for you to know which version of
`awk' you should run when writing your programs.  The best advice we
can give here is to check your local documentation. Look for `awk',
`oawk', and `nawk', as well as for `gawk'.  It is likely that you
already have some version of new `awk' on your system, which is what
you should use when running your programs.  (Of course, if you're
reading this Info file, chances are good that you have `gawk'!)

   Throughout this Info file, whenever we refer to a language feature
that should be available in any complete implementation of POSIX `awk',
we simply use the term `awk'.  When referring to a feature that is
specific to the GNU implementation, we use the term `gawk'.

   ---------- Footnotes ----------

   (1) Often, these systems use `gawk' for their `awk' implementation!


File: gawk.info,  Node: This Manual,  Next: Conventions,  Prev: Names,  Up: Preface

Using This Book
===============

The term `awk' refers to a particular program as well as to the
language you use to tell this program what to do.  When we need to be
careful, we call the language "the `awk' language," and the program
"the `awk' utility."  This Info file explains both how to write
programs in the `awk' language and how to run the `awk' utility.  The
term "`awk' program" refers to a program written by you in the `awk'
programming language.

   Primarily, this Info file explains the features of `awk' as defined
in the POSIX standard.  It does so in the context of the `gawk'
implementation.  While doing so, it also attempts to describe important
differences between `gawk' and other `awk' implementations.(1) Finally,
any `gawk' features that are not in the POSIX standard for `awk' are
noted.

   There are subsections labeled as *Advanced Notes* scattered
throughout the Info file.  They add a more complete explanation of
points that are relevant, but not likely to be of interest on first
reading.  All appear in the index, under the heading "advanced
features."

   Most of the time, the examples use complete `awk' programs.  Some of
the more advanced sections show only the part of the `awk' program that
illustrates the concept currently being described.

   While this Info file is aimed principally at people who have not been
exposed to `awk', there is a lot of information here that even the `awk'
expert should find useful.  In particular, the description of POSIX
`awk' and the example programs in *note Library Functions::, and in
*note Sample Programs::, should be of interest.

   *note Getting Started::, provides the essentials you need to know to
begin using `awk'.

   *note Invoking Gawk::, describes how to run `gawk', the meaning of
its command-line options, and how it finds `awk' program source files.

   *note Regexp::, introduces regular expressions in general, and in
particular the flavors supported by POSIX `awk' and `gawk'.

   *note Reading Files::, describes how `awk' reads your data.  It
introduces the concepts of records and fields, as well as the `getline'
command.  I/O redirection is first described here.  Network I/O is also
briefly introduced here.

   *note Printing::, describes how `awk' programs can produce output
with `print' and `printf'.

   *note Expressions::, describes expressions, which are the basic
building blocks for getting most things done in a program.

   *note Patterns and Actions::, describes how to write patterns for
matching records, actions for doing something when a record is matched,
and the built-in variables `awk' and `gawk' use.

   *note Arrays::, covers `awk''s one-and-only data structure:
associative arrays.  Deleting array elements and whole arrays is also
described, as well as sorting arrays in `gawk'.  It also describes how
`gawk' provides arrays of arrays.

   *note Functions::, describes the built-in functions `awk' and `gawk'
provide, as well as how to define your own functions.

   *note Internationalization::, describes special features in `gawk'
for translating program messages into different languages at runtime.

   *note Advanced Features::, describes a number of `gawk'-specific
advanced features.  Of particular note are the abilities to have
two-way communications with another process, perform TCP/IP networking,
and profile your `awk' programs.

   *note Library Functions::, and *note Sample Programs::, provide many
sample `awk' programs.  Reading them allows you to see `awk' solving
real problems.

   *note Debugger::, describes the `awk' debugger, `dgawk'.

   *note Language History::, describes how the `awk' language has
evolved since its first release to present.  It also describes how
`gawk' has acquired features over time.

   *note Installation::, describes how to get `gawk', how to compile it
on POSIX-compatible systems, and how to compile and use it on different
non-POSIX systems.  It also describes how to report bugs in `gawk' and
where to get other freely available `awk' implementations.

   *note Notes::, describes how to disable `gawk''s extensions, as well
as how to contribute new code to `gawk', how to write extension
libraries, and some possible future directions for `gawk' development.

   *note Basic Concepts::, provides some very cursory background
material for those who are completely unfamiliar with computer
programming.  Also centralized there is a discussion of some of the
issues surrounding floating-point numbers.

   The *note Glossary::, defines most, if not all, the significant
terms used throughout the book.  If you find terms that you aren't
familiar with, try looking them up here.

   *note Copying::, and *note GNU Free Documentation License::, present
the licenses that cover the `gawk' source code and this Info file,
respectively.

   ---------- Footnotes ----------

   (1) All such differences appear in the index under the entry
"differences in `awk' and `gawk'."


File: gawk.info,  Node: Conventions,  Next: Manual History,  Prev: This Manual,  Up: Preface

Typographical Conventions
=========================

This Info file is written in Texinfo (http://texinfo.org), the GNU
documentation formatting language.  A single Texinfo source file is
used to produce both the printed and online versions of the
documentation.  This minor node briefly documents the typographical
conventions used in Texinfo.

   Examples you would type at the command-line are preceded by the
common shell primary and secondary prompts, `$' and `>'.  Input that
you type is shown `like this'.  Output from the command is preceded by
the glyph "-|".  This typically represents the command's standard
output.  Error messages, and other output on the command's standard
error, are preceded by the glyph "error-->".  For example:

     $ echo hi on stdout
     -| hi on stdout
     $ echo hello on stderr 1>&2
     error--> hello on stderr

   Characters that you type at the keyboard look `like this'.  In
particular, there are special characters called "control characters."
These are characters that you type by holding down both the `CONTROL'
key and another key, at the same time.  For example, a `Ctrl-d' is typed
by first pressing and holding the `CONTROL' key, next pressing the `d'
key and finally releasing both keys.

Dark Corners
............

     Dark corners are basically fractal -- no matter how much you
     illuminate, there's always a smaller but darker one.
     Brian Kernighan

   Until the POSIX standard (and `GAWK: Effective AWK Programming'),
many features of `awk' were either poorly documented or not documented
at all.  Descriptions of such features (often called "dark corners")
are noted in this Info file with "(d.c.)".  They also appear in the
index under the heading "dark corner."

   As noted by the opening quote, though, any coverage of dark corners
is, by definition, incomplete.

   Extensions to the standard `awk' language that are supported by more
than one `awk' implementation are marked "(c.e.)," and listed in the
index under "common extensions" and "extensions, common."


File: gawk.info,  Node: Manual History,  Next: How To Contribute,  Prev: Conventions,  Up: Preface

The GNU Project and This Book
=============================

The Free Software Foundation (FSF) is a nonprofit organization dedicated
to the production and distribution of freely distributable software.
It was founded by Richard M. Stallman, the author of the original Emacs
editor.  GNU Emacs is the most widely used version of Emacs today.

   The GNU(1) Project is an ongoing effort on the part of the Free
Software Foundation to create a complete, freely distributable,
POSIX-compliant computing environment.  The FSF uses the "GNU General
Public License" (GPL) to ensure that their software's source code is
always available to the end user. A copy of the GPL is included for
your reference (*note Copying::).  The GPL applies to the C language
source code for `gawk'.  To find out more about the FSF and the GNU
Project online, see the GNU Project's home page (http://www.gnu.org).
This Info file may also be read from their web site
(http://www.gnu.org/software/gawk/manual/).

   A shell, an editor (Emacs), highly portable optimizing C, C++, and
Objective-C compilers, a symbolic debugger and dozens of large and
small utilities (such as `gawk'), have all been completed and are
freely available.  The GNU operating system kernel (the HURD), has been
released but remains in an early stage of development.

   Until the GNU operating system is more fully developed, you should
consider using GNU/Linux, a freely distributable, Unix-like operating
system for Intel(R), Power Architecture, Sun SPARC, IBM S/390, and other
systems.(2) Many GNU/Linux distributions are available for download
from the Internet.

   (There are numerous other freely available, Unix-like operating
systems based on the Berkeley Software Distribution, and some of them
use recent versions of `gawk' for their versions of `awk'.  NetBSD
(http://www.netbsd.org), FreeBSD (http://www.freebsd.org), and OpenBSD
(http://www.openbsd.org) are three of the most popular ones, but there
are others.)

   The Info file itself has gone through a number of previous editions.
Paul Rubin wrote the very first draft of `The GAWK Manual'; it was
around 40 pages in size.  Diane Close and Richard Stallman improved it,
yielding a version that was around 90 pages long and barely described
the original, "old" version of `awk'.

   I started working with that version in the fall of 1988.  As work on
it progressed, the FSF published several preliminary versions (numbered
0.X).  In 1996, Edition 1.0 was released with `gawk' 3.0.0.  The FSF
published the first two editions under the title `The GNU Awk User's
Guide'.

   This edition maintains the basic structure of the previous editions.
For Edition 4.0, the content has been thoroughly reviewed and updated.
All references to versions prior to 4.0 have been removed.  Of
significant note for this edition is *note Debugger::.

   `GAWK: Effective AWK Programming' will undoubtedly continue to
evolve.  An electronic version comes with the `gawk' distribution from
the FSF.  If you find an error in this Info file, please report it!
*Note Bugs::, for information on submitting problem reports
electronically.

   ---------- Footnotes ----------

   (1) GNU stands for "GNU's not Unix."

   (2) The terminology "GNU/Linux" is explained in the *note Glossary::.


File: gawk.info,  Node: How To Contribute,  Next: Acknowledgments,  Prev: Manual History,  Up: Preface

How to Contribute
=================

As the maintainer of GNU `awk', I once thought that I would be able to
manage a collection of publicly available `awk' programs and I even
solicited contributions.  Making things available on the Internet helps
keep the `gawk' distribution down to manageable size.

   The initial collection of material, such as it is, is still available
at `ftp://ftp.freefriends.org/arnold/Awkstuff'.  In the hopes of doing
something more broad, I acquired the `awk.info' domain.

   However, I found that I could not dedicate enough time to managing
contributed code: the archive did not grow and the domain went unused
for several years.

   Fortunately, late in 2008, a volunteer took on the task of setting up
an `awk'-related web site--`http://awk.info'--and did a very nice job.

   If you have written an interesting `awk' program, or have written a
`gawk' extension that you would like to share with the rest of the
world, please see `http://awk.info/?contribute' for how to contribute
it to the web site.


File: gawk.info,  Node: Acknowledgments,  Prev: How To Contribute,  Up: Preface

Acknowledgments
===============

The initial draft of `The GAWK Manual' had the following
acknowledgments:

     Many people need to be thanked for their assistance in producing
     this manual.  Jay Fenlason contributed many ideas and sample
     programs.  Richard Mlynarik and Robert Chassell gave helpful
     comments on drafts of this manual.  The paper `A Supplemental
     Document for `awk'' by John W.  Pierce of the Chemistry Department
     at UC San Diego, pinpointed several issues relevant both to `awk'
     implementation and to this manual, that would otherwise have
     escaped us.

   I would like to acknowledge Richard M. Stallman, for his vision of a
better world and for his courage in founding the FSF and starting the
GNU Project.

   Earlier editions of this Info file had the following
acknowledgements:

     The following people (in alphabetical order) provided helpful
     comments on various versions of this book, Rick Adams, Dr. Nelson
     H.F. Beebe, Karl Berry, Dr. Michael Brennan, Rich Burridge, Claire
     Cloutier, Diane Close, Scott Deifik, Christopher ("Topher") Eliot,
     Jeffrey Friedl, Dr. Darrel Hankerson, Michal Jaegermann, Dr.
     Richard J. LeBlanc, Michael Lijewski, Pat Rankin, Miriam Robbins,
     Mary Sheehan, and Chuck Toporek.

     Robert J. Chassell provided much valuable advice on the use of
     Texinfo.  He also deserves special thanks for convincing me _not_
     to title this Info file `How To Gawk Politely'.  Karl Berry helped
     significantly with the TeX part of Texinfo.

     I would like to thank Marshall and Elaine Hartholz of Seattle and
     Dr. Bert and Rita Schreiber of Detroit for large amounts of quiet
     vacation time in their homes, which allowed me to make significant
     progress on this Info file and on `gawk' itself.

     Phil Hughes of SSC contributed in a very important way by loaning
     me his laptop GNU/Linux system, not once, but twice, which allowed
     me to do a lot of work while away from home.

     David Trueman deserves special credit; he has done a yeoman job of
     evolving `gawk' so that it performs well and without bugs.
     Although he is no longer involved with `gawk', working with him on
     this project was a significant pleasure.

     The intrepid members of the GNITS mailing list, and most notably
     Ulrich Drepper, provided invaluable help and feedback for the
     design of the internationalization features.

     Chuck Toporek, Mary Sheehan, and Claire Coutier of O'Reilly &
     Associates contributed significant editorial help for this Info
     file for the 3.1 release of `gawk'.

   Dr. Nelson Beebe, Andreas Buening, Antonio Colombo, Stephen Davies,
Scott Deifik, John H. DuBois III, Darrel Hankerson, Michal Jaegermann,
Ju"rgen Kahrs, Dave Pitts, Stepan Kasal, Pat Rankin, Andrew Schorr,
Corinna Vinschen, Anders Wallin, and Eli Zaretskii (in alphabetical
order) make up the current `gawk' "crack portability team."  Without
their hard work and help, `gawk' would not be nearly the fine program
it is today.  It has been and continues to be a pleasure working with
this team of fine people.

   John Haque contributed the modifications to convert `gawk' into a
byte-code interpreter, including the debugger. Stephen Davies
contributed to the effort to bring the byte-code changes into the
mainstream code base.  Efraim Yawitz contributed the initial text of
*note Debugger::.

   I would like to thank Brian Kernighan for invaluable assistance
during the testing and debugging of `gawk', and for ongoing help and
advice in clarifying numerous points about the language.   We could not
have done nearly as good a job on either `gawk' or its documentation
without his help.

   I must thank my wonderful wife, Miriam, for her patience through the
many versions of this project, for her proofreading, and for sharing me
with the computer.  I would like to thank my parents for their love,
and for the grace with which they raised and educated me.  Finally, I
also must acknowledge my gratitude to G-d, for the many opportunities
He has sent my way, as well as for the gifts He has given me with which
to take advantage of those opportunities.


Arnold Robbins
Nof Ayalon
ISRAEL
March, 2011


File: gawk.info,  Node: Getting Started,  Next: Invoking Gawk,  Prev: Preface,  Up: Top

1 Getting Started with `awk'
****************************

The basic function of `awk' is to search files for lines (or other
units of text) that contain certain patterns.  When a line matches one
of the patterns, `awk' performs specified actions on that line.  `awk'
keeps processing input lines in this way until it reaches the end of
the input files.

   Programs in `awk' are different from programs in most other
languages, because `awk' programs are "data-driven"; that is, you
describe the data you want to work with and then what to do when you
find it.  Most other languages are "procedural"; you have to describe,
in great detail, every step the program is to take.  When working with
procedural languages, it is usually much harder to clearly describe the
data your program will process.  For this reason, `awk' programs are
often refreshingly easy to read and write.

   When you run `awk', you specify an `awk' "program" that tells `awk'
what to do.  The program consists of a series of "rules".  (It may also
contain "function definitions", an advanced feature that we will ignore
for now.  *Note User-defined::.)  Each rule specifies one pattern to
search for and one action to perform upon finding the pattern.

   Syntactically, a rule consists of a pattern followed by an action.
The action is enclosed in curly braces to separate it from the pattern.
Newlines usually separate rules.  Therefore, an `awk' program looks
like this:

     PATTERN { ACTION }
     PATTERN { ACTION }
     ...

* Menu:

* Running gawk::                How to run `gawk' programs; includes
                                command-line syntax.
* Sample Data Files::           Sample data files for use in the `awk'
                                programs illustrated in this Info file.
* Very Simple::                 A very simple example.
* Two Rules::                   A less simple one-line example using two
                                rules.
* More Complex::                A more complex example.
* Statements/Lines::            Subdividing or combining statements into
                                lines.
* Other Features::              Other Features of `awk'.
* When::                        When to use `gawk' and when to use
                                other things.


File: gawk.info,  Node: Running gawk,  Next: Sample Data Files,  Up: Getting Started

1.1 How to Run `awk' Programs
=============================

There are several ways to run an `awk' program.  If the program is
short, it is easiest to include it in the command that runs `awk', like
this:

     awk 'PROGRAM' INPUT-FILE1 INPUT-FILE2 ...

   When the program is long, it is usually more convenient to put it in
a file and run it with a command like this:

     awk -f PROGRAM-FILE INPUT-FILE1 INPUT-FILE2 ...

   This minor node discusses both mechanisms, along with several
variations of each.

* Menu:

* One-shot::                    Running a short throwaway `awk'
                                program.
* Read Terminal::               Using no input files (input from terminal
                                instead).
* Long::                        Putting permanent `awk' programs in
                                files.
* Executable Scripts::          Making self-contained `awk' programs.
* Comments::                    Adding documentation to `gawk'
                                programs.
* Quoting::                     More discussion of shell quoting issues.


File: gawk.info,  Node: One-shot,  Next: Read Terminal,  Up: Running gawk

1.1.1 One-Shot Throwaway `awk' Programs
---------------------------------------

Once you are familiar with `awk', you will often type in simple
programs the moment you want to use them.  Then you can write the
program as the first argument of the `awk' command, like this:

     awk 'PROGRAM' INPUT-FILE1 INPUT-FILE2 ...

where PROGRAM consists of a series of PATTERNS and ACTIONS, as
described earlier.

   This command format instructs the "shell", or command interpreter,
to start `awk' and use the PROGRAM to process records in the input
file(s).  There are single quotes around PROGRAM so the shell won't
interpret any `awk' characters as special shell characters.  The quotes
also cause the shell to treat all of PROGRAM as a single argument for
`awk', and allow PROGRAM to be more than one line long.

   This format is also useful for running short or medium-sized `awk'
programs from shell scripts, because it avoids the need for a separate
file for the `awk' program.  A self-contained shell script is more
reliable because there are no other files to misplace.

   *note Very Simple::, presents several short, self-contained programs.


File: gawk.info,  Node: Read Terminal,  Next: Long,  Prev: One-shot,  Up: Running gawk

1.1.2 Running `awk' Without Input Files
---------------------------------------

You can also run `awk' without any input files.  If you type the
following command line:

     awk 'PROGRAM'

`awk' applies the PROGRAM to the "standard input", which usually means
whatever you type on the terminal.  This continues until you indicate
end-of-file by typing `Ctrl-d'.  (On other operating systems, the
end-of-file character may be different.  For example, on OS/2, it is
`Ctrl-z'.)

   As an example, the following program prints a friendly piece of
advice (from Douglas Adams's `The Hitchhiker's Guide to the Galaxy'),
to keep you from worrying about the complexities of computer
programming(1) (`BEGIN' is a feature we haven't discussed yet):

     $ awk "BEGIN { print \"Don't Panic!\" }"
     -| Don't Panic!

   This program does not read any input.  The `\' before each of the
inner double quotes is necessary because of the shell's quoting
rules--in particular because it mixes both single quotes and double
quotes.(2)

   This next simple `awk' program emulates the `cat' utility; it copies
whatever you type on the keyboard to its standard output (why this
works is explained shortly).

     $ awk '{ print }'
     Now is the time for all good men
     -| Now is the time for all good men
     to come to the aid of their country.
     -| to come to the aid of their country.
     Four score and seven years ago, ...
     -| Four score and seven years ago, ...
     What, me worry?
     -| What, me worry?
     Ctrl-d

   ---------- Footnotes ----------

   (1) If you use Bash as your shell, you should execute the command
`set +H' before running this program interactively, to disable the C
shell-style command history, which treats `!' as a special character.
We recommend putting this command into your personal startup file.

   (2) Although we generally recommend the use of single quotes around
the program text, double quotes are needed here in order to put the
single quote into the message.


File: gawk.info,  Node: Long,  Next: Executable Scripts,  Prev: Read Terminal,  Up: Running gawk

1.1.3 Running Long Programs
---------------------------

Sometimes your `awk' programs can be very long.  In this case, it is
more convenient to put the program into a separate file.  In order to
tell `awk' to use that file for its program, you type:

     awk -f SOURCE-FILE INPUT-FILE1 INPUT-FILE2 ...

   The `-f' instructs the `awk' utility to get the `awk' program from
the file SOURCE-FILE.  Any file name can be used for SOURCE-FILE.  For
example, you could put the program:

     BEGIN { print "Don't Panic!" }

into the file `advice'.  Then this command:

     awk -f advice

does the same thing as this one:

     awk "BEGIN { print \"Don't Panic!\" }"

This was explained earlier (*note Read Terminal::).  Note that you
don't usually need single quotes around the file name that you specify
with `-f', because most file names don't contain any of the shell's
special characters.  Notice that in `advice', the `awk' program did not
have single quotes around it.  The quotes are only needed for programs
that are provided on the `awk' command line.

   If you want to clearly identify your `awk' program files as such,
you can add the extension `.awk' to the file name.  This doesn't affect
the execution of the `awk' program but it does make "housekeeping"
easier.


File: gawk.info,  Node: Executable Scripts,  Next: Comments,  Prev: Long,  Up: Running gawk

1.1.4 Executable `awk' Programs
-------------------------------

Once you have learned `awk', you may want to write self-contained `awk'
scripts, using the `#!' script mechanism.  You can do this on many
systems.(1) For example, you could update the file `advice' to look
like this:

     #! /bin/awk -f

     BEGIN { print "Don't Panic!" }

After making this file executable (with the `chmod' utility), simply
type `advice' at the shell and the system arranges to run `awk'(2) as
if you had typed `awk -f advice':

     $ chmod +x advice
     $ advice
     -| Don't Panic!

(We assume you have the current directory in your shell's search path
variable [typically `$PATH'].  If not, you may need to type `./advice'
at the shell.)

   Self-contained `awk' scripts are useful when you want to write a
program that users can invoke without their having to know that the
program is written in `awk'.

Advanced Notes: Portability Issues with `#!'
--------------------------------------------

Some systems limit the length of the interpreter name to 32 characters.
Often, this can be dealt with by using a symbolic link.

   You should not put more than one argument on the `#!' line after the
path to `awk'. It does not work. The operating system treats the rest
of the line as a single argument and passes it to `awk'.  Doing this
leads to confusing behavior--most likely a usage diagnostic of some
sort from `awk'.

   Finally, the value of `ARGV[0]' (*note Built-in Variables::) varies
depending upon your operating system.  Some systems put `awk' there,
some put the full pathname of `awk' (such as `/bin/awk'), and some put
the name of your script (`advice').  (d.c.)  Don't rely on the value of
`ARGV[0]' to provide your script name.

   ---------- Footnotes ----------

   (1) The `#!' mechanism works on GNU/Linux systems, BSD-based systems
and commercial Unix systems.

   (2) The line beginning with `#!' lists the full file name of an
interpreter to run and an optional initial command-line argument to
pass to that interpreter.  The operating system then runs the
interpreter with the given argument and the full argument list of the
executed program.  The first argument in the list is the full file name
of the `awk' program.  The rest of the argument list contains either
options to `awk', or data files, or both.


File: gawk.info,  Node: Comments,  Next: Quoting,  Prev: Executable Scripts,  Up: Running gawk

1.1.5 Comments in `awk' Programs
--------------------------------

A "comment" is some text that is included in a program for the sake of
human readers; it is not really an executable part of the program.
Comments can explain what the program does and how it works.  Nearly all
programming languages have provisions for comments, as programs are
typically hard to understand without them.

   In the `awk' language, a comment starts with the sharp sign
character (`#') and continues to the end of the line.  The `#' does not
have to be the first character on the line. The `awk' language ignores
the rest of a line following a sharp sign.  For example, we could have
put the following into `advice':

     # This program prints a nice friendly message.  It helps
     # keep novice users from being afraid of the computer.
     BEGIN    { print "Don't Panic!" }

   You can put comment lines into keyboard-composed throwaway `awk'
programs, but this usually isn't very useful; the purpose of a comment
is to help you or another person understand the program when reading it
at a later time.

     CAUTION: As mentioned in *note One-shot::, you can enclose small
     to medium programs in single quotes, in order to keep your shell
     scripts self-contained.  When doing so, _don't_ put an apostrophe
     (i.e., a single quote) into a comment (or anywhere else in your
     program). The shell interprets the quote as the closing quote for
     the entire program. As a result, usually the shell prints a
     message about mismatched quotes, and if `awk' actually runs, it
     will probably print strange messages about syntax errors.  For
     example, look at the following:

          $ awk '{ print "hello" } # let's be cute'
          >

     The shell sees that the first two quotes match, and that a new
     quoted object begins at the end of the command line.  It therefore
     prompts with the secondary prompt, waiting for more input.  With
     Unix `awk', closing the quoted string produces this result:

          $ awk '{ print "hello" } # let's be cute'
          > '
          error--> awk: can't open file be
          error-->  source line number 1

     Putting a backslash before the single quote in `let's' wouldn't
     help, since backslashes are not special inside single quotes.  The
     next node describes the shell's quoting rules.


File: gawk.info,  Node: Quoting,  Prev: Comments,  Up: Running gawk

1.1.6 Shell-Quoting Issues
--------------------------

* Menu:

* DOS Quoting::                 Quoting in Windows Batch Files.

   For short to medium length `awk' programs, it is most convenient to
enter the program on the `awk' command line.  This is best done by
enclosing the entire program in single quotes.  This is true whether
you are entering the program interactively at the shell prompt, or
writing it as part of a larger shell script:

     awk 'PROGRAM TEXT' INPUT-FILE1 INPUT-FILE2 ...

   Once you are working with the shell, it is helpful to have a basic
knowledge of shell quoting rules.  The following rules apply only to
POSIX-compliant, Bourne-style shells (such as Bash, the GNU Bourne-Again
Shell).  If you use the C shell, you're on your own.

   * Quoted items can be concatenated with nonquoted items as well as
     with other quoted items.  The shell turns everything into one
     argument for the command.

   * Preceding any single character with a backslash (`\') quotes that
     character.  The shell removes the backslash and passes the quoted
     character on to the command.

   * Single quotes protect everything between the opening and closing
     quotes.  The shell does no interpretation of the quoted text,
     passing it on verbatim to the command.  It is _impossible_ to
     embed a single quote inside single-quoted text.  Refer back to
     *note Comments::, for an example of what happens if you try.

   * Double quotes protect most things between the opening and closing
     quotes.  The shell does at least variable and command substitution
     on the quoted text.  Different shells may do additional kinds of
     processing on double-quoted text.

     Since certain characters within double-quoted text are processed
     by the shell, they must be "escaped" within the text.  Of note are
     the characters `$', ``', `\', and `"', all of which must be
     preceded by a backslash within double-quoted text if they are to
     be passed on literally to the program.  (The leading backslash is
     stripped first.)  Thus, the example seen in *note Read Terminal::,
     is applicable:

          $ awk "BEGIN { print \"Don't Panic!\" }"
          -| Don't Panic!

     Note that the single quote is not special within double quotes.

   * Null strings are removed when they occur as part of a non-null
     command-line argument, while explicit non-null objects are kept.
     For example, to specify that the field separator `FS' should be
     set to the null string, use:

          awk -F "" 'PROGRAM' FILES # correct

     Don't use this:

          awk -F"" 'PROGRAM' FILES  # wrong!

     In the second case, `awk' will attempt to use the text of the
     program as the value of `FS', and the first file name as the text
     of the program!  This results in syntax errors at best, and
     confusing behavior at worst.

   Mixing single and double quotes is difficult.  You have to resort to
shell quoting tricks, like this:

     $ awk 'BEGIN { print "Here is a single quote <'"'"'>" }'
     -| Here is a single quote <'>

This program consists of three concatenated quoted strings.  The first
and the third are single-quoted, the second is double-quoted.

   This can be "simplified" to:

     $ awk 'BEGIN { print "Here is a single quote <'\''>" }'
     -| Here is a single quote <'>

Judge for yourself which of these two is the more readable.

   Another option is to use double quotes, escaping the embedded,
`awk'-level double quotes:

     $ awk "BEGIN { print \"Here is a single quote <'>\" }"
     -| Here is a single quote <'>

This option is also painful, because double quotes, backslashes, and
dollar signs are very common in more advanced `awk' programs.

   A third option is to use the octal escape sequence equivalents
(*note Escape Sequences::) for the single- and double-quote characters,
like so:

     $ awk 'BEGIN { print "Here is a single quote <\47>" }'
     -| Here is a single quote <'>
     $ awk 'BEGIN { print "Here is a double quote <\42>" }'
     -| Here is a double quote <">

This works nicely, except that you should comment clearly what the
escapes mean.

   A fourth option is to use command-line variable assignment, like
this:

     $ awk -v sq="'" 'BEGIN { print "Here is a single quote <" sq ">" }'
     -| Here is a single quote <'>

   If you really need both single and double quotes in your `awk'
program, it is probably best to move it into a separate file, where the
shell won't be part of the picture, and you can say what you mean.


File: gawk.info,  Node: DOS Quoting,  Up: Quoting

1.1.6.1 Quoting in MS-Windows Batch Files
.........................................

Although this Info file generally only worries about POSIX systems and
the POSIX shell, the following issue arises often enough for many users
that it is worth addressing.

   The "shells" on Microsoft Windows systems use the double-quote
character for quoting, and make it difficult or impossible to include an
escaped double-quote character in a command-line script.  The following
example, courtesy of Jeroen Brink, shows how to print all lines in a
file surrounded by double quotes:

     gawk "{ print \"\042\" $0 \"\042\" }" FILE


File: gawk.info,  Node: Sample Data Files,  Next: Very Simple,  Prev: Running gawk,  Up: Getting Started

1.2 Data Files for the Examples
===============================

Many of the examples in this Info file take their input from two sample
data files.  The first, `BBS-list', represents a list of computer
bulletin board systems together with information about those systems.
The second data file, called `inventory-shipped', contains information
about monthly shipments.  In both files, each line is considered to be
one "record".

   In the data file `BBS-list', each record contains the name of a
computer bulletin board, its phone number, the board's baud rate(s),
and a code for the number of hours it is operational.  An `A' in the
last column means the board operates 24 hours a day.  A `B' in the last
column means the board only operates on evening and weekend hours.  A
`C' means the board operates only on weekends:

     aardvark     555-5553     1200/300          B
     alpo-net     555-3412     2400/1200/300     A
     barfly       555-7685     1200/300          A
     bites        555-1675     2400/1200/300     A
     camelot      555-0542     300               C
     core         555-2912     1200/300          C
     fooey        555-1234     2400/1200/300     B
     foot         555-6699     1200/300          B
     macfoo       555-6480     1200/300          A
     sdace        555-3430     2400/1200/300     A
     sabafoo      555-2127     1200/300          C

   The data file `inventory-shipped' represents information about
shipments during the year.  Each record contains the month, the number
of green crates shipped, the number of red boxes shipped, the number of
orange bags shipped, and the number of blue packages shipped,
respectively.  There are 16 entries, covering the 12 months of last year
and the first four months of the current year.

     Jan  13  25  15 115
     Feb  15  32  24 226
     Mar  15  24  34 228
     Apr  31  52  63 420
     May  16  34  29 208
     Jun  31  42  75 492
     Jul  24  34  67 436
     Aug  15  34  47 316
     Sep  13  55  37 277
     Oct  29  54  68 525
     Nov  20  87  82 577
     Dec  17  35  61 401

     Jan  21  36  64 620
     Feb  26  58  80 652
     Mar  24  75  70 495
     Apr  21  70  74 514

   If you are reading this in GNU Emacs using Info, you can copy the
regions of text showing these sample files into your own test files.
This way you can try out the examples shown in the remainder of this
document.  You do this by using the command `M-x write-region' to copy
text from the Info file into a file for use with `awk' (*Note
Miscellaneous File Operations: (emacs)Misc File Ops, for more
information).  Using this information, create your own `BBS-list' and
`inventory-shipped' files and practice what you learn in this Info file.

   If you are using the stand-alone version of Info, see *note Extract
Program::, for an `awk' program that extracts these data files from
`gawk.texi', the Texinfo source file for this Info file.


File: gawk.info,  Node: Very Simple,  Next: Two Rules,  Prev: Sample Data Files,  Up: Getting Started

1.3 Some Simple Examples
========================

The following command runs a simple `awk' program that searches the
input file `BBS-list' for the character string `foo' (a grouping of
characters is usually called a "string"; the term "string" is based on
similar usage in English, such as "a string of pearls," or "a string of
cars in a train"):

     awk '/foo/ { print $0 }' BBS-list

When lines containing `foo' are found, they are printed because
`print $0' means print the current line.  (Just `print' by itself means
the same thing, so we could have written that instead.)

   You will notice that slashes (`/') surround the string `foo' in the
`awk' program.  The slashes indicate that `foo' is the pattern to
search for.  This type of pattern is called a "regular expression",
which is covered in more detail later (*note Regexp::).  The pattern is
allowed to match parts of words.  There are single quotes around the
`awk' program so that the shell won't interpret any of it as special
shell characters.

   Here is what this program prints:

     $ awk '/foo/ { print $0 }' BBS-list
     -| fooey        555-1234     2400/1200/300     B
     -| foot         555-6699     1200/300          B
     -| macfoo       555-6480     1200/300          A
     -| sabafoo      555-2127     1200/300          C

   In an `awk' rule, either the pattern or the action can be omitted,
but not both.  If the pattern is omitted, then the action is performed
for _every_ input line.  If the action is omitted, the default action
is to print all lines that match the pattern.

   Thus, we could leave out the action (the `print' statement and the
curly braces) in the previous example and the result would be the same:
`awk' prints all lines matching the pattern `foo'.  By comparison,
omitting the `print' statement but retaining the curly braces makes an
empty action that does nothing (i.e., no lines are printed).

   Many practical `awk' programs are just a line or two.  Following is a
collection of useful, short programs to get you started.  Some of these
programs contain constructs that haven't been covered yet. (The
description of the program will give you a good idea of what is going
on, but please read the rest of the Info file to become an `awk'
expert!)  Most of the examples use a data file named `data'.  This is
just a placeholder; if you use these programs yourself, substitute your
own file names for `data'.  For future reference, note that there is
often more than one way to do things in `awk'.  At some point, you may
want to look back at these examples and see if you can come up with
different ways to do the same things shown here:

   * Print the length of the longest input line:

          awk '{ if (length($0) > max) max = length($0) }
               END { print max }' data

   * Print every line that is longer than 80 characters:

          awk 'length($0) > 80' data

     The sole rule has a relational expression as its pattern and it
     has no action--so the default action, printing the record, is used.

   * Print the length of the longest line in `data':

          expand data | awk '{ if (x < length()) x = length() }
                        END { print "maximum line length is " x }'

     The input is processed by the `expand' utility to change TABs into
     spaces, so the widths compared are actually the right-margin
     columns.

   * Print every line that has at least one field:

          awk 'NF > 0' data

     This is an easy way to delete blank lines from a file (or rather,
     to create a new file similar to the old file but from which the
     blank lines have been removed).

   * Print seven random numbers from 0 to 100, inclusive:

          awk 'BEGIN { for (i = 1; i <= 7; i++)
                           print int(101 * rand()) }'

   * Print the total number of bytes used by FILES:

          ls -l FILES | awk '{ x += $5 }
                            END { print "total bytes: " x }'

   * Print the total number of kilobytes used by FILES:

          ls -l FILES | awk '{ x += $5 }
             END { print "total K-bytes:", x / 1024 }'

   * Print a sorted list of the login names of all users:

          awk -F: '{ print $1 }' /etc/passwd | sort

   * Count the lines in a file:

          awk 'END { print NR }' data

   * Print the even-numbered lines in the data file:

          awk 'NR % 2 == 0' data

     If you use the expression `NR % 2 == 1' instead, the program would
     print the odd-numbered lines.


File: gawk.info,  Node: Two Rules,  Next: More Complex,  Prev: Very Simple,  Up: Getting Started

1.4 An Example with Two Rules
=============================

The `awk' utility reads the input files one line at a time.  For each
line, `awk' tries the patterns of each of the rules.  If several
patterns match, then several actions are run in the order in which they
appear in the `awk' program.  If no patterns match, then no actions are
run.

   After processing all the rules that match the line (and perhaps
there are none), `awk' reads the next line.  (However, *note Next
Statement::, and also *note Nextfile Statement::).  This continues
until the program reaches the end of the file.  For example, the
following `awk' program contains two rules:

     /12/  { print $0 }
     /21/  { print $0 }

The first rule has the string `12' as the pattern and `print $0' as the
action.  The second rule has the string `21' as the pattern and also
has `print $0' as the action.  Each rule's action is enclosed in its
own pair of braces.

   This program prints every line that contains the string `12' _or_
the string `21'.  If a line contains both strings, it is printed twice,
once by each rule.

   This is what happens if we run this program on our two sample data
files, `BBS-list' and `inventory-shipped':

     $ awk '/12/ { print $0 }
     >      /21/ { print $0 }' BBS-list inventory-shipped
     -| aardvark     555-5553     1200/300          B
     -| alpo-net     555-3412     2400/1200/300     A
     -| barfly       555-7685     1200/300          A
     -| bites        555-1675     2400/1200/300     A
     -| core         555-2912     1200/300          C
     -| fooey        555-1234     2400/1200/300     B
     -| foot         555-6699     1200/300          B
     -| macfoo       555-6480     1200/300          A
     -| sdace        555-3430     2400/1200/300     A
     -| sabafoo      555-2127     1200/300          C
     -| sabafoo      555-2127     1200/300          C
     -| Jan  21  36  64 620
     -| Apr  21  70  74 514

Note how the line beginning with `sabafoo' in `BBS-list' was printed
twice, once for each rule.


File: gawk.info,  Node: More Complex,  Next: Statements/Lines,  Prev: Two Rules,  Up: Getting Started

1.5 A More Complex Example
==========================

Now that we've mastered some simple tasks, let's look at what typical
`awk' programs do.  This example shows how `awk' can be used to
summarize, select, and rearrange the output of another utility.  It uses
features that haven't been covered yet, so don't worry if you don't
understand all the details:

     LC_ALL=C ls -l | awk '$6 == "Nov" { sum += $5 }
                           END { print sum }'

   This command prints the total number of bytes in all the files in the
current directory that were last modified in November (of any year).
The `ls -l' part of this example is a system command that gives you a
listing of the files in a directory, including each file's size and the
date the file was last modified. Its output looks like this:

     -rw-r--r--  1 arnold   user   1933 Nov  7 13:05 Makefile
     -rw-r--r--  1 arnold   user  10809 Nov  7 13:03 awk.h
     -rw-r--r--  1 arnold   user    983 Apr 13 12:14 awk.tab.h
     -rw-r--r--  1 arnold   user  31869 Jun 15 12:20 awkgram.y
     -rw-r--r--  1 arnold   user  22414 Nov  7 13:03 awk1.c
     -rw-r--r--  1 arnold   user  37455 Nov  7 13:03 awk2.c
     -rw-r--r--  1 arnold   user  27511 Dec  9 13:07 awk3.c
     -rw-r--r--  1 arnold   user   7989 Nov  7 13:03 awk4.c

The first field contains read-write permissions, the second field
contains the number of links to the file, and the third field
identifies the owner of the file. The fourth field identifies the group
of the file.  The fifth field contains the size of the file in bytes.
The sixth, seventh, and eighth fields contain the month, day, and time,
respectively, that the file was last modified.  Finally, the ninth field
contains the file name.(1)

   The `$6 == "Nov"' in our `awk' program is an expression that tests
whether the sixth field of the output from `ls -l' matches the string
`Nov'.  Each time a line has the string `Nov' for its sixth field, the
action `sum += $5' is performed.  This adds the fifth field (the file's
size) to the variable `sum'.  As a result, when `awk' has finished
reading all the input lines, `sum' is the total of the sizes of the
files whose lines matched the pattern.  (This works because `awk'
variables are automatically initialized to zero.)

   After the last line of output from `ls' has been processed, the
`END' rule executes and prints the value of `sum'.  In this example,
the value of `sum' is 80600.

   These more advanced `awk' techniques are covered in later sections
(*note Action Overview::).  Before you can move on to more advanced
`awk' programming, you have to know how `awk' interprets your input and
displays your output.  By manipulating fields and using `print'
statements, you can produce some very useful and impressive-looking
reports.

   ---------- Footnotes ----------

   (1) The `LC_ALL=C' is needed to produce this traditional-style
output from `ls'.


File: gawk.info,  Node: Statements/Lines,  Next: Other Features,  Prev: More Complex,  Up: Getting Started

1.6 `awk' Statements Versus Lines
=================================

Most often, each line in an `awk' program is a separate statement or
separate rule, like this:

     awk '/12/  { print $0 }
          /21/  { print $0 }' BBS-list inventory-shipped

   However, `gawk' ignores newlines after any of the following symbols
and keywords:

     ,    {    ?    :    ||    &&    do    else

A newline at any other point is considered the end of the statement.(1)

   If you would like to split a single statement into two lines at a
point where a newline would terminate it, you can "continue" it by
ending the first line with a backslash character (`\').  The backslash
must be the final character on the line in order to be recognized as a
continuation character.  A backslash is allowed anywhere in the
statement, even in the middle of a string or regular expression.  For
example:

     awk '/This regular expression is too long, so continue it\
      on the next line/ { print $1 }'

We have generally not used backslash continuation in our sample
programs.  `gawk' places no limit on the length of a line, so backslash
continuation is never strictly necessary; it just makes programs more
readable.  For this same reason, as well as for clarity, we have kept
most statements short in the sample programs presented throughout the
Info file.  Backslash continuation is most useful when your `awk'
program is in a separate source file instead of entered from the
command line.  You should also note that many `awk' implementations are
more particular about where you may use backslash continuation. For
example, they may not allow you to split a string constant using
backslash continuation.  Thus, for maximum portability of your `awk'
programs, it is best not to split your lines in the middle of a regular
expression or a string.

     CAUTION: _Backslash continuation does not work as described with
     the C shell._  It works for `awk' programs in files and for
     one-shot programs, _provided_ you are using a POSIX-compliant
     shell, such as the Unix Bourne shell or Bash.  But the C shell
     behaves differently!  There, you must use two backslashes in a
     row, followed by a newline.  Note also that when using the C
     shell, _every_ newline in your `awk' program must be escaped with
     a backslash. To illustrate:

          % awk 'BEGIN { \
          ?   print \\
          ?       "hello, world" \
          ? }'
          -| hello, world

     Here, the `%' and `?' are the C shell's primary and secondary
     prompts, analogous to the standard shell's `$' and `>'.

     Compare the previous example to how it is done with a
     POSIX-compliant shell:

          $ awk 'BEGIN {
          >   print \
          >       "hello, world"
          > }'
          -| hello, world

   `awk' is a line-oriented language.  Each rule's action has to begin
on the same line as the pattern.  To have the pattern and action on
separate lines, you _must_ use backslash continuation; there is no
other option.

   Another thing to keep in mind is that backslash continuation and
comments do not mix. As soon as `awk' sees the `#' that starts a
comment, it ignores _everything_ on the rest of the line. For example:

     $ gawk 'BEGIN { print "dont panic" # a friendly \
     >                                    BEGIN rule
     > }'
     error--> gawk: cmd. line:2:                BEGIN rule
     error--> gawk: cmd. line:2:                ^ parse error

In this case, it looks like the backslash would continue the comment
onto the next line. However, the backslash-newline combination is never
even noticed because it is "hidden" inside the comment. Thus, the
`BEGIN' is noted as a syntax error.

   When `awk' statements within one rule are short, you might want to
put more than one of them on a line.  This is accomplished by
separating the statements with a semicolon (`;').  This also applies to
the rules themselves.  Thus, the program shown at the start of this
minor node could also be written this way:

     /12/ { print $0 } ; /21/ { print $0 }

     NOTE: The requirement that states that rules on the same line must
     be separated with a semicolon was not in the original `awk'
     language; it was added for consistency with the treatment of
     statements within an action.

   ---------- Footnotes ----------

   (1) The `?' and `:' referred to here is the three-operand
conditional expression described in *note Conditional Exp::.  Splitting
lines after `?' and `:' is a minor `gawk' extension; if `--posix' is
specified (*note Options::), then this extension is disabled.


File: gawk.info,  Node: Other Features,  Next: When,  Prev: Statements/Lines,  Up: Getting Started

1.7 Other Features of `awk'
===========================

The `awk' language provides a number of predefined, or "built-in",
variables that your programs can use to get information from `awk'.
There are other variables your program can set as well to control how
`awk' processes your data.

   In addition, `awk' provides a number of built-in functions for doing
common computational and string-related operations.  `gawk' provides
built-in functions for working with timestamps, performing bit
manipulation, for runtime string translation (internationalization),
determining the type of a variable, and array sorting.

   As we develop our presentation of the `awk' language, we introduce
most of the variables and many of the functions. They are described
systematically in *note Built-in Variables::, and *note Built-in::.


File: gawk.info,  Node: When,  Prev: Other Features,  Up: Getting Started

1.8 When to Use `awk'
=====================

Now that you've seen some of what `awk' can do, you might wonder how
`awk' could be useful for you.  By using utility programs, advanced
patterns, field separators, arithmetic statements, and other selection
criteria, you can produce much more complex output.  The `awk' language
is very useful for producing reports from large amounts of raw data,
such as summarizing information from the output of other utility
programs like `ls'.  (*Note More Complex::.)

   Programs written with `awk' are usually much smaller than they would
be in other languages.  This makes `awk' programs easy to compose and
use.  Often, `awk' programs can be quickly composed at your keyboard,
used once, and thrown away.  Because `awk' programs are interpreted, you
can avoid the (usually lengthy) compilation part of the typical
edit-compile-test-debug cycle of software development.

   Complex programs have been written in `awk', including a complete
retargetable assembler for eight-bit microprocessors (*note Glossary::,
for more information), and a microcode assembler for a special-purpose
Prolog computer.  While the original `awk''s capabilities were strained
by tasks of such complexity, modern versions are more capable.  Even
Brian Kernighan's version of `awk' has fewer predefined limits, and
those that it has are much larger than they used to be.

   If you find yourself writing `awk' scripts of more than, say, a few
hundred lines, you might consider using a different programming
language.  Emacs Lisp is a good choice if you need sophisticated string
or pattern matching capabilities.  The shell is also good at string and
pattern matching; in addition, it allows powerful use of the system
utilities.  More conventional languages, such as C, C++, and Java, offer
better facilities for system programming and for managing the complexity
of large programs.  Programs in these languages may require more lines
of source code than the equivalent `awk' programs, but they are easier
to maintain and usually run more efficiently.


File: gawk.info,  Node: Invoking Gawk,  Next: Regexp,  Prev: Getting Started,  Up: Top

2 Running `awk' and `gawk'
**************************

This major node covers how to run awk, both POSIX-standard and
`gawk'-specific command-line options, and what `awk' and `gawk' do with
non-option arguments.  It then proceeds to cover how `gawk' searches
for source files, reading standard input along with other files,
`gawk''s environment variables, `gawk''s exit status, using include
files, and obsolete and undocumented options and/or features.

   Many of the options and features described here are discussed in
more detail later in the Info file; feel free to skip over things in
this major node that don't interest you right now.

* Menu:

* Command Line::                How to run `awk'.
* Options::                     Command-line options and their meanings.
* Other Arguments::             Input file names and variable assignments.
* Naming Standard Input::       How to specify standard input with other
                                files.
* Environment Variables::       The environment variables `gawk' uses.
* Exit Status::                 `gawk''s exit status.
* Include Files::               Including other files into your program.
* Obsolete::                    Obsolete Options and/or features.
* Undocumented::                Undocumented Options and Features.


File: gawk.info,  Node: Command Line,  Next: Options,  Up: Invoking Gawk

2.1 Invoking `awk'
==================

There are two ways to run `awk'--with an explicit program or with one
or more program files.  Here are templates for both of them; items
enclosed in [...] in these templates are optional:

     awk [OPTIONS] -f progfile [`--'] FILE ...
     awk [OPTIONS] [`--'] 'PROGRAM' FILE ...

   Besides traditional one-letter POSIX-style options, `gawk' also
supports GNU long options.

   It is possible to invoke `awk' with an empty program:

     awk '' datafile1 datafile2

Doing so makes little sense, though; `awk' exits silently when given an
empty program.  (d.c.)  If `--lint' has been specified on the command
line, `gawk' issues a warning that the program is empty.


File: gawk.info,  Node: Options,  Next: Other Arguments,  Prev: Command Line,  Up: Invoking Gawk

2.2 Command-Line Options
========================

Options begin with a dash and consist of a single character.  GNU-style
long options consist of two dashes and a keyword.  The keyword can be
abbreviated, as long as the abbreviation allows the option to be
uniquely identified.  If the option takes an argument, then the keyword
is either immediately followed by an equals sign (`=') and the
argument's value, or the keyword and the argument's value are separated
by whitespace.  If a particular option with a value is given more than
once, it is the last value that counts.

   Each long option for `gawk' has a corresponding POSIX-style short
option.  The long and short options are interchangeable in all contexts.
The following list describes options mandated by the POSIX standard:

`-F FS'
`--field-separator FS'
     Set the `FS' variable to FS (*note Field Separators::).

`-f SOURCE-FILE'
`--file SOURCE-FILE'
     Read `awk' program source from SOURCE-FILE instead of in the first
     non-option argument.  This option may be given multiple times; the
     `awk' program consists of the concatenation the contents of each
     specified SOURCE-FILE.

`-v VAR=VAL'
`--assign VAR=VAL'
     Set the variable VAR to the value VAL _before_ execution of the
     program begins.  Such variable values are available inside the
     `BEGIN' rule (*note Other Arguments::).

     The `-v' option can only set one variable, but it can be used more
     than once, setting another variable each time, like this: `awk
     -v foo=1 -v bar=2 ...'.

          CAUTION: Using `-v' to set the values of the built-in
          variables may lead to surprising results.  `awk' will reset
          the values of those variables as it needs to, possibly
          ignoring any predefined value you may have given.

`-W GAWK-OPT'
     Provide an implementation-specific option.  This is the POSIX
     convention for providing implementation-specific options.  These
     options also have corresponding GNU-style long options.  Note that
     the long options may be abbreviated, as long as the abbreviations
     remain unique.  The full list of `gawk'-specific options is
     provided next.

`--'
     Signal the end of the command-line options.  The following
     arguments are not treated as options even if they begin with `-'.
     This interpretation of `--' follows the POSIX argument parsing
     conventions.

     This is useful if you have file names that start with `-', or in
     shell scripts, if you have file names that will be specified by
     the user that could start with `-'.  It is also useful for passing
     options on to the `awk' program; see *note Getopt Function::.

   The following list describes `gawk'-specific options:

`-b'
`--characters-as-bytes'
     Cause `gawk' to treat all input data as single-byte characters.
     Normally, `gawk' follows the POSIX standard and attempts to process
     its input data according to the current locale. This can often
     involve converting multibyte characters into wide characters
     (internally), and can lead to problems or confusion if the input
     data does not contain valid multibyte characters. This option is
     an easy way to tell `gawk': "hands off my data!".

`-c'
`--traditional'
     Specify "compatibility mode", in which the GNU extensions to the
     `awk' language are disabled, so that `gawk' behaves just like
     Brian Kernighan's version `awk'.  *Note POSIX/GNU::, which
     summarizes the extensions.  Also see *note Compatibility Mode::.

`-C'
`--copyright'
     Print the short version of the General Public License and then
     exit.

`-d[FILE]'
`--dump-variables[=FILE]'
     Print a sorted list of global variables, their types, and final
     values to FILE.  If no FILE is provided, print this list to the
     file named `awkvars.out' in the current directory.  No space is
     allowed between the `-d' and FILE, if FILE is supplied.

     Having a list of all global variables is a good way to look for
     typographical errors in your programs.  You would also use this
     option if you have a large program with a lot of functions, and
     you want to be sure that your functions don't inadvertently use
     global variables that you meant to be local.  (This is a
     particularly easy mistake to make with simple variable names like
     `i', `j', etc.)

`-e PROGRAM-TEXT'
`--source PROGRAM-TEXT'
     Provide program source code in the PROGRAM-TEXT.  This option
     allows you to mix source code in files with source code that you
     enter on the command line.  This is particularly useful when you
     have library functions that you want to use from your command-line
     programs (*note AWKPATH Variable::).

`-E FILE'
`--exec FILE'
     Similar to `-f', read `awk' program text from FILE.  There are two
     differences from `-f':

        * This option terminates option processing; anything else on
          the command line is passed on directly to the `awk' program.

        * Command-line variable assignments of the form `VAR=VALUE' are
          disallowed.

     This option is particularly necessary for World Wide Web CGI
     applications that pass arguments through the URL; using this
     option prevents a malicious (or other) user from passing in
     options, assignments, or `awk' source code (via `--source') to the
     CGI application.  This option should be used with `#!' scripts
     (*note Executable Scripts::), like so:

          #! /usr/local/bin/gawk -E

          AWK PROGRAM HERE ...

`-g'
`--gen-pot'
     Analyze the source program and generate a GNU `gettext' Portable
     Object Template file on standard output for all string constants
     that have been marked for translation.  *Note
     Internationalization::, for information about this option.

`-h'
`--help'
     Print a "usage" message summarizing the short and long style
     options that `gawk' accepts and then exit.

`-L [value]'
`--lint[=value]'
     Warn about constructs that are dubious or nonportable to other
     `awk' implementations.  Some warnings are issued when `gawk' first
     reads your program.  Others are issued at runtime, as your program
     executes.  With an optional argument of `fatal', lint warnings
     become fatal errors.  This may be drastic, but its use will
     certainly encourage the development of cleaner `awk' programs.
     With an optional argument of `invalid', only warnings about things
     that are actually invalid are issued. (This is not fully
     implemented yet.)

     Some warnings are only printed once, even if the dubious
     constructs they warn about occur multiple times in your `awk'
     program.  Thus, when eliminating problems pointed out by `--lint',
     you should take care to search for all occurrences of each
     inappropriate construct. As `awk' programs are usually short,
     doing so is not burdensome.

`-n'
`--non-decimal-data'
     Enable automatic interpretation of octal and hexadecimal values in
     input data (*note Nondecimal Data::).

          CAUTION: This option can severely break old programs.  Use
          with care.

`-N'
`--use-lc-numeric'
     Force the use of the locale's decimal point character when parsing
     numeric input data (*note Locales::).

`-O'
`--optimize'
     Enable some optimizations on the internal representation of the
     program.  At the moment this includes just simple constant
     folding. The `gawk' maintainer hopes to add more optimizations
     over time.

`-p[FILE]'
`--profile[=FILE]'
     Enable profiling of `awk' programs (*note Profiling::).  By
     default, profiles are created in a file named `awkprof.out'.  The
     optional FILE argument allows you to specify a different file name
     for the profile file.  No space is allowed between the `-p' and
     FILE, if FILE is supplied.

     When run with `gawk', the profile is just a "pretty printed"
     version of the program.  When run with `pgawk', the profile
     contains execution counts for each statement in the program in the
     left margin, and function call counts for each function.

`-P'
`--posix'
     Operate in strict POSIX mode.  This disables all `gawk' extensions
     (just like `--traditional') and disables all extensions not
     allowed by POSIX.  *Note Common Extensions::, for a summary of the
     extensions in `gawk' that are disabled by this option.  Also, the
     following additional restrictions apply:

        * Newlines do not act as whitespace to separate fields when
          `FS' is equal to a single space (*note Fields::).

        * Newlines are not allowed after `?' or `:' (*note Conditional
          Exp::).

        * Specifying `-Ft' on the command-line does not set the value
          of `FS' to be a single TAB character (*note Field
          Separators::).

        * The locale's decimal point character is used for parsing input
          data (*note Locales::).

     If you supply both `--traditional' and `--posix' on the command
     line, `--posix' takes precedence. `gawk' also issues a warning if
     both options are supplied.

`-r'
`--re-interval'
     Allow interval expressions (*note Regexp Operators::) in regexps.
     This is now `gawk''s default behavior.  Nevertheless, this option
     remains both for backward compatibility, and for use in
     combination with the `--traditional' option.

`-R FILE'
`--command=FILE'
     `dgawk' only.  Read `dgawk' debugger options and commands from
     FILE.  *Note Dgawk Info::, for more information.

`-S'
`--sandbox'
     Disable the `system()' function, input redirections with `getline',
     output redirections with `print' and `printf', and dynamic
     extensions.  This is particularly useful when you want to run
     `awk' scripts from questionable sources and need to make sure the
     scripts can't access your system (other than the specified input
     data file).

`-t'
`--lint-old'
     Warn about constructs that are not available in the original
     version of `awk' from Version 7 Unix (*note V7/SVR3.1::).

`-V'
`--version'
     Print version information for this particular copy of `gawk'.
     This allows you to determine if your copy of `gawk' is up to date
     with respect to whatever the Free Software Foundation is currently
     distributing.  It is also useful for bug reports (*note Bugs::).

   As long as program text has been supplied, any other options are
flagged as invalid with a warning message but are otherwise ignored.

   In compatibility mode, as a special case, if the value of FS supplied
to the `-F' option is `t', then `FS' is set to the TAB character
(`"\t"').  This is true only for `--traditional' and not for `--posix'
(*note Field Separators::).

   The `-f' option may be used more than once on the command line.  If
it is, `awk' reads its program source from all of the named files, as
if they had been concatenated together into one big file.  This is
useful for creating libraries of `awk' functions.  These functions can
be written once and then retrieved from a standard place, instead of
having to be included into each individual program.  (As mentioned in
*note Definition Syntax::, function names must be unique.)

   With standard `awk', library functions can still be used, even if
the program is entered at the terminal, by specifying `-f /dev/tty'.
After typing your program, type `Ctrl-d' (the end-of-file character) to
terminate it.  (You may also use `-f -' to read program source from the
standard input but then you will not be able to also use the standard
input as a source of data.)

   Because it is clumsy using the standard `awk' mechanisms to mix
source file and command-line `awk' programs, `gawk' provides the
`--source' option.  This does not require you to pre-empt the standard
input for your source code; it allows you to easily mix command-line
and library source code (*note AWKPATH Variable::).  The `--source'
option may also be used multiple times on the command line.

   If no `-f' or `--source' option is specified, then `gawk' uses the
first non-option command-line argument as the text of the program
source code.

   If the environment variable `POSIXLY_CORRECT' exists, then `gawk'
behaves in strict POSIX mode, exactly as if you had supplied the
`--posix' command-line option.  Many GNU programs look for this
environment variable to turn on strict POSIX mode. If `--lint' is
supplied on the command line and `gawk' turns on POSIX mode because of
`POSIXLY_CORRECT', then it issues a warning message indicating that
POSIX mode is in effect.  You would typically set this variable in your
shell's startup file.  For a Bourne-compatible shell (such as Bash),
you would add these lines to the `.profile' file in your home directory:

     POSIXLY_CORRECT=true
     export POSIXLY_CORRECT

   For a C shell-compatible shell,(1) you would add this line to the
`.login' file in your home directory:

     setenv POSIXLY_CORRECT true

   Having `POSIXLY_CORRECT' set is not recommended for daily use, but
it is good for testing the portability of your programs to other
environments.

   ---------- Footnotes ----------

   (1) Not recommended.


File: gawk.info,  Node: Other Arguments,  Next: Naming Standard Input,  Prev: Options,  Up: Invoking Gawk

2.3 Other Command-Line Arguments
================================

Any additional arguments on the command line are normally treated as
input files to be processed in the order specified.   However, an
argument that has the form `VAR=VALUE', assigns the value VALUE to the
variable VAR--it does not specify a file at all.  (See *note Assignment
Options::.)

   All these arguments are made available to your `awk' program in the
`ARGV' array (*note Built-in Variables::).  Command-line options and
the program text (if present) are omitted from `ARGV'.  All other
arguments, including variable assignments, are included.   As each
element of `ARGV' is processed, `gawk' sets the variable `ARGIND' to
the index in `ARGV' of the current element.

   The distinction between file name arguments and variable-assignment
arguments is made when `awk' is about to open the next input file.  At
that point in execution, it checks the file name to see whether it is
really a variable assignment; if so, `awk' sets the variable instead of
reading a file.

   Therefore, the variables actually receive the given values after all
previously specified files have been read.  In particular, the values of
variables assigned in this fashion are _not_ available inside a `BEGIN'
rule (*note BEGIN/END::), because such rules are run before `awk'
begins scanning the argument list.

   The variable values given on the command line are processed for
escape sequences (*note Escape Sequences::).  (d.c.)

   In some earlier implementations of `awk', when a variable assignment
occurred before any file names, the assignment would happen _before_
the `BEGIN' rule was executed.  `awk''s behavior was thus inconsistent;
some command-line assignments were available inside the `BEGIN' rule,
while others were not.  Unfortunately, some applications came to depend
upon this "feature."  When `awk' was changed to be more consistent, the
`-v' option was added to accommodate applications that depended upon
the old behavior.

   The variable assignment feature is most useful for assigning to
variables such as `RS', `OFS', and `ORS', which control input and
output formats before scanning the data files.  It is also useful for
controlling state if multiple passes are needed over a data file.  For
example:

     awk 'pass == 1  { PASS 1 STUFF }
          pass == 2  { PASS 2 STUFF }' pass=1 mydata pass=2 mydata

   Given the variable assignment feature, the `-F' option for setting
the value of `FS' is not strictly necessary.  It remains for historical
compatibility.


File: gawk.info,  Node: Naming Standard Input,  Next: Environment Variables,  Prev: Other Arguments,  Up: Invoking Gawk

2.4 Naming Standard Input
=========================

Often, you may wish to read standard input together with other files.
For example, you may wish to read one file, read standard input coming
from a pipe, and then read another file.

   The way to name the standard input, with all versions of `awk', is
to use a single, standalone minus sign or dash, `-'.  For example:

     SOME_COMMAND | awk -f myprog.awk file1 - file2

Here, `awk' first reads `file1', then it reads the output of
SOME_COMMAND, and finally it reads `file2'.

   You may also use `"-"' to name standard input when reading files
with `getline' (*note Getline/File::).

   In addition, `gawk' allows you to specify the special file name
`/dev/stdin', both on the command line and with `getline'.  Some other
versions of `awk' also support this, but it is not standard.  (Some
operating systems provide a `/dev/stdin' file in the file system,
however, `gawk' always processes this file name itself.)


File: gawk.info,  Node: Environment Variables,  Next: Exit Status,  Prev: Naming Standard Input,  Up: Invoking Gawk

2.5 The Environment Variables `gawk' Uses
=========================================

A number of environment variables influence how `gawk' behaves.

* Menu:

* AWKPATH Variable::            Searching directories for `awk'
                                programs.
* Other Environment Variables:: The environment variables.


File: gawk.info,  Node: AWKPATH Variable,  Next: Other Environment Variables,  Up: Environment Variables

2.5.1 The `AWKPATH' Environment Variable
----------------------------------------

The previous minor node described how `awk' program files can be named
on the command-line with the `-f' option.  In most `awk'
implementations, you must supply a precise path name for each program
file, unless the file is in the current directory.  But in `gawk', if
the file name supplied to the `-f' option does not contain a `/', then
`gawk' searches a list of directories (called the "search path"), one
by one, looking for a file with the specified name.

The search path is a string consisting of directory names separated by
colons.  `gawk' gets its search path from the `AWKPATH' environment
variable.  If that variable does not exist, `gawk' uses a default path,
`.:/usr/local/share/awk'.(1)

   The search path feature is particularly useful for building libraries
of useful `awk' functions.  The library files can be placed in a
standard directory in the default path and then specified on the
command line with a short file name.  Otherwise, the full file name
would have to be typed for each file.

   By using both the `--source' and `-f' options, your command-line
`awk' programs can use facilities in `awk' library files (*note Library
Functions::).  Path searching is not done if `gawk' is in compatibility
mode.  This is true for both `--traditional' and `--posix'.  *Note
Options::.

     NOTE: To include the current directory in the path, either place
     `.' explicitly in the path or write a null entry in the path.  (A
     null entry is indicated by starting or ending the path with a
     colon or by placing two colons next to each other (`::').)  This
     path search mechanism is similar to the shell's.

     However, `gawk' always looks in the current directory _before_
     searching `AWKPATH', so there is no real reason to include the
     current directory in the search path.

   If `AWKPATH' is not defined in the environment, `gawk' places its
default search path into `ENVIRON["AWKPATH"]'. This makes it easy to
determine the actual search path that `gawk' will use from within an
`awk' program.

   While you can change `ENVIRON["AWKPATH"]' within your `awk' program,
this has no effect on the running program's behavior.  This makes
sense: the `AWKPATH' environment variable is used to find the program
source files.  Once your program is running, all the files have been
found, and `gawk' no longer needs to use `AWKPATH'.

   ---------- Footnotes ----------

   (1) Your version of `gawk' may use a different directory; it will
depend upon how `gawk' was built and installed. The actual directory is
the value of `$(datadir)' generated when `gawk' was configured.  You
probably don't need to worry about this, though.


File: gawk.info,  Node: Other Environment Variables,  Prev: AWKPATH Variable,  Up: Environment Variables

2.5.2 Other Environment Variables
---------------------------------

A number of other environment variables affect `gawk''s behavior, but
they are more specialized. Those in the following list are meant to be
used by regular users.

`POSIXLY_CORRECT'
     Causes `gawk' to switch POSIX compatibility mode, disabling all
     traditional and GNU extensions.  *Note Options::.

`GAWK_SOCK_RETRIES'
     Controls the number of time `gawk' will attempt to retry a two-way
     TCP/IP (socket) connection before giving up.  *Note TCP/IP
     Networking::.

`GAWK_MSEC_SLEEP'
     Specifies the interval between connection retries, in
     milliseconds. On systems that do not support the `usleep()' system
     call, the value is rounded up to an integral number of seconds.

   The environment variables in the following list are meant for use by
the `gawk' developers for testing and tuning.  They are subject to
change. The variables are:

`AVG_CHAIN_MAX'
     The average number of items `gawk' will maintain on a hash chain
     for managing arrays.

`AWK_HASH'
     If this variable exists with a value of `gst', `gawk' will switch
     to using the hash function from GNU Smalltalk for managing arrays.
     This function may be marginally faster than the standard function.

`AWKREADFUNC'
     If this variable exists, `gawk' switches to reading source files
     one line at a time, instead of reading in blocks. This exists for
     debugging problems on filesystems on non-POSIX operating systems
     where I/O is performed in records, not in blocks.

`GAWK_NO_DFA'
     If this variable exists, `gawk' does not use the DFA regexp matcher
     for "does it match" kinds of tests. This can cause `gawk' to be
     slower. Its purpose is to help isolate differences between the two
     regexp matchers that `gawk' uses internally. (There aren't
     supposed to be differences, but occasionally theory and practice
     don't coordinate with each other.)

`GAWK_STACKSIZE'
     This specifies the amount by which `gawk' should grow its internal
     evaluation stack, when needed.

`TIDYMEM'
     If this variable exists, `gawk' uses the `mtrace()' library calls
     from GNU LIBC to help track down possible memory leaks.


File: gawk.info,  Node: Exit Status,  Next: Include Files,  Prev: Environment Variables,  Up: Invoking Gawk

2.6 `gawk''s Exit Status
========================

If the `exit' statement is used with a value (*note Exit Statement::),
then `gawk' exits with the numeric value given to it.

   Otherwise, if there were no problems during execution, `gawk' exits
with the value of the C constant `EXIT_SUCCESS'.  This is usually zero.

   If an error occurs, `gawk' exits with the value of the C constant
`EXIT_FAILURE'.  This is usually one.

   If `gawk' exits because of a fatal error, the exit status is 2.  On
non-POSIX systems, this value may be mapped to `EXIT_FAILURE'.


File: gawk.info,  Node: Include Files,  Next: Obsolete,  Prev: Exit Status,  Up: Invoking Gawk

2.7 Including Other Files Into Your Program
===========================================

This minor node describes a feature that is specific to `gawk'.

   The `@include' keyword can be used to read external `awk' source
files.  This gives you the ability to split large `awk' source files
into smaller, more manageable pieces, and also lets you reuse common
`awk' code from various `awk' scripts.  In other words, you can group
together `awk' functions, used to carry out specific tasks, into
external files. These files can be used just like function libraries,
using the `@include' keyword in conjunction with the `AWKPATH'
environment variable.

   Let's see an example.  We'll start with two (trivial) `awk' scripts,
namely `test1' and `test2'. Here is the `test1' script:

     BEGIN {
         print "This is script test1."
     }

and here is `test2':

     @include "test1"
     BEGIN {
         print "This is script test2."
     }

   Running `gawk' with `test2' produces the following result:

     $ gawk -f test2
     -| This is file test1.
     -| This is file test2.

   `gawk' runs the `test2' script which includes `test1' using the
`@include' keyword.  So, to include external `awk' source files you just
use `@include' followed by the name of the file to be included,
enclosed in double quotes.

     NOTE: Keep in mind that this is a language construct and the file
     name cannot be a string variable, but rather just a literal string
     in double quotes.

   The files to be included may be nested; e.g., given a third script,
namely `test3':

     @include "test2"
     BEGIN {
         print "This is script test3."
     }

Running `gawk' with the `test3' script produces the following results:

     $ gawk -f test3
     -| This is file test1.
     -| This is file test2.
     -| This is file test3.

   The file name can, of course, be a pathname. For example:

     @include "../io_funcs"

or:

     @include "/usr/awklib/network"

are valid. The `AWKPATH' environment variable can be of great value
when using `@include'. The same rules for the use of the `AWKPATH'
variable in command-line file searches (*note AWKPATH Variable::) apply
to `@include' also.

   This is very helpful in constructing `gawk' function libraries.  If
you have a large script with useful, general purpose `awk' functions,
you can break it down into library files and put those files in a
special directory.  You can then include those "libraries," using
either the full pathnames of the files, or by setting the `AWKPATH'
environment variable accordingly and then using `@include' with just
the file part of the full pathname. Of course you can have more than
one directory to keep library files; the more complex the working
environment is, the more directories you may need to organize the files
to be included.

   Given the ability to specify multiple `-f' options, the `@include'
mechanism is not strictly necessary.  However, the `@include' keyword
can help you in constructing self-contained `gawk' programs, thus
reducing the need for writing complex and tedious command lines.  In
particular, `@include' is very useful for writing CGI scripts to be run
from web pages.

   As mentioned in *note AWKPATH Variable::, the current directory is
always searched first for source files, before searching in `AWKPATH',
and this also applies to files named with `@include'.


File: gawk.info,  Node: Obsolete,  Next: Undocumented,  Prev: Include Files,  Up: Invoking Gawk

2.8 Obsolete Options and/or Features
====================================

This minor node describes features and/or command-line options from
previous releases of `gawk' that are either not available in the
current version or that are still supported but deprecated (meaning that
they will _not_ be in the next release).

   The process-related special files `/dev/pid', `/dev/ppid',
`/dev/pgrpid', and `/dev/user' were deprecated in `gawk' 3.1, but still
worked.  As of version 4.0, they are no longer interpreted specially by
`gawk'.  (Use `PROCINFO' instead; see *note Auto-set::.)


File: gawk.info,  Node: Undocumented,  Prev: Obsolete,  Up: Invoking Gawk

2.9 Undocumented Options and Features
=====================================

     Use the Source, Luke!
     Obi-Wan

   This minor node intentionally left blank.


File: gawk.info,  Node: Regexp,  Next: Reading Files,  Prev: Invoking Gawk,  Up: Top

3 Regular Expressions
*********************

A "regular expression", or "regexp", is a way of describing a set of
strings.  Because regular expressions are such a fundamental part of
`awk' programming, their format and use deserve a separate major node.

   A regular expression enclosed in slashes (`/') is an `awk' pattern
that matches every input record whose text belongs to that set.  The
simplest regular expression is a sequence of letters, numbers, or both.
Such a regexp matches any string that contains that sequence.  Thus,
the regexp `foo' matches any string containing `foo'.  Therefore, the
pattern `/foo/' matches any input record containing the three
characters `foo' _anywhere_ in the record.  Other kinds of regexps let
you specify more complicated classes of strings.

* Menu:

* Regexp Usage::                How to Use Regular Expressions.
* Escape Sequences::            How to write nonprinting characters.
* Regexp Operators::            Regular Expression Operators.
* Bracket Expressions::         What can go between `[...]'.
* GNU Regexp Operators::        Operators specific to GNU software.
* Case-sensitivity::            How to do case-insensitive matching.
* Leftmost Longest::            How much text matches.
* Computed Regexps::            Using Dynamic Regexps.


File: gawk.info,  Node: Regexp Usage,  Next: Escape Sequences,  Up: Regexp

3.1 How to Use Regular Expressions
==================================

A regular expression can be used as a pattern by enclosing it in
slashes.  Then the regular expression is tested against the entire text
of each record.  (Normally, it only needs to match some part of the
text in order to succeed.)  For example, the following prints the
second field of each record that contains the string `foo' anywhere in
it:

     $ awk '/foo/ { print $2 }' BBS-list
     -| 555-1234
     -| 555-6699
     -| 555-6480
     -| 555-2127

   Regular expressions can also be used in matching expressions.  These
expressions allow you to specify the string to match against; it need
not be the entire current input record.  The two operators `~' and `!~'
perform regular expression comparisons.  Expressions using these
operators can be used as patterns, or in `if', `while', `for', and `do'
statements.  (*Note Statements::.)  For example:

     EXP ~ /REGEXP/

is true if the expression EXP (taken as a string) matches REGEXP.  The
following example matches, or selects, all input records with the
uppercase letter `J' somewhere in the first field:

     $ awk '$1 ~ /J/' inventory-shipped
     -| Jan  13  25  15 115
     -| Jun  31  42  75 492
     -| Jul  24  34  67 436
     -| Jan  21  36  64 620

   So does this:

     awk '{ if ($1 ~ /J/) print }' inventory-shipped

   This next example is true if the expression EXP (taken as a
character string) does _not_ match REGEXP:

     EXP !~ /REGEXP/

   The following example matches, or selects, all input records whose
first field _does not_ contain the uppercase letter `J':

     $ awk '$1 !~ /J/' inventory-shipped
     -| Feb  15  32  24 226
     -| Mar  15  24  34 228
     -| Apr  31  52  63 420
     -| May  16  34  29 208
     ...

   When a regexp is enclosed in slashes, such as `/foo/', we call it a
"regexp constant", much like `5.27' is a numeric constant and `"foo"'
is a string constant.


File: gawk.info,  Node: Escape Sequences,  Next: Regexp Operators,  Prev: Regexp Usage,  Up: Regexp

3.2 Escape Sequences
====================

Some characters cannot be included literally in string constants
(`"foo"') or regexp constants (`/foo/').  Instead, they should be
represented with "escape sequences", which are character sequences
beginning with a backslash (`\').  One use of an escape sequence is to
include a double-quote character in a string constant.  Because a plain
double quote ends the string, you must use `\"' to represent an actual
double-quote character as a part of the string.  For example:

     $ awk 'BEGIN { print "He said \"hi!\" to her." }'
     -| He said "hi!" to her.

   The  backslash character itself is another character that cannot be
included normally; you must write `\\' to put one backslash in the
string or regexp.  Thus, the string whose contents are the two
characters `"' and `\' must be written `"\"\\"'.

   Other escape sequences represent unprintable characters such as TAB
or newline.  While there is nothing to stop you from entering most
unprintable characters directly in a string constant or regexp constant,
they may look ugly.

   The following table lists all the escape sequences used in `awk' and
what they represent. Unless noted otherwise, all these escape sequences
apply to both string constants and regexp constants:

`\\'
     A literal backslash, `\'.

`\a'
     The "alert" character, `Ctrl-g', ASCII code 7 (BEL).  (This
     usually makes some sort of audible noise.)

`\b'
     Backspace, `Ctrl-h', ASCII code 8 (BS).

`\f'
     Formfeed, `Ctrl-l', ASCII code 12 (FF).

`\n'
     Newline, `Ctrl-j', ASCII code 10 (LF).

`\r'
     Carriage return, `Ctrl-m', ASCII code 13 (CR).

`\t'
     Horizontal TAB, `Ctrl-i', ASCII code 9 (HT).

`\v'
     Vertical tab, `Ctrl-k', ASCII code 11 (VT).

`\NNN'
     The octal value NNN, where NNN stands for 1 to 3 digits between
     `0' and `7'.  For example, the code for the ASCII ESC (escape)
     character is `\033'.

`\xHH...'
     The hexadecimal value HH, where HH stands for a sequence of
     hexadecimal digits (`0'-`9', and either `A'-`F' or `a'-`f').  Like
     the same construct in ISO C, the escape sequence continues until
     the first nonhexadecimal digit is seen. (c.e.)  However, using
     more than two hexadecimal digits produces undefined results. (The
     `\x' escape sequence is not allowed in POSIX `awk'.)

`\/'
     A literal slash (necessary for regexp constants only).  This
     sequence is used when you want to write a regexp constant that
     contains a slash. Because the regexp is delimited by slashes, you
     need to escape the slash that is part of the pattern, in order to
     tell `awk' to keep processing the rest of the regexp.

`\"'
     A literal double quote (necessary for string constants only).
     This sequence is used when you want to write a string constant
     that contains a double quote. Because the string is delimited by
     double quotes, you need to escape the quote that is part of the
     string, in order to tell `awk' to keep processing the rest of the
     string.

   In `gawk', a number of additional two-character sequences that begin
with a backslash have special meaning in regexps.  *Note GNU Regexp
Operators::.

   In a regexp, a backslash before any character that is not in the
previous list and not listed in *note GNU Regexp Operators::, means
that the next character should be taken literally, even if it would
normally be a regexp operator.  For example, `/a\+b/' matches the three
characters `a+b'.

   For complete portability, do not use a backslash before any
character not shown in the previous list.

   To summarize:

   * The escape sequences in the table above are always processed first,
     for both string constants and regexp constants. This happens very
     early, as soon as `awk' reads your program.

   * `gawk' processes both regexp constants and dynamic regexps (*note
     Computed Regexps::), for the special operators listed in *note GNU
     Regexp Operators::.

   * A backslash before any other character means to treat that
     character literally.

Advanced Notes: Backslash Before Regular Characters
---------------------------------------------------

If you place a backslash in a string constant before something that is
not one of the characters previously listed, POSIX `awk' purposely
leaves what happens as undefined.  There are two choices:

Strip the backslash out
     This is what Brian Kernighan's `awk' and `gawk' both do.  For
     example, `"a\qc"' is the same as `"aqc"'.  (Because this is such
     an easy bug both to introduce and to miss, `gawk' warns you about
     it.)  Consider `FS = "[ \t]+\|[ \t]+"' to use vertical bars
     surrounded by whitespace as the field separator. There should be
     two backslashes in the string: `FS = "[ \t]+\\|[ \t]+"'.)

Leave the backslash alone
     Some other `awk' implementations do this.  In such
     implementations, typing `"a\qc"' is the same as typing `"a\\qc"'.

Advanced Notes: Escape Sequences for Metacharacters
---------------------------------------------------

Suppose you use an octal or hexadecimal escape to represent a regexp
metacharacter.  (See *note Regexp Operators::.)  Does `awk' treat the
character as a literal character or as a regexp operator?

   Historically, such characters were taken literally.  (d.c.)
However, the POSIX standard indicates that they should be treated as
real metacharacters, which is what `gawk' does.  In compatibility mode
(*note Options::), `gawk' treats the characters represented by octal
and hexadecimal escape sequences literally when used in regexp
constants. Thus, `/a\52b/' is equivalent to `/a\*b/'.


File: gawk.info,  Node: Regexp Operators,  Next: Bracket Expressions,  Prev: Escape Sequences,  Up: Regexp

3.3 Regular Expression Operators
================================

You can combine regular expressions with special characters, called
"regular expression operators" or "metacharacters", to increase the
power and versatility of regular expressions.

   The escape sequences described in *note Escape Sequences::, are
valid inside a regexp.  They are introduced by a `\' and are recognized
and converted into corresponding real characters as the very first step
in processing regexps.

   Here is a list of metacharacters.  All characters that are not escape
sequences and that are not listed in the table stand for themselves:

`\'
     This is used to suppress the special meaning of a character when
     matching.  For example, `\$' matches the character `$'.

`^'
     This matches the beginning of a string.  For example, `^@chapter'
     matches `@chapter' at the beginning of a string and can be used to
     identify chapter beginnings in Texinfo source files.  The `^' is
     known as an "anchor", because it anchors the pattern to match only
     at the beginning of the string.

     It is important to realize that `^' does not match the beginning of
     a line embedded in a string.  The condition is not true in the
     following example:

          if ("line1\nLINE 2" ~ /^L/) ...

`$'
     This is similar to `^', but it matches only at the end of a string.
     For example, `p$' matches a record that ends with a `p'.  The `$'
     is an anchor and does not match the end of a line embedded in a
     string.  The condition in the following example is not true:

          if ("line1\nLINE 2" ~ /1$/) ...

`. (period)'
     This matches any single character, _including_ the newline
     character.  For example, `.P' matches any single character
     followed by a `P' in a string.  Using concatenation, we can make a
     regular expression such as `U.A', which matches any
     three-character sequence that begins with `U' and ends with `A'.

     In strict POSIX mode (*note Options::), `.' does not match the NUL
     character, which is a character with all bits equal to zero.
     Otherwise, NUL is just another character. Other versions of `awk'
     may not be able to match the NUL character.

`[...]'
     This is called a "bracket expression".(1) It matches any _one_ of
     the characters that are enclosed in the square brackets.  For
     example, `[MVX]' matches any one of the characters `M', `V', or
     `X' in a string.  A full discussion of what can be inside the
     square brackets of a bracket expression is given in *note Bracket
     Expressions::.

`[^ ...]'
     This is a "complemented bracket expression".  The first character
     after the `[' _must_ be a `^'.  It matches any characters _except_
     those in the square brackets.  For example, `[^awk]' matches any
     character that is not an `a', `w', or `k'.

`|'
     This is the "alternation operator" and it is used to specify
     alternatives.  The `|' has the lowest precedence of all the regular
     expression operators.  For example, `^P|[[:digit:]]' matches any
     string that matches either `^P' or `[[:digit:]]'.  This means it
     matches any string that starts with `P' or contains a digit.

     The alternation applies to the largest possible regexps on either
     side.

`(...)'
     Parentheses are used for grouping in regular expressions, as in
     arithmetic.  They can be used to concatenate regular expressions
     containing the alternation operator, `|'.  For example,
     `@(samp|code)\{[^}]+\}' matches both `@code{foo}' and `@samp{bar}'.
     (These are Texinfo formatting control sequences. The `+' is
     explained further on in this list.)

`*'
     This symbol means that the preceding regular expression should be
     repeated as many times as necessary to find a match.  For example,
     `ph*' applies the `*' symbol to the preceding `h' and looks for
     matches of one `p' followed by any number of `h's.  This also
     matches just `p' if no `h's are present.

     The `*' repeats the _smallest_ possible preceding expression.
     (Use parentheses if you want to repeat a larger expression.)  It
     finds as many repetitions as possible.  For example, `awk
     '/\(c[ad][ad]*r x\)/ { print }' sample' prints every record in
     `sample' containing a string of the form `(car x)', `(cdr x)',
     `(cadr x)', and so on.  Notice the escaping of the parentheses by
     preceding them with backslashes.

`+'
     This symbol is similar to `*', except that the preceding
     expression must be matched at least once.  This means that `wh+y'
     would match `why' and `whhy', but not `wy', whereas `wh*y' would
     match all three of these strings.  The following is a simpler way
     of writing the last `*' example:

          awk '/\(c[ad]+r x\)/ { print }' sample

`?'
     This symbol is similar to `*', except that the preceding
     expression can be matched either once or not at all.  For example,
     `fe?d' matches `fed' and `fd', but nothing else.

`{N}'
`{N,}'
`{N,M}'
     One or two numbers inside braces denote an "interval expression".
     If there is one number in the braces, the preceding regexp is
     repeated N times.  If there are two numbers separated by a comma,
     the preceding regexp is repeated N to M times.  If there is one
     number followed by a comma, then the preceding regexp is repeated
     at least N times:

    `wh{3}y'
          Matches `whhhy', but not `why' or `whhhhy'.

    `wh{3,5}y'
          Matches `whhhy', `whhhhy', or `whhhhhy', only.

    `wh{2,}y'
          Matches `whhy' or `whhhy', and so on.

     Interval expressions were not traditionally available in `awk'.
     They were added as part of the POSIX standard to make `awk' and
     `egrep' consistent with each other.

     Initially, because old programs may use `{' and `}' in regexp
     constants, `gawk' did _not_ match interval expressions in regexps.

     However, beginning with version 4.0, `gawk' does match interval
     expressions by default.  This is because compatibility with POSIX
     has become more important to most `gawk' users than compatibility
     with old programs.

     For programs that use `{' and `}' in regexp constants, it is good
     practice to always escape them with a backslash.  Then the regexp
     constants are valid and work the way you want them to, using any
     version of `awk'.(2)

   In regular expressions, the `*', `+', and `?' operators, as well as
the braces `{' and `}', have the highest precedence, followed by
concatenation, and finally by `|'.  As in arithmetic, parentheses can
change how operators are grouped.

   In POSIX `awk' and `gawk', the `*', `+', and `?' operators stand for
themselves when there is nothing in the regexp that precedes them.  For
example, `/+/' matches a literal plus sign.  However, many other
versions of `awk' treat such a usage as a syntax error.

   If `gawk' is in compatibility mode (*note Options::), interval
expressions are not available in regular expressions.

   ---------- Footnotes ----------

   (1) In other literature, you may see a bracket expression referred
to as either a "character set", a "character class", or a "character
list".

   (2) Use two backslashes if you're using a string constant with a
regexp operator or function.


File: gawk.info,  Node: Bracket Expressions,  Next: GNU Regexp Operators,  Prev: Regexp Operators,  Up: Regexp

3.4 Using Bracket Expressions
=============================

As mentioned earlier, a bracket expression matches any character amongst
those listed between the opening and closing square brackets.

   Within a bracket expression, a "range expression" consists of two
characters separated by a hyphen.  It matches any single character that
sorts between the two characters, based upon the system's native
character set.  For example, `[0-9]' is equivalent to `[0123456789]'.
(See *note Ranges and Locales::, for an explanation of how the POSIX
standard and `gawk' have changed over time.  This is mainly of
historical interest.)

   To include one of the characters `\', `]', `-', or `^' in a bracket
expression, put a `\' in front of it.  For example:

     [d\]]

matches either `d' or `]'.

   This treatment of `\' in bracket expressions is compatible with
other `awk' implementations and is also mandated by POSIX.  The regular
expressions in `awk' are a superset of the POSIX specification for
Extended Regular Expressions (EREs).  POSIX EREs are based on the
regular expressions accepted by the traditional `egrep' utility.

   "Character classes" are a feature introduced in the POSIX standard.
A character class is a special notation for describing lists of
characters that have a specific attribute, but the actual characters
can vary from country to country and/or from character set to character
set.  For example, the notion of what is an alphabetic character
differs between the United States and France.

   A character class is only valid in a regexp _inside_ the brackets of
a bracket expression.  Character classes consist of `[:', a keyword
denoting the class, and `:]'.  *note table-char-classes:: lists the
character classes defined by the POSIX standard.

Class       Meaning
-------------------------------------------------------------------------- 
`[:alnum:]' Alphanumeric characters.
`[:alpha:]' Alphabetic characters.
`[:blank:]' Space and TAB characters.
`[:cntrl:]' Control characters.
`[:digit:]' Numeric characters.
`[:graph:]' Characters that are both printable and visible.  (A space is
            printable but not visible, whereas an `a' is both.)
`[:lower:]' Lowercase alphabetic characters.
`[:print:]' Printable characters (characters that are not control
            characters).
`[:punct:]' Punctuation characters (characters that are not letters,
            digits, control characters, or space characters).
`[:space:]' Space characters (such as space, TAB, and formfeed, to name
            a few).
`[:upper:]' Uppercase alphabetic characters.
`[:xdigit:]'Characters that are hexadecimal digits.

Table 3.1: POSIX Character Classes

   For example, before the POSIX standard, you had to write
`/[A-Za-z0-9]/' to match alphanumeric characters.  If your character
set had other alphabetic characters in it, this would not match them.
With the POSIX character classes, you can write `/[[:alnum:]]/' to
match the alphabetic and numeric characters in your character set.

   Two additional special sequences can appear in bracket expressions.
These apply to non-ASCII character sets, which can have single symbols
(called "collating elements") that are represented with more than one
character. They can also have several characters that are equivalent for
"collating", or sorting, purposes.  (For example, in French, a plain "e"
and a grave-accented "e`" are equivalent.)  These sequences are:

Collating symbols
     Multicharacter collating elements enclosed between `[.' and `.]'.
     For example, if `ch' is a collating element, then `[[.ch.]]' is a
     regexp that matches this collating element, whereas `[ch]' is a
     regexp that matches either `c' or `h'.

Equivalence classes
     Locale-specific names for a list of characters that are equal. The
     name is enclosed between `[=' and `=]'.  For example, the name `e'
     might be used to represent all of "e," "e`," and "e'." In this
     case, `[[=e=]]' is a regexp that matches any of `e', `e'', or `e`'.

   These features are very valuable in non-English-speaking locales.

     CAUTION: The library functions that `gawk' uses for regular
     expression matching currently recognize only POSIX character
     classes; they do not recognize collating symbols or equivalence
     classes.


File: gawk.info,  Node: GNU Regexp Operators,  Next: Case-sensitivity,  Prev: Bracket Expressions,  Up: Regexp

3.5 `gawk'-Specific Regexp Operators
====================================

GNU software that deals with regular expressions provides a number of
additional regexp operators.  These operators are described in this
minor node and are specific to `gawk'; they are not available in other
`awk' implementations.  Most of the additional operators deal with word
matching.  For our purposes, a "word" is a sequence of one or more
letters, digits, or underscores (`_'):

`\s'
     Matches any whitespace character.  Think of it as shorthand for
     `[[:space:]]'.

`\S'
     Matches any character that is not whitespace.  Think of it as
     shorthand for `[^[:space:]]'.

`\w'
     Matches any word-constituent character--that is, it matches any
     letter, digit, or underscore. Think of it as shorthand for
     `[[:alnum:]_]'.

`\W'
     Matches any character that is not word-constituent.  Think of it
     as shorthand for `[^[:alnum:]_]'.

`\<'
     Matches the empty string at the beginning of a word.  For example,
     `/\<away/' matches `away' but not `stowaway'.

`\>'
     Matches the empty string at the end of a word.  For example,
     `/stow\>/' matches `stow' but not `stowaway'.

`\y'
     Matches the empty string at either the beginning or the end of a
     word (i.e., the word boundar*y*).  For example, `\yballs?\y'
     matches either `ball' or `balls', as a separate word.

`\B'
     Matches the empty string that occurs between two word-constituent
     characters. For example, `/\Brat\B/' matches `crate' but it does
     not match `dirty rat'.  `\B' is essentially the opposite of `\y'.

   There are two other operators that work on buffers.  In Emacs, a
"buffer" is, naturally, an Emacs buffer.  For other programs, `gawk''s
regexp library routines consider the entire string to match as the
buffer.  The operators are:

`\`'
     Matches the empty string at the beginning of a buffer (string).

`\''
     Matches the empty string at the end of a buffer (string).

   Because `^' and `$' always work in terms of the beginning and end of
strings, these operators don't add any new capabilities for `awk'.
They are provided for compatibility with other GNU software.

   In other GNU software, the word-boundary operator is `\b'. However,
that conflicts with the `awk' language's definition of `\b' as
backspace, so `gawk' uses a different letter.  An alternative method
would have been to require two backslashes in the GNU operators, but
this was deemed too confusing. The current method of using `\y' for the
GNU `\b' appears to be the lesser of two evils.

   The various command-line options (*note Options::) control how
`gawk' interprets characters in regexps:

No options
     In the default case, `gawk' provides all the facilities of POSIX
     regexps and the GNU regexp operators described in *note Regexp
     Operators::.

`--posix'
     Only POSIX regexps are supported; the GNU operators are not special
     (e.g., `\w' matches a literal `w').  Interval expressions are
     allowed.

`--traditional'
     Traditional Unix `awk' regexps are matched. The GNU operators are
     not special, and interval expressions are not available.  The
     POSIX character classes (`[[:alnum:]]', etc.) are supported, as
     Brian Kernighan's `awk' does support them.  Characters described
     by octal and hexadecimal escape sequences are treated literally,
     even if they represent regexp metacharacters.

`--re-interval'
     Allow interval expressions in regexps, if `--traditional' has been
     provided.  Otherwise, interval expressions are available by
     default.


File: gawk.info,  Node: Case-sensitivity,  Next: Leftmost Longest,  Prev: GNU Regexp Operators,  Up: Regexp

3.6 Case Sensitivity in Matching
================================

Case is normally significant in regular expressions, both when matching
ordinary characters (i.e., not metacharacters) and inside bracket
expressions.  Thus, a `w' in a regular expression matches only a
lowercase `w' and not an uppercase `W'.

   The simplest way to do a case-independent match is to use a bracket
expression--for example, `[Ww]'.  However, this can be cumbersome if
you need to use it often, and it can make the regular expressions harder
to read.  There are two alternatives that you might prefer.

   One way to perform a case-insensitive match at a particular point in
the program is to convert the data to a single case, using the
`tolower()' or `toupper()' built-in string functions (which we haven't
discussed yet; *note String Functions::).  For example:

     tolower($1) ~ /foo/  { ... }

converts the first field to lowercase before matching against it.  This
works in any POSIX-compliant `awk'.

   Another method, specific to `gawk', is to set the variable
`IGNORECASE' to a nonzero value (*note Built-in Variables::).  When
`IGNORECASE' is not zero, _all_ regexp and string operations ignore
case.  Changing the value of `IGNORECASE' dynamically controls the
case-sensitivity of the program as it runs.  Case is significant by
default because `IGNORECASE' (like most variables) is initialized to
zero:

     x = "aB"
     if (x ~ /ab/) ...   # this test will fail

     IGNORECASE = 1
     if (x ~ /ab/) ...   # now it will succeed

   In general, you cannot use `IGNORECASE' to make certain rules
case-insensitive and other rules case-sensitive, because there is no
straightforward way to set `IGNORECASE' just for the pattern of a
particular rule.(1) To do this, use either bracket expressions or
`tolower()'.  However, one thing you can do with `IGNORECASE' only is
dynamically turn case-sensitivity on or off for all the rules at once.

   `IGNORECASE' can be set on the command line or in a `BEGIN' rule
(*note Other Arguments::; also *note Using BEGIN/END::).  Setting
`IGNORECASE' from the command line is a way to make a program
case-insensitive without having to edit it.

   Both regexp and string comparison operations are affected by
`IGNORECASE'.

   In multibyte locales, the equivalences between upper- and lowercase
characters are tested based on the wide-character values of the
locale's character set.  Otherwise, the characters are tested based on
the ISO-8859-1 (ISO Latin-1) character set. This character set is a
superset of the traditional 128 ASCII characters, which also provides a
number of characters suitable for use with European languages.(2)

   The value of `IGNORECASE' has no effect if `gawk' is in
compatibility mode (*note Options::).  Case is always significant in
compatibility mode.

   ---------- Footnotes ----------

   (1) Experienced C and C++ programmers will note that it is possible,
using something like `IGNORECASE = 1 && /foObAr/ { ... }' and
`IGNORECASE = 0 || /foobar/ { ... }'.  However, this is somewhat
obscure and we don't recommend it.

   (2) If you don't understand this, don't worry about it; it just
means that `gawk' does the right thing.


File: gawk.info,  Node: Leftmost Longest,  Next: Computed Regexps,  Prev: Case-sensitivity,  Up: Regexp

3.7 How Much Text Matches?
==========================

Consider the following:

     echo aaaabcd | awk '{ sub(/a+/, "<A>"); print }'

   This example uses the `sub()' function (which we haven't discussed
yet; *note String Functions::) to make a change to the input record.
Here, the regexp `/a+/' indicates "one or more `a' characters," and the
replacement text is `<A>'.

   The input contains four `a' characters.  `awk' (and POSIX) regular
expressions always match the leftmost, _longest_ sequence of input
characters that can match.  Thus, all four `a' characters are replaced
with `<A>' in this example:

     $ echo aaaabcd | awk '{ sub(/a+/, "<A>"); print }'
     -| <A>bcd

   For simple match/no-match tests, this is not so important. But when
doing text matching and substitutions with the `match()', `sub()',
`gsub()', and `gensub()' functions, it is very important.  *Note String
Functions::, for more information on these functions.  Understanding
this principle is also important for regexp-based record and field
splitting (*note Records::, and also *note Field Separators::).


File: gawk.info,  Node: Computed Regexps,  Prev: Leftmost Longest,  Up: Regexp

3.8 Using Dynamic Regexps
=========================

The righthand side of a `~' or `!~' operator need not be a regexp
constant (i.e., a string of characters between slashes).  It may be any
expression.  The expression is evaluated and converted to a string if
necessary; the contents of the string are then used as the regexp.  A
regexp computed in this way is called a "dynamic regexp":

     BEGIN { digits_regexp = "[[:digit:]]+" }
     $0 ~ digits_regexp    { print }

This sets `digits_regexp' to a regexp that describes one or more digits,
and tests whether the input record matches this regexp.

     NOTE: When using the `~' and `!~' operators, there is a difference
     between a regexp constant enclosed in slashes and a string
     constant enclosed in double quotes.  If you are going to use a
     string constant, you have to understand that the string is, in
     essence, scanned _twice_: the first time when `awk' reads your
     program, and the second time when it goes to match the string on
     the lefthand side of the operator with the pattern on the right.
     This is true of any string-valued expression (such as
     `digits_regexp', shown previously), not just string constants.

   What difference does it make if the string is scanned twice? The
answer has to do with escape sequences, and particularly with
backslashes.  To get a backslash into a regular expression inside a
string, you have to type two backslashes.

   For example, `/\*/' is a regexp constant for a literal `*'.  Only
one backslash is needed.  To do the same thing with a string, you have
to type `"\\*"'.  The first backslash escapes the second one so that
the string actually contains the two characters `\' and `*'.

   Given that you can use both regexp and string constants to describe
regular expressions, which should you use?  The answer is "regexp
constants," for several reasons:

   * String constants are more complicated to write and more difficult
     to read. Using regexp constants makes your programs less
     error-prone.  Not understanding the difference between the two
     kinds of constants is a common source of errors.

   * It is more efficient to use regexp constants. `awk' can note that
     you have supplied a regexp and store it internally in a form that
     makes pattern matching more efficient.  When using a string
     constant, `awk' must first convert the string into this internal
     form and then perform the pattern matching.

   * Using regexp constants is better form; it shows clearly that you
     intend a regexp match.

Advanced Notes: Using `\n' in Bracket Expressions of Dynamic Regexps
--------------------------------------------------------------------

Some commercial versions of `awk' do not allow the newline character to
be used inside a bracket expression for a dynamic regexp:

     $ awk '$0 ~ "[ \t\n]"'
     error--> awk: newline in character class [
     error--> ]...
     error-->  source line number 1
     error-->  context is
     error-->          >>>  <<<

   But a newline in a regexp constant works with no problem:

     $ awk '$0 ~ /[ \t\n]/'
     here is a sample line
     -| here is a sample line
     Ctrl-d

   `gawk' does not have this problem, and it isn't likely to occur
often in practice, but it's worth noting for future reference.


File: gawk.info,  Node: Reading Files,  Next: Printing,  Prev: Regexp,  Up: Top

4 Reading Input Files
*********************

In the typical `awk' program, `awk' reads all input either from the
standard input (by default, this is the keyboard, but often it is a
pipe from another command) or from files whose names you specify on the
`awk' command line.  If you specify input files, `awk' reads them in
order, processing all the data from one before going on to the next.
The name of the current input file can be found in the built-in variable
`FILENAME' (*note Built-in Variables::).

   The input is read in units called "records", and is processed by the
rules of your program one record at a time.  By default, each record is
one line.  Each record is automatically split into chunks called
"fields".  This makes it more convenient for programs to work on the
parts of a record.

   On rare occasions, you may need to use the `getline' command.  The
`getline' command is valuable, both because it can do explicit input
from any number of files, and because the files used with it do not
have to be named on the `awk' command line (*note Getline::).

* Menu:

* Records::                     Controlling how data is split into records.
* Fields::                      An introduction to fields.
* Nonconstant Fields::          Nonconstant Field Numbers.
* Changing Fields::             Changing the Contents of a Field.
* Field Separators::            The field separator and how to change it.
* Constant Size::               Reading constant width data.
* Splitting By Content::        Defining Fields By Content
* Multiple Line::               Reading multi-line records.
* Getline::                     Reading files under explicit program control
                                using the `getline' function.
* Command line directories::    What happens if you put a directory on the
                                command line.


File: gawk.info,  Node: Records,  Next: Fields,  Up: Reading Files

4.1 How Input Is Split into Records
===================================

The `awk' utility divides the input for your `awk' program into records
and fields.  `awk' keeps track of the number of records that have been
read so far from the current input file.  This value is stored in a
built-in variable called `FNR'.  It is reset to zero when a new file is
started.  Another built-in variable, `NR', records the total number of
input records read so far from all data files.  It starts at zero, but
is never automatically reset to zero.

   Records are separated by a character called the "record separator".
By default, the record separator is the newline character.  This is why
records are, by default, single lines.  A different character can be
used for the record separator by assigning the character to the
built-in variable `RS'.

   Like any other variable, the value of `RS' can be changed in the
`awk' program with the assignment operator, `=' (*note Assignment
Ops::).  The new record-separator character should be enclosed in
quotation marks, which indicate a string constant.  Often the right
time to do this is at the beginning of execution, before any input is
processed, so that the very first record is read with the proper
separator.  To do this, use the special `BEGIN' pattern (*note
BEGIN/END::).  For example:

     awk 'BEGIN { RS = "/" }
          { print $0 }' BBS-list

changes the value of `RS' to `"/"', before reading any input.  This is
a string whose first character is a slash; as a result, records are
separated by slashes.  Then the input file is read, and the second rule
in the `awk' program (the action with no pattern) prints each record.
Because each `print' statement adds a newline at the end of its output,
this `awk' program copies the input with each slash changed to a
newline.  Here are the results of running the program on `BBS-list':

     $ awk 'BEGIN { RS = "/" }
     >      { print $0 }' BBS-list
     -| aardvark     555-5553     1200
     -| 300          B
     -| alpo-net     555-3412     2400
     -| 1200
     -| 300     A
     -| barfly       555-7685     1200
     -| 300          A
     -| bites        555-1675     2400
     -| 1200
     -| 300     A
     -| camelot      555-0542     300               C
     -| core         555-2912     1200
     -| 300          C
     -| fooey        555-1234     2400
     -| 1200
     -| 300     B
     -| foot         555-6699     1200
     -| 300          B
     -| macfoo       555-6480     1200
     -| 300          A
     -| sdace        555-3430     2400
     -| 1200
     -| 300     A
     -| sabafoo      555-2127     1200
     -| 300          C
     -|

Note that the entry for the `camelot' BBS is not split.  In the
original data file (*note Sample Data Files::), the line looks like
this:

     camelot      555-0542     300               C

It has one baud rate only, so there are no slashes in the record,
unlike the others which have two or more baud rates.  In fact, this
record is treated as part of the record for the `core' BBS; the newline
separating them in the output is the original newline in the data file,
not the one added by `awk' when it printed the record!

   Another way to change the record separator is on the command line,
using the variable-assignment feature (*note Other Arguments::):

     awk '{ print $0 }' RS="/" BBS-list

This sets `RS' to `/' before processing `BBS-list'.

   Using an unusual character such as `/' for the record separator
produces correct behavior in the vast majority of cases.  However, the
following (extreme) pipeline prints a surprising `1':

     $ echo | awk 'BEGIN { RS = "a" } ; { print NF }'
     -| 1

   There is one field, consisting of a newline.  The value of the
built-in variable `NF' is the number of fields in the current record.

   Reaching the end of an input file terminates the current input
record, even if the last character in the file is not the character in
`RS'.  (d.c.)

   The empty string `""' (a string without any characters) has a
special meaning as the value of `RS'. It means that records are
separated by one or more blank lines and nothing else.  *Note Multiple
Line::, for more details.

   If you change the value of `RS' in the middle of an `awk' run, the
new value is used to delimit subsequent records, but the record
currently being processed, as well as records already processed, are not
affected.

   After the end of the record has been determined, `gawk' sets the
variable `RT' to the text in the input that matched `RS'.

   When using `gawk', the value of `RS' is not limited to a
one-character string.  It can be any regular expression (*note
Regexp::). (c.e.)  In general, each record ends at the next string that
matches the regular expression; the next record starts at the end of
the matching string.  This general rule is actually at work in the
usual case, where `RS' contains just a newline: a record ends at the
beginning of the next matching string (the next newline in the input),
and the following record starts just after the end of this string (at
the first character of the following line).  The newline, because it
matches `RS', is not part of either record.

   When `RS' is a single character, `RT' contains the same single
character. However, when `RS' is a regular expression, `RT' contains
the actual input text that matched the regular expression.

   If the input file ended without any text that matches `RS', `gawk'
sets `RT' to the null string.

   The following example illustrates both of these features.  It sets
`RS' equal to a regular expression that matches either a newline or a
series of one or more uppercase letters with optional leading and/or
trailing whitespace:

     $ echo record 1 AAAA record 2 BBBB record 3 |
     > gawk 'BEGIN { RS = "\n|( *[[:upper:]]+ *)" }
     >             { print "Record =", $0, "and RT =", RT }'
     -| Record = record 1 and RT =  AAAA
     -| Record = record 2 and RT =  BBBB
     -| Record = record 3 and RT =
     -|

The final line of output has an extra blank line. This is because the
value of `RT' is a newline, and the `print' statement supplies its own
terminating newline.  *Note Simple Sed::, for a more useful example of
`RS' as a regexp and `RT'.

   If you set `RS' to a regular expression that allows optional
trailing text, such as `RS = "abc(XYZ)?"' it is possible, due to
implementation constraints, that `gawk' may match the leading part of
the regular expression, but not the trailing part, particularly if the
input text that could match the trailing part is fairly long.  `gawk'
attempts to avoid this problem, but currently, there's no guarantee
that this will never happen.

     NOTE: Remember that in `awk', the `^' and `$' anchor
     metacharacters match the beginning and end of a _string_, and not
     the beginning and end of a _line_.  As a result, something like
     `RS = "^[[:upper:]]"' can only match at the beginning of a file.
     This is because `gawk' views the input file as one long string
     that happens to contain newline characters in it.  It is thus best
     to avoid anchor characters in the value of `RS'.

   The use of `RS' as a regular expression and the `RT' variable are
`gawk' extensions; they are not available in compatibility mode (*note
Options::).  In compatibility mode, only the first character of the
value of `RS' is used to determine the end of the record.

Advanced Notes: `RS = "\0"' Is Not Portable
-------------------------------------------

There are times when you might want to treat an entire data file as a
single record.  The only way to make this happen is to give `RS' a
value that you know doesn't occur in the input file.  This is hard to
do in a general way, such that a program always works for arbitrary
input files.

   You might think that for text files, the NUL character, which
consists of a character with all bits equal to zero, is a good value to
use for `RS' in this case:

     BEGIN { RS = "\0" }  # whole file becomes one record?

   `gawk' in fact accepts this, and uses the NUL character for the
record separator.  However, this usage is _not_ portable to other `awk'
implementations.

   All other `awk' implementations(1) store strings internally as
C-style strings.  C strings use the NUL character as the string
terminator.  In effect, this means that `RS = "\0"' is the same as `RS
= ""'.  (d.c.)

   The best way to treat a whole file as a single record is to simply
read the file in, one record at a time, concatenating each record onto
the end of the previous ones.

   ---------- Footnotes ----------

   (1) At least that we know about.


File: gawk.info,  Node: Fields,  Next: Nonconstant Fields,  Prev: Records,  Up: Reading Files

4.2 Examining Fields
====================

When `awk' reads an input record, the record is automatically "parsed"
or separated by the `awk' utility into chunks called "fields".  By
default, fields are separated by "whitespace", like words in a line.
Whitespace in `awk' means any string of one or more spaces, TABs, or
newlines;(1) other characters, such as formfeed, vertical tab, etc.,
that are considered whitespace by other languages, are _not_ considered
whitespace by `awk'.

   The purpose of fields is to make it more convenient for you to refer
to these pieces of the record.  You don't have to use them--you can
operate on the whole record if you want--but fields are what make
simple `awk' programs so powerful.

   A dollar-sign (`$') is used to refer to a field in an `awk' program,
followed by the number of the field you want.  Thus, `$1' refers to the
first field, `$2' to the second, and so on.  (Unlike the Unix shells,
the field numbers are not limited to single digits.  `$127' is the one
hundred twenty-seventh field in the record.)  For example, suppose the
following is a line of input:

     This seems like a pretty nice example.

Here the first field, or `$1', is `This', the second field, or `$2', is
`seems', and so on.  Note that the last field, `$7', is `example.'.
Because there is no space between the `e' and the `.', the period is
considered part of the seventh field.

   `NF' is a built-in variable whose value is the number of fields in
the current record.  `awk' automatically updates the value of `NF' each
time it reads a record.  No matter how many fields there are, the last
field in a record can be represented by `$NF'.  So, `$NF' is the same
as `$7', which is `example.'.  If you try to reference a field beyond
the last one (such as `$8' when the record has only seven fields), you
get the empty string.  (If used in a numeric operation, you get zero.)

   The use of `$0', which looks like a reference to the "zero-th"
field, is a special case: it represents the whole input record when you
are not interested in specific fields.  Here are some more examples:

     $ awk '$1 ~ /foo/ { print $0 }' BBS-list
     -| fooey        555-1234     2400/1200/300     B
     -| foot         555-6699     1200/300          B
     -| macfoo       555-6480     1200/300          A
     -| sabafoo      555-2127     1200/300          C

This example prints each record in the file `BBS-list' whose first
field contains the string `foo'.  The operator `~' is called a
"matching operator" (*note Regexp Usage::); it tests whether a string
(here, the field `$1') matches a given regular expression.

   By contrast, the following example looks for `foo' in _the entire
record_ and prints the first field and the last field for each matching
input record:

     $ awk '/foo/ { print $1, $NF }' BBS-list
     -| fooey B
     -| foot B
     -| macfoo A
     -| sabafoo C

   ---------- Footnotes ----------

   (1) In POSIX `awk', newlines are not considered whitespace for
separating fields.


File: gawk.info,  Node: Nonconstant Fields,  Next: Changing Fields,  Prev: Fields,  Up: Reading Files

4.3 Nonconstant Field Numbers
=============================

The number of a field does not need to be a constant.  Any expression in
the `awk' language can be used after a `$' to refer to a field.  The
value of the expression specifies the field number.  If the value is a
string, rather than a number, it is converted to a number.  Consider
this example:

     awk '{ print $NR }'

Recall that `NR' is the number of records read so far: one in the first
record, two in the second, etc.  So this example prints the first field
of the first record, the second field of the second record, and so on.
For the twentieth record, field number 20 is printed; most likely, the
record has fewer than 20 fields, so this prints a blank line.  Here is
another example of using expressions as field numbers:

     awk '{ print $(2*2) }' BBS-list

   `awk' evaluates the expression `(2*2)' and uses its value as the
number of the field to print.  The `*' sign represents multiplication,
so the expression `2*2' evaluates to four.  The parentheses are used so
that the multiplication is done before the `$' operation; they are
necessary whenever there is a binary operator in the field-number
expression.  This example, then, prints the hours of operation (the
fourth field) for every line of the file `BBS-list'.  (All of the `awk'
operators are listed, in order of decreasing precedence, in *note
Precedence::.)

   If the field number you compute is zero, you get the entire record.
Thus, `$(2-2)' has the same value as `$0'.  Negative field numbers are
not allowed; trying to reference one usually terminates the program.
(The POSIX standard does not define what happens when you reference a
negative field number.  `gawk' notices this and terminates your
program.  Other `awk' implementations may behave differently.)

   As mentioned in *note Fields::, `awk' stores the current record's
number of fields in the built-in variable `NF' (also *note Built-in
Variables::).  The expression `$NF' is not a special feature--it is the
direct consequence of evaluating `NF' and using its value as a field
number.


File: gawk.info,  Node: Changing Fields,  Next: Field Separators,  Prev: Nonconstant Fields,  Up: Reading Files

4.4 Changing the Contents of a Field
====================================

The contents of a field, as seen by `awk', can be changed within an
`awk' program; this changes what `awk' perceives as the current input
record.  (The actual input is untouched; `awk' _never_ modifies the
input file.)  Consider the following example and its output:

     $ awk '{ nboxes = $3 ; $3 = $3 - 10
     >        print nboxes, $3 }' inventory-shipped
     -| 25 15
     -| 32 22
     -| 24 14
     ...

The program first saves the original value of field three in the
variable `nboxes'.  The `-' sign represents subtraction, so this
program reassigns field three, `$3', as the original value of field
three minus ten: `$3 - 10'.  (*Note Arithmetic Ops::.)  Then it prints
the original and new values for field three.  (Someone in the warehouse
made a consistent mistake while inventorying the red boxes.)

   For this to work, the text in field `$3' must make sense as a
number; the string of characters must be converted to a number for the
computer to do arithmetic on it.  The number resulting from the
subtraction is converted back to a string of characters that then
becomes field three.  *Note Conversion::.

   When the value of a field is changed (as perceived by `awk'), the
text of the input record is recalculated to contain the new field where
the old one was.  In other words, `$0' changes to reflect the altered
field.  Thus, this program prints a copy of the input file, with 10
subtracted from the second field of each line:

     $ awk '{ $2 = $2 - 10; print $0 }' inventory-shipped
     -| Jan 3 25 15 115
     -| Feb 5 32 24 226
     -| Mar 5 24 34 228
     ...

   It is also possible to also assign contents to fields that are out
of range.  For example:

     $ awk '{ $6 = ($5 + $4 + $3 + $2)
     >        print $6 }' inventory-shipped
     -| 168
     -| 297
     -| 301
     ...

We've just created `$6', whose value is the sum of fields `$2', `$3',
`$4', and `$5'.  The `+' sign represents addition.  For the file
`inventory-shipped', `$6' represents the total number of parcels
shipped for a particular month.

   Creating a new field changes `awk''s internal copy of the current
input record, which is the value of `$0'.  Thus, if you do `print $0'
after adding a field, the record printed includes the new field, with
the appropriate number of field separators between it and the previously
existing fields.

   This recomputation affects and is affected by `NF' (the number of
fields; *note Fields::).  For example, the value of `NF' is set to the
number of the highest field you create.  The exact format of `$0' is
also affected by a feature that has not been discussed yet: the "output
field separator", `OFS', used to separate the fields (*note Output
Separators::).

   Note, however, that merely _referencing_ an out-of-range field does
_not_ change the value of either `$0' or `NF'.  Referencing an
out-of-range field only produces an empty string.  For example:

     if ($(NF+1) != "")
         print "can't happen"
     else
         print "everything is normal"

should print `everything is normal', because `NF+1' is certain to be
out of range.  (*Note If Statement::, for more information about
`awk''s `if-else' statements.  *Note Typing and Comparison::, for more
information about the `!=' operator.)

   It is important to note that making an assignment to an existing
field changes the value of `$0' but does not change the value of `NF',
even when you assign the empty string to a field.  For example:

     $ echo a b c d | awk '{ OFS = ":"; $2 = ""
     >                       print $0; print NF }'
     -| a::c:d
     -| 4

The field is still there; it just has an empty value, denoted by the
two colons between `a' and `c'.  This example shows what happens if you
create a new field:

     $ echo a b c d | awk '{ OFS = ":"; $2 = ""; $6 = "new"
     >                       print $0; print NF }'
     -| a::c:d::new
     -| 6

The intervening field, `$5', is created with an empty value (indicated
by the second pair of adjacent colons), and `NF' is updated with the
value six.

   Decrementing `NF' throws away the values of the fields after the new
value of `NF' and recomputes `$0'.  (d.c.)  Here is an example:

     $ echo a b c d e f | awk '{ print "NF =", NF;
     >                            NF = 3; print $0 }'
     -| NF = 6
     -| a b c

     CAUTION: Some versions of `awk' don't rebuild `$0' when `NF' is
     decremented. Caveat emptor.

   Finally, there are times when it is convenient to force `awk' to
rebuild the entire record, using the current value of the fields and
`OFS'.  To do this, use the seemingly innocuous assignment:

     $1 = $1   # force record to be reconstituted
     print $0  # or whatever else with $0

This forces `awk' rebuild the record.  It does help to add a comment,
as we've shown here.

   There is a flip side to the relationship between `$0' and the
fields.  Any assignment to `$0' causes the record to be reparsed into
fields using the _current_ value of `FS'.  This also applies to any
built-in function that updates `$0', such as `sub()' and `gsub()'
(*note String Functions::).

Advanced Notes: Understanding `$0'
----------------------------------

It is important to remember that `$0' is the _full_ record, exactly as
it was read from the input.  This includes any leading or trailing
whitespace, and the exact whitespace (or other characters) that
separate the fields.

   It is a not-uncommon error to try to change the field separators in
a record simply by setting `FS' and `OFS', and then expecting a plain
`print' or `print $0' to print the modified record.

   But this does not work, since nothing was done to change the record
itself.  Instead, you must force the record to be rebuilt, typically
with a statement such as `$1 = $1', as described earlier.


File: gawk.info,  Node: Field Separators,  Next: Constant Size,  Prev: Changing Fields,  Up: Reading Files

4.5 Specifying How Fields Are Separated
=======================================

* Menu:

* Default Field Splitting::      How fields are normally separated.
* Regexp Field Splitting::       Using regexps as the field separator.
* Single Character Fields::      Making each character a separate field.
* Command Line Field Separator:: Setting `FS' from the command-line.
* Field Splitting Summary::      Some final points and a summary table.

   The "field separator", which is either a single character or a
regular expression, controls the way `awk' splits an input record into
fields.  `awk' scans the input record for character sequences that
match the separator; the fields themselves are the text between the
matches.

   In the examples that follow, we use the bullet symbol (*) to
represent spaces in the output.  If the field separator is `oo', then
the following line:

     moo goo gai pan

is split into three fields: `m', `*g', and `*gai*pan'.  Note the
leading spaces in the values of the second and third fields.

   The field separator is represented by the built-in variable `FS'.
Shell programmers take note:  `awk' does _not_ use the name `IFS' that
is used by the POSIX-compliant shells (such as the Unix Bourne shell,
`sh', or Bash).

   The value of `FS' can be changed in the `awk' program with the
assignment operator, `=' (*note Assignment Ops::).  Often the right
time to do this is at the beginning of execution before any input has
been processed, so that the very first record is read with the proper
separator.  To do this, use the special `BEGIN' pattern (*note
BEGIN/END::).  For example, here we set the value of `FS' to the string
`","':

     awk 'BEGIN { FS = "," } ; { print $2 }'

Given the input line:

     John Q. Smith, 29 Oak St., Walamazoo, MI 42139

this `awk' program extracts and prints the string `*29*Oak*St.'.

   Sometimes the input data contains separator characters that don't
separate fields the way you thought they would.  For instance, the
person's name in the example we just used might have a title or suffix
attached, such as:

     John Q. Smith, LXIX, 29 Oak St., Walamazoo, MI 42139

The same program would extract `*LXIX', instead of `*29*Oak*St.'.  If
you were expecting the program to print the address, you would be
surprised.  The moral is to choose your data layout and separator
characters carefully to prevent such problems.  (If the data is not in
a form that is easy to process, perhaps you can massage it first with a
separate `awk' program.)


File: gawk.info,  Node: Default Field Splitting,  Next: Regexp Field Splitting,  Up: Field Separators

4.5.1 Whitespace Normally Separates Fields
------------------------------------------

Fields are normally separated by whitespace sequences (spaces, TABs,
and newlines), not by single spaces.  Two spaces in a row do not
delimit an empty field.  The default value of the field separator `FS'
is a string containing a single space, `" "'.  If `awk' interpreted
this value in the usual way, each space character would separate
fields, so two spaces in a row would make an empty field between them.
The reason this does not happen is that a single space as the value of
`FS' is a special case--it is taken to specify the default manner of
delimiting fields.

   If `FS' is any other single character, such as `","', then each
occurrence of that character separates two fields.  Two consecutive
occurrences delimit an empty field.  If the character occurs at the
beginning or the end of the line, that too delimits an empty field.  The
space character is the only single character that does not follow these
rules.


File: gawk.info,  Node: Regexp Field Splitting,  Next: Single Character Fields,  Prev: Default Field Splitting,  Up: Field Separators

4.5.2 Using Regular Expressions to Separate Fields
--------------------------------------------------

The previous node discussed the use of single characters or simple
strings as the value of `FS'.  More generally, the value of `FS' may be
a string containing any regular expression.  In this case, each match
in the record for the regular expression separates fields.  For
example, the assignment:

     FS = ", \t"

makes every area of an input line that consists of a comma followed by a
space and a TAB into a field separator.  (`\t' is an "escape sequence"
that stands for a TAB; *note Escape Sequences::, for the complete list
of similar escape sequences.)

   For a less trivial example of a regular expression, try using single
spaces to separate fields the way single commas are used.  `FS' can be
set to `"[ ]"' (left bracket, space, right bracket).  This regular
expression matches a single space and nothing else (*note Regexp::).

   There is an important difference between the two cases of `FS = " "'
(a single space) and `FS = "[ \t\n]+"' (a regular expression matching
one or more spaces, TABs, or newlines).  For both values of `FS',
fields are separated by "runs" (multiple adjacent occurrences) of
spaces, TABs, and/or newlines.  However, when the value of `FS' is
`" "', `awk' first strips leading and trailing whitespace from the
record and then decides where the fields are.  For example, the
following pipeline prints `b':

     $ echo ' a b c d ' | awk '{ print $2 }'
     -| b

However, this pipeline prints `a' (note the extra spaces around each
letter):

     $ echo ' a  b  c  d ' | awk 'BEGIN { FS = "[ \t\n]+" }
     >                                  { print $2 }'
     -| a

In this case, the first field is "null" or empty.

   The stripping of leading and trailing whitespace also comes into
play whenever `$0' is recomputed.  For instance, study this pipeline:

     $ echo '   a b c d' | awk '{ print; $2 = $2; print }'
     -|    a b c d
     -| a b c d

The first `print' statement prints the record as it was read, with
leading whitespace intact.  The assignment to `$2' rebuilds `$0' by
concatenating `$1' through `$NF' together, separated by the value of
`OFS'.  Because the leading whitespace was ignored when finding `$1',
it is not part of the new `$0'.  Finally, the last `print' statement
prints the new `$0'.

   There is an additional subtlety to be aware of when using regular
expressions for field splitting.  It is not well-specified in the POSIX
standard, or anywhere else, what `^' means when splitting fields.  Does
the `^'  match only at the beginning of the entire record? Or is each
field separator a new string?  It turns out that different `awk'
versions answer this question differently, and you should not rely on
any specific behavior in your programs.  (d.c.)

   As a point of information, Brian Kernighan's `awk' allows `^' to
match only at the beginning of the record. `gawk' also works this way.
For example:

     $ echo 'xxAA  xxBxx  C' |
     > gawk -F '(^x+)|( +)' '{ for (i = 1; i <= NF; i++)
     >                                   printf "-->%s<--\n", $i }'
     -| --><--
     -| -->AA<--
     -| -->xxBxx<--
     -| -->C<--


File: gawk.info,  Node: Single Character Fields,  Next: Command Line Field Separator,  Prev: Regexp Field Splitting,  Up: Field Separators

4.5.3 Making Each Character a Separate Field
--------------------------------------------

There are times when you may want to examine each character of a record
separately.  This can be done in `gawk' by simply assigning the null
string (`""') to `FS'. (c.e.)  In this case, each individual character
in the record becomes a separate field.  For example:

     $ echo a b | gawk 'BEGIN { FS = "" }
     >                  {
     >                      for (i = 1; i <= NF; i = i + 1)
     >                          print "Field", i, "is", $i
     >                  }'
     -| Field 1 is a
     -| Field 2 is
     -| Field 3 is b

   Traditionally, the behavior of `FS' equal to `""' was not defined.
In this case, most versions of Unix `awk' simply treat the entire record
as only having one field.  (d.c.)  In compatibility mode (*note
Options::), if `FS' is the null string, then `gawk' also behaves this
way.


File: gawk.info,  Node: Command Line Field Separator,  Next: Field Splitting Summary,  Prev: Single Character Fields,  Up: Field Separators

4.5.4 Setting `FS' from the Command Line
----------------------------------------

`FS' can be set on the command line.  Use the `-F' option to do so.
For example:

     awk -F, 'PROGRAM' INPUT-FILES

sets `FS' to the `,' character.  Notice that the option uses an
uppercase `F' instead of a lowercase `f'. The latter option (`-f')
specifies a file containing an `awk' program.  Case is significant in
command-line options: the `-F' and `-f' options have nothing to do with
each other.  You can use both options at the same time to set the `FS'
variable _and_ get an `awk' program from a file.

   The value used for the argument to `-F' is processed in exactly the
same way as assignments to the built-in variable `FS'.  Any special
characters in the field separator must be escaped appropriately.  For
example, to use a `\' as the field separator on the command line, you
would have to type:

     # same as FS = "\\"
     awk -F\\\\ '...' files ...

Because `\' is used for quoting in the shell, `awk' sees `-F\\'.  Then
`awk' processes the `\\' for escape characters (*note Escape
Sequences::), finally yielding a single `\' to use for the field
separator.

   As a special case, in compatibility mode (*note Options::), if the
argument to `-F' is `t', then `FS' is set to the TAB character.  If you
type `-F\t' at the shell, without any quotes, the `\' gets deleted, so
`awk' figures that you really want your fields to be separated with
TABs and not `t's.  Use `-v FS="t"' or `-F"[t]"' on the command line if
you really do want to separate your fields with `t's.

   As an example, let's use an `awk' program file called `baud.awk'
that contains the pattern `/300/' and the action `print $1':

     /300/   { print $1 }

   Let's also set `FS' to be the `-' character and run the program on
the file `BBS-list'.  The following command prints a list of the names
of the bulletin boards that operate at 300 baud and the first three
digits of their phone numbers:

     $ awk -F- -f baud.awk BBS-list
     -| aardvark     555
     -| alpo
     -| barfly       555
     -| bites        555
     -| camelot      555
     -| core         555
     -| fooey        555
     -| foot         555
     -| macfoo       555
     -| sdace        555
     -| sabafoo      555

Note the second line of output.  The second line in the original file
looked like this:

     alpo-net     555-3412     2400/1200/300     A

   The `-' as part of the system's name was used as the field
separator, instead of the `-' in the phone number that was originally
intended.  This demonstrates why you have to be careful in choosing
your field and record separators.

   Perhaps the most common use of a single character as the field
separator occurs when processing the Unix system password file.  On
many Unix systems, each user has a separate entry in the system password
file, one line per user.  The information in these lines is separated
by colons.  The first field is the user's login name and the second is
the user's (encrypted or shadow) password.  A password file entry might
look like this:

     arnold:xyzzy:2076:10:Arnold Robbins:/home/arnold:/bin/bash

   The following program searches the system password file and prints
the entries for users who have no password:

     awk -F: '$2 == ""' /etc/passwd


File: gawk.info,  Node: Field Splitting Summary,  Prev: Command Line Field Separator,  Up: Field Separators

4.5.5 Field-Splitting Summary
-----------------------------

It is important to remember that when you assign a string constant as
the value of `FS', it undergoes normal `awk' string processing.  For
example, with Unix `awk' and `gawk', the assignment `FS = "\.."'
assigns the character string `".."' to `FS' (the backslash is
stripped).  This creates a regexp meaning "fields are separated by
occurrences of any two characters."  If instead you want fields to be
separated by a literal period followed by any single character, use `FS
= "\\.."'.

   The following table summarizes how fields are split, based on the
value of `FS' (`==' means "is equal to"):

`FS == " "'
     Fields are separated by runs of whitespace.  Leading and trailing
     whitespace are ignored.  This is the default.

`FS == ANY OTHER SINGLE CHARACTER'
     Fields are separated by each occurrence of the character.  Multiple
     successive occurrences delimit empty fields, as do leading and
     trailing occurrences.  The character can even be a regexp
     metacharacter; it does not need to be escaped.

`FS == REGEXP'
     Fields are separated by occurrences of characters that match
     REGEXP.  Leading and trailing matches of REGEXP delimit empty
     fields.

`FS == ""'
     Each individual character in the record becomes a separate field.
     (This is a `gawk' extension; it is not specified by the POSIX
     standard.)

Advanced Notes: Changing `FS' Does Not Affect the Fields
--------------------------------------------------------

According to the POSIX standard, `awk' is supposed to behave as if each
record is split into fields at the time it is read.  In particular,
this means that if you change the value of `FS' after a record is read,
the value of the fields (i.e., how they were split) should reflect the
old value of `FS', not the new one.

   However, many older implementations of `awk' do not work this way.
Instead, they defer splitting the fields until a field is actually
referenced.  The fields are split using the _current_ value of `FS'!
(d.c.)  This behavior can be difficult to diagnose. The following
example illustrates the difference between the two methods.  (The
`sed'(1) command prints just the first line of `/etc/passwd'.)

     sed 1q /etc/passwd | awk '{ FS = ":" ; print $1 }'

which usually prints:

     root

on an incorrect implementation of `awk', while `gawk' prints something
like:

     root:nSijPlPhZZwgE:0:0:Root:/:

Advanced Notes: `FS' and `IGNORECASE'
-------------------------------------

The `IGNORECASE' variable (*note User-modified::) affects field
splitting _only_ when the value of `FS' is a regexp.  It has no effect
when `FS' is a single character, even if that character is a letter.
Thus, in the following code:

     FS = "c"
     IGNORECASE = 1
     $0 = "aCa"
     print $1

The output is `aCa'.  If you really want to split fields on an
alphabetic character while ignoring case, use a regexp that will do it
for you.  E.g., `FS = "[c]"'.  In this case, `IGNORECASE' will take
effect.

   ---------- Footnotes ----------

   (1) The `sed' utility is a "stream editor."  Its behavior is also
defined by the POSIX standard.


File: gawk.info,  Node: Constant Size,  Next: Splitting By Content,  Prev: Field Separators,  Up: Reading Files

4.6 Reading Fixed-Width Data
============================

(This minor node discusses an advanced feature of `awk'.  If you are a
novice `awk' user, you might want to skip it on the first reading.)

`gawk' provides a facility for dealing with fixed-width fields with no
distinctive field separator.  For example, data of this nature arises
in the input for old Fortran programs where numbers are run together,
or in the output of programs that did not anticipate the use of their
output as input for other programs.

   An example of the latter is a table where all the columns are lined
up by the use of a variable number of spaces and _empty fields are just
spaces_.  Clearly, `awk''s normal field splitting based on `FS' does
not work well in this case.  Although a portable `awk' program can use
a series of `substr()' calls on `$0' (*note String Functions::), this
is awkward and inefficient for a large number of fields.

   The splitting of an input record into fixed-width fields is
specified by assigning a string containing space-separated numbers to
the built-in variable `FIELDWIDTHS'.  Each number specifies the width
of the field, _including_ columns between fields.  If you want to
ignore the columns between fields, you can specify the width as a
separate field that is subsequently ignored.  It is a fatal error to
supply a field width that is not a positive number.  The following data
is the output of the Unix `w' utility.  It is useful to illustrate the
use of `FIELDWIDTHS':

      10:06pm  up 21 days, 14:04,  23 users
     User     tty       login  idle   JCPU   PCPU  what
     hzuo     ttyV0     8:58pm            9      5  vi p24.tex
     hzang    ttyV3     6:37pm    50                -csh
     eklye    ttyV5     9:53pm            7      1  em thes.tex
     dportein ttyV6     8:17pm  1:47                -csh
     gierd    ttyD3    10:00pm     1                elm
     dave     ttyD4     9:47pm            4      4  w
     brent    ttyp0    26Jun91  4:46  26:46   4:41  bash
     dave     ttyq4    26Jun9115days     46     46  wnewmail

   The following program takes the above input, converts the idle time
to number of seconds, and prints out the first two fields and the
calculated idle time:

     NOTE: This program uses a number of `awk' features that haven't
     been introduced yet.

     BEGIN  { FIELDWIDTHS = "9 6 10 6 7 7 35" }
     NR > 2 {
         idle = $4
         sub(/^  */, "", idle)   # strip leading spaces
         if (idle == "")
             idle = 0
         if (idle ~ /:/) {
             split(idle, t, ":")
             idle = t[1] * 60 + t[2]
         }
         if (idle ~ /days/)
             idle *= 24 * 60 * 60

         print $1, $2, idle
     }

   Running the program on the data produces the following results:

     hzuo      ttyV0  0
     hzang     ttyV3  50
     eklye     ttyV5  0
     dportein  ttyV6  107
     gierd     ttyD3  1
     dave      ttyD4  0
     brent     ttyp0  286
     dave      ttyq4  1296000

   Another (possibly more practical) example of fixed-width input data
is the input from a deck of balloting cards.  In some parts of the
United States, voters mark their choices by punching holes in computer
cards.  These cards are then processed to count the votes for any
particular candidate or on any particular issue.  Because a voter may
choose not to vote on some issue, any column on the card may be empty.
An `awk' program for processing such data could use the `FIELDWIDTHS'
feature to simplify reading the data.  (Of course, getting `gawk' to
run on a system with card readers is another story!)

   Assigning a value to `FS' causes `gawk' to use `FS' for field
splitting again.  Use `FS = FS' to make this happen, without having to
know the current value of `FS'.  In order to tell which kind of field
splitting is in effect, use `PROCINFO["FS"]' (*note Auto-set::).  The
value is `"FS"' if regular field splitting is being used, or it is
`"FIELDWIDTHS"' if fixed-width field splitting is being used:

     if (PROCINFO["FS"] == "FS")
         REGULAR FIELD SPLITTING ...
     else if  (PROCINFO["FS"] == "FIELDWIDTHS")
         FIXED-WIDTH FIELD SPLITTING ...
     else
         CONTENT-BASED FIELD SPLITTING ... (see next minor node)

   This information is useful when writing a function that needs to
temporarily change `FS' or `FIELDWIDTHS', read some records, and then
restore the original settings (*note Passwd Functions::, for an example
of such a function).


File: gawk.info,  Node: Splitting By Content,  Next: Multiple Line,  Prev: Constant Size,  Up: Reading Files

4.7 Defining Fields By Content
==============================

(This minor node discusses an advanced feature of `awk'.  If you are a
novice `awk' user, you might want to skip it on the first reading.)

Normally, when using `FS', `gawk' defines the fields as the parts of
the record that occur in between each field separator. In other words,
`FS' defines what a field _is not_, instead of what a field _is_.
However, there are times when you really want to define the fields by
what they are, and not by what they are not.

   The most notorious such case is so-called "comma separated value"
(CSV) data. Many spreadsheet programs, for example, can export their
data into text files, where each record is terminated with a newline,
and fields are separated by commas. If only commas separated the data,
there wouldn't be an issue. The problem comes when one of the fields
contains an _embedded_ comma. While there is no formal standard
specification for CSV data(1), in such cases, most programs embed the
field in double quotes. So we might have data like this:

     Robbins,Arnold,"1234 A Pretty Street, NE",MyTown,MyState,12345-6789,USA

   The `FPAT' variable offers a solution for cases like this.  The
value of `FPAT' should be a string that provides a regular expression.
This regular expression describes the contents of each field.

   In the case of CSV data as presented above, each field is either
"anything that is not a comma," or "a double quote, anything that is
not a double quote, and a closing double quote."  If written as a
regular expression constant (*note Regexp::), we would have
`/([^,]+)|("[^"]+")/'.  Writing this as a string requires us to escape
the double quotes, leading to:

     FPAT = "([^,]+)|(\"[^\"]+\")"

   Putting this to use, here is a simple program to parse the data:

     BEGIN {
         FPAT = "([^,]+)|(\"[^\"]+\")"
     }

     {
         print "NF = ", NF
         for (i = 1; i <= NF; i++) {
             printf("$%d = <%s>\n", i, $i)
         }
     }

   When run, we get the following:

     $ gawk -f simple-csv.awk addresses.csv
     NF =  7
     $1 = <Robbins>
     $2 = <Arnold>
     $3 = <"1234 A Pretty Street, NE">
     $4 = <MyTown>
     $5 = <MyState>
     $6 = <12345-6789>
     $7 = <USA>

   Note the embedded comma in the value of `$3'.

   A straightforward improvement when processing CSV data of this sort
would be to remove the quotes when they occur, with something like this:

     if (substr($i, 1, 1) == "\"") {
         len = length($i)
         $i = substr($i, 2, len - 2)    # Get text within the two quotes
     }

   As with `FS', the `IGNORECASE' variable (*note User-modified::)
affects field splitting with `FPAT'.

   Similar to `FIELDWIDTHS', the value of `PROCINFO["FS"]' will be
`"FPAT"' if content-based field splitting is being used.

     NOTE: Some programs export CSV data that contains embedded
     newlines between the double quotes.  `gawk' provides no way to
     deal with this.  Since there is no formal specification for CSV
     data, there isn't much more to be done; the `FPAT' mechanism
     provides an elegant solution for the majority of cases, and the
     `gawk' maintainer is satisfied with that.

   As written, the regexp used for `FPAT' requires that each field have
a least one character.  A straightforward modification (changing
changed the first `+' to `*') allows fields to be empty:

     FPAT = "([^,]*)|(\"[^\"]+\")"

   Finally, the `patsplit()' function makes the same functionality
available for splitting regular strings (*note String Functions::).

   ---------- Footnotes ----------

   (1) At least, we don't know of one.


File: gawk.info,  Node: Multiple Line,  Next: Getline,  Prev: Splitting By Content,  Up: Reading Files

4.8 Multiple-Line Records
=========================

In some databases, a single line cannot conveniently hold all the
information in one entry.  In such cases, you can use multiline
records.  The first step in doing this is to choose your data format.

   One technique is to use an unusual character or string to separate
records.  For example, you could use the formfeed character (written
`\f' in `awk', as in C) to separate them, making each record a page of
the file.  To do this, just set the variable `RS' to `"\f"' (a string
containing the formfeed character).  Any other character could equally
well be used, as long as it won't be part of the data in a record.

   Another technique is to have blank lines separate records.  By a
special dispensation, an empty string as the value of `RS' indicates
that records are separated by one or more blank lines.  When `RS' is set
to the empty string, each record always ends at the first blank line
encountered.  The next record doesn't start until the first nonblank
line that follows.  No matter how many blank lines appear in a row, they
all act as one record separator.  (Blank lines must be completely
empty; lines that contain only whitespace do not count.)

   You can achieve the same effect as `RS = ""' by assigning the string
`"\n\n+"' to `RS'. This regexp matches the newline at the end of the
record and one or more blank lines after the record.  In addition, a
regular expression always matches the longest possible sequence when
there is a choice (*note Leftmost Longest::).  So the next record
doesn't start until the first nonblank line that follows--no matter how
many blank lines appear in a row, they are considered one record
separator.

   There is an important difference between `RS = ""' and `RS =
"\n\n+"'. In the first case, leading newlines in the input data file
are ignored, and if a file ends without extra blank lines after the
last record, the final newline is removed from the record.  In the
second case, this special processing is not done.  (d.c.)

   Now that the input is separated into records, the second step is to
separate the fields in the record.  One way to do this is to divide each
of the lines into fields in the normal manner.  This happens by default
as the result of a special feature.  When `RS' is set to the empty
string, _and_ `FS' is set to a single character, the newline character
_always_ acts as a field separator.  This is in addition to whatever
field separations result from `FS'.(1)

   The original motivation for this special exception was probably to
provide useful behavior in the default case (i.e., `FS' is equal to
`" "').  This feature can be a problem if you really don't want the
newline character to separate fields, because there is no way to
prevent it.  However, you can work around this by using the `split()'
function to break up the record manually (*note String Functions::).
If you have a single character field separator, you can work around the
special feature in a different way, by making `FS' into a regexp for
that single character.  For example, if the field separator is a
percent character, instead of `FS = "%"', use `FS = "[%]"'.

   Another way to separate fields is to put each field on a separate
line: to do this, just set the variable `FS' to the string `"\n"'.
(This single character separator matches a single newline.)  A
practical example of a data file organized this way might be a mailing
list, where each entry is separated by blank lines.  Consider a mailing
list in a file named `addresses', which looks like this:

     Jane Doe
     123 Main Street
     Anywhere, SE 12345-6789

     John Smith
     456 Tree-lined Avenue
     Smallville, MW 98765-4321
     ...

A simple program to process this file is as follows:

     # addrs.awk --- simple mailing list program

     # Records are separated by blank lines.
     # Each line is one field.
     BEGIN { RS = "" ; FS = "\n" }

     {
           print "Name is:", $1
           print "Address is:", $2
           print "City and State are:", $3
           print ""
     }

   Running the program produces the following output:

     $ awk -f addrs.awk addresses
     -| Name is: Jane Doe
     -| Address is: 123 Main Street
     -| City and State are: Anywhere, SE 12345-6789
     -|
     -| Name is: John Smith
     -| Address is: 456 Tree-lined Avenue
     -| City and State are: Smallville, MW 98765-4321
     -|
     ...

   *Note Labels Program::, for a more realistic program that deals with
address lists.  The following table summarizes how records are split,
based on the value of `RS'.  (`==' means "is equal to.")

`RS == "\n"'
     Records are separated by the newline character (`\n').  In effect,
     every line in the data file is a separate record, including blank
     lines.  This is the default.

`RS == ANY SINGLE CHARACTER'
     Records are separated by each occurrence of the character.
     Multiple successive occurrences delimit empty records.

`RS == ""'
     Records are separated by runs of blank lines.  When `FS' is a
     single character, then the newline character always serves as a
     field separator, in addition to whatever value `FS' may have.
     Leading and trailing newlines in a file are ignored.

`RS == REGEXP'
     Records are separated by occurrences of characters that match
     REGEXP.  Leading and trailing matches of REGEXP delimit empty
     records.  (This is a `gawk' extension; it is not specified by the
     POSIX standard.)

   In all cases, `gawk' sets `RT' to the input text that matched the
value specified by `RS'.  But if the input file ended without any text
that matches `RS', then `gawk' sets `RT' to the null string.

   ---------- Footnotes ----------

   (1) When `FS' is the null string (`""') or a regexp, this special
feature of `RS' does not apply.  It does apply to the default field
separator of a single space: `FS = " "'.


File: gawk.info,  Node: Getline,  Next: Command line directories,  Prev: Multiple Line,  Up: Reading Files

4.9 Explicit Input with `getline'
=================================

So far we have been getting our input data from `awk''s main input
stream--either the standard input (usually your terminal, sometimes the
output from another program) or from the files specified on the command
line.  The `awk' language has a special built-in command called
`getline' that can be used to read input under your explicit control.

   The `getline' command is used in several different ways and should
_not_ be used by beginners.  The examples that follow the explanation
of the `getline' command include material that has not been covered
yet.  Therefore, come back and study the `getline' command _after_ you
have reviewed the rest of this Info file and have a good knowledge of
how `awk' works.

   The `getline' command returns one if it finds a record and zero if
it encounters the end of the file.  If there is some error in getting a
record, such as a file that cannot be opened, then `getline' returns
-1.  In this case, `gawk' sets the variable `ERRNO' to a string
describing the error that occurred.

   In the following examples, COMMAND stands for a string value that
represents a shell command.

     NOTE: When `--sandbox' is specified (*note Options::), reading
     lines from files, pipes and coprocesses is disabled.

* Menu:

* Plain Getline::               Using `getline' with no arguments.
* Getline/Variable::            Using `getline' into a variable.
* Getline/File::                Using `getline' from a file.
* Getline/Variable/File::       Using `getline' into a variable from a
                                file.
* Getline/Pipe::                Using `getline' from a pipe.
* Getline/Variable/Pipe::       Using `getline' into a variable from a
                                pipe.
* Getline/Coprocess::           Using `getline' from a coprocess.
* Getline/Variable/Coprocess::  Using `getline' into a variable from a
                                coprocess.
* Getline Notes::               Important things to know about `getline'.
* Getline Summary::             Summary of `getline' Variants.


File: gawk.info,  Node: Plain Getline,  Next: Getline/Variable,  Up: Getline

4.9.1 Using `getline' with No Arguments
---------------------------------------

The `getline' command can be used without arguments to read input from
the current input file.  All it does in this case is read the next
input record and split it up into fields.  This is useful if you've
finished processing the current record, but want to do some special
processing on the next record _right now_.  For example:

     {
          if ((t = index($0, "/*")) != 0) {
               # value of `tmp' will be "" if t is 1
               tmp = substr($0, 1, t - 1)
               u = index(substr($0, t + 2), "*/")
               offset = t + 2
               while (u == 0) {
                    if (getline <= 0) {
                         m = "unexpected EOF or error"
                         m = (m ": " ERRNO)
                         print m > "/dev/stderr"
                         exit
                    }
                    u = index($0, "*/")
                    offset = 0
               }
               # substr() expression will be "" if */
               # occurred at end of line
               $0 = tmp substr($0, offset + u + 2)
          }
          print $0
     }

   This `awk' program deletes C-style comments (`/* ...  */') from the
input.  By replacing the `print $0' with other statements, you could
perform more complicated processing on the decommented input, such as
searching for matches of a regular expression.  (This program has a
subtle problem--it does not work if one comment ends and another begins
on the same line.)

   This form of the `getline' command sets `NF', `NR', `FNR', and the
value of `$0'.

     NOTE: The new value of `$0' is used to test the patterns of any
     subsequent rules.  The original value of `$0' that triggered the
     rule that executed `getline' is lost.  By contrast, the `next'
     statement reads a new record but immediately begins processing it
     normally, starting with the first rule in the program.  *Note Next
     Statement::.


File: gawk.info,  Node: Getline/Variable,  Next: Getline/File,  Prev: Plain Getline,  Up: Getline

4.9.2 Using `getline' into a Variable
-------------------------------------

You can use `getline VAR' to read the next record from `awk''s input
into the variable VAR.  No other processing is done.  For example,
suppose the next line is a comment or a special string, and you want to
read it without triggering any rules.  This form of `getline' allows
you to read that line and store it in a variable so that the main
read-a-line-and-check-each-rule loop of `awk' never sees it.  The
following example swaps every two lines of input:

     {
          if ((getline tmp) > 0) {
               print tmp
               print $0
          } else
               print $0
     }

It takes the following list:

     wan
     tew
     free
     phore

and produces these results:

     tew
     wan
     phore
     free

   The `getline' command used in this way sets only the variables `NR'
and `FNR' (and of course, VAR).  The record is not split into fields,
so the values of the fields (including `$0') and the value of `NF' do
not change.


File: gawk.info,  Node: Getline/File,  Next: Getline/Variable/File,  Prev: Getline/Variable,  Up: Getline

4.9.3 Using `getline' from a File
---------------------------------

Use `getline < FILE' to read the next record from FILE.  Here FILE is a
string-valued expression that specifies the file name.  `< FILE' is
called a "redirection" because it directs input to come from a
different place.  For example, the following program reads its input
record from the file `secondary.input' when it encounters a first field
with a value equal to 10 in the current input file:

     {
         if ($1 == 10) {
              getline < "secondary.input"
              print
         } else
              print
     }

   Because the main input stream is not used, the values of `NR' and
`FNR' are not changed. However, the record it reads is split into
fields in the normal manner, so the values of `$0' and the other fields
are changed, resulting in a new value of `NF'.

   According to POSIX, `getline < EXPRESSION' is ambiguous if
EXPRESSION contains unparenthesized operators other than `$'; for
example, `getline < dir "/" file' is ambiguous because the
concatenation operator is not parenthesized.  You should write it as
`getline < (dir "/" file)' if you want your program to be portable to
all `awk' implementations.


File: gawk.info,  Node: Getline/Variable/File,  Next: Getline/Pipe,  Prev: Getline/File,  Up: Getline

4.9.4 Using `getline' into a Variable from a File
-------------------------------------------------

Use `getline VAR < FILE' to read input from the file FILE, and put it
in the variable VAR.  As above, FILE is a string-valued expression that
specifies the file from which to read.

   In this version of `getline', none of the built-in variables are
changed and the record is not split into fields.  The only variable
changed is VAR.(1) For example, the following program copies all the
input files to the output, except for records that say
`@include FILENAME'.  Such a record is replaced by the contents of the
file FILENAME:

     {
          if (NF == 2 && $1 == "@include") {
               while ((getline line < $2) > 0)
                    print line
               close($2)
          } else
               print
     }

   Note here how the name of the extra input file is not built into the
program; it is taken directly from the data, specifically from the
second field on the `@include' line.

   The `close()' function is called to ensure that if two identical
`@include' lines appear in the input, the entire specified file is
included twice.  *Note Close Files And Pipes::.

   One deficiency of this program is that it does not process nested
`@include' statements (i.e., `@include' statements in included files)
the way a true macro preprocessor would.  *Note Igawk Program::, for a
program that does handle nested `@include' statements.

   ---------- Footnotes ----------

   (1) This is not quite true. `RT' could be changed if `RS' is a
regular expression.


File: gawk.info,  Node: Getline/Pipe,  Next: Getline/Variable/Pipe,  Prev: Getline/Variable/File,  Up: Getline

4.9.5 Using `getline' from a Pipe
---------------------------------

The output of a command can also be piped into `getline', using
`COMMAND | getline'.  In this case, the string COMMAND is run as a
shell command and its output is piped into `awk' to be used as input.
This form of `getline' reads one record at a time from the pipe.  For
example, the following program copies its input to its output, except
for lines that begin with `@execute', which are replaced by the output
produced by running the rest of the line as a shell command:

     {
          if ($1 == "@execute") {
               tmp = substr($0, 10)        # Remove "@execute"
               while ((tmp | getline) > 0)
                    print
               close(tmp)
          } else
               print
     }

The `close()' function is called to ensure that if two identical
`@execute' lines appear in the input, the command is run for each one.
*Note Close Files And Pipes::.  Given the input:

     foo
     bar
     baz
     @execute who
     bletch

the program might produce:

     foo
     bar
     baz
     arnold     ttyv0   Jul 13 14:22
     miriam     ttyp0   Jul 13 14:23     (murphy:0)
     bill       ttyp1   Jul 13 14:23     (murphy:0)
     bletch

Notice that this program ran the command `who' and printed the previous
result.  (If you try this program yourself, you will of course get
different results, depending upon who is logged in on your system.)

   This variation of `getline' splits the record into fields, sets the
value of `NF', and recomputes the value of `$0'.  The values of `NR'
and `FNR' are not changed.

   According to POSIX, `EXPRESSION | getline' is ambiguous if
EXPRESSION contains unparenthesized operators other than `$'--for
example, `"echo " "date" | getline' is ambiguous because the
concatenation operator is not parenthesized.  You should write it as
`("echo " "date") | getline' if you want your program to be portable to
all `awk' implementations.

     NOTE: Unfortunately, `gawk' has not been consistent in its
     treatment of a construct like `"echo " "date" | getline'.  Most
     versions, including the current version, treat it at as `("echo "
     "date") | getline'.  (This how Brian Kernighan's `awk' behaves.)
     Some versions changed and treated it as `"echo " ("date" |
     getline)'.  (This is how `mawk' behaves.)  In short, _always_ use
     explicit parentheses, and then you won't have to worry.


File: gawk.info,  Node: Getline/Variable/Pipe,  Next: Getline/Coprocess,  Prev: Getline/Pipe,  Up: Getline

4.9.6 Using `getline' into a Variable from a Pipe
-------------------------------------------------

When you use `COMMAND | getline VAR', the output of COMMAND is sent
through a pipe to `getline' and into the variable VAR.  For example, the
following program reads the current date and time into the variable
`current_time', using the `date' utility, and then prints it:

     BEGIN {
          "date" | getline current_time
          close("date")
          print "Report printed on " current_time
     }

   In this version of `getline', none of the built-in variables are
changed and the record is not split into fields.

   According to POSIX, `EXPRESSION | getline VAR' is ambiguous if
EXPRESSION contains unparenthesized operators other than `$'; for
example, `"echo " "date" | getline VAR' is ambiguous because the
concatenation operator is not parenthesized. You should write it as
`("echo " "date") | getline VAR' if you want your program to be
portable to other `awk' implementations.


File: gawk.info,  Node: Getline/Coprocess,  Next: Getline/Variable/Coprocess,  Prev: Getline/Variable/Pipe,  Up: Getline

4.9.7 Using `getline' from a Coprocess
--------------------------------------

Input into `getline' from a pipe is a one-way operation.  The command
that is started with `COMMAND | getline' only sends data _to_ your
`awk' program.

   On occasion, you might want to send data to another program for
processing and then read the results back.  `gawk' allows you to start
a "coprocess", with which two-way communications are possible.  This is
done with the `|&' operator.  Typically, you write data to the
coprocess first and then read results back, as shown in the following:

     print "SOME QUERY" |& "db_server"
     "db_server" |& getline

which sends a query to `db_server' and then reads the results.

   The values of `NR' and `FNR' are not changed, because the main input
stream is not used.  However, the record is split into fields in the
normal manner, thus changing the values of `$0', of the other fields,
and of `NF'.

   Coprocesses are an advanced feature. They are discussed here only
because this is the minor node on `getline'.  *Note Two-way I/O::,
where coprocesses are discussed in more detail.


File: gawk.info,  Node: Getline/Variable/Coprocess,  Next: Getline Notes,  Prev: Getline/Coprocess,  Up: Getline

4.9.8 Using `getline' into a Variable from a Coprocess
------------------------------------------------------

When you use `COMMAND |& getline VAR', the output from the coprocess
COMMAND is sent through a two-way pipe to `getline' and into the
variable VAR.

   In this version of `getline', none of the built-in variables are
changed and the record is not split into fields.  The only variable
changed is VAR.

   Coprocesses are an advanced feature. They are discussed here only
because this is the minor node on `getline'.  *Note Two-way I/O::,
where coprocesses are discussed in more detail.


File: gawk.info,  Node: Getline Notes,  Next: Getline Summary,  Prev: Getline/Variable/Coprocess,  Up: Getline

4.9.9 Points to Remember About `getline'
----------------------------------------

Here are some miscellaneous points about `getline' that you should bear
in mind:

   * When `getline' changes the value of `$0' and `NF', `awk' does
     _not_ automatically jump to the start of the program and start
     testing the new record against every pattern.  However, the new
     record is tested against any subsequent rules.

   * Many `awk' implementations limit the number of pipelines that an
     `awk' program may have open to just one.  In `gawk', there is no
     such limit.  You can open as many pipelines (and coprocesses) as
     the underlying operating system permits.

   * An interesting side effect occurs if you use `getline' without a
     redirection inside a `BEGIN' rule. Because an unredirected
     `getline' reads from the command-line data files, the first
     `getline' command causes `awk' to set the value of `FILENAME'.
     Normally, `FILENAME' does not have a value inside `BEGIN' rules,
     because you have not yet started to process the command-line data
     files.  (d.c.)  (*Note BEGIN/END::, also *note Auto-set::.)

   * Using `FILENAME' with `getline' (`getline < FILENAME') is likely
     to be a source for confusion.  `awk' opens a separate input stream
     from the current input file.  However, by not using a variable,
     `$0' and `NR' are still updated.  If you're doing this, it's
     probably by accident, and you should reconsider what it is you're
     trying to accomplish.

   * *note Getline Summary::, presents a table summarizing the
     `getline' variants and which variables they can affect.  It is
     worth noting that those variants which do not use redirection can
     cause `FILENAME' to be updated if they cause `awk' to start
     reading a new input file.


File: gawk.info,  Node: Getline Summary,  Prev: Getline Notes,  Up: Getline

4.9.10 Summary of `getline' Variants
------------------------------------

*note table-getline-variants:: summarizes the eight variants of
`getline', listing which built-in variables are set by each one, and
whether the variant is standard or a `gawk' extension.

Variant                  Effect                      Standard /
                                                     Extension
------------------------------------------------------------------------- 
`getline'                Sets `$0', `NF', `FNR',     Standard
                         and `NR'                    
`getline' VAR            Sets VAR, `FNR', and `NR'   Standard
`getline <' FILE         Sets `$0' and `NF'          Standard
`getline VAR < FILE'     Sets VAR                    Standard
COMMAND `| getline'      Sets `$0' and `NF'          Standard
COMMAND `| getline' VAR  Sets VAR                    Standard
COMMAND `|& getline'     Sets `$0' and `NF'          Extension
COMMAND `|& getline'     Sets VAR                    Extension
VAR                                                  

Table 4.1: getline Variants and What They Set


File: gawk.info,  Node: Command line directories,  Prev: Getline,  Up: Reading Files

4.10 Directories On The Command Line
====================================

According to the POSIX standard, files named on the `awk' command line
must be text files.  It is a fatal error if they are not.  Most
versions of `awk' treat a directory on the command line as a fatal
error.

   By default, `gawk' produces a warning for a directory on the command
line, but otherwise ignores it.  If either of the `--posix' or
`--traditional' options is given, then `gawk' reverts to treating a
directory on the command line as a fatal error.


File: gawk.info,  Node: Printing,  Next: Expressions,  Prev: Reading Files,  Up: Top

5 Printing Output
*****************

One of the most common programming actions is to "print", or output,
some or all of the input.  Use the `print' statement for simple output,
and the `printf' statement for fancier formatting.  The `print'
statement is not limited when computing _which_ values to print.
However, with two exceptions, you cannot specify _how_ to print
them--how many columns, whether to use exponential notation or not, and
so on.  (For the exceptions, *note Output Separators::, and *note
OFMT::.)  For printing with specifications, you need the `printf'
statement (*note Printf::).

   Besides basic and formatted printing, this major node also covers
I/O redirections to files and pipes, introduces the special file names
that `gawk' processes internally, and discusses the `close()' built-in
function.

* Menu:

* Print::                       The `print' statement.
* Print Examples::              Simple examples of `print' statements.
* Output Separators::           The output separators and how to change them.
* OFMT::                        Controlling Numeric Output With `print'.
* Printf::                      The `printf' statement.
* Redirection::                 How to redirect output to multiple files and
                                pipes.
* Special Files::               File name interpretation in `gawk'.
                                `gawk' allows access to inherited file
                                descriptors.
* Close Files And Pipes::       Closing Input and Output Files and Pipes.


File: gawk.info,  Node: Print,  Next: Print Examples,  Up: Printing

5.1 The `print' Statement
=========================

The `print' statement is used for producing output with simple,
standardized formatting.  Specify only the strings or numbers to print,
in a list separated by commas.  They are output, separated by single
spaces, followed by a newline.  The statement looks like this:

     print ITEM1, ITEM2, ...

The entire list of items may be optionally enclosed in parentheses.  The
parentheses are necessary if any of the item expressions uses the `>'
relational operator; otherwise it could be confused with an output
redirection (*note Redirection::).

   The items to print can be constant strings or numbers, fields of the
current record (such as `$1'), variables, or any `awk' expression.
Numeric values are converted to strings and then printed.

   The simple statement `print' with no items is equivalent to `print
$0': it prints the entire current record.  To print a blank line, use
`print ""', where `""' is the empty string.  To print a fixed piece of
text, use a string constant, such as `"Don't Panic"', as one item.  If
you forget to use the double-quote characters, your text is taken as an
`awk' expression, and you will probably get an error.  Keep in mind
that a space is printed between any two items.


File: gawk.info,  Node: Print Examples,  Next: Output Separators,  Prev: Print,  Up: Printing

5.2 `print' Statement Examples
==============================

Each `print' statement makes at least one line of output.  However, it
isn't limited to only one line.  If an item value is a string
containing a newline, the newline is output along with the rest of the
string.  A single `print' statement can make any number of lines this
way.

   The following is an example of printing a string that contains
embedded newlines (the `\n' is an escape sequence, used to represent
the newline character; *note Escape Sequences::):

     $ awk 'BEGIN { print "line one\nline two\nline three" }'
     -| line one
     -| line two
     -| line three

   The next example, which is run on the `inventory-shipped' file,
prints the first two fields of each input record, with a space between
them:

     $ awk '{ print $1, $2 }' inventory-shipped
     -| Jan 13
     -| Feb 15
     -| Mar 15
     ...

   A common mistake in using the `print' statement is to omit the comma
between two items.  This often has the effect of making the items run
together in the output, with no space.  The reason for this is that
juxtaposing two string expressions in `awk' means to concatenate them.
Here is the same program, without the comma:

     $ awk '{ print $1 $2 }' inventory-shipped
     -| Jan13
     -| Feb15
     -| Mar15
     ...

   To someone unfamiliar with the `inventory-shipped' file, neither
example's output makes much sense.  A heading line at the beginning
would make it clearer.  Let's add some headings to our table of months
(`$1') and green crates shipped (`$2').  We do this using the `BEGIN'
pattern (*note BEGIN/END::) so that the headings are only printed once:

     awk 'BEGIN {  print "Month Crates"
                   print "----- ------" }
                {  print $1, $2 }' inventory-shipped

When run, the program prints the following:

     Month Crates
     ----- ------
     Jan 13
     Feb 15
     Mar 15
     ...

The only problem, however, is that the headings and the table data
don't line up!  We can fix this by printing some spaces between the two
fields:

     awk 'BEGIN { print "Month Crates"
                  print "----- ------" }
                { print $1, "     ", $2 }' inventory-shipped

   Lining up columns this way can get pretty complicated when there are
many columns to fix.  Counting spaces for two or three columns is
simple, but any more than this can take up a lot of time. This is why
the `printf' statement was created (*note Printf::); one of its
specialties is lining up columns of data.

     NOTE: You can continue either a `print' or `printf' statement
     simply by putting a newline after any comma (*note
     Statements/Lines::).


File: gawk.info,  Node: Output Separators,  Next: OFMT,  Prev: Print Examples,  Up: Printing

5.3 Output Separators
=====================

As mentioned previously, a `print' statement contains a list of items
separated by commas.  In the output, the items are normally separated
by single spaces.  However, this doesn't need to be the case; a single
space is simply the default.  Any string of characters may be used as
the "output field separator" by setting the built-in variable `OFS'.
The initial value of this variable is the string `" "'--that is, a
single space.

   The output from an entire `print' statement is called an "output
record".  Each `print' statement outputs one output record, and then
outputs a string called the "output record separator" (or `ORS').  The
initial value of `ORS' is the string `"\n"'; i.e., a newline character.
Thus, each `print' statement normally makes a separate line.

   In order to change how output fields and records are separated,
assign new values to the variables `OFS' and `ORS'.  The usual place to
do this is in the `BEGIN' rule (*note BEGIN/END::), so that it happens
before any input is processed.  It can also be done with assignments on
the command line, before the names of the input files, or using the
`-v' command-line option (*note Options::).  The following example
prints the first and second fields of each input record, separated by a
semicolon, with a blank line added after each newline:

     $ awk 'BEGIN { OFS = ";"; ORS = "\n\n" }
     >            { print $1, $2 }' BBS-list
     -| aardvark;555-5553
     -|
     -| alpo-net;555-3412
     -|
     -| barfly;555-7685
     ...

   If the value of `ORS' does not contain a newline, the program's
output runs together on a single line.


File: gawk.info,  Node: OFMT,  Next: Printf,  Prev: Output Separators,  Up: Printing

5.4 Controlling Numeric Output with `print'
===========================================

When printing numeric values with the `print' statement, `awk'
internally converts the number to a string of characters and prints
that string.  `awk' uses the `sprintf()' function to do this conversion
(*note String Functions::).  For now, it suffices to say that the
`sprintf()' function accepts a "format specification" that tells it how
to format numbers (or strings), and that there are a number of
different ways in which numbers can be formatted.  The different format
specifications are discussed more fully in *note Control Letters::.

   The built-in variable `OFMT' contains the default format
specification that `print' uses with `sprintf()' when it wants to
convert a number to a string for printing.  The default value of `OFMT'
is `"%.6g"'.  The way `print' prints numbers can be changed by
supplying different format specifications as the value of `OFMT', as
shown in the following example:

     $ awk 'BEGIN {
     >   OFMT = "%.0f"  # print numbers as integers (rounds)
     >   print 17.23, 17.54 }'
     -| 17 18

According to the POSIX standard, `awk''s behavior is undefined if
`OFMT' contains anything but a floating-point conversion specification.
(d.c.)


File: gawk.info,  Node: Printf,  Next: Redirection,  Prev: OFMT,  Up: Printing

5.5 Using `printf' Statements for Fancier Printing
==================================================

For more precise control over the output format than what is provided
by `print', use `printf'.  With `printf' you can specify the width to
use for each item, as well as various formatting choices for numbers
(such as what output base to use, whether to print an exponent, whether
to print a sign, and how many digits to print after the decimal point).
You do this by supplying a string, called the "format string", that
controls how and where to print the other arguments.

* Menu:

* Basic Printf::                Syntax of the `printf' statement.
* Control Letters::             Format-control letters.
* Format Modifiers::            Format-specification modifiers.
* Printf Examples::             Several examples.


File: gawk.info,  Node: Basic Printf,  Next: Control Letters,  Up: Printf

5.5.1 Introduction to the `printf' Statement
--------------------------------------------

A simple `printf' statement looks like this:

     printf FORMAT, ITEM1, ITEM2, ...

The entire list of arguments may optionally be enclosed in parentheses.
The parentheses are necessary if any of the item expressions use the `>'
relational operator; otherwise, it can be confused with an output
redirection (*note Redirection::).

   The difference between `printf' and `print' is the FORMAT argument.
This is an expression whose value is taken as a string; it specifies
how to output each of the other arguments.  It is called the "format
string".

   The format string is very similar to that in the ISO C library
function `printf()'.  Most of FORMAT is text to output verbatim.
Scattered among this text are "format specifiers"--one per item.  Each
format specifier says to output the next item in the argument list at
that place in the format.

   The `printf' statement does not automatically append a newline to
its output.  It outputs only what the format string specifies.  So if a
newline is needed, you must include one in the format string.  The
output separator variables `OFS' and `ORS' have no effect on `printf'
statements. For example:

     $ awk 'BEGIN {
     >    ORS = "\nOUCH!\n"; OFS = "+"
     >    msg = "Dont Panic!"
     >    printf "%s\n", msg
     > }'
     -| Dont Panic!

Here, neither the `+' nor the `OUCH' appear in the output message.


File: gawk.info,  Node: Control Letters,  Next: Format Modifiers,  Prev: Basic Printf,  Up: Printf

5.5.2 Format-Control Letters
----------------------------

A format specifier starts with the character `%' and ends with a
"format-control letter"--it tells the `printf' statement how to output
one item.  The format-control letter specifies what _kind_ of value to
print.  The rest of the format specifier is made up of optional
"modifiers" that control _how_ to print the value, such as the field
width.  Here is a list of the format-control letters:

`%c'
     Print a number as an ASCII character; thus, `printf "%c", 65'
     outputs the letter `A'. The output for a string value is the first
     character of the string.

          NOTE: The POSIX standard says the first character of a string
          is printed.  In locales with multibyte characters, `gawk'
          attempts to convert the leading bytes of the string into a
          valid wide character and then to print the multibyte encoding
          of that character.  Similarly, when printing a numeric value,
          `gawk' allows the value to be within the numeric range of
          values that can be held in a wide character.

          Other `awk' versions generally restrict themselves to printing
          the first byte of a string or to numeric values within the
          range of a single byte (0-255).

`%d, %i'
     Print a decimal integer.  The two control letters are equivalent.
     (The `%i' specification is for compatibility with ISO C.)

`%e, %E'
     Print a number in scientific (exponential) notation; for example:

          printf "%4.3e\n", 1950

     prints `1.950e+03', with a total of four significant figures,
     three of which follow the decimal point.  (The `4.3' represents
     two modifiers, discussed in the next node.)  `%E' uses `E' instead
     of `e' in the output.

`%f'
     Print a number in floating-point notation.  For example:

          printf "%4.3f", 1950

     prints `1950.000', with a total of four significant figures, three
     of which follow the decimal point.  (The `4.3' represents two
     modifiers, discussed in the next node.)

     On systems supporting IEEE 754 floating point format, values
     representing negative infinity are formatted as `-inf' or
     `-infinity', and positive infinity as `inf' and `infinity'.  The
     special "not a number" value formats as `-nan' or `nan'.

`%F'
     Like `%f' but the infinity and "not a number" values are spelled
     using uppercase letters.

     The `%F' format is a POSIX extension to ISO C; not all systems
     support it.  On those that don't, `gawk' uses `%f' instead.

`%g, %G'
     Print a number in either scientific notation or in floating-point
     notation, whichever uses fewer characters; if the result is
     printed in scientific notation, `%G' uses `E' instead of `e'.

`%o'
     Print an unsigned octal integer (*note Nondecimal-numbers::).

`%s'
     Print a string.

`%u'
     Print an unsigned decimal integer.  (This format is of marginal
     use, because all numbers in `awk' are floating-point; it is
     provided primarily for compatibility with C.)

`%x, %X'
     Print an unsigned hexadecimal integer; `%X' uses the letters `A'
     through `F' instead of `a' through `f' (*note
     Nondecimal-numbers::).

`%%'
     Print a single `%'.  This does not consume an argument and it
     ignores any modifiers.

     NOTE: When using the integer format-control letters for values
     that are outside the range of the widest C integer type, `gawk'
     switches to the `%g' format specifier. If `--lint' is provided on
     the command line (*note Options::), `gawk' warns about this.
     Other versions of `awk' may print invalid values or do something
     else entirely.  (d.c.)


File: gawk.info,  Node: Format Modifiers,  Next: Printf Examples,  Prev: Control Letters,  Up: Printf

5.5.3 Modifiers for `printf' Formats
------------------------------------

A format specification can also include "modifiers" that can control
how much of the item's value is printed, as well as how much space it
gets.  The modifiers come between the `%' and the format-control letter.
We will use the bullet symbol "*" in the following examples to represent
spaces in the output. Here are the possible modifiers, in the order in
which they may appear:

`N$'
     An integer constant followed by a `$' is a "positional specifier".
     Normally, format specifications are applied to arguments in the
     order given in the format string.  With a positional specifier,
     the format specification is applied to a specific argument,
     instead of what would be the next argument in the list.
     Positional specifiers begin counting with one. Thus:

          printf "%s %s\n", "don't", "panic"
          printf "%2$s %1$s\n", "panic", "don't"

     prints the famous friendly message twice.

     At first glance, this feature doesn't seem to be of much use.  It
     is in fact a `gawk' extension, intended for use in translating
     messages at runtime.  *Note Printf Ordering::, which describes how
     and why to use positional specifiers.  For now, we will not use
     them.

`-'
     The minus sign, used before the width modifier (see later on in
     this list), says to left-justify the argument within its specified
     width.  Normally, the argument is printed right-justified in the
     specified width.  Thus:

          printf "%-4s", "foo"

     prints `foo*'.

`SPACE'
     For numeric conversions, prefix positive values with a space and
     negative values with a minus sign.

`+'
     The plus sign, used before the width modifier (see later on in
     this list), says to always supply a sign for numeric conversions,
     even if the data to format is positive. The `+' overrides the
     space modifier.

`#'
     Use an "alternate form" for certain control letters.  For `%o',
     supply a leading zero.  For `%x' and `%X', supply a leading `0x'
     or `0X' for a nonzero result.  For `%e', `%E', `%f', and `%F', the
     result always contains a decimal point.  For `%g' and `%G',
     trailing zeros are not removed from the result.

`0'
     A leading `0' (zero) acts as a flag that indicates that output
     should be padded with zeros instead of spaces.  This applies only
     to the numeric output formats.  This flag only has an effect when
     the field width is wider than the value to print.

`''
     A single quote or apostrophe character is a POSIX extension to ISO
     C.  It indicates that the integer part of a floating point value,
     or the entire part of an integer decimal value, should have a
     thousands-separator character in it.  This only works in locales
     that support such characters.  For example:

          $ cat thousands.awk          Show source program
          -| BEGIN { printf "%'d\n", 1234567 }
          $ LC_ALL=C gawk -f thousands.awk
          -| 1234567                   Results in "C" locale
          $ LC_ALL=en_US.UTF-8 gawk -f thousands.awk
          -| 1,234,567                 Results in US English UTF locale

     For more information about locales and internationalization issues,
     see *note Locales::.

          NOTE: The `'' flag is a nice feature, but its use complicates
          things: it becomes difficult to use it in command-line
          programs.  For information on appropriate quoting tricks, see
          *note Quoting::.

`WIDTH'
     This is a number specifying the desired minimum width of a field.
     Inserting any number between the `%' sign and the format-control
     character forces the field to expand to this width.  The default
     way to do this is to pad with spaces on the left.  For example:

          printf "%4s", "foo"

     prints `*foo'.

     The value of WIDTH is a minimum width, not a maximum.  If the item
     value requires more than WIDTH characters, it can be as wide as
     necessary.  Thus, the following:

          printf "%4s", "foobar"

     prints `foobar'.

     Preceding the WIDTH with a minus sign causes the output to be
     padded with spaces on the right, instead of on the left.

`.PREC'
     A period followed by an integer constant specifies the precision
     to use when printing.  The meaning of the precision varies by
     control letter:

    `%d', `%i', `%o', `%u', `%x', `%X'
          Minimum number of digits to print.

    `%e', `%E', `%f', `%F'
          Number of digits to the right of the decimal point.

    `%g', `%G'
          Maximum number of significant digits.

    `%s'
          Maximum number of characters from the string that should
          print.

     Thus, the following:

          printf "%.4s", "foobar"

     prints `foob'.

   The C library `printf''s dynamic WIDTH and PREC capability (for
example, `"%*.*s"') is supported.  Instead of supplying explicit WIDTH
and/or PREC values in the format string, they are passed in the
argument list.  For example:

     w = 5
     p = 3
     s = "abcdefg"
     printf "%*.*s\n", w, p, s

is exactly equivalent to:

     s = "abcdefg"
     printf "%5.3s\n", s

Both programs output `**abc'.  Earlier versions of `awk' did not
support this capability.  If you must use such a version, you may
simulate this feature by using concatenation to build up the format
string, like so:

     w = 5
     p = 3
     s = "abcdefg"
     printf "%" w "." p "s\n", s

This is not particularly easy to read but it does work.

   C programmers may be used to supplying additional `l', `L', and `h'
modifiers in `printf' format strings. These are not valid in `awk'.
Most `awk' implementations silently ignore them.  If `--lint' is
provided on the command line (*note Options::), `gawk' warns about
their use. If `--posix' is supplied, their use is a fatal error.


File: gawk.info,  Node: Printf Examples,  Prev: Format Modifiers,  Up: Printf

5.5.4 Examples Using `printf'
-----------------------------

The following simple example shows how to use `printf' to make an
aligned table:

     awk '{ printf "%-10s %s\n", $1, $2 }' BBS-list

This command prints the names of the bulletin boards (`$1') in the file
`BBS-list' as a string of 10 characters that are left-justified.  It
also prints the phone numbers (`$2') next on the line.  This produces
an aligned two-column table of names and phone numbers, as shown here:

     $ awk '{ printf "%-10s %s\n", $1, $2 }' BBS-list
     -| aardvark   555-5553
     -| alpo-net   555-3412
     -| barfly     555-7685
     -| bites      555-1675
     -| camelot    555-0542
     -| core       555-2912
     -| fooey      555-1234
     -| foot       555-6699
     -| macfoo     555-6480
     -| sdace      555-3430
     -| sabafoo    555-2127

   In this case, the phone numbers had to be printed as strings because
the numbers are separated by a dash.  Printing the phone numbers as
numbers would have produced just the first three digits: `555'.  This
would have been pretty confusing.

   It wasn't necessary to specify a width for the phone numbers because
they are last on their lines.  They don't need to have spaces after
them.

   The table could be made to look even nicer by adding headings to the
tops of the columns.  This is done using the `BEGIN' pattern (*note
BEGIN/END::) so that the headers are only printed once, at the
beginning of the `awk' program:

     awk 'BEGIN { print "Name      Number"
                  print "----      ------" }
          { printf "%-10s %s\n", $1, $2 }' BBS-list

   The above example mixes `print' and `printf' statements in the same
program.  Using just `printf' statements can produce the same results:

     awk 'BEGIN { printf "%-10s %s\n", "Name", "Number"
                  printf "%-10s %s\n", "----", "------" }
          { printf "%-10s %s\n", $1, $2 }' BBS-list

Printing each column heading with the same format specification used
for the column elements ensures that the headings are aligned just like
the columns.

   The fact that the same format specification is used three times can
be emphasized by storing it in a variable, like this:

     awk 'BEGIN { format = "%-10s %s\n"
                  printf format, "Name", "Number"
                  printf format, "----", "------" }
          { printf format, $1, $2 }' BBS-list

   At this point, it would be a worthwhile exercise to use the `printf'
statement to line up the headings and table data for the
`inventory-shipped' example that was covered earlier in the minor node
on the `print' statement (*note Print::).


File: gawk.info,  Node: Redirection,  Next: Special Files,  Prev: Printf,  Up: Printing

5.6 Redirecting Output of `print' and `printf'
==============================================

So far, the output from `print' and `printf' has gone to the standard
output, usually the screen.  Both `print' and `printf' can also send
their output to other places.  This is called "redirection".

     NOTE: When `--sandbox' is specified (*note Options::), redirecting
     output to files and pipes is disabled.

   A redirection appears after the `print' or `printf' statement.
Redirections in `awk' are written just like redirections in shell
commands, except that they are written inside the `awk' program.

   There are four forms of output redirection: output to a file, output
appended to a file, output through a pipe to another command, and output
to a coprocess.  They are all shown for the `print' statement, but they
work identically for `printf':

`print ITEMS > OUTPUT-FILE'
     This redirection prints the items into the output file named
     OUTPUT-FILE.  The file name OUTPUT-FILE can be any expression.
     Its value is changed to a string and then used as a file name
     (*note Expressions::).

     When this type of redirection is used, the OUTPUT-FILE is erased
     before the first output is written to it.  Subsequent writes to
     the same OUTPUT-FILE do not erase OUTPUT-FILE, but append to it.
     (This is different from how you use redirections in shell scripts.)
     If OUTPUT-FILE does not exist, it is created.  For example, here
     is how an `awk' program can write a list of BBS names to one file
     named `name-list', and a list of phone numbers to another file
     named `phone-list':

          $ awk '{ print $2 > "phone-list"
          >        print $1 > "name-list" }' BBS-list
          $ cat phone-list
          -| 555-5553
          -| 555-3412
          ...
          $ cat name-list
          -| aardvark
          -| alpo-net
          ...

     Each output file contains one name or number per line.

`print ITEMS >> OUTPUT-FILE'
     This redirection prints the items into the pre-existing output file
     named OUTPUT-FILE.  The difference between this and the single-`>'
     redirection is that the old contents (if any) of OUTPUT-FILE are
     not erased.  Instead, the `awk' output is appended to the file.
     If OUTPUT-FILE does not exist, then it is created.

`print ITEMS | COMMAND'
     It is possible to send output to another program through a pipe
     instead of into a file.   This redirection opens a pipe to
     COMMAND, and writes the values of ITEMS through this pipe to
     another process created to execute COMMAND.

     The redirection argument COMMAND is actually an `awk' expression.
     Its value is converted to a string whose contents give the shell
     command to be run.  For example, the following produces two files,
     one unsorted list of BBS names, and one list sorted in reverse
     alphabetical order:

          awk '{ print $1 > "names.unsorted"
                 command = "sort -r > names.sorted"
                 print $1 | command }' BBS-list

     The unsorted list is written with an ordinary redirection, while
     the sorted list is written by piping through the `sort' utility.

     The next example uses redirection to mail a message to the mailing
     list `bug-system'.  This might be useful when trouble is
     encountered in an `awk' script run periodically for system
     maintenance:

          report = "mail bug-system"
          print "Awk script failed:", $0 | report
          m = ("at record number " FNR " of " FILENAME)
          print m | report
          close(report)

     The message is built using string concatenation and saved in the
     variable `m'.  It's then sent down the pipeline to the `mail'
     program.  (The parentheses group the items to concatenate--see
     *note Concatenation::.)

     The `close()' function is called here because it's a good idea to
     close the pipe as soon as all the intended output has been sent to
     it.  *Note Close Files And Pipes::, for more information.

     This example also illustrates the use of a variable to represent a
     FILE or COMMAND--it is not necessary to always use a string
     constant.  Using a variable is generally a good idea, because (if
     you mean to refer to that same file or command) `awk' requires
     that the string value be spelled identically every time.

`print ITEMS |& COMMAND'
     This redirection prints the items to the input of COMMAND.  The
     difference between this and the single-`|' redirection is that the
     output from COMMAND can be read with `getline'.  Thus COMMAND is a
     "coprocess", which works together with, but subsidiary to, the
     `awk' program.

     This feature is a `gawk' extension, and is not available in POSIX
     `awk'.  *Note Getline/Coprocess::, for a brief discussion.  *Note
     Two-way I/O::, for a more complete discussion.

   Redirecting output using `>', `>>', `|', or `|&' asks the system to
open a file, pipe, or coprocess only if the particular FILE or COMMAND
you specify has not already been written to by your program or if it
has been closed since it was last written to.

   It is a common error to use `>' redirection for the first `print' to
a file, and then to use `>>' for subsequent output:

     # clear the file
     print "Don't panic" > "guide.txt"
     ...
     # append
     print "Avoid improbability generators" >> "guide.txt"

This is indeed how redirections must be used from the shell.  But in
`awk', it isn't necessary.  In this kind of case, a program should use
`>' for all the `print' statements, since the output file is only
opened once. (It happens that if you mix `>' and `>>' that output is
produced in the expected order. However, mixing the operators for the
same file is definitely poor style, and is confusing to readers of your
program.)

   Many older `awk' implementations limit the number of pipelines that
an `awk' program may have open to just one!  In `gawk', there is no
such limit.  `gawk' allows a program to open as many pipelines as the
underlying operating system permits.

Advanced Notes: Piping into `sh'
--------------------------------

A particularly powerful way to use redirection is to build command lines
and pipe them into the shell, `sh'.  For example, suppose you have a
list of files brought over from a system where all the file names are
stored in uppercase, and you wish to rename them to have names in all
lowercase.  The following program is both simple and efficient:

     { printf("mv %s %s\n", $0, tolower($0)) | "sh" }

     END { close("sh") }

   The `tolower()' function returns its argument string with all
uppercase characters converted to lowercase (*note String Functions::).
The program builds up a list of command lines, using the `mv' utility
to rename the files.  It then sends the list to the shell for execution.


File: gawk.info,  Node: Special Files,  Next: Close Files And Pipes,  Prev: Redirection,  Up: Printing

5.7 Special File Names in `gawk'
================================

`gawk' provides a number of special file names that it interprets
internally.  These file names provide access to standard file
descriptors and TCP/IP networking.

* Menu:

* Special FD::                  Special files for I/O.
* Special Network::             Special files for network communications.
* Special Caveats::             Things to watch out for.


File: gawk.info,  Node: Special FD,  Next: Special Network,  Up: Special Files

5.7.1 Special Files for Standard Descriptors
--------------------------------------------

Running programs conventionally have three input and output streams
already available to them for reading and writing.  These are known as
the "standard input", "standard output", and "standard error output".
These streams are, by default, connected to your keyboard and screen,
but they are often redirected with the shell, via the `<', `<<', `>',
`>>', `>&', and `|' operators.  Standard error is typically used for
writing error messages; the reason there are two separate streams,
standard output and standard error, is so that they can be redirected
separately.

   In other implementations of `awk', the only way to write an error
message to standard error in an `awk' program is as follows:

     print "Serious error detected!" | "cat 1>&2"

This works by opening a pipeline to a shell command that can access the
standard error stream that it inherits from the `awk' process.  This is
far from elegant, and it is also inefficient, because it requires a
separate process.  So people writing `awk' programs often don't do
this.  Instead, they send the error messages to the screen, like this:

     print "Serious error detected!" > "/dev/tty"

(`/dev/tty' is a special file supplied by the operating system that is
connected to your keyboard and screen. It represents the "terminal,"(1)
which on modern systems is a keyboard and screen, not a serial console.)
This usually has the same effect but not always: although the standard
error stream is usually the screen, it can be redirected; when that
happens, writing to the screen is not correct.  In fact, if `awk' is
run from a background job, it may not have a terminal at all.  Then
opening `/dev/tty' fails.

   `gawk' provides special file names for accessing the three standard
streams. (c.e.). It also provides syntax for accessing any other
inherited open files.  If the file name matches one of these special
names when `gawk' redirects input or output, then it directly uses the
stream that the file name stands for.  These special file names work
for all operating systems that `gawk' has been ported to, not just
those that are POSIX-compliant:

`/dev/stdin'
     The standard input (file descriptor 0).

`/dev/stdout'
     The standard output (file descriptor 1).

`/dev/stderr'
     The standard error output (file descriptor 2).

`/dev/fd/N'
     The file associated with file descriptor N.  Such a file must be
     opened by the program initiating the `awk' execution (typically
     the shell).  Unless special pains are taken in the shell from which
     `gawk' is invoked, only descriptors 0, 1, and 2 are available.

   The file names `/dev/stdin', `/dev/stdout', and `/dev/stderr' are
aliases for `/dev/fd/0', `/dev/fd/1', and `/dev/fd/2', respectively.
However, they are more self-explanatory.  The proper way to write an
error message in a `gawk' program is to use `/dev/stderr', like this:

     print "Serious error detected!" > "/dev/stderr"

   Note the use of quotes around the file name.  Like any other
redirection, the value must be a string.  It is a common error to omit
the quotes, which leads to confusing results.

   Finally, using the `close()' function on a file name of the form
`"/dev/fd/N"', for file descriptor numbers above two, will actually
close the given file descriptor.

   The `/dev/stdin', `/dev/stdout', and `/dev/stderr' special files are
also recognized internally by several other versions of `awk'.

   ---------- Footnotes ----------

   (1) The "tty" in `/dev/tty' stands for "Teletype," a serial terminal.


File: gawk.info,  Node: Special Network,  Next: Special Caveats,  Prev: Special FD,  Up: Special Files

5.7.2 Special Files for Network Communications
----------------------------------------------

`gawk' programs can open a two-way TCP/IP connection, acting as either
a client or a server.  This is done using a special file name of the
form:

     `/NET-TYPE/PROTOCOL/LOCAL-PORT/REMOTE-HOST/REMOTE-PORT'

   The NET-TYPE is one of `inet', `inet4' or `inet6'.  The PROTOCOL is
one of `tcp' or `udp', and the other fields represent the other
essential pieces of information for making a networking connection.
These file names are used with the `|&' operator for communicating with
a coprocess (*note Two-way I/O::).  This is an advanced feature,
mentioned here only for completeness.  Full discussion is delayed until
*note TCP/IP Networking::.


File: gawk.info,  Node: Special Caveats,  Prev: Special Network,  Up: Special Files

5.7.3 Special File Name Caveats
-------------------------------

Here is a list of things to bear in mind when using the special file
names that `gawk' provides:

   * Recognition of these special file names is disabled if `gawk' is in
     compatibility mode (*note Options::).

   * `gawk' _always_ interprets these special file names.  For example,
     using `/dev/fd/4' for output actually writes on file descriptor 4,
     and not on a new file descriptor that is `dup()''ed from file
     descriptor 4.  Most of the time this does not matter; however, it
     is important to _not_ close any of the files related to file
     descriptors 0, 1, and 2.  Doing so results in unpredictable
     behavior.


File: gawk.info,  Node: Close Files And Pipes,  Prev: Special Files,  Up: Printing

5.8 Closing Input and Output Redirections
=========================================

If the same file name or the same shell command is used with `getline'
more than once during the execution of an `awk' program (*note
Getline::), the file is opened (or the command is executed) the first
time only.  At that time, the first record of input is read from that
file or command.  The next time the same file or command is used with
`getline', another record is read from it, and so on.

   Similarly, when a file or pipe is opened for output, `awk' remembers
the file name or command associated with it, and subsequent writes to
the same file or command are appended to the previous writes.  The file
or pipe stays open until `awk' exits.

   This implies that special steps are necessary in order to read the
same file again from the beginning, or to rerun a shell command (rather
than reading more output from the same command).  The `close()' function
makes these things possible:

     close(FILENAME)

or:

     close(COMMAND)

   The argument FILENAME or COMMAND can be any expression.  Its value
must _exactly_ match the string that was used to open the file or start
the command (spaces and other "irrelevant" characters included). For
example, if you open a pipe with this:

     "sort -r names" | getline foo

then you must close it with this:

     close("sort -r names")

   Once this function call is executed, the next `getline' from that
file or command, or the next `print' or `printf' to that file or
command, reopens the file or reruns the command.  Because the
expression that you use to close a file or pipeline must exactly match
the expression used to open the file or run the command, it is good
practice to use a variable to store the file name or command.  The
previous example becomes the following:

     sortcom = "sort -r names"
     sortcom | getline foo
     ...
     close(sortcom)

This helps avoid hard-to-find typographical errors in your `awk'
programs.  Here are some of the reasons for closing an output file:

   * To write a file and read it back later on in the same `awk'
     program.  Close the file after writing it, then begin reading it
     with `getline'.

   * To write numerous files, successively, in the same `awk' program.
     If the files aren't closed, eventually `awk' may exceed a system
     limit on the number of open files in one process.  It is best to
     close each one when the program has finished writing it.

   * To make a command finish.  When output is redirected through a
     pipe, the command reading the pipe normally continues to try to
     read input as long as the pipe is open.  Often this means the
     command cannot really do its work until the pipe is closed.  For
     example, if output is redirected to the `mail' program, the
     message is not actually sent until the pipe is closed.

   * To run the same program a second time, with the same arguments.
     This is not the same thing as giving more input to the first run!

     For example, suppose a program pipes output to the `mail' program.
     If it outputs several lines redirected to this pipe without closing
     it, they make a single message of several lines.  By contrast, if
     the program closes the pipe after each line of output, then each
     line makes a separate message.

   If you use more files than the system allows you to have open,
`gawk' attempts to multiplex the available open files among your data
files.  `gawk''s ability to do this depends upon the facilities of your
operating system, so it may not always work.  It is therefore both good
practice and good portability advice to always use `close()' on your
files when you are done with them.  In fact, if you are using a lot of
pipes, it is essential that you close commands when done. For example,
consider something like this:

     {
         ...
         command = ("grep " $1 " /some/file | my_prog -q " $3)
         while ((command | getline) > 0) {
             PROCESS OUTPUT OF command
         }
         # need close(command) here
     }

   This example creates a new pipeline based on data in _each_ record.
Without the call to `close()' indicated in the comment, `awk' creates
child processes to run the commands, until it eventually runs out of
file descriptors for more pipelines.

   Even though each command has finished (as indicated by the
end-of-file return status from `getline'), the child process is not
terminated;(1) more importantly, the file descriptor for the pipe is
not closed and released until `close()' is called or `awk' exits.

   `close()' will silently do nothing if given an argument that does
not represent a file, pipe or coprocess that was opened with a
redirection.

   Note also that `close(FILENAME)' has no "magic" effects on the
implicit loop that reads through the files named on the command line.
It is, more likely, a close of a file that was never opened, so `awk'
silently does nothing.

   When using the `|&' operator to communicate with a coprocess, it is
occasionally useful to be able to close one end of the two-way pipe
without closing the other.  This is done by supplying a second argument
to `close()'.  As in any other call to `close()', the first argument is
the name of the command or special file used to start the coprocess.
The second argument should be a string, with either of the values
`"to"' or `"from"'.  Case does not matter.  As this is an advanced
feature, a more complete discussion is delayed until *note Two-way
I/O::, which discusses it in more detail and gives an example.

Advanced Notes: Using `close()''s Return Value
----------------------------------------------

In many versions of Unix `awk', the `close()' function is actually a
statement.  It is a syntax error to try and use the return value from
`close()': (d.c.)

     command = "..."
     command | getline info
     retval = close(command)  # syntax error in many Unix awks

   `gawk' treats `close()' as a function.  The return value is -1 if
the argument names something that was never opened with a redirection,
or if there is a system problem closing the file or process.  In these
cases, `gawk' sets the built-in variable `ERRNO' to a string describing
the problem.

   In `gawk', when closing a pipe or coprocess (input or output), the
return value is the exit status of the command.(2) Otherwise, it is the
return value from the system's `close()' or `fclose()' C functions when
closing input or output files, respectively.  This value is zero if the
close succeeds, or -1 if it fails.

   The POSIX standard is very vague; it says that `close()' returns
zero on success and nonzero otherwise.  In general, different
implementations vary in what they report when closing pipes; thus the
return value cannot be used portably.  (d.c.)  In POSIX mode (*note
Options::), `gawk' just returns zero when closing a pipe.

   ---------- Footnotes ----------

   (1) The technical terminology is rather morbid.  The finished child
is called a "zombie," and cleaning up after it is referred to as
"reaping."

   (2) This is a full 16-bit value as returned by the `wait()' system
call. See the system manual pages for information on how to decode this
value.


File: gawk.info,  Node: Expressions,  Next: Patterns and Actions,  Prev: Printing,  Up: Top

6 Expressions
*************

Expressions are the basic building blocks of `awk' patterns and
actions.  An expression evaluates to a value that you can print, test,
or pass to a function.  Additionally, an expression can assign a new
value to a variable or a field by using an assignment operator.

   An expression can serve as a pattern or action statement on its own.
Most other kinds of statements contain one or more expressions that
specify the data on which to operate.  As in other languages,
expressions in `awk' include variables, array references, constants,
and function calls, as well as combinations of these with various
operators.

* Menu:

* Values::                      Constants, Variables, and Regular Expressions.
* All Operators::               `gawk''s operators.
* Truth Values and Conditions:: Testing for true and false.
* Function Calls::              A function call is an expression.
* Precedence::                  How various operators nest.
* Locales::                     How the locale affects things.


File: gawk.info,  Node: Values,  Next: All Operators,  Up: Expressions

6.1 Constants, Variables and Conversions
========================================

Expressions are built up from values and the operations performed upon
them. This minor node describes the elementary objects which provide
the values used in expressions.

* Menu:

* Constants::                   String, numeric and regexp constants.
* Using Constant Regexps::      When and how to use a regexp constant.
* Variables::                   Variables give names to values for later use.
* Conversion::                  The conversion of strings to numbers and vice
                                versa.


File: gawk.info,  Node: Constants,  Next: Using Constant Regexps,  Up: Values

6.1.1 Constant Expressions
--------------------------

The simplest type of expression is the "constant", which always has the
same value.  There are three types of constants: numeric, string, and
regular expression.

   Each is used in the appropriate context when you need a data value
that isn't going to change.  Numeric constants can have different
forms, but are stored identically internally.

* Menu:

* Scalar Constants::            Numeric and string constants.
* Nondecimal-numbers::          What are octal and hex numbers.
* Regexp Constants::            Regular Expression constants.


File: gawk.info,  Node: Scalar Constants,  Next: Nondecimal-numbers,  Up: Constants

6.1.1.1 Numeric and String Constants
....................................

A "numeric constant" stands for a number.  This number can be an
integer, a decimal fraction, or a number in scientific (exponential)
notation.(1) Here are some examples of numeric constants that all have
the same value:

     105
     1.05e+2
     1050e-1

   A string constant consists of a sequence of characters enclosed in
double-quotation marks.  For example:

     "parrot"

represents the string whose contents are `parrot'.  Strings in `gawk'
can be of any length, and they can contain any of the possible
eight-bit ASCII characters including ASCII NUL (character code zero).
Other `awk' implementations may have difficulty with some character
codes.

   ---------- Footnotes ----------

   (1) The internal representation of all numbers, including integers,
uses double precision floating-point numbers.  On most modern systems,
these are in IEEE 754 standard format.


File: gawk.info,  Node: Nondecimal-numbers,  Next: Regexp Constants,  Prev: Scalar Constants,  Up: Constants

6.1.1.2 Octal and Hexadecimal Numbers
.....................................

In `awk', all numbers are in decimal; i.e., base 10.  Many other
programming languages allow you to specify numbers in other bases, often
octal (base 8) and hexadecimal (base 16).  In octal, the numbers go 0,
1, 2, 3, 4, 5, 6, 7, 10, 11, 12, etc.  Just as `11', in decimal, is 1
times 10 plus 1, so `11', in octal, is 1 times 8, plus 1. This equals 9
in decimal.  In hexadecimal, there are 16 digits. Since the everyday
decimal number system only has ten digits (`0'-`9'), the letters `a'
through `f' are used to represent the rest.  (Case in the letters is
usually irrelevant; hexadecimal `a' and `A' have the same value.)
Thus, `11', in hexadecimal, is 1 times 16 plus 1, which equals 17 in
decimal.

   Just by looking at plain `11', you can't tell what base it's in.
So, in C, C++, and other languages derived from C, there is a special
notation to signify the base.  Octal numbers start with a leading `0',
and hexadecimal numbers start with a leading `0x' or `0X':

`11'
     Decimal value 11.

`011'
     Octal 11, decimal value 9.

`0x11'
     Hexadecimal 11, decimal value 17.

   This example shows the difference:

     $ gawk 'BEGIN { printf "%d, %d, %d\n", 011, 11, 0x11 }'
     -| 9, 11, 17

   Being able to use octal and hexadecimal constants in your programs
is most useful when working with data that cannot be represented
conveniently as characters or as regular numbers, such as binary data
of various sorts.

   `gawk' allows the use of octal and hexadecimal constants in your
program text.  However, such numbers in the input data are not treated
differently; doing so by default would break old programs.  (If you
really need to do this, use the `--non-decimal-data' command-line
option; *note Nondecimal Data::.)  If you have octal or hexadecimal
data, you can use the `strtonum()' function (*note String Functions::)
to convert the data into a number.  Most of the time, you will want to
use octal or hexadecimal constants when working with the built-in bit
manipulation functions; see *note Bitwise Functions::, for more
information.

   Unlike some early C implementations, `8' and `9' are not valid in
octal constants; e.g., `gawk' treats `018' as decimal 18:

     $ gawk 'BEGIN { print "021 is", 021 ; print 018 }'
     -| 021 is 17
     -| 18

   Octal and hexadecimal source code constants are a `gawk' extension.
If `gawk' is in compatibility mode (*note Options::), they are not
available.

Advanced Notes: A Constant's Base Does Not Affect Its Value
-----------------------------------------------------------

Once a numeric constant has been converted internally into a number,
`gawk' no longer remembers what the original form of the constant was;
the internal value is always used.  This has particular consequences
for conversion of numbers to strings:

     $ gawk 'BEGIN { printf "0x11 is <%s>\n", 0x11 }'
     -| 0x11 is <17>


File: gawk.info,  Node: Regexp Constants,  Prev: Nondecimal-numbers,  Up: Constants

6.1.1.3 Regular Expression Constants
....................................

A regexp constant is a regular expression description enclosed in
slashes, such as `/^beginning and end$/'.  Most regexps used in `awk'
programs are constant, but the `~' and `!~' matching operators can also
match computed or dynamic regexps (which are just ordinary strings or
variables that contain a regexp).


File: gawk.info,  Node: Using Constant Regexps,  Next: Variables,  Prev: Constants,  Up: Values

6.1.2 Using Regular Expression Constants
----------------------------------------

When used on the righthand side of the `~' or `!~' operators, a regexp
constant merely stands for the regexp that is to be matched.  However,
regexp constants (such as `/foo/') may be used like simple expressions.
When a regexp constant appears by itself, it has the same meaning as if
it appeared in a pattern, i.e., `($0 ~ /foo/)' (d.c.)  *Note Expression
Patterns::.  This means that the following two code segments:

     if ($0 ~ /barfly/ || $0 ~ /camelot/)
         print "found"

and:

     if (/barfly/ || /camelot/)
         print "found"

are exactly equivalent.  One rather bizarre consequence of this rule is
that the following Boolean expression is valid, but does not do what
the user probably intended:

     # Note that /foo/ is on the left of the ~
     if (/foo/ ~ $1) print "found foo"

This code is "obviously" testing `$1' for a match against the regexp
`/foo/'.  But in fact, the expression `/foo/ ~ $1' really means `($0 ~
/foo/) ~ $1'.  In other words, first match the input record against the
regexp `/foo/'.  The result is either zero or one, depending upon the
success or failure of the match.  That result is then matched against
the first field in the record.  Because it is unlikely that you would
ever really want to make this kind of test, `gawk' issues a warning
when it sees this construct in a program.  Another consequence of this
rule is that the assignment statement:

     matches = /foo/

assigns either zero or one to the variable `matches', depending upon
the contents of the current input record.

   Constant regular expressions are also used as the first argument for
the `gensub()', `sub()', and `gsub()' functions, as the second argument
of the `match()' function, and as the third argument of the
`patsplit()' function (*note String Functions::).  Modern
implementations of `awk', including `gawk', allow the third argument of
`split()' to be a regexp constant, but some older implementations do
not.  (d.c.)  This can lead to confusion when attempting to use regexp
constants as arguments to user-defined functions (*note User-defined::).
For example:

     function mysub(pat, repl, str, global)
     {
         if (global)
             gsub(pat, repl, str)
         else
             sub(pat, repl, str)
         return str
     }

     {
         ...
         text = "hi! hi yourself!"
         mysub(/hi/, "howdy", text, 1)
         ...
     }

   In this example, the programmer wants to pass a regexp constant to
the user-defined function `mysub', which in turn passes it on to either
`sub()' or `gsub()'.  However, what really happens is that the `pat'
parameter is either one or zero, depending upon whether or not `$0'
matches `/hi/'.  `gawk' issues a warning when it sees a regexp constant
used as a parameter to a user-defined function, since passing a truth
value in this way is probably not what was intended.


File: gawk.info,  Node: Variables,  Next: Conversion,  Prev: Using Constant Regexps,  Up: Values

6.1.3 Variables
---------------

Variables are ways of storing values at one point in your program for
use later in another part of your program.  They can be manipulated
entirely within the program text, and they can also be assigned values
on the `awk' command line.

* Menu:

* Using Variables::             Using variables in your programs.
* Assignment Options::          Setting variables on the command-line and a
                                summary of command-line syntax. This is an
                                advanced method of input.


File: gawk.info,  Node: Using Variables,  Next: Assignment Options,  Up: Variables

6.1.3.1 Using Variables in a Program
....................................

Variables let you give names to values and refer to them later.
Variables have already been used in many of the examples.  The name of
a variable must be a sequence of letters, digits, or underscores, and
it may not begin with a digit.  Case is significant in variable names;
`a' and `A' are distinct variables.

   A variable name is a valid expression by itself; it represents the
variable's current value.  Variables are given new values with
"assignment operators", "increment operators", and "decrement
operators".  *Note Assignment Ops::.  In addition, the `sub()' and
`gsub()' functions can change a variable's value, and the `match()',
`patsplit()' and `split()' functions can change the contents of their
array parameters. *Note String Functions::.

   A few variables have special built-in meanings, such as `FS' (the
field separator), and `NF' (the number of fields in the current input
record).  *Note Built-in Variables::, for a list of the built-in
variables.  These built-in variables can be used and assigned just like
all other variables, but their values are also used or changed
automatically by `awk'.  All built-in variables' names are entirely
uppercase.

   Variables in `awk' can be assigned either numeric or string values.
The kind of value a variable holds can change over the life of a
program.  By default, variables are initialized to the empty string,
which is zero if converted to a number.  There is no need to explicitly
"initialize" a variable in `awk', which is what you would do in C and
in most other traditional languages.


File: gawk.info,  Node: Assignment Options,  Prev: Using Variables,  Up: Variables

6.1.3.2 Assigning Variables on the Command Line
...............................................

Any `awk' variable can be set by including a "variable assignment"
among the arguments on the command line when `awk' is invoked (*note
Other Arguments::).  Such an assignment has the following form:

     VARIABLE=TEXT

With it, a variable is set either at the beginning of the `awk' run or
in between input files.  When the assignment is preceded with the `-v'
option, as in the following:

     -v VARIABLE=TEXT

the variable is set at the very beginning, even before the `BEGIN'
rules execute.  The `-v' option and its assignment must precede all the
file name arguments, as well as the program text.  (*Note Options::,
for more information about the `-v' option.)  Otherwise, the variable
assignment is performed at a time determined by its position among the
input file arguments--after the processing of the preceding input file
argument.  For example:

     awk '{ print $n }' n=4 inventory-shipped n=2 BBS-list

prints the value of field number `n' for all input records.  Before the
first file is read, the command line sets the variable `n' equal to
four.  This causes the fourth field to be printed in lines from
`inventory-shipped'.  After the first file has finished, but before the
second file is started, `n' is set to two, so that the second field is
printed in lines from `BBS-list':

     $ awk '{ print $n }' n=4 inventory-shipped n=2 BBS-list
     -| 15
     -| 24
     ...
     -| 555-5553
     -| 555-3412
     ...

   Command-line arguments are made available for explicit examination by
the `awk' program in the `ARGV' array (*note ARGC and ARGV::).  `awk'
processes the values of command-line assignments for escape sequences
(*note Escape Sequences::).  (d.c.)


File: gawk.info,  Node: Conversion,  Prev: Variables,  Up: Values

6.1.4 Conversion of Strings and Numbers
---------------------------------------

Strings are converted to numbers and numbers are converted to strings,
if the context of the `awk' program demands it.  For example, if the
value of either `foo' or `bar' in the expression `foo + bar' happens to
be a string, it is converted to a number before the addition is
performed.  If numeric values appear in string concatenation, they are
converted to strings.  Consider the following:

     two = 2; three = 3
     print (two three) + 4

This prints the (numeric) value 27.  The numeric values of the
variables `two' and `three' are converted to strings and concatenated
together.  The resulting string is converted back to the number 23, to
which 4 is then added.

   If, for some reason, you need to force a number to be converted to a
string, concatenate that number with the empty string, `""'.  To force
a string to be converted to a number, add zero to that string.  A
string is converted to a number by interpreting any numeric prefix of
the string as numerals: `"2.5"' converts to 2.5, `"1e3"' converts to
1000, and `"25fix"' has a numeric value of 25.  Strings that can't be
interpreted as valid numbers convert to zero.

   The exact manner in which numbers are converted into strings is
controlled by the `awk' built-in variable `CONVFMT' (*note Built-in
Variables::).  Numbers are converted using the `sprintf()' function
with `CONVFMT' as the format specifier (*note String Functions::).

   `CONVFMT''s default value is `"%.6g"', which prints a value with at
most six significant digits.  For some applications, you might want to
change it to specify more precision.  On most modern machines, 17
digits is usually enough to capture a floating-point number's value
exactly.(1)

   Strange results can occur if you set `CONVFMT' to a string that
doesn't tell `sprintf()' how to format floating-point numbers in a
useful way.  For example, if you forget the `%' in the format, `awk'
converts all numbers to the same constant string.

   As a special case, if a number is an integer, then the result of
converting it to a string is _always_ an integer, no matter what the
value of `CONVFMT' may be.  Given the following code fragment:

     CONVFMT = "%2.2f"
     a = 12
     b = a ""

`b' has the value `"12"', not `"12.00"'.  (d.c.)

   Prior to the POSIX standard, `awk' used the value of `OFMT' for
converting numbers to strings.  `OFMT' specifies the output format to
use when printing numbers with `print'.  `CONVFMT' was introduced in
order to separate the semantics of conversion from the semantics of
printing.  Both `CONVFMT' and `OFMT' have the same default value:
`"%.6g"'.  In the vast majority of cases, old `awk' programs do not
change their behavior.  However, these semantics for `OFMT' are
something to keep in mind if you must port your new-style program to
older implementations of `awk'.  We recommend that instead of changing
your programs, just port `gawk' itself.  *Note Print::, for more
information on the `print' statement.

   And, once again, where you are can matter when it comes to converting
between numbers and strings.  In *note Locales::, we mentioned that the
local character set and language (the locale) can affect how `gawk'
matches characters.  The locale also affects numeric formats.  In
particular, for `awk' programs, it affects the decimal point character.
The `"C"' locale, and most English-language locales, use the period
character (`.') as the decimal point.  However, many (if not most)
European and non-English locales use the comma (`,') as the decimal
point character.

   The POSIX standard says that `awk' always uses the period as the
decimal point when reading the `awk' program source code, and for
command-line variable assignments (*note Other Arguments::).  However,
when interpreting input data, for `print' and `printf' output, and for
number to string conversion, the local decimal point character is used.
Here are some examples indicating the difference in behavior, on a
GNU/Linux system:

     $ gawk 'BEGIN { printf "%g\n", 3.1415927 }'
     -| 3.14159
     $ LC_ALL=en_DK gawk 'BEGIN { printf "%g\n", 3.1415927 }'
     -| 3,14159
     $ echo 4,321 | gawk '{ print $1 + 1 }'
     -| 5
     $ echo 4,321 | LC_ALL=en_DK gawk '{ print $1 + 1 }'
     -| 5,321

The `en_DK' locale is for English in Denmark, where the comma acts as
the decimal point separator.  In the normal `"C"' locale, `gawk' treats
`4,321' as `4', while in the Danish locale, it's treated as the full
number, 4.321.

   Some earlier versions of `gawk' fully complied with this aspect of
the standard.  However, many users in non-English locales complained
about this behavior, since their data used a period as the decimal
point, so the default behavior was restored to use a period as the
decimal point character.  You can use the `--use-lc-numeric' option
(*note Options::) to force `gawk' to use the locale's decimal point
character.  (`gawk' also uses the locale's decimal point character when
in POSIX mode, either via `--posix', or the `POSIXLY_CORRECT'
environment variable.)

   *note table-locale-affects:: describes the cases in which the
locale's decimal point character is used and when a period is used.
Some of these features have not been described yet.

Feature     Default        `--posix' or `--use-lc-numeric'
------------------------------------------------------------ 
`%'g'       Use locale     Use locale
`%g'        Use period     Use locale
Input       Use period     Use locale
`strtonum()'Use period     Use locale

Table 6.1: Locale Decimal Point versus A Period

   Finally, modern day formal standards and IEEE standard floating point
representation can have an unusual but important effect on the way
`gawk' converts some special string values to numbers.  The details are
presented in *note POSIX Floating Point Problems::.

   ---------- Footnotes ----------

   (1) Pathological cases can require up to 752 digits (!), but we
doubt that you need to worry about this.


File: gawk.info,  Node: All Operators,  Next: Truth Values and Conditions,  Prev: Values,  Up: Expressions

6.2 Operators: Doing Something With Values
==========================================

This minor node introduces the "operators" which make use of the values
provided by constants and variables.

* Menu:

* Arithmetic Ops::              Arithmetic operations (`+', `-',
                                etc.)
* Concatenation::               Concatenating strings.
* Assignment Ops::              Changing the value of a variable or a field.
* Increment Ops::               Incrementing the numeric value of a variable.


File: gawk.info,  Node: Arithmetic Ops,  Next: Concatenation,  Up: All Operators

6.2.1 Arithmetic Operators
--------------------------

The `awk' language uses the common arithmetic operators when evaluating
expressions.  All of these arithmetic operators follow normal
precedence rules and work as you would expect them to.

   The following example uses a file named `grades', which contains a
list of student names as well as three test scores per student (it's a
small class):

     Pat   100 97 58
     Sandy  84 72 93
     Chris  72 92 89

This program takes the file `grades' and prints the average of the
scores:

     $ awk '{ sum = $2 + $3 + $4 ; avg = sum / 3
     >        print $1, avg }' grades
     -| Pat 85
     -| Sandy 83
     -| Chris 84.3333

   The following list provides the arithmetic operators in `awk', in
order from the highest precedence to the lowest:

`- X'
     Negation.

`+ X'
     Unary plus; the expression is converted to a number.

`X ^ Y'
`X ** Y'
     Exponentiation; X raised to the Y power.  `2 ^ 3' has the value
     eight; the character sequence `**' is equivalent to `^'. (c.e.)

`X * Y'
     Multiplication.

`X / Y'
     Division;  because all numbers in `awk' are floating-point
     numbers, the result is _not_ rounded to an integer--`3 / 4' has
     the value 0.75.  (It is a common mistake, especially for C
     programmers, to forget that _all_ numbers in `awk' are
     floating-point, and that division of integer-looking constants
     produces a real number, not an integer.)

`X % Y'
     Remainder; further discussion is provided in the text, just after
     this list.

`X + Y'
     Addition.

`X - Y'
     Subtraction.

   Unary plus and minus have the same precedence, the multiplication
operators all have the same precedence, and addition and subtraction
have the same precedence.

   When computing the remainder of `X % Y', the quotient is rounded
toward zero to an integer and multiplied by Y. This result is
subtracted from X; this operation is sometimes known as "trunc-mod."
The following relation always holds:

     b * int(a / b) + (a % b) == a

   One possibly undesirable effect of this definition of remainder is
that `X % Y' is negative if X is negative.  Thus:

     -17 % 8 = -1

   In other `awk' implementations, the signedness of the remainder may
be machine-dependent.

     NOTE: The POSIX standard only specifies the use of `^' for
     exponentiation.  For maximum portability, do not use the `**'
     operator.


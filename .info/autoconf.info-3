This is autoconf.info, produced by makeinfo version 4.13 from
/home/remote/eblake/autoconf/doc/autoconf.texi.

This manual (21 September 2010) is for GNU Autoconf (version 2.68), a
package for creating scripts to configure source code packages using
templates and an M4 macro package.

   Copyright (C) 1992, 1993, 1994, 1995, 1996, 1998, 1999, 2000, 2001,
2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010 Free Software
Foundation, Inc.

     Permission is granted to copy, distribute and/or modify this
     document under the terms of the GNU Free Documentation License,
     Version 1.3 or any later version published by the Free Software
     Foundation; with no Invariant Sections, with the Front-Cover texts
     being "A GNU Manual," and with the Back-Cover Texts as in (a)
     below.  A copy of the license is included in the section entitled
     "GNU Free Documentation License."

     (a) The FSF's Back-Cover Text is: "You have the freedom to copy and
     modify this GNU manual.  Buying copies from the FSF supports it in
     developing GNU and promoting software freedom."

INFO-DIR-SECTION Software development
START-INFO-DIR-ENTRY
* Autoconf: (autoconf).         Create source code configuration scripts.
END-INFO-DIR-ENTRY

INFO-DIR-SECTION Individual utilities
START-INFO-DIR-ENTRY
* autoscan: (autoconf)autoscan Invocation.
                                Semi-automatic `configure.ac' writing
* ifnames: (autoconf)ifnames Invocation.        Listing conditionals in source.
* autoconf-invocation: (autoconf)autoconf Invocation.
                                How to create configuration scripts
* autoreconf: (autoconf)autoreconf Invocation.
                                Remaking multiple `configure' scripts
* autoheader: (autoconf)autoheader Invocation.
                                How to create configuration templates
* autom4te: (autoconf)autom4te Invocation.
                                The Autoconf executables backbone
* configure: (autoconf)configure Invocation.    Configuring a package.
* autoupdate: (autoconf)autoupdate Invocation.
                                Automatic update of `configure.ac'
* config.status: (autoconf)config.status Invocation. Recreating configurations.
* testsuite: (autoconf)testsuite Invocation.    Running an Autotest test suite.
END-INFO-DIR-ENTRY


File: autoconf.info,  Node: Limitations of Usual Tools,  Prev: Limitations of Builtins,  Up: Portable Shell

11.13 Limitations of Usual Tools
================================

The small set of tools you can expect to find on any machine can still
include some limitations you should be aware of.

`awk'
     Don't leave white space before the opening parenthesis in a user
     function call.  Posix does not allow this and GNU Awk rejects it:

          $ gawk 'function die () { print "Aaaaarg!"  }
                  BEGIN { die () }'
          gawk: cmd. line:2:         BEGIN { die () }
          gawk: cmd. line:2:                      ^ parse error
          $ gawk 'function die () { print "Aaaaarg!"  }
                  BEGIN { die() }'
          Aaaaarg!

     Posix says that if a program contains only `BEGIN' actions, and
     contains no instances of `getline', then the program merely
     executes the actions without reading input.  However, traditional
     Awk implementations (such as Solaris 10 `awk') read and discard
     input in this case.  Portable scripts can redirect input from
     `/dev/null' to work around the problem.  For example:

          awk 'BEGIN {print "hello world"}' </dev/null

     Posix says that in an `END' action, `$NF' (and presumably, `$1')
     retain their value from the last record read, if no intervening
     `getline' occurred.  However, some implementations (such as
     Solaris 10 `/usr/bin/awk', `nawk', or Darwin `awk') reset these
     variables.  A workaround is to use an intermediate variable prior
     to the `END' block.  For example:

          $ cat end.awk
          { tmp = $1 }
          END { print "a", $1, $NF, "b", tmp }
          $ echo 1 | awk -f end.awk
          a   b 1
          $ echo 1 | gawk -f end.awk
          a 1 1 b 1

     If you want your program to be deterministic, don't depend on `for'
     on arrays:

          $ cat for.awk
          END {
            arr["foo"] = 1
            arr["bar"] = 1
            for (i in arr)
              print i
          }
          $ gawk -f for.awk </dev/null
          foo
          bar
          $ nawk -f for.awk </dev/null
          bar
          foo

     Some Awk implementations, such as HP-UX 11.0's native one,
     mishandle anchors:

          $ echo xfoo | $AWK '/foo|^bar/ { print }'
          $ echo bar | $AWK '/foo|^bar/ { print }'
          bar
          $ echo xfoo | $AWK '/^bar|foo/ { print }'
          xfoo
          $ echo bar | $AWK '/^bar|foo/ { print }'
          bar

     Either do not depend on such patterns (i.e., use `/^(.*foo|bar)/',
     or use a simple test to reject such implementations.

     On `ia64-hp-hpux11.23', Awk mishandles `printf' conversions after
     `%u':

          $ awk 'BEGIN { printf "%u %d\n", 0, -1 }'
          0 0

     AIX version 5.2 has an arbitrary limit of 399 on the length of
     regular expressions and literal strings in an Awk program.

     Traditional Awk implementations derived from Unix version 7, such
     as Solaris `/bin/awk', have many limitations and do not conform to
     Posix.  Nowadays `AC_PROG_AWK' (*note Particular Programs::) finds
     you an Awk that doesn't have these problems, but if for some
     reason you prefer not to use `AC_PROG_AWK' you may need to address
     them.  For more detailed descriptions, see *note `awk' language
     history: (gawk)Language History.

     Traditional Awk does not support multidimensional arrays or
     user-defined functions.

     Traditional Awk does not support the `-v' option.  You can use
     assignments after the program instead, e.g., `$AWK '{print v $1}'
     v=x'; however, don't forget that such assignments are not
     evaluated until they are encountered (e.g., after any `BEGIN'
     action).

     Traditional Awk does not support the keywords `delete' or `do'.

     Traditional Awk does not support the expressions `A?B:C', `!A',
     `A^B', or `A^=B'.

     Traditional Awk does not support the predefined `CONVFMT' or
     `ENVIRON' variables.

     Traditional Awk supports only the predefined functions `exp',
     `index', `int', `length', `log', `split', `sprintf', `sqrt', and
     `substr'.

     Traditional Awk `getline' is not at all compatible with Posix;
     avoid it.

     Traditional Awk has `for (i in a) ...' but no other uses of the
     `in' keyword.  For example, it lacks `if (i in a) ...'.

     In code portable to both traditional and modern Awk, `FS' must be a
     string containing just one ordinary character, and similarly for
     the field-separator argument to `split'.

     Traditional Awk has a limit of 99 fields in a record.  Since some
     Awk implementations, like Tru64's, split the input even if you
     don't refer to any field in the script, to circumvent this
     problem, set `FS' to an unusual character and use `split'.

     Traditional Awk has a limit of at most 99 bytes in a number
     formatted by `OFMT'; for example, `OFMT="%.300e"; print 0.1;'
     typically dumps core.

     The original version of Awk had a limit of at most 99 bytes per
     `split' field, 99 bytes per `substr' substring, and 99 bytes per
     run of non-special characters in a `printf' format, but these bugs
     have been fixed on all practical hosts that we know of.

     HP-UX 11.00 and IRIX 6.5 Awk require that input files have a line
     length of at most 3070 bytes.

`basename'
     Not all hosts have a working `basename'.  You can use `expr'
     instead.

`cat'
     Don't rely on any option.

`cc'
     The command `cc -c foo.c' traditionally produces an object file
     named `foo.o'.  Most compilers allow `-c' to be combined with `-o'
     to specify a different object file name, but Posix does not
     require this combination and a few compilers lack support for it.
     *Note C Compiler::, for how GNU Make tests for this feature with
     `AC_PROG_CC_C_O'.

     When a compilation such as `cc -o foo foo.c' fails, some compilers
     (such as CDS on Reliant Unix) leave a `foo.o'.

     HP-UX `cc' doesn't accept `.S' files to preprocess and assemble.
     `cc -c foo.S' appears to succeed, but in fact does nothing.

     The default executable, produced by `cc foo.c', can be

        * `a.out' -- usual Posix convention.

        * `b.out' -- i960 compilers (including `gcc').

        * `a.exe' -- DJGPP port of `gcc'.

        * `a_out.exe' -- GNV `cc' wrapper for DEC C on OpenVMS.

        * `foo.exe' -- various MS-DOS compilers.

     The C compiler's traditional name is `cc', but other names like
     `gcc' are common.  Posix 1003.1-2001 specifies the name `c99', but
     older Posix editions specified `c89' and anyway these standard
     names are rarely used in practice.  Typically the C compiler is
     invoked from makefiles that use `$(CC)', so the value of the `CC'
     make variable selects the compiler name.

`chgrp'
`chown'
     It is not portable to change a file's group to a group that the
     owner does not belong to.

`chmod'
     Avoid usages like `chmod -w file'; use `chmod a-w file' instead,
     for two reasons.  First, plain `-w' does not necessarily make the
     file unwritable, since it does not affect mode bits that
     correspond to bits in the file mode creation mask.  Second, Posix
     says that the `-w' might be interpreted as an
     implementation-specific option, not as a mode; Posix suggests
     using `chmod -- -w file' to avoid this confusion, but unfortunately
     `--' does not work on some older hosts.

`cmp'
     `cmp' performs a raw data comparison of two files, while `diff'
     compares two text files.  Therefore, if you might compare DOS
     files, even if only checking whether two files are different, use
     `diff' to avoid spurious differences due to differences of newline
     encoding.

`cp'
     Avoid the `-r' option, since Posix 1003.1-2004 marks it as
     obsolescent and its behavior on special files is
     implementation-defined.  Use `-R' instead.  On GNU hosts the two
     options are equivalent, but on Solaris hosts (for example) `cp -r'
     reads from pipes instead of replicating them.

     Some `cp' implementations (e.g., BSD/OS 4.2) do not allow trailing
     slashes at the end of nonexistent destination directories.  To
     avoid this problem, omit the trailing slashes.  For example, use
     `cp -R source /tmp/newdir' rather than `cp -R source /tmp/newdir/'
     if `/tmp/newdir' does not exist.

     The ancient SunOS 4 `cp' does not support `-f', although its `mv'
     does.

     Traditionally, file timestamps had 1-second resolution, and `cp
     -p' copied the timestamps exactly.  However, many modern file
     systems have timestamps with 1-nanosecond resolution.
     Unfortunately, `cp -p' implementations truncate timestamps when
     copying files, so this can result in the destination file
     appearing to be older than the source.  The exact amount of
     truncation depends on the resolution of the system calls that `cp'
     uses; traditionally this was `utime', which has 1-second
     resolution, but some newer `cp' implementations use `utimes',
     which has 1-microsecond resolution.  These newer implementations
     include GNU Core Utilities 5.0.91 or later, and Solaris 8 (sparc)
     patch 109933-02 or later.  Unfortunately as of January 2006 there
     is still no system call to set timestamps to the full nanosecond
     resolution.

     Bob Proulx notes that `cp -p' always _tries_ to copy ownerships.
     But whether it actually does copy ownerships or not is a system
     dependent policy decision implemented by the kernel.  If the
     kernel allows it then it happens.  If the kernel does not allow it
     then it does not happen.  It is not something `cp' itself has
     control over.

     In Unix System V any user can chown files to any other user, and
     System V also has a non-sticky `/tmp'.  That probably derives from
     the heritage of System V in a business environment without hostile
     users.  BSD changed this to be a more secure model where only root
     can `chown' files and a sticky `/tmp' is used.  That undoubtedly
     derives from the heritage of BSD in a campus environment.

     GNU/Linux and Solaris by default follow BSD, but can be configured
     to allow a System V style `chown'.  On the other hand, HP-UX
     follows System V, but can be configured to use the modern security
     model and disallow `chown'.  Since it is an
     administrator-configurable parameter you can't use the name of the
     kernel as an indicator of the behavior.

`date'
     Some versions of `date' do not recognize special `%' directives,
     and unfortunately, instead of complaining, they just pass them
     through, and exit with success:

          $ uname -a
          OSF1 medusa.sis.pasteur.fr V5.1 732 alpha
          $ date "+%s"
          %s

`diff'
     Option `-u' is nonportable.

     Some implementations, such as Tru64's, fail when comparing to
     `/dev/null'.  Use an empty file instead.

`dirname'
     Not all hosts have a working `dirname', and you should instead use
     `AS_DIRNAME' (*note Programming in M4sh::).  For example:

          dir=`dirname "$file"`       # This is not portable.
          dir=`AS_DIRNAME(["$file"])` # This is more portable.

`egrep'
     Posix 1003.1-2001 no longer requires `egrep', but many hosts do
     not yet support the Posix replacement `grep -E'.  Also, some
     traditional implementations do not work on long input lines.  To
     work around these problems, invoke `AC_PROG_EGREP' and then use
     `$EGREP'.

     Portable extended regular expressions should use `\' only to escape
     characters in the string `$()*+.?[\^{|'.  For example, `\}' is not
     portable, even though it typically matches `}'.

     The empty alternative is not portable.  Use `?' instead.  For
     instance with Digital Unix v5.0:

          > printf "foo\n|foo\n" | $EGREP '^(|foo|bar)$'
          |foo
          > printf "bar\nbar|\n" | $EGREP '^(foo|bar|)$'
          bar|
          > printf "foo\nfoo|\n|bar\nbar\n" | $EGREP '^(foo||bar)$'
          foo
          |bar

     `$EGREP' also suffers the limitations of `grep' (*note Limitations
     of Usual Tools: grep.).

`expr'
     Not all implementations obey the Posix rule that `--' separates
     options from arguments; likewise, not all implementations provide
     the extension to Posix that the first argument can be treated as
     part of a valid expression rather than an invalid option if it
     begins with `-'.  When performing arithmetic, use `expr 0 + $var'
     if `$var' might be a negative number, to keep `expr' from
     interpreting it as an option.

     No `expr' keyword starts with `X', so use `expr X"WORD" :
     'XREGEX'' to keep `expr' from misinterpreting WORD.

     Don't use `length', `substr', `match' and `index'.

`expr' (`|')
     You can use `|'.  Although Posix does require that `expr '''
     return the empty string, it does not specify the result when you
     `|' together the empty string (or zero) with the empty string.  For
     example:

          expr '' \| ''

     Posix 1003.2-1992 returns the empty string for this case, but
     traditional Unix returns `0' (Solaris is one such example).  In
     Posix 1003.1-2001, the specification was changed to match
     traditional Unix's behavior (which is bizarre, but it's too late
     to fix this).  Please note that the same problem does arise when
     the empty string results from a computation, as in:

          expr bar : foo \| foo : bar

     Avoid this portability problem by avoiding the empty string.

`expr' (`:')
     Portable `expr' regular expressions should use `\' to escape only
     characters in the string `$()*.0123456789[\^n{}'.  For example,
     alternation, `\|', is common but Posix does not require its
     support, so it should be avoided in portable scripts.  Similarly,
     `\+' and `\?' should be avoided.

     Portable `expr' regular expressions should not begin with `^'.
     Patterns are automatically anchored so leading `^' is not needed
     anyway.

     On the other hand, the behavior of the `$' anchor is not portable
     on multi-line strings.  Posix is ambiguous whether the anchor
     applies to each line, as was done in older versions of GNU
     Coreutils, or whether it applies only to the end of the overall
     string, as in Coreutils 6.0 and most other implementations.

          $ baz='foo
          > bar'
          $ expr "X$baz" : 'X\(foo\)$'

          $ expr-5.97 "X$baz" : 'X\(foo\)$'
          foo

     The Posix standard is ambiguous as to whether `expr 'a' : '\(b\)''
     outputs `0' or the empty string.  In practice, it outputs the
     empty string on most platforms, but portable scripts should not
     assume this.  For instance, the QNX 4.25 native `expr' returns `0'.

     One might think that a way to get a uniform behavior would be to
     use the empty string as a default value:

          expr a : '\(b\)' \| ''

     Unfortunately this behaves exactly as the original expression; see
     the `expr' (`|') entry for more information.

     Some ancient `expr' implementations (e.g., SunOS 4 `expr' and
     Solaris 8 `/usr/ucb/expr') have a silly length limit that causes
     `expr' to fail if the matched substring is longer than 120 bytes.
     In this case, you might want to fall back on `echo|sed' if `expr'
     fails.  Nowadays this is of practical importance only for the rare
     installer who mistakenly puts `/usr/ucb' before `/usr/bin' in
     `PATH'.

     On Mac OS X 10.4, `expr' mishandles the pattern `[^-]' in some
     cases.  For example, the command
          expr Xpowerpc-apple-darwin8.1.0 : 'X[^-]*-[^-]*-\(.*\)'

     outputs `apple-darwin8.1.0' rather than the correct `darwin8.1.0'.
     This particular case can be worked around by substituting `[^--]'
     for `[^-]'.

     Don't leave, there is some more!

     The QNX 4.25 `expr', in addition of preferring `0' to the empty
     string, has a funny behavior in its exit status: it's always 1
     when parentheses are used!

          $ val=`expr 'a' : 'a'`; echo "$?: $val"
          0: 1
          $ val=`expr 'a' : 'b'`; echo "$?: $val"
          1: 0

          $ val=`expr 'a' : '\(a\)'`; echo "?: $val"
          1: a
          $ val=`expr 'a' : '\(b\)'`; echo "?: $val"
          1: 0

     In practice this can be a big problem if you are ready to catch
     failures of `expr' programs with some other method (such as using
     `sed'), since you may get twice the result.  For instance

          $ expr 'a' : '\(a\)' || echo 'a' | sed 's/^\(a\)$/\1/'

     outputs `a' on most hosts, but `aa' on QNX 4.25.  A simple
     workaround consists of testing `expr' and using a variable set to
     `expr' or to `false' according to the result.

     Tru64 `expr' incorrectly treats the result as a number, if it can
     be interpreted that way:

          $ expr 00001 : '.*\(...\)'
          1

     On HP-UX 11, `expr' only supports a single sub-expression.

          $ expr 'Xfoo' : 'X\(f\(oo\)*\)$'
          expr: More than one '\(' was used.

`fgrep'
     Posix 1003.1-2001 no longer requires `fgrep', but many hosts do
     not yet support the Posix replacement `grep -F'.  Also, some
     traditional implementations do not work on long input lines.  To
     work around these problems, invoke `AC_PROG_FGREP' and then use
     `$FGREP'.

     Tru64/OSF 5.1 `fgrep' does not match an empty pattern.

`find'
     The option `-maxdepth' seems to be GNU specific.  Tru64 v5.1,
     NetBSD 1.5 and Solaris `find' commands do not understand it.

     The replacement of `{}' is guaranteed only if the argument is
     exactly _{}_, not if it's only a part of an argument.  For
     instance on DU, and HP-UX 10.20 and HP-UX 11:

          $ touch foo
          $ find . -name foo -exec echo "{}-{}" \;
          {}-{}

     while GNU `find' reports `./foo-./foo'.

`grep'
     Portable scripts can rely on the `grep' options `-c', `-l', `-n',
     and `-v', but should avoid other options.  For example, don't use
     `-w', as Posix does not require it and Irix 6.5.16m's `grep' does
     not support it.  Also, portable scripts should not combine `-c'
     with `-l', as Posix does not allow this.

     Some of the options required by Posix are not portable in practice.
     Don't use `grep -q' to suppress output, because many `grep'
     implementations (e.g., Solaris) do not support `-q'.  Don't use
     `grep -s' to suppress output either, because Posix says `-s' does
     not suppress output, only some error messages; also, the `-s'
     option of traditional `grep' behaved like `-q' does in most modern
     implementations.  Instead, redirect the standard output and
     standard error (in case the file doesn't exist) of `grep' to
     `/dev/null'.  Check the exit status of `grep' to determine whether
     it found a match.

     The QNX4 implementation fails to count lines with `grep -c '$'',
     but works with `grep -c '^''.  Other alternatives for counting
     lines are to use `sed -n '$='' or `wc -l'.

     Some traditional `grep' implementations do not work on long input
     lines.  On AIX the default `grep' silently truncates long lines on
     the input before matching.

     Also, many implementations do not support multiple regexps with
     `-e': they either reject `-e' entirely (e.g., Solaris) or honor
     only the last pattern (e.g., IRIX 6.5 and NeXT).  To work around
     these problems, invoke `AC_PROG_GREP' and then use `$GREP'.

     Another possible workaround for the multiple `-e' problem is to
     separate the patterns by newlines, for example:

          grep 'foo
          bar' in.txt

     except that this fails with traditional `grep' implementations and
     with OpenBSD 3.8 `grep'.

     Traditional `grep' implementations (e.g., Solaris) do not support
     the `-E' or `-F' options.  To work around these problems, invoke
     `AC_PROG_EGREP' and then use `$EGREP', and similarly for
     `AC_PROG_FGREP' and `$FGREP'.  Even if you are willing to require
     support for Posix `grep', your script should not use both `-E' and
     `-F', since Posix does not allow this combination.

     Portable `grep' regular expressions should use `\' only to escape
     characters in the string `$()*.0123456789[\^{}'.  For example,
     alternation, `\|', is common but Posix does not require its
     support in basic regular expressions, so it should be avoided in
     portable scripts.  Solaris and HP-UX `grep' do not support it.
     Similarly, the following escape sequences should also be avoided:
     `\<', `\>', `\+', `\?', `\`', `\'', `\B', `\b', `\S', `\s', `\W',
     and `\w'.

     Posix does not specify the behavior of `grep' on binary files.  An
     example where this matters is using BSD `grep' to search text that
     includes embedded ANSI escape sequences for colored output to
     terminals (`\033[m' is the sequence to restore normal output); the
     behavior depends on whether input is seekable:

          $ printf 'esc\033[mape\n' > sample
          $ grep . sample
          Binary file sample matches
          $ cat sample | grep .
          escape

`join'
     Solaris 8 `join' has bugs when the second operand is standard
     input, and when standard input is a pipe.  For example, the
     following shell script causes Solaris 8 `join' to loop forever:

          cat >file <<'EOF'
          1 x
          2 y
          EOF
          cat file | join file -

     Use `join - file' instead.

`ln'
     Don't rely on `ln' having a `-f' option.  Symbolic links are not
     available on old systems; use `$(LN_S)' as a portable substitute.

     For versions of the DJGPP before 2.04, `ln' emulates symbolic links
     to executables by generating a stub that in turn calls the real
     program.  This feature also works with nonexistent files like in
     the Posix spec.  So `ln -s file link' generates `link.exe', which
     attempts to call `file.exe' if run.  But this feature only works
     for executables, so `cp -p' is used instead for these systems.
     DJGPP versions 2.04 and later have full support for symbolic links.

`ls'
     The portable options are `-acdilrtu'.  Current practice is for
     `-l' to output both owner and group, even though ancient versions
     of `ls' omitted the group.

     On ancient hosts, `ls foo' sent the diagnostic `foo not found' to
     standard output if `foo' did not exist.  Hence a shell command
     like `sources=`ls *.c 2>/dev/null`' did not always work, since it
     was equivalent to `sources='*.c not found'' in the absence of `.c'
     files.  This is no longer a practical problem, since current `ls'
     implementations send diagnostics to standard error.

     The behavior of `ls' on a directory that is being concurrently
     modified is not always predictable, because of a data race where
     cached information returned by `readdir' does not match the current
     directory state.  In fact, MacOS 10.5 has an intermittent bug where
     `readdir', and thus `ls', sometimes lists a file more than once if
     other files were added or removed from the directory immediately
     prior to the `ls' call.  Since `ls' already sorts its output, the
     duplicate entries can be avoided by piping the results through
     `uniq'.

`mkdir'
     No `mkdir' option is portable to older systems.  Instead of `mkdir
     -p FILE-NAME', you should use `AS_MKDIR_P(FILE-NAME)' (*note
     Programming in M4sh::) or `AC_PROG_MKDIR_P' (*note Particular
     Programs::).

     Combining the `-m' and `-p' options, as in `mkdir -m go-w -p DIR',
     often leads to trouble.  FreeBSD `mkdir' incorrectly attempts to
     change the permissions of DIR even if it already exists.  HP-UX
     11.23 and IRIX 6.5 `mkdir' often assign the wrong permissions to
     any newly-created parents of DIR.

     Posix does not clearly specify whether `mkdir -p foo' should
     succeed when `foo' is a symbolic link to an already-existing
     directory.  The GNU Core Utilities 5.1.0 `mkdir' succeeds, but
     Solaris `mkdir' fails.

     Traditional `mkdir -p' implementations suffer from race conditions.
     For example, if you invoke `mkdir -p a/b' and `mkdir -p a/c' at
     the same time, both processes might detect that `a' is missing,
     one might create `a', then the other might try to create `a' and
     fail with a `File exists' diagnostic.  The GNU Core Utilities
     (`fileutils' version 4.1), FreeBSD 5.0, NetBSD 2.0.2, and OpenBSD
     2.4 are known to be race-free when two processes invoke `mkdir -p'
     simultaneously, but earlier versions are vulnerable.  Solaris
     `mkdir' is still vulnerable as of Solaris 10, and other
     traditional Unix systems are probably vulnerable too.  This
     possible race is harmful in parallel builds when several Make
     rules call `mkdir -p' to construct directories.  You may use
     `install-sh -d' as a safe replacement, provided this script is
     recent enough; the copy shipped with Autoconf 2.60 and Automake
     1.10 is OK, but copies from older versions are vulnerable.

`mkfifo'
`mknod'
     The GNU Coding Standards state that `mknod' is safe to use on
     platforms where it has been tested to exist; but it is generally
     portable only for creating named FIFOs, since device numbers are
     platform-specific.  Autotest uses `mkfifo' to implement parallel
     testsuites.  Posix states that behavior is unspecified when
     opening a named FIFO for both reading and writing; on at least
     Cygwin, this results in failure on any attempt to read or write to
     that file descriptor.

`mktemp'
     Shell scripts can use temporary files safely with `mktemp', but it
     does not exist on all systems.  A portable way to create a safe
     temporary file name is to create a temporary directory with mode
     700 and use a file inside this directory.  Both methods prevent
     attackers from gaining control, though `mktemp' is far less likely
     to fail gratuitously under attack.

     Here is sample code to create a new temporary directory `$dir'
     safely:

          # Create a temporary directory $dir in $TMPDIR (default /tmp).
          # Use mktemp if possible; otherwise fall back on mkdir,
          # with $RANDOM to make collisions less likely.
          : "${TMPDIR:=/tmp}"
          {
            dir=`
              (umask 077 && mktemp -d "$TMPDIR/fooXXXXXX") 2>/dev/null
            ` &&
            test -d "$dir"
          } || {
            dir=$TMPDIR/foo$$-$RANDOM
            (umask 077 && mkdir "$dir")
          } || exit $?

`mv'
     The only portable options are `-f' and `-i'.

     Moving individual files between file systems is portable (it was
     in Unix version 6), but it is not always atomic: when doing `mv
     new existing', there's a critical section where neither the old
     nor the new version of `existing' actually exists.

     On some systems moving files from `/tmp' can sometimes cause
     undesirable (but perfectly valid) warnings, even if you created
     these files.  This is because `/tmp' belongs to a group that
     ordinary users are not members of, and files created in `/tmp'
     inherit the group of `/tmp'.  When the file is copied, `mv' issues
     a diagnostic without failing:

          $ touch /tmp/foo
          $ mv /tmp/foo .
          error-->mv: ./foo: set owner/group (was: 100/0): Operation not permitted
          $ echo $?
          0
          $ ls foo
          foo

     This annoying behavior conforms to Posix, unfortunately.

     Moving directories across mount points is not portable, use `cp'
     and `rm'.

     DOS variants cannot rename or remove open files, and do not
     support commands like `mv foo bar >foo', even though this is
     perfectly portable among Posix hosts.

`od'
     In Mac OS X 10.3, `od' does not support the standard Posix options
     `-A', `-j', `-N', or `-t', or the XSI option `-s'.  The only
     supported Posix option is `-v', and the only supported XSI options
     are those in `-bcdox'.  The BSD `hexdump' program can be used
     instead.

     This problem no longer exists in Mac OS X 10.4.3.

`rm'
     The `-f' and `-r' options are portable.

     It is not portable to invoke `rm' without operands.  For example,
     on many systems `rm -f -r' (with no other arguments) silently
     succeeds without doing anything, but it fails with a diagnostic on
     NetBSD 2.0.2.

     A file might not be removed even if its parent directory is
     writable and searchable.  Many Posix hosts cannot remove a mount
     point, a named stream, a working directory, or a last link to a
     file that is being executed.

     DOS variants cannot rename or remove open files, and do not
     support commands like `rm foo >foo', even though this is perfectly
     portable among Posix hosts.

`rmdir'
     Just as with `rm', some platforms refuse to remove a working
     directory.

`sed'
     Patterns should not include the separator (unless escaped), even
     as part of a character class.  In conformance with Posix, the Cray
     `sed' rejects `s/[^/]*$//': use `s%[^/]*$%%'.  Even when escaped,
     patterns should not include separators that are also used as `sed'
     metacharacters.  For example, GNU sed 4.0.9 rejects
     `s,x\{1\,\},,', while sed 4.1 strips the backslash before the comma
     before evaluating the basic regular expression.

     Avoid empty patterns within parentheses (i.e., `\(\)').  Posix does
     not require support for empty patterns, and Unicos 9 `sed' rejects
     them.

     Unicos 9 `sed' loops endlessly on patterns like `.*\n.*'.

     Sed scripts should not use branch labels longer than 7 characters
     and should not contain comments; AIX 5.3 `sed' rejects indented
     comments.  HP-UX sed has a limit of 99 commands (not counting `:'
     commands) and 48 labels, which can not be circumvented by using
     more than one script file.  It can execute up to 19 reads with the
     `r' command per cycle.  Solaris `/usr/ucb/sed' rejects usages that
     exceed a limit of about 6000 bytes for the internal representation
     of commands.

     Avoid redundant `;', as some `sed' implementations, such as NetBSD
     1.4.2's, incorrectly try to interpret the second `;' as a command:

          $ echo a | sed 's/x/x/;;s/x/x/'
          sed: 1: "s/x/x/;;s/x/x/": invalid command code ;

     Input should not have unreasonably long lines, since some `sed'
     implementations have an input buffer limited to 4000 bytes.
     Likewise, not all `sed' implementations can handle embedded `NUL'
     or a missing trailing newline.

     Remember that ranges within a bracket expression of a regular
     expression are only well-defined in the `C' (or `POSIX') locale.
     Meanwhile, support for character classes like `[[:upper:]]' is not
     yet universal, so if you cannot guarantee the setting of `LC_ALL',
     it is better to spell out a range `[ABCDEFGHIJKLMNOPQRSTUVWXYZ]'
     than to rely on `[A-Z]'.

     Additionally, Posix states that regular expressions are only
     well-defined on characters.  Unfortunately, there exist platforms
     such as MacOS X 10.5 where not all 8-bit byte values are valid
     characters, even though that platform has a single-byte `C'
     locale.  And Posix allows the existence of a multi-byte `C'
     locale, although that does not yet appear to be a common
     implementation.  At any rate, it means that not all bytes will be
     matched by the regular expression `.':

          $ printf '\200\n' | LC_ALL=C sed -n /./p | wc -l
          0
          $ printf '\200\n' | LC_ALL=en_US.ISO8859-1 sed -n /./p | wc -l
          1

     Portable `sed' regular expressions should use `\' only to escape
     characters in the string `$()*.0123456789[\^n{}'.  For example,
     alternation, `\|', is common but Posix does not require its
     support, so it should be avoided in portable scripts.  Solaris
     `sed' does not support alternation; e.g., `sed '/a\|b/d'' deletes
     only lines that contain the literal string `a|b'.  Similarly, `\+'
     and `\?' should be avoided.

     Anchors (`^' and `$') inside groups are not portable.

     Nested parentheses in patterns (e.g., `\(\(a*\)b*)\)') are quite
     portable to current hosts, but was not supported by some ancient
     `sed' implementations like SVR3.

     Some `sed' implementations, e.g., Solaris, restrict the special
     role of the asterisk `*' to one-character regular expressions and
     back-references, and the special role of interval expressions
     `\{M\}', `\{M,\}', or `\{M,N\}' to one-character regular
     expressions.  This may lead to unexpected behavior:

          $ echo '1*23*4' | /usr/bin/sed 's/\(.\)*/x/g'
          x2x4
          $ echo '1*23*4' | /usr/xpg4/bin/sed 's/\(.\)*/x/g'
          x

     The `-e' option is mostly portable.  However, its argument cannot
     start with `a', `c', or `i', as this runs afoul of a Tru64 5.1 bug.
     Also, its argument cannot be empty, as this fails on AIX 5.3.
     Some people prefer to use `-e':

          sed -e 'COMMAND-1' \
              -e 'COMMAND-2'

     as opposed to the equivalent:

          sed '
            COMMAND-1
            COMMAND-2
          '

     The following usage is sometimes equivalent:

          sed 'COMMAND-1;COMMAND-2'

     but Posix says that this use of a semicolon has undefined effect if
     COMMAND-1's verb is `{', `a', `b', `c', `i', `r', `t', `w', `:',
     or `#', so you should use semicolon only with simple scripts that
     do not use these verbs.

     Posix up to the 2008 revision requires the argument of the `-e'
     option to be a syntactically complete script.  GNU `sed' allows to
     pass multiple script fragments, each as argument of a separate
     `-e' option, that are then combined, with newlines between the
     fragments, and a future Posix revision may allow this as well.
     This approach is not portable with script fragments ending in
     backslash; for example, the `sed' programs on Solaris 10, HP-UX
     11, and AIX don't allow splitting in this case:

          $ echo a | sed -n -e 'i\
          0'
          0
          $ echo a | sed -n -e 'i\' -e 0
          Unrecognized command: 0

     In practice, however, this technique of joining fragments through
     `-e' works for multiple `sed' functions within `{' and `}', even
     if that is not specified by Posix:

          $ echo a | sed -n -e '/a/{' -e s/a/b/ -e p -e '}'
          b

     Commands inside { } brackets are further restricted.  Posix 2008
     says that they cannot be preceded by addresses, `!', or `;', and
     that each command must be followed immediately by a newline,
     without any intervening blanks or semicolons.  The closing bracket
     must be alone on a line, other than white space preceding or
     following it.  However, a future version of Posix may standardize
     the use of addresses within brackets.

     Contrary to yet another urban legend, you may portably use `&' in
     the replacement part of the `s' command to mean "what was
     matched".  All descendants of Unix version 7 `sed' (at least; we
     don't have first hand experience with older `sed' implementations)
     have supported it.

     Posix requires that you must not have any white space between `!'
     and the following command.  It is OK to have blanks between the
     address and the `!'.  For instance, on Solaris:

          $ echo "foo" | sed -n '/bar/ ! p'
          error-->Unrecognized command: /bar/ ! p
          $ echo "foo" | sed -n '/bar/! p'
          error-->Unrecognized command: /bar/! p
          $ echo "foo" | sed -n '/bar/ !p'
          foo

     Posix also says that you should not combine `!' and `;'.  If you
     use `!', it is best to put it on a command that is delimited by
     newlines rather than `;'.

     Also note that Posix requires that the `b', `t', `r', and `w'
     commands be followed by exactly one space before their argument.
     On the other hand, no white space is allowed between `:' and the
     subsequent label name.

     If a sed script is specified on the command line and ends in an
     `a', `c', or `i' command, the last line of inserted text should be
     followed by a newline.  Otherwise some `sed' implementations
     (e.g., OpenBSD 3.9) do not append a newline to the inserted text.

     Many `sed' implementations (e.g., MacOS X 10.4, OpenBSD 3.9,
     Solaris 10 `/usr/ucb/sed') strip leading white space from the text
     of `a', `c', and `i' commands.  Prepend a backslash to work around
     this incompatibility with Posix:

          $ echo flushleft | sed 'a\
          >    indented
          > '
          flushleft
          indented
          $ echo foo | sed 'a\
          > \   indented
          > '
          flushleft
             indented

     Posix requires that with an empty regular expression, the last
     non-empty regular expression from either an address specification
     or substitution command is applied.  However, busybox 1.6.1
     complains when using a substitution command with a replacement
     containing a back-reference to an empty regular expression; the
     workaround is repeating the regular expression.

          $ echo abc | busybox sed '/a\(b\)c/ s//\1/'
          sed: No previous regexp.
          $ echo abc | busybox sed '/a\(b\)c/ s/a\(b\)c/\1/'
          b

`sed' (`t')
     Some old systems have `sed' that "forget" to reset their `t' flag
     when starting a new cycle.  For instance on MIPS RISC/OS, and on
     IRIX 5.3, if you run the following `sed' script (the line numbers
     are not actual part of the texts):

          s/keep me/kept/g  # a
          t end             # b
          s/.*/deleted/g    # c
          :end              # d

     on

          delete me         # 1
          delete me         # 2
          keep me           # 3
          delete me         # 4

     you get

          deleted
          delete me
          kept
          deleted

     instead of

          deleted
          deleted
          kept
          deleted

     Why?  When processing line 1, (c) matches, therefore sets the `t'
     flag, and the output is produced.  When processing line 2, the `t'
     flag is still set (this is the bug).  Command (a) fails to match,
     but `sed' is not supposed to clear the `t' flag when a
     substitution fails.  Command (b) sees that the flag is set,
     therefore it clears it, and jumps to (d), hence you get `delete me'
     instead of `deleted'.  When processing line (3), `t' is clear, (a)
     matches, so the flag is set, hence (b) clears the flags and jumps.
     Finally, since the flag is clear, line 4 is processed properly.

     There are two things one should remember about `t' in `sed'.
     Firstly, always remember that `t' jumps if _some_ substitution
     succeeded, not only the immediately preceding substitution.
     Therefore, always use a fake `t clear' followed by a `:clear' on
     the next line, to reset the `t' flag where needed.

     Secondly, you cannot rely on `sed' to clear the flag at each new
     cycle.

     One portable implementation of the script above is:

          t clear
          :clear
          s/keep me/kept/g
          t end
          s/.*/deleted/g
          :end

`sleep'
     Using `sleep' is generally portable.  However, remember that
     adding a `sleep' to work around timestamp issues, with a minimum
     granularity of one second, doesn't scale well for parallel builds
     on modern machines with sub-second process completion.

`sort'
     Remember that sort order is influenced by the current locale.
     Inside `configure', the C locale is in effect, but in Makefile
     snippets, you may need to specify `LC_ALL=C sort'.

`tar'
     There are multiple file formats for `tar'; if you use Automake,
     the macro `AM_INIT_AUTOMAKE' has some options controlling which
     level of portability to use.

`touch'
     If you specify the desired timestamp (e.g., with the `-r' option),
     `touch' typically uses the `utime' or `utimes' system call, which
     can result in the same kind of timestamp truncation problems that
     `cp -p' has.

     On ancient BSD systems, `touch' or any command that results in an
     empty file does not update the timestamps, so use a command like
     `echo' as a workaround.  Also, GNU `touch' 3.16r (and presumably
     all before that) fails to work on SunOS 4.1.3 when the empty file
     is on an NFS-mounted 4.2 volume.  However, these problems are no
     longer of practical concern.

`tr'
     Not all versions of `tr' handle all backslash character escapes.
     For example, Solaris 10 `/usr/ucb/tr' falls over, even though
     Solaris contains more modern `tr' in other locations.  Using octal
     escapes is more portable for carriage returns, since `\015' is the
     same for both ASCII and EBCDIC, and since use of literal carriage
     returns in scripts causes a number of other problems.  But for
     other characters, like newline, using octal escapes ties the
     operation to ASCII, so it is better to use literal characters.

          $ { echo moon; echo light; } | /usr/ucb/tr -d '\n' ; echo
          moo
          light
          $ { echo moon; echo light; } | /usr/bin/tr -d '\n' ; echo
          moonlight
          $ { echo moon; echo light; } | /usr/ucb/tr -d '\012' ; echo
          moonlight
          $ nl='
          '; { echo moon; echo light; } | /usr/ucb/tr -d "$nl" ; echo
          moonlight

     Not all versions of `tr' recognize ranges of characters: at least
     Solaris `/usr/bin/tr' still fails to do so.  But you can use
     `/usr/xpg4/bin/tr' instead.

          $ echo "Hazy Fantazy" | LC_ALL=C /usr/bin/tr a-z A-Z
          HAZy FAntAZy
          $ echo "Hazy Fantazy" | LC_ALL=C /usr/xpg4/bin/tr a-z A-Z
          HAZY FANTAZY

     When providing two arguments, be sure the second string is at
     least as long as the first.

          $ echo abc | /usr/xpg4/bin/tr bc d
          adc
          $ echo abc | coreutils/tr bc d
          add

     Posix requires `tr' to operate on binary files.  But at least
     Solaris `/usr/ucb/tr' and `/usr/bin/tr' silently discard `NUL' in
     the input prior to doing any translation.  When using `tr' to
     process a binary file that may contain `NUL' bytes, it is
     necessary to use `/usr/xpg4/bin/tr' instead, or `/usr/xpg6/bin/tr'
     if that is available.

          $ printf 'a\0b' | /usr/ucb/tr x x | od -An -tx1
           61 62
          $ printf 'a\0b' | /usr/bin/tr x x | od -An -tx1
           61 62
          $ printf 'a\0b' | /usr/xpg4/bin/tr x x | od -An -tx1
           61 00 62

     Solaris `/usr/ucb/tr' additionally fails to handle `\0' as the
     octal escape for `NUL'.

          $ printf 'abc' | /usr/ucb/tr 'bc' '\0d' | od -An -tx1
           61 62 63
          $ printf 'abc' | /usr/bin/tr 'bc' '\0d' | od -An -tx1
           61 00 64
          $ printf 'abc' | /usr/xpg4/bin/tr 'bc' '\0d' | od -An -tx1
           61 00 64



File: autoconf.info,  Node: Portable Make,  Next: Portable C and C++,  Prev: Portable Shell,  Up: Top

12 Portable Make Programming
****************************

Writing portable makefiles is an art.  Since a makefile's commands are
executed by the shell, you must consider the shell portability issues
already mentioned.  However, other issues are specific to `make' itself.

* Menu:

* $< in Ordinary Make Rules::   $< in ordinary rules
* Failure in Make Rules::       Failing portably in rules
* Special Chars in Names::      Special Characters in Macro Names
* Backslash-Newline-Newline::   Empty last lines in macro definitions
* Backslash-Newline Comments::  Spanning comments across line boundaries
* Long Lines in Makefiles::     Line length limitations
* Macros and Submakes::         `make macro=value' and submakes
* The Make Macro MAKEFLAGS::    `$(MAKEFLAGS)' portability issues
* The Make Macro SHELL::        `$(SHELL)' portability issues
* Parallel Make::               Parallel `make' quirks
* Comments in Make Rules::      Other problems with Make comments
* Newlines in Make Rules::      Using literal newlines in rules
* obj/ and Make::               Don't name a subdirectory `obj'
* make -k Status::              Exit status of `make -k'
* VPATH and Make::              `VPATH' woes
* Single Suffix Rules::         Single suffix rules and separated dependencies
* Timestamps and Make::         Subsecond timestamp resolution


File: autoconf.info,  Node: $< in Ordinary Make Rules,  Next: Failure in Make Rules,  Up: Portable Make

12.1 `$<' in Ordinary Make Rules
================================

Posix says that the `$<' construct in makefiles can be used only in
inference rules and in the `.DEFAULT' rule; its meaning in ordinary
rules is unspecified.  Solaris `make' for instance replaces it with the
empty string.  OpenBSD (3.0 and later) `make' diagnoses these uses and
errors out.


File: autoconf.info,  Node: Failure in Make Rules,  Next: Special Chars in Names,  Prev: $< in Ordinary Make Rules,  Up: Portable Make

12.2 Failure in Make Rules
==========================

Posix 2008 requires that `make' must invoke each command with the
equivalent of a `sh -e -c' subshell, which causes the subshell to exit
immediately if a subsidiary simple-command fails, although not all
`make' implementations have historically followed this rule.  For
example, the command `touch T; rm -f U' may attempt to remove `U' even
if the `touch' fails, although this is not permitted with Posix make.
One way to work around failures in simple commands is to reword them so
that they always succeed, e.g., `touch T || :; rm -f U'.  However, even
this approach can run into common bugs in BSD implementations of the
`-e' option of `sh' and `set' (*note Limitations of Shell Builtins:
set.), so if you are worried about porting to buggy BSD shells it may
be simpler to migrate complicated `make' actions into separate scripts.


File: autoconf.info,  Node: Special Chars in Names,  Next: Backslash-Newline-Newline,  Prev: Failure in Make Rules,  Up: Portable Make

12.3 Special Characters in Make Macro Names
===========================================

Posix limits macro names to nonempty strings containing only ASCII
letters and digits, `.', and `_'.  Many `make' implementations allow a
wider variety of characters, but portable makefiles should avoid them.
It is portable to start a name with a special character, e.g.,
`$(.FOO)'.

   Some ancient `make' implementations don't support leading
underscores in macro names.  An example is NEWS-OS 4.2R.

     $ cat Makefile
     _am_include = #
     _am_quote =
     all:; @echo this is test
     $ make
     Make: Must be a separator on rules line 2.  Stop.
     $ cat Makefile2
     am_include = #
     am_quote =
     all:; @echo this is test
     $ make -f Makefile2
     this is test

However, this problem is no longer of practical concern.


File: autoconf.info,  Node: Backslash-Newline-Newline,  Next: Backslash-Newline Comments,  Prev: Special Chars in Names,  Up: Portable Make

12.4 Backslash-Newline-Newline in Make Macro Values
===================================================

On some versions of HP-UX, `make' reads multiple newlines following a
backslash, continuing to the next non-empty line.  For example,

     FOO = one \

     BAR = two

     test:
             : FOO is "$(FOO)"
             : BAR is "$(BAR)"

shows `FOO' equal to `one BAR = two'.  Other implementations sensibly
let a backslash continue only to the immediately following line.


File: autoconf.info,  Node: Backslash-Newline Comments,  Next: Long Lines in Makefiles,  Prev: Backslash-Newline-Newline,  Up: Portable Make

12.5 Backslash-Newline in Make Comments
=======================================

According to Posix, Make comments start with `#' and continue until an
unescaped newline is reached.

     $ cat Makefile
     # A = foo \
           bar \
           baz

     all:
             @echo ok
     $ make   # GNU make
     ok

However this is not always the case.  Some implementations discard
everything from `#' through the end of the line, ignoring any trailing
backslash.

     $ pmake  # BSD make
     "Makefile", line 3: Need an operator
     Fatal errors encountered -- cannot continue

Therefore, if you want to comment out a multi-line definition, prefix
each line with `#', not only the first.

     # A = foo \
     #     bar \
     #     baz


File: autoconf.info,  Node: Long Lines in Makefiles,  Next: Macros and Submakes,  Prev: Backslash-Newline Comments,  Up: Portable Make

12.6 Long Lines in Makefiles
============================

Tru64 5.1's `make' has been reported to crash when given a makefile
with lines longer than around 20 kB.  Earlier versions are reported to
exit with `Line too long' diagnostics.


File: autoconf.info,  Node: Macros and Submakes,  Next: The Make Macro MAKEFLAGS,  Prev: Long Lines in Makefiles,  Up: Portable Make

12.7 `make macro=value' and Submakes
====================================

A command-line variable definition such as `foo=bar' overrides any
definition of `foo' in a makefile.  Some `make' implementations (such
as GNU `make') propagate this override to subsidiary invocations of
`make'.  Some other implementations do not pass the substitution along
to submakes.

     $ cat Makefile
     foo = foo
     one:
             @echo $(foo)
             $(MAKE) two
     two:
             @echo $(foo)
     $ make foo=bar            # GNU make 3.79.1
     bar
     make two
     make[1]: Entering directory `/home/adl'
     bar
     make[1]: Leaving directory `/home/adl'
     $ pmake foo=bar           # BSD make
     bar
     pmake two
     foo

   You have a few possibilities if you do want the `foo=bar' override
to propagate to submakes.  One is to use the `-e' option, which causes
all environment variables to have precedence over the makefile macro
definitions, and declare foo as an environment variable:

     $ env foo=bar make -e

   The `-e' option is propagated to submakes automatically, and since
the environment is inherited between `make' invocations, the `foo'
macro is overridden in submakes as expected.

   This syntax (`foo=bar make -e') is portable only when used outside
of a makefile, for instance from a script or from the command line.
When run inside a `make' rule, GNU `make' 3.80 and prior versions
forget to propagate the `-e' option to submakes.

   Moreover, using `-e' could have unexpected side effects if your
environment contains some other macros usually defined by the makefile.
(See also the note about `make -e' and `SHELL' below.)

   If you can foresee all macros that a user might want to override,
then you can propagate them to submakes manually, from your makefile:

     foo = foo
     one:
             @echo $(foo)
             $(MAKE) foo=$(foo) two
     two:
             @echo $(foo)

   Another way to propagate a variable to submakes in a portable way is
to expand an extra variable in every invocation of `$(MAKE)' within
your makefile:

     foo = foo
     one:
             @echo $(foo)
             $(MAKE) $(SUBMAKEFLAGS) two
     two:
             @echo $(foo)

   Users must be aware that this technique is in use to take advantage
of it, e.g. with `make foo=bar SUBMAKEFLAGS='foo=bar'', but it allows
any macro to be overridden.  Makefiles generated by `automake' use this
technique, expanding `$(AM_MAKEFLAGS)' on the command lines of submakes
(*note Automake: (automake)Subdirectories.).


File: autoconf.info,  Node: The Make Macro MAKEFLAGS,  Next: The Make Macro SHELL,  Prev: Macros and Submakes,  Up: Portable Make

12.8 The Make Macro MAKEFLAGS
=============================

Posix requires `make' to use `MAKEFLAGS' to affect the current and
recursive invocations of make, but allows implementations several
formats for the variable.  It is tricky to parse `$MAKEFLAGS' to
determine whether `-s' for silent execution or `-k' for continued
execution are in effect.  For example, you cannot assume that the first
space-separated word in `$MAKEFLAGS' contains single-letter options,
since in the Cygwin version of GNU `make' it is either `--unix' or
`--win32' with the second word containing single-letter options.

     $ cat Makefile
     all:
             @echo MAKEFLAGS = $(MAKEFLAGS)
     $ make
     MAKEFLAGS = --unix
     $ make -k
     MAKEFLAGS = --unix -k


File: autoconf.info,  Node: The Make Macro SHELL,  Next: Parallel Make,  Prev: The Make Macro MAKEFLAGS,  Up: Portable Make

12.9 The Make Macro `SHELL'
===========================

Posix-compliant `make' internally uses the `$(SHELL)' macro to spawn
shell processes and execute Make rules.  This is a builtin macro
supplied by `make', but it can be modified by a makefile or by a
command-line argument.

   Not all `make' implementations define this `SHELL' macro.  Tru64
`make' is an example; this implementation always uses `/bin/sh'.  So
it's a good idea to always define `SHELL' in your makefiles.  If you
use Autoconf, do

     SHELL = @SHELL@

If you use Automake, this is done for you.

   Do not force `SHELL = /bin/sh' because that is not correct
everywhere.  Remember, `/bin/sh' is not Posix compliant on many
systems, such as FreeBSD 4, NetBSD 3, AIX 3, Solaris 10, or Tru64.
Additionally, DJGPP lacks `/bin/sh', and when its GNU `make' port sees
such a setting it enters a special emulation mode where features like
pipes and redirections are emulated on top of DOS's `command.com'.
Unfortunately this emulation is incomplete; for instance it does not
handle command substitutions.  Using `@SHELL@' means that your makefile
will benefit from the same improved shell, such as `bash' or `ksh',
that was discovered during `configure', so that you aren't fighting two
different sets of shell bugs between the two contexts.

   Posix-compliant `make' should never acquire the value of $(SHELL)
from the environment, even when `make -e' is used (otherwise, think
about what would happen to your rules if `SHELL=/bin/tcsh').

   However not all `make' implementations have this exception.  For
instance it's not surprising that Tru64 `make' doesn't protect `SHELL',
since it doesn't use it.

     $ cat Makefile
     SHELL = /bin/sh
     FOO = foo
     all:
             @echo $(SHELL)
             @echo $(FOO)
     $ env SHELL=/bin/tcsh FOO=bar make -e   # Tru64 Make
     /bin/tcsh
     bar
     $ env SHELL=/bin/tcsh FOO=bar gmake -e  # GNU make
     /bin/sh
     bar

   Conversely, `make' is not supposed to export any changes to the
macro `SHELL' to child processes.  Again, many implementations break
this rule:

     $ cat Makefile
     all:
             @echo $(SHELL)
             @printenv SHELL
     $ env SHELL=sh make -e SHELL=/bin/ksh   # BSD Make, GNU make 3.80
     /bin/ksh
     /bin/ksh
     $ env SHELL=sh gmake -e SHELL=/bin/ksh  # GNU make 3.81
     /bin/ksh
     sh


File: autoconf.info,  Node: Parallel Make,  Next: Comments in Make Rules,  Prev: The Make Macro SHELL,  Up: Portable Make

12.10 Parallel Make
===================

Support for parallel execution in `make' implementation varies.
Generally, using GNU make is your best bet.  When NetBSD `make' is
invoked with `-jN', it will reuse the same shell for multiple commands
within one recipe.  This can have unexpected consequences.(1) For
example, change of directories or variables persist between commands:

     all:
             @var=value; cd /; pwd; echo $$var; echo $$$$
             @pwd; echo $$var; echo $$$$

may output the following with `make -j1':

     --- all ---
     /
     value
     32235
     /
     value
     32235

   while without `-j1', or with `-B', the output looks less surprising:

     /
     value
     32238
     /tmp

     32239

   Another consequence of this is that, if one command in a recipe uses
`exit 0' to indicate a successful exit, the shell will be gone and the
remaining commands of this recipe will not be executed.

   The above example also shows additional status output NetBSD `make'
produces in parallel mode for targets being updated.

   Furthermore, parallel NetBSD `make' will route standard error from
commands that it spawns into its own standard output, and may remove
leading whitespace from output lines.

   You can avoid these issues by using the `-B' option to enable
compatibility semantics.  However, that will effectively also disable
all parallelism as that will cause prerequisites to be updated in the
order they are listed in a rule.

   ---------- Footnotes ----------

   (1) Note that GNU make has heuristics to avoid spawning a shell at
all if the command is deemed safe to be executed directly.


File: autoconf.info,  Node: Comments in Make Rules,  Next: Newlines in Make Rules,  Prev: Parallel Make,  Up: Portable Make

12.11 Comments in Make Rules
============================

Never put comments in a rule.

   Some `make' treat anything starting with a tab as a command for the
current rule, even if the tab is immediately followed by a `#'.  The
`make' from Tru64 Unix V5.1 is one of them.  The following makefile
runs `# foo' through the shell.

     all:
             # foo

   As a workaround, you can use the `:' no-op command with a string
argument that gets ignored:

     all:
             : "foo"


File: autoconf.info,  Node: Newlines in Make Rules,  Next: obj/ and Make,  Prev: Comments in Make Rules,  Up: Portable Make

12.12 Newlines in Make Rules
============================

In shell scripts, newlines can be used inside string literals.  But in
the shell statements of `Makefile' rules, this is not possible: A
newline not preceded by a backslash is a separator between shell
statements.  Whereas a newline that is preceded by a backslash becomes
part of the shell statement according to POSIX, but gets replaced,
together with the backslash that precedes it, by a space in GNU `make'
3.80 and older.  So, how can a newline be used in a string literal?

   The trick is to set up a shell variable that contains a newline:

     nlinit=`echo 'nl="'; echo '"'`; eval "$$nlinit"

   For example, in order to create a multiline `sed' expression that
inserts a blank line after every line of a file, this code can be used:

     nlinit=`echo 'nl="'; echo '"'`; eval "$$nlinit"; \
     sed -e "s/\$$/\\$${nl}/" < input > output


File: autoconf.info,  Node: obj/ and Make,  Next: make -k Status,  Prev: Newlines in Make Rules,  Up: Portable Make

12.13 The `obj/' Subdirectory and Make
======================================

Never name one of your subdirectories `obj/' if you don't like
surprises.

   If an `obj/' directory exists, BSD `make' enters it before reading
the makefile.  Hence the makefile in the current directory is not read.

     $ cat Makefile
     all:
             echo Hello
     $ cat obj/Makefile
     all:
             echo World
     $ make      # GNU make
     echo Hello
     Hello
     $ pmake     # BSD make
     echo World
     World


File: autoconf.info,  Node: make -k Status,  Next: VPATH and Make,  Prev: obj/ and Make,  Up: Portable Make

12.14 Exit Status of `make -k'
==============================

Do not rely on the exit status of `make -k'.  Some implementations
reflect whether they encountered an error in their exit status; other
implementations always succeed.

     $ cat Makefile
     all:
             false
     $ make -k; echo exit status: $?    # GNU make
     false
     make: *** [all] Error 1
     exit status: 2
     $ pmake -k; echo exit status: $?   # BSD make
     false
     *** Error code 1 (continuing)
     exit status: 0


File: autoconf.info,  Node: VPATH and Make,  Next: Single Suffix Rules,  Prev: make -k Status,  Up: Portable Make

12.15 `VPATH' and Make
======================

Posix does not specify the semantics of `VPATH'.  Typically, `make'
supports `VPATH', but its implementation is not consistent.

   Autoconf and Automake support makefiles whose usages of `VPATH' are
portable to recent-enough popular implementations of `make', but to
keep the resulting makefiles portable, a package's makefile prototypes
must take the following issues into account.  These issues are
complicated and are often poorly understood, and installers who use
`VPATH' should expect to find many bugs in this area.  If you use
`VPATH', the simplest way to avoid these portability bugs is to stick
with GNU `make', since it is the most commonly-used `make' among
Autoconf users.

   Here are some known issues with some `VPATH' implementations.

* Menu:

* Variables listed in VPATH::   `VPATH' must be literal on ancient hosts
* VPATH and Double-colon::      Problems with `::' on ancient hosts
* $< in Explicit Rules::        `$<' does not work in ordinary rules
* Automatic Rule Rewriting::    `VPATH' goes wild on Solaris
* Tru64 Directory Magic::       `mkdir' goes wild on Tru64
* Make Target Lookup::          More details about `VPATH' lookup


File: autoconf.info,  Node: Variables listed in VPATH,  Next: VPATH and Double-colon,  Up: VPATH and Make

12.15.1 Variables listed in `VPATH'
-----------------------------------

Do not set `VPATH' to the value of another variable, for example `VPATH
= $(srcdir)', because some ancient versions of `make' do not do
variable substitutions on the value of `VPATH'.  For example, use this

     srcdir = @srcdir@
     VPATH = @srcdir@

rather than `VPATH = $(srcdir)'.  Note that with GNU Automake, there is
no need to set this yourself.


File: autoconf.info,  Node: VPATH and Double-colon,  Next: $< in Explicit Rules,  Prev: Variables listed in VPATH,  Up: VPATH and Make

12.15.2 `VPATH' and Double-colon Rules
--------------------------------------

With ancient versions of Sun `make', any assignment to `VPATH' causes
`make' to execute only the first set of double-colon rules.  However,
this problem is no longer of practical concern.


File: autoconf.info,  Node: $< in Explicit Rules,  Next: Automatic Rule Rewriting,  Prev: VPATH and Double-colon,  Up: VPATH and Make

12.15.3 `$<' Not Supported in Explicit Rules
--------------------------------------------

Using `$<' in explicit rules is not portable.  The prerequisite file
must be named explicitly in the rule.  If you want to find the
prerequisite via a `VPATH' search, you have to code the whole thing
manually.  *Note Build Directories::.


File: autoconf.info,  Node: Automatic Rule Rewriting,  Next: Tru64 Directory Magic,  Prev: $< in Explicit Rules,  Up: VPATH and Make

12.15.4 Automatic Rule Rewriting
--------------------------------

Some `make' implementations, such as Solaris and Tru64, search for
prerequisites in `VPATH' and then rewrite each occurrence as a plain
word in the rule.  For instance:

     # This isn't portable to GNU make.
     VPATH = ../pkg/src
     f.c: if.c
             cp if.c f.c

executes `cp ../pkg/src/if.c f.c' if `if.c' is found in `../pkg/src'.

   However, this rule leads to real problems in practice.  For example,
if the source directory contains an ordinary file named `test' that is
used in a dependency, Solaris `make' rewrites commands like `if test -r
foo; ...' to `if ../pkg/src/test -r foo; ...', which is typically
undesirable.  To avoid this problem, portable makefiles should never
mention a source file whose name is that of a shell keyword like
`until' or a shell command like `cat' or `gcc' or `test'.

   Because of these problems GNU `make' and many other `make'
implementations do not rewrite commands, so portable makefiles should
search `VPATH' manually.  It is tempting to write this:

     # This isn't portable to Solaris make.
     VPATH = ../pkg/src
     f.c: if.c
             cp `test -f if.c || echo $(VPATH)/`if.c f.c

However, the "prerequisite rewriting" still applies here.  So if `if.c'
is in `../pkg/src', Solaris and Tru64 `make' execute

     cp `test -f ../pkg/src/if.c || echo ../pkg/src/`if.c f.c

which reduces to

     cp if.c f.c

and thus fails.  Oops.

   A simple workaround, and good practice anyway, is to use `$?' and
`$@' when possible:

     VPATH = ../pkg/src
     f.c: if.c
             cp $? $@

but this does not generalize well to commands with multiple
prerequisites.  A more general workaround is to rewrite the rule so that
the prerequisite `if.c' never appears as a plain word.  For example,
these three rules would be safe, assuming `if.c' is in `../pkg/src' and
the other files are in the working directory:

     VPATH = ../pkg/src
     f.c: if.c f1.c
             cat `test -f ./if.c || echo $(VPATH)/`if.c f1.c >$@
     g.c: if.c g1.c
             cat `test -f 'if.c' || echo $(VPATH)/`if.c g1.c >$@
     h.c: if.c h1.c
             cat `test -f "if.c" || echo $(VPATH)/`if.c h1.c >$@

   Things get worse when your prerequisites are in a macro.

     VPATH = ../pkg/src
     HEADERS = f.h g.h h.h
     install-HEADERS: $(HEADERS)
             for i in $(HEADERS); do \
               $(INSTALL) -m 644 \
                 `test -f $$i || echo $(VPATH)/`$$i \
                 $(DESTDIR)$(includedir)/$$i; \
             done

   The above `install-HEADERS' rule is not Solaris-proof because `for i
in $(HEADERS);' is expanded to `for i in f.h g.h h.h;' where `f.h' and
`g.h' are plain words and are hence subject to `VPATH' adjustments.

   If the three files are in `../pkg/src', the rule is run as:

     for i in ../pkg/src/f.h ../pkg/src/g.h h.h; do \
       install -m 644 \
          `test -f $i || echo ../pkg/src/`$i \
          /usr/local/include/$i; \
     done

   where the two first `install' calls fail.  For instance, consider
the `f.h' installation:

     install -m 644 \
       `test -f ../pkg/src/f.h || \
         echo ../pkg/src/ \
       `../pkg/src/f.h \
       /usr/local/include/../pkg/src/f.h;

It reduces to:

     install -m 644 \
       ../pkg/src/f.h \
       /usr/local/include/../pkg/src/f.h;

   Note that the manual `VPATH' search did not cause any problems here;
however this command installs `f.h' in an incorrect directory.

   Trying to quote `$(HEADERS)' in some way, as we did for `foo.c' a
few makefiles ago, does not help:

     install-HEADERS: $(HEADERS)
             headers='$(HEADERS)'; \
             for i in $$headers; do \
               $(INSTALL) -m 644 \
                 `test -f $$i || echo $(VPATH)/`$$i \
                 $(DESTDIR)$(includedir)/$$i; \
             done

   Now, `headers='$(HEADERS)'' macro-expands to:

     headers='f.h g.h h.h'

but `g.h' is still a plain word.  (As an aside, the idiom
`headers='$(HEADERS)'; for i in $$headers;' is a good idea if
`$(HEADERS)' can be empty, because some shells diagnose a syntax error
on `for i in;'.)

   One workaround is to strip this unwanted `../pkg/src/' prefix
manually:

     VPATH = ../pkg/src
     HEADERS = f.h g.h h.h
     install-HEADERS: $(HEADERS)
             headers='$(HEADERS)'; \
             for i in $$headers; do \
               i=`expr "$$i" : '$(VPATH)/\(.*\)'`;
               $(INSTALL) -m 644 \
                 `test -f $$i || echo $(VPATH)/`$$i \
                 $(DESTDIR)$(includedir)/$$i; \
             done

   Automake does something similar.  However the above hack works only
if the files listed in `HEADERS' are in the current directory or a
subdirectory; they should not be in an enclosing directory.  If we had
`HEADERS = ../f.h', the above fragment would fail in a VPATH build with
Tru64 `make'.  The reason is that not only does Tru64 `make' rewrite
dependencies, but it also simplifies them.  Hence `../f.h' becomes
`../pkg/f.h' instead of `../pkg/src/../f.h'.  This obviously defeats
any attempt to strip a leading `../pkg/src/' component.

   The following example makes the behavior of Tru64 `make' more
apparent.

     $ cat Makefile
     VPATH = sub
     all: ../foo
             echo ../foo
     $ ls
     Makefile foo
     $ make
     echo foo
     foo

Dependency `../foo' was found in `sub/../foo', but Tru64 `make'
simplified it as `foo'.  (Note that the `sub/' directory does not even
exist, this just means that the simplification occurred before the file
was checked for.)

   For the record here is how SunOS 4 `make' behaves on this example.

     $ make
     make: Fatal error: Don't know how to make target `../foo'
     $ mkdir sub
     $ make
     echo sub/../foo
     sub/../foo


File: autoconf.info,  Node: Tru64 Directory Magic,  Next: Make Target Lookup,  Prev: Automatic Rule Rewriting,  Up: VPATH and Make

12.15.5 Tru64 `make' Creates Prerequisite Directories Magically
---------------------------------------------------------------

When a prerequisite is a subdirectory of `VPATH', Tru64 `make' creates
it in the current directory.

     $ mkdir -p foo/bar build
     $ cd build
     $ cat >Makefile <<END
     VPATH = ..
     all: foo/bar
     END
     $ make
     mkdir foo
     mkdir foo/bar

   This can yield unexpected results if a rule uses a manual `VPATH'
search as presented before.

     VPATH = ..
     all : foo/bar
             command `test -d foo/bar || echo ../`foo/bar

   The above `command' is run on the empty `foo/bar' directory that was
created in the current directory.


File: autoconf.info,  Node: Make Target Lookup,  Prev: Tru64 Directory Magic,  Up: VPATH and Make

12.15.6 Make Target Lookup
--------------------------

GNU `make' uses a complex algorithm to decide when it should use files
found via a `VPATH' search.  *Note How Directory Searches are
Performed: (make)Search Algorithm.

   If a target needs to be rebuilt, GNU `make' discards the file name
found during the `VPATH' search for this target, and builds the file
locally using the file name given in the makefile.  If a target does
not need to be rebuilt, GNU `make' uses the file name found during the
`VPATH' search.

   Other `make' implementations, like NetBSD `make', are easier to
describe: the file name found during the `VPATH' search is used whether
the target needs to be rebuilt or not.  Therefore new files are created
locally, but existing files are updated at their `VPATH' location.

   OpenBSD and FreeBSD `make', however, never perform a `VPATH' search
for a dependency that has an explicit rule.  This is extremely annoying.

   When attempting a `VPATH' build for an autoconfiscated package
(e.g., `mkdir build && cd build && ../configure'), this means GNU
`make' builds everything locally in the `build' directory, while BSD
`make' builds new files locally and updates existing files in the
source directory.

     $ cat Makefile
     VPATH = ..
     all: foo.x bar.x
     foo.x bar.x: newer.x
             @echo Building $@
     $ touch ../bar.x
     $ touch ../newer.x
     $ make        # GNU make
     Building foo.x
     Building bar.x
     $ pmake       # NetBSD make
     Building foo.x
     Building ../bar.x
     $ fmake       # FreeBSD make, OpenBSD make
     Building foo.x
     Building bar.x
     $ tmake       # Tru64 make
     Building foo.x
     Building bar.x
     $ touch ../bar.x
     $ make        # GNU make
     Building foo.x
     $ pmake       # NetBSD make
     Building foo.x
     $ fmake       # FreeBSD make, OpenBSD make
     Building foo.x
     Building bar.x
     $ tmake       # Tru64 make
     Building foo.x
     Building bar.x

   Note how NetBSD `make' updates `../bar.x' in its VPATH location, and
how FreeBSD, OpenBSD, and Tru64 `make' always update `bar.x', even when
`../bar.x' is up to date.

   Another point worth mentioning is that once GNU `make' has decided
to ignore a `VPATH' file name (e.g., it ignored `../bar.x' in the above
example) it continues to ignore it when the target occurs as a
prerequisite of another rule.

   The following example shows that GNU `make' does not look up `bar.x'
in `VPATH' before performing the `.x.y' rule, because it ignored the
`VPATH' result of `bar.x' while running the `bar.x: newer.x' rule.

     $ cat Makefile
     VPATH = ..
     all: bar.y
     bar.x: newer.x
             @echo Building $@
     .SUFFIXES: .x .y
     .x.y:
             cp $< $@
     $ touch ../bar.x
     $ touch ../newer.x
     $ make        # GNU make
     Building bar.x
     cp bar.x bar.y
     cp: cannot stat `bar.x': No such file or directory
     make: *** [bar.y] Error 1
     $ pmake       # NetBSD make
     Building ../bar.x
     cp ../bar.x bar.y
     $ rm bar.y
     $ fmake       # FreeBSD make, OpenBSD make
     echo Building bar.x
     cp bar.x bar.y
     cp: cannot stat `bar.x': No such file or directory
     *** Error code 1
     $ tmake       # Tru64 make
     Building bar.x
     cp: bar.x: No such file or directory
     *** Exit 1

   Note that if you drop away the command from the `bar.x: newer.x'
rule, GNU `make' magically starts to work: it knows that `bar.x' hasn't
been updated, therefore it doesn't discard the result from `VPATH'
(`../bar.x') in succeeding uses.  Tru64 also works, but FreeBSD and
OpenBSD still don't.

     $ cat Makefile
     VPATH = ..
     all: bar.y
     bar.x: newer.x
     .SUFFIXES: .x .y
     .x.y:
             cp $< $@
     $ touch ../bar.x
     $ touch ../newer.x
     $ make        # GNU make
     cp ../bar.x bar.y
     $ rm bar.y
     $ pmake       # NetBSD make
     cp ../bar.x bar.y
     $ rm bar.y
     $ fmake       # FreeBSD make, OpenBSD make
     cp bar.x bar.y
     cp: cannot stat `bar.x': No such file or directory
     *** Error code 1
     $ tmake       # Tru64 make
     cp ../bar.x bar.y

   It seems the sole solution that would please every `make'
implementation is to never rely on `VPATH' searches for targets.  In
other words, `VPATH' should be reserved to unbuilt sources.


File: autoconf.info,  Node: Single Suffix Rules,  Next: Timestamps and Make,  Prev: VPATH and Make,  Up: Portable Make

12.16 Single Suffix Rules and Separated Dependencies
====================================================

A "Single Suffix Rule" is basically a usual suffix (inference) rule
(`.from.to:'), but which _destination_ suffix is empty (`.from:').

   "Separated dependencies" simply refers to listing the prerequisite
of a target, without defining a rule.  Usually one can list on the one
hand side, the rules, and on the other hand side, the dependencies.

   Solaris `make' does not support separated dependencies for targets
defined by single suffix rules:

     $ cat Makefile
     .SUFFIXES: .in
     foo: foo.in
     .in:
             cp $< $@
     $ touch foo.in
     $ make
     $ ls
     Makefile  foo.in

while GNU Make does:

     $ gmake
     cp foo.in foo
     $ ls
     Makefile  foo       foo.in

   Note it works without the `foo: foo.in' dependency.

     $ cat Makefile
     .SUFFIXES: .in
     .in:
             cp $< $@
     $ make foo
     cp foo.in foo

and it works with double suffix inference rules:

     $ cat Makefile
     foo.out: foo.in
     .SUFFIXES: .in .out
     .in.out:
             cp $< $@
     $ make
     cp foo.in foo.out

   As a result, in such a case, you have to write target rules.


File: autoconf.info,  Node: Timestamps and Make,  Prev: Single Suffix Rules,  Up: Portable Make

12.17 Timestamp Resolution and Make
===================================

Traditionally, file timestamps had 1-second resolution, and `make' used
those timestamps to determine whether one file was newer than the
other.  However, many modern file systems have timestamps with
1-nanosecond resolution.  Some `make' implementations look at the
entire timestamp; others ignore the fractional part, which can lead to
incorrect results.  Normally this is not a problem, but in some extreme
cases you may need to use tricks like `sleep 1' to work around
timestamp truncation bugs.

   Commands like `cp -p' and `touch -r' typically do not copy file
timestamps to their full resolutions (*note Limitations of Usual Tools:
touch.).  Hence you should be wary of rules like this:

     dest: src
             cp -p src dest

   as `dest' often appears to be older than `src' after the timestamp
is truncated, and this can cause `make' to do needless rework the next
time it is invoked.  To work around this problem, you can use a
timestamp file, e.g.:

     dest-stamp: src
             cp -p src dest
             date >dest-stamp


File: autoconf.info,  Node: Portable C and C++,  Next: Manual Configuration,  Prev: Portable Make,  Up: Top

13 Portable C and C++ Programming
*********************************

C and C++ programs often use low-level features of the underlying
system, and therefore are often more difficult to make portable to other
platforms.

   Several standards have been developed to help make your programs more
portable.  If you write programs with these standards in mind, you can
have greater confidence that your programs work on a wide variety of
systems.  *Note Language Standards Supported by GCC: (gcc)Standards,
for a list of C-related standards.  Many programs also assume the Posix
standard (http://www.opengroup.org/susv3).

   Some old code is written to be portable to K&R C, which predates any
C standard.  K&R C compilers are no longer of practical interest,
though, and the rest of section assumes at least C89, the first C
standard.

   Program portability is a huge topic, and this section can only
briefly introduce common pitfalls.  *Note Portability between System
Types: (standards)System Portability, for more information.

* Menu:

* Varieties of Unportability::  How to make your programs unportable
* Integer Overflow::            When integers get too large
* Preprocessor Arithmetic::     `#if' expression problems
* Null Pointers::               Properties of null pointers
* Buffer Overruns::             Subscript errors and the like
* Volatile Objects::            `volatile' and signals
* Floating Point Portability::  Portable floating-point arithmetic
* Exiting Portably::            Exiting and the exit status


File: autoconf.info,  Node: Varieties of Unportability,  Next: Integer Overflow,  Up: Portable C and C++

13.1 Varieties of Unportability
===============================

Autoconf tests and ordinary programs often need to test what is allowed
on a system, and therefore they may need to deliberately exceed the
boundaries of what the standards allow, if only to see whether an
optional feature is present.  When you write such a program, you should
keep in mind the difference between constraints, unspecified behavior,
and undefined behavior.

   In C, a "constraint" is a rule that the compiler must enforce.  An
example constraint is that C programs must not declare a bit-field with
negative width.  Tests can therefore reliably assume that programs with
negative-width bit-fields are rejected by a compiler that conforms to
the standard.

   "Unspecified behavior" is valid behavior, where the standard allows
multiple possibilities.  For example, the order of evaluation of
function arguments is unspecified.  Some unspecified behavior is
"implementation-defined", i.e., documented by the implementation, but
since Autoconf tests cannot read the documentation they cannot
distinguish between implementation-defined and other unspecified
behavior.  It is common for Autoconf tests to probe implementations to
determine otherwise-unspecified behavior.

   "Undefined behavior" is invalid behavior, where the standard allows
the implementation to do anything it pleases.  For example,
dereferencing a null pointer leads to undefined behavior.  If possible,
test programs should avoid undefined behavior, since a program with
undefined behavior might succeed on a test that should fail.

   The above rules apply to programs that are intended to conform to the
standard.  However, strictly-conforming programs are quite rare, since
the standards are so limiting.  A major goal of Autoconf is to support
programs that use implementation features not described by the standard,
and it is fairly common for test programs to violate the above rules, if
the programs work well enough in practice.


File: autoconf.info,  Node: Integer Overflow,  Next: Preprocessor Arithmetic,  Prev: Varieties of Unportability,  Up: Portable C and C++

13.2 Integer Overflow
=====================

In practice many portable C programs assume that signed integer
overflow wraps around reliably using two's complement arithmetic.  Yet
the C standard says that program behavior is undefined on overflow, and
in a few cases C programs do not work on some modern implementations
because their overflows do not wrap around as their authors expected.
Conversely, in signed integer remainder, the C standard requires
overflow behavior that is commonly not implemented.

* Menu:

* Integer Overflow Basics::      Why integer overflow is a problem
* Signed Overflow Examples::     Examples of code assuming wraparound
* Optimization and Wraparound::  Optimizations that break uses of wraparound
* Signed Overflow Advice::       Practical advice for signed overflow issues
* Signed Integer Division::      `INT_MIN / -1' and `INT_MIN % -1'


File: autoconf.info,  Node: Integer Overflow Basics,  Next: Signed Overflow Examples,  Up: Integer Overflow

13.2.1 Basics of Integer Overflow
---------------------------------

In languages like C, unsigned integer overflow reliably wraps around;
e.g., `UINT_MAX + 1' yields zero.  This is guaranteed by the C standard
and is portable in practice, unless you specify aggressive, nonstandard
optimization options suitable only for special applications.

   In contrast, the C standard says that signed integer overflow leads
to undefined behavior where a program can do anything, including dumping
core or overrunning a buffer.  The misbehavior can even precede the
overflow.  Such an overflow can occur during addition, subtraction,
multiplication, division, and left shift.

   Despite this requirement of the standard, many C programs and
Autoconf tests assume that signed integer overflow silently wraps
around modulo a power of two, using two's complement arithmetic, so
long as you cast the resulting value to a signed integer type or store
it into a signed integer variable.  If you use conservative
optimization flags, such programs are generally portable to the vast
majority of modern platforms, with a few exceptions discussed later.

   For historical reasons the C standard also allows implementations
with ones' complement or signed magnitude arithmetic, but it is safe to
assume two's complement nowadays.

   Also, overflow can occur when converting an out-of-range value to a
signed integer type.  Here a standard implementation must define what
happens, but this might include raising an exception.  In practice all
known implementations support silent wraparound in this case, so you
need not worry about other possibilities.


File: autoconf.info,  Node: Signed Overflow Examples,  Next: Optimization and Wraparound,  Prev: Integer Overflow Basics,  Up: Integer Overflow

13.2.2 Examples of Code Assuming Wraparound Overflow
----------------------------------------------------

There has long been a tension between what the C standard requires for
signed integer overflow, and what C programs commonly assume.  The
standard allows aggressive optimizations based on assumptions that
overflow never occurs, but many practical C programs rely on overflow
wrapping around.  These programs do not conform to the standard, but
they commonly work in practice because compiler writers are
understandably reluctant to implement optimizations that would break
many programs, unless perhaps a user specifies aggressive optimization.

   The C Standard says that if a program has signed integer overflow its
behavior is undefined, and the undefined behavior can even precede the
overflow.  To take an extreme example:

     if (password == expected_password)
       allow_superuser_privileges ();
     else if (counter++ == INT_MAX)
       abort ();
     else
       printf ("%d password mismatches\n", counter);

If the `int' variable `counter' equals `INT_MAX', `counter++' must
overflow and the behavior is undefined, so the C standard allows the
compiler to optimize away the test against `INT_MAX' and the `abort'
call.  Worse, if an earlier bug in the program lets the compiler deduce
that `counter == INT_MAX' or that `counter' previously overflowed, the
C standard allows the compiler to optimize away the password test and
generate code that allows superuser privileges unconditionally.

   Despite this requirement by the standard, it has long been common
for C code to assume wraparound arithmetic after signed overflow, and
all known practical C implementations support some C idioms that assume
wraparound signed arithmetic, even if the idioms do not conform
strictly to the standard.  If your code looks like the following
examples it will almost surely work with real-world compilers.

   Here is an example derived from the 7th Edition Unix implementation
of `atoi' (1979-01-10):

     char *p;
     int f, n;
     ...
     while (*p >= '0' && *p <= '9')
       n = n * 10 + *p++ - '0';
     return (f ? -n : n);

Even if the input string is in range, on most modern machines this has
signed overflow when computing the most negative integer (the `-n'
overflows) or a value near an extreme integer (the first `+' overflows).

   Here is another example, derived from the 7th Edition implementation
of `rand' (1979-01-10).  Here the programmer expects both
multiplication and addition to wrap on overflow:

     static long int randx = 1;
     ...
     randx = randx * 1103515245 + 12345;
     return (randx >> 16) & 077777;

   In the following example, derived from the GNU C Library 2.5
implementation of `mktime' (2006-09-09), the code assumes wraparound
arithmetic in `+' to detect signed overflow:

     time_t t, t1, t2;
     int sec_requested, sec_adjustment;
     ...
     t1 = t + sec_requested;
     t2 = t1 + sec_adjustment;
     if (((t1 < t) != (sec_requested < 0))
         | ((t2 < t1) != (sec_adjustment < 0)))
       return -1;

   If your code looks like these examples, it is probably safe even
though it does not strictly conform to the C standard.  This might lead
one to believe that one can generally assume wraparound on overflow,
but that is not always true, as can be seen in the next section.


File: autoconf.info,  Node: Optimization and Wraparound,  Next: Signed Overflow Advice,  Prev: Signed Overflow Examples,  Up: Integer Overflow

13.2.3 Optimizations That Break Wraparound Arithmetic
-----------------------------------------------------

Compilers sometimes generate code that is incompatible with wraparound
integer arithmetic.  A simple example is an algebraic simplification: a
compiler might translate `(i * 2000) / 1000' to `i * 2' because it
assumes that `i * 2000' does not overflow.  The translation is not
equivalent to the original when overflow occurs: e.g., in the typical
case of 32-bit signed two's complement wraparound `int', if `i' has
type `int' and value `1073742', the original expression returns
-2147483 but the optimized version returns the mathematically correct
value 2147484.

   More subtly, loop induction optimizations often exploit the undefined
behavior of signed overflow.  Consider the following contrived function
`sumc':

     int
     sumc (int lo, int hi)
     {
       int sum = 0;
       int i;
       for (i = lo; i <= hi; i++)
         sum ^= i * 53;
       return sum;
     }

To avoid multiplying by 53 each time through the loop, an optimizing
compiler might internally transform `sumc' to the equivalent of the
following:

     int
     transformed_sumc (int lo, int hi)
     {
       int sum = 0;
       int hic = hi * 53;
       int ic;
       for (ic = lo * 53; ic <= hic; ic += 53)
         sum ^= ic;
       return sum;
     }

This transformation is allowed by the C standard, but it is invalid for
wraparound arithmetic when `INT_MAX / 53 < hi', because then the
overflow in computing expressions like `hi * 53' can cause the
expression `i <= hi' to yield a different value from the transformed
expression `ic <= hic'.

   For this reason, compilers that use loop induction and similar
techniques often do not support reliable wraparound arithmetic when a
loop induction variable like `ic' is involved.  Since loop induction
variables are generated by the compiler, and are not visible in the
source code, it is not always trivial to say whether the problem
affects your code.

   Hardly any code actually depends on wraparound arithmetic in cases
like these, so in practice these loop induction optimizations are almost
always useful.  However, edge cases in this area can cause problems.
For example:

     int j;
     for (j = 1; 0 < j; j *= 2)
       test (j);

Here, the loop attempts to iterate through all powers of 2 that `int'
can represent, but the C standard allows a compiler to optimize away
the comparison and generate an infinite loop, under the argument that
behavior is undefined on overflow.  As of this writing this
optimization is not done by any production version of GCC with `-O2',
but it might be performed by other compilers, or by more aggressive GCC
optimization options, and the GCC developers have not decided whether
it will continue to work with GCC and `-O2'.


File: autoconf.info,  Node: Signed Overflow Advice,  Next: Signed Integer Division,  Prev: Optimization and Wraparound,  Up: Integer Overflow

13.2.4 Practical Advice for Signed Overflow Issues
--------------------------------------------------

Ideally the safest approach is to avoid signed integer overflow
entirely.  For example, instead of multiplying two signed integers, you
can convert them to unsigned integers, multiply the unsigned values,
then test whether the result is in signed range.

   Rewriting code in this way will be inconvenient, though,
particularly if the signed values might be negative.  Also, it may hurt
performance.  Using unsigned arithmetic to check for overflow is
particularly painful to do portably and efficiently when dealing with an
integer type like `uid_t' whose width and signedness vary from platform
to platform.

   Furthermore, many C applications pervasively assume wraparound
behavior and typically it is not easy to find and remove all these
assumptions.  Hence it is often useful to maintain nonstandard code
that assumes wraparound on overflow, instead of rewriting the code.
The rest of this section attempts to give practical advice for this
situation.

   If your code wants to detect signed integer overflow in `sum = a +
b', it is generally safe to use an expression like `(sum < a) != (b <
0)'.

   If your code uses a signed loop index, make sure that the index
cannot overflow, along with all signed expressions derived from the
index.  Here is a contrived example of problematic code with two
instances of overflow.

     for (i = INT_MAX - 10; i <= INT_MAX; i++)
       if (i + 1 < 0)
         {
           report_overflow ();
           break;
         }

Because of the two overflows, a compiler might optimize away or
transform the two comparisons in a way that is incompatible with the
wraparound assumption.

   If your code uses an expression like `(i * 2000) / 1000' and you
actually want the multiplication to wrap around on overflow, use
unsigned arithmetic to do it, e.g., `((int) (i * 2000u)) / 1000'.

   If your code assumes wraparound behavior and you want to insulate it
against any GCC optimizations that would fail to support that behavior,
you should use GCC's `-fwrapv' option, which causes signed overflow to
wrap around reliably (except for division and remainder, as discussed
in the next section).

   If you need to port to platforms where signed integer overflow does
not reliably wrap around (e.g., due to hardware overflow checking, or to
highly aggressive optimizations), you should consider debugging with
GCC's `-ftrapv' option, which causes signed overflow to raise an
exception.


File: autoconf.info,  Node: Signed Integer Division,  Prev: Signed Overflow Advice,  Up: Integer Overflow

13.2.5 Signed Integer Division and Integer Overflow
---------------------------------------------------

Overflow in signed integer division is not always harmless: for
example, on CPUs of the i386 family, dividing `INT_MIN' by `-1' yields
a SIGFPE signal which by default terminates the program.  Worse, taking
the remainder of these two values typically yields the same signal on
these CPUs, even though the C standard requires `INT_MIN % -1' to yield
zero because the expression does not overflow.


File: autoconf.info,  Node: Preprocessor Arithmetic,  Next: Null Pointers,  Prev: Integer Overflow,  Up: Portable C and C++

13.3 Preprocessor Arithmetic
============================

In C99, preprocessor arithmetic, used for `#if' expressions, must be
evaluated as if all signed values are of type `intmax_t' and all
unsigned values of type `uintmax_t'.  Many compilers are buggy in this
area, though.  For example, as of 2007, Sun C mishandles `#if LLONG_MIN
< 0' on a platform with 32-bit `long int' and 64-bit `long long int'.
Also, some older preprocessors mishandle constants ending in `LL'.  To
work around these problems, you can compute the value of expressions
like `LONG_MAX < LLONG_MAX' at `configure'-time rather than at
`#if'-time.


File: autoconf.info,  Node: Null Pointers,  Next: Buffer Overruns,  Prev: Preprocessor Arithmetic,  Up: Portable C and C++

13.4 Properties of Null Pointers
================================

Most modern hosts reliably fail when you attempt to dereference a null
pointer.

   On almost all modern hosts, null pointers use an all-bits-zero
internal representation, so you can reliably use `memset' with 0 to set
all the pointers in an array to null values.

   If `p' is a null pointer to an object type, the C expression `p + 0'
always evaluates to `p' on modern hosts, even though the standard says
that it has undefined behavior.


File: autoconf.info,  Node: Buffer Overruns,  Next: Volatile Objects,  Prev: Null Pointers,  Up: Portable C and C++

13.5 Buffer Overruns and Subscript Errors
=========================================

Buffer overruns and subscript errors are the most common dangerous
errors in C programs.  They result in undefined behavior because storing
outside an array typically modifies storage that is used by some other
object, and most modern systems lack runtime checks to catch these
errors.  Programs should not rely on buffer overruns being caught.

   There is one exception to the usual rule that a portable program
cannot address outside an array.  In C, it is valid to compute the
address just past an object, e.g., `&a[N]' where `a' has `N' elements,
so long as you do not dereference the resulting pointer.  But it is not
valid to compute the address just before an object, e.g., `&a[-1]'; nor
is it valid to compute two past the end, e.g., `&a[N+1]'.  On most
platforms `&a[-1] < &a[0] && &a[N] < &a[N+1]', but this is not reliable
in general, and it is usually easy enough to avoid the potential
portability problem, e.g., by allocating an extra unused array element
at the start or end.

   Valgrind (http://valgrind.org/) can catch many overruns.  GCC users
might also consider using the `-fmudflap' option to catch overruns.

   Buffer overruns are usually caused by off-by-one errors, but there
are more subtle ways to get them.

   Using `int' values to index into an array or compute array sizes
causes problems on typical 64-bit hosts where an array index might be
2^31 or larger.  Index values of type `size_t' avoid this problem, but
cannot be negative.  Index values of type `ptrdiff_t' are signed, and
are wide enough in practice.

   If you add or multiply two numbers to calculate an array size, e.g.,
`malloc (x * sizeof y + z)', havoc ensues if the addition or
multiplication overflows.

   Many implementations of the `alloca' function silently misbehave and
can generate buffer overflows if given sizes that are too large.  The
size limits are implementation dependent, but are at least 4000 bytes
on all platforms that we know about.

   The standard functions `asctime', `asctime_r', `ctime', `ctime_r',
and `gets' are prone to buffer overflows, and portable code should not
use them unless the inputs are known to be within certain limits.  The
time-related functions can overflow their buffers if given timestamps
out of range (e.g., a year less than -999 or greater than 9999).
Time-related buffer overflows cannot happen with recent-enough versions
of the GNU C library, but are possible with other implementations.  The
`gets' function is the worst, since it almost invariably overflows its
buffer when presented with an input line larger than the buffer.


File: autoconf.info,  Node: Volatile Objects,  Next: Floating Point Portability,  Prev: Buffer Overruns,  Up: Portable C and C++

13.6 Volatile Objects
=====================

The keyword `volatile' is often misunderstood in portable code.  Its
use inhibits some memory-access optimizations, but programmers often
wish that it had a different meaning than it actually does.

   `volatile' was designed for code that accesses special objects like
memory-mapped device registers whose contents spontaneously change.
Such code is inherently low-level, and it is difficult to specify
portably what `volatile' means in these cases.  The C standard says,
"What constitutes an access to an object that has volatile-qualified
type is implementation-defined," so in theory each implementation is
supposed to fill in the gap by documenting what `volatile' means for
that implementation.  In practice, though, this documentation is
usually absent or incomplete.

   One area of confusion is the distinction between objects defined with
volatile types, and volatile lvalues.  From the C standard's point of
view, an object defined with a volatile type has externally visible
behavior.  You can think of such objects as having little oscilloscope
probes attached to them, so that the user can observe some properties of
accesses to them, just as the user can observe data written to output
files.  However, the standard does not make it clear whether users can
observe accesses by volatile lvalues to ordinary objects.  For example:

     /* Declare and access a volatile object.
        Accesses to X are "visible" to users.  */
     static int volatile x;
     x = 1;

     /* Access two ordinary objects via a volatile lvalue.
        It's not clear whether accesses to *P are "visible".  */
     int y;
     int *z = malloc (sizeof (int));
     int volatile *p;
     p = &y;
     *p = 1;
     p = z;
     *p = 1;

   Programmers often wish that `volatile' meant "Perform the memory
access here and now, without merging several memory accesses, without
changing the memory word size, and without reordering."  But the C
standard does not require this.  For objects defined with a volatile
type, accesses must be done before the next sequence point; but
otherwise merging, reordering, and word-size change is allowed.  Worse,
it is not clear from the standard whether volatile lvalues provide more
guarantees in general than nonvolatile lvalues, if the underlying
objects are ordinary.

   Even when accessing objects defined with a volatile type, the C
standard allows only extremely limited signal handlers: the behavior is
undefined if a signal handler reads any nonlocal object, or writes to
any nonlocal object whose type is not `sig_atomic_t volatile', or calls
any standard library function other than `abort', `signal', and (if C99)
`_Exit'.  Hence C compilers need not worry about a signal handler
disturbing ordinary computation, unless the computation accesses a
`sig_atomic_t volatile' lvalue that is not a local variable.  (There is
an obscure exception for accesses via a pointer to a volatile
character, since it may point into part of a `sig_atomic_t volatile'
object.)  Posix adds to the list of library functions callable from a
portable signal handler, but otherwise is like the C standard in this
area.

   Some C implementations allow memory-access optimizations within each
translation unit, such that actual behavior agrees with the behavior
required by the standard only when calling a function in some other
translation unit, and a signal handler acts like it was called from a
different translation unit.  The C standard hints that in these
implementations, objects referred to by signal handlers "would require
explicit specification of `volatile' storage, as well as other
implementation-defined restrictions."  But unfortunately even for this
special case these other restrictions are often not documented well.
*Note When is a Volatile Object Accessed?: (gcc)Volatiles, for some
restrictions imposed by GCC.  *Note Defining Signal Handlers:
(libc)Defining Handlers, for some restrictions imposed by the GNU C
library.  Restrictions differ on other platforms.

   If possible, it is best to use a signal handler that fits within the
limits imposed by the C and Posix standards.

   If this is not practical, you can try the following rules of thumb.
A signal handler should access only volatile lvalues, preferably lvalues
that refer to objects defined with a volatile type, and should not
assume that the accessed objects have an internally consistent state if
they are larger than a machine word.  Furthermore, installers should
employ compilers and compiler options that are commonly used for
building operating system kernels, because kernels often need more from
`volatile' than the C Standard requires, and installers who compile an
application in a similar environment can sometimes benefit from the
extra constraints imposed by kernels on compilers.  Admittedly we are
handwaving somewhat here, as there are few guarantees in this area; the
rules of thumb may help to fix some bugs but there is a good chance
that they will not fix them all.

   For `volatile', C++ has the same problems that C does.
Multithreaded applications have even more problems with `volatile', but
they are beyond the scope of this section.

   The bottom line is that using `volatile' typically hurts performance
but should not hurt correctness.  In some cases its use does help
correctness, but these cases are often so poorly understood that all
too often adding `volatile' to a data structure merely alleviates some
symptoms of a bug while not fixing the bug in general.


File: autoconf.info,  Node: Floating Point Portability,  Next: Exiting Portably,  Prev: Volatile Objects,  Up: Portable C and C++

13.7 Floating Point Portability
===============================

Almost all modern systems use IEEE-754 floating point, and it is safe to
assume IEEE-754 in most portable code these days.  For more information,
please see David Goldberg's classic paper What Every Computer Scientist
Should Know About Floating-Point Arithmetic
(http://www.validlab.com/goldberg/paper.pdf).


File: autoconf.info,  Node: Exiting Portably,  Prev: Floating Point Portability,  Up: Portable C and C++

13.8 Exiting Portably
=====================

A C or C++ program can exit with status N by returning N from the
`main' function.  Portable programs are supposed to exit either with
status 0 or `EXIT_SUCCESS' to succeed, or with status `EXIT_FAILURE' to
fail, but in practice it is portable to fail by exiting with status 1,
and test programs that assume Posix can fail by exiting with status
values from 1 through 255.  Programs on SunOS 2.0 (1985) through 3.5.2
(1988) incorrectly exited with zero status when `main' returned
nonzero, but ancient systems like these are no longer of practical
concern.

   A program can also exit with status N by passing N to the `exit'
function, and a program can fail by calling the `abort' function.  If a
program is specialized to just some platforms, it can fail by calling
functions specific to those platforms, e.g., `_exit' (Posix) and
`_Exit' (C99).  However, like other functions, an exit function should
be declared, typically by including a header.  For example, if a C
program calls `exit', it should include `stdlib.h' either directly or
via the default includes (*note Default Includes::).

   A program can fail due to undefined behavior such as dereferencing a
null pointer, but this is not recommended as undefined behavior allows
an implementation to do whatever it pleases and this includes exiting
successfully.


File: autoconf.info,  Node: Manual Configuration,  Next: Site Configuration,  Prev: Portable C and C++,  Up: Top

14 Manual Configuration
***********************

A few kinds of features can't be guessed automatically by running test
programs.  For example, the details of the object-file format, or
special options that need to be passed to the compiler or linker.  You
can check for such features using ad-hoc means, such as having
`configure' check the output of the `uname' program, or looking for
libraries that are unique to particular systems.  However, Autoconf
provides a uniform method for handling unguessable features.

* Menu:

* Specifying Target Triplets::  Specifying target triplets
* Canonicalizing::              Getting the canonical system type
* Using System Type::           What to do with the system type


File: autoconf.info,  Node: Specifying Target Triplets,  Next: Canonicalizing,  Up: Manual Configuration

14.1 Specifying target triplets
===============================

Autoconf-generated `configure' scripts can make decisions based on a
canonical name for the system type, or "target triplet", which has the
form: `CPU-VENDOR-OS', where OS can be `SYSTEM' or `KERNEL-SYSTEM'

   `configure' can usually guess the canonical name for the type of
system it's running on.  To do so it runs a script called
`config.guess', which infers the name using the `uname' command or
symbols predefined by the C preprocessor.

   Alternately, the user can specify the system type with command line
arguments to `configure' (*note System Type::.  Doing so is necessary
when cross-compiling.  In the most complex case of cross-compiling,
three system types are involved.  The options to specify them are:

`--build=BUILD-TYPE'
     the type of system on which the package is being configured and
     compiled.  It defaults to the result of running `config.guess'.

`--host=HOST-TYPE'
     the type of system on which the package runs.  By default it is the
     same as the build machine.  Specifying it enables the
     cross-compilation mode.

`--target=TARGET-TYPE'
     the type of system for which any compiler tools in the package
     produce code (rarely needed).  By default, it is the same as host.

   If you mean to override the result of `config.guess', use `--build',
not `--host', since the latter enables cross-compilation.  For
historical reasons, whenever you specify `--host', be sure to specify
`--build' too; this will be fixed in the future.  So, to enter
cross-compilation mode, use a command like this

     ./configure --build=i686-pc-linux-gnu --host=m68k-coff

Note that if you do not specify `--host', `configure' fails if it can't
run the code generated by the specified compiler.  For example,
configuring as follows fails:

     ./configure CC=m68k-coff-gcc

   When cross-compiling, `configure' will warn about any tools
(compilers, linkers, assemblers) whose name is not prefixed with the
host type.  This is an aid to users performing cross-compilation.
Continuing the example above, if a cross-compiler named `cc' is used
with a native `pkg-config', then libraries found by `pkg-config' will
likely cause subtle build failures; but using the names `m68k-coff-cc'
and `m68k-coff-pkg-config' avoids any confusion.  Avoiding the warning
is as simple as creating the correct symlinks naming the cross tools.

   `configure' recognizes short aliases for many system types; for
example, `decstation' can be used instead of `mips-dec-ultrix4.2'.
`configure' runs a script called `config.sub' to canonicalize system
type aliases.

   This section deliberately omits the description of the obsolete
interface; see *note Hosts and Cross-Compilation::.


File: autoconf.info,  Node: Canonicalizing,  Next: Using System Type,  Prev: Specifying Target Triplets,  Up: Manual Configuration

14.2 Getting the Canonical System Type
======================================

The following macros make the system type available to `configure'
scripts.

   The variables `build_alias', `host_alias', and `target_alias' are
always exactly the arguments of `--build', `--host', and `--target'; in
particular, they are left empty if the user did not use them, even if
the corresponding `AC_CANONICAL' macro was run.  Any configure script
may use these variables anywhere.  These are the variables that should
be used when in interaction with the user.

   If you need to recognize some special environments based on their
system type, run the following macros to get canonical system names.
These variables are not set before the macro call.

   If you use these macros, you must distribute `config.guess' and
`config.sub' along with your source code.  *Note Output::, for
information about the `AC_CONFIG_AUX_DIR' macro which you can use to
control in which directory `configure' looks for those scripts.

 -- Macro: AC_CANONICAL_BUILD
     Compute the canonical build-system type variable, `build', and its
     three individual parts `build_cpu', `build_vendor', and `build_os'.

     If `--build' was specified, then `build' is the canonicalization
     of `build_alias' by `config.sub', otherwise it is determined by
     the shell script `config.guess'.

 -- Macro: AC_CANONICAL_HOST
     Compute the canonical host-system type variable, `host', and its
     three individual parts `host_cpu', `host_vendor', and `host_os'.

     If `--host' was specified, then `host' is the canonicalization of
     `host_alias' by `config.sub', otherwise it defaults to `build'.

 -- Macro: AC_CANONICAL_TARGET
     Compute the canonical target-system type variable, `target', and
     its three individual parts `target_cpu', `target_vendor', and
     `target_os'.

     If `--target' was specified, then `target' is the canonicalization
     of `target_alias' by `config.sub', otherwise it defaults to `host'.

   Note that there can be artifacts due to the backward compatibility
code.  *Note Hosts and Cross-Compilation::, for more.


File: autoconf.info,  Node: Using System Type,  Prev: Canonicalizing,  Up: Manual Configuration

14.3 Using the System Type
==========================

In `configure.ac' the system type is generally used by one or more
`case' statements to select system-specifics.  Shell wildcards can be
used to match a group of system types.

   For example, an extra assembler code object file could be chosen,
giving access to a CPU cycle counter register.  `$(CYCLE_OBJ)' in the
following would be used in a makefile to add the object to a program or
library.

     AS_CASE([$host],
       [alpha*-*-*], [CYCLE_OBJ=rpcc.o],
       [i?86-*-*],   [CYCLE_OBJ=rdtsc.o],
       [CYCLE_OBJ=""]
     )
     AC_SUBST([CYCLE_OBJ])

   `AC_CONFIG_LINKS' (*note Configuration Links::) is another good way
to select variant source files, for example optimized code for some
CPUs.  The configured CPU type doesn't always indicate exact CPU types,
so some runtime capability checks may be necessary too.

     case $host in
       alpha*-*-*)   AC_CONFIG_LINKS([dither.c:alpha/dither.c]) ;;
       powerpc*-*-*) AC_CONFIG_LINKS([dither.c:powerpc/dither.c]) ;;
       *-*-*)        AC_CONFIG_LINKS([dither.c:generic/dither.c]) ;;
     esac

   The host system type can also be used to find cross-compilation tools
with `AC_CHECK_TOOL' (*note Generic Programs::).

   The above examples all show `$host', since this is where the code is
going to run.  Only rarely is it necessary to test `$build' (which is
where the build is being done).

   Whenever you're tempted to use `$host' it's worth considering
whether some sort of probe would be better.  New system types come along
periodically or previously missing features are added.  Well-written
probes can adapt themselves to such things, but hard-coded lists of
names can't.  Here are some guidelines,

   * Availability of libraries and library functions should always be
     checked by probing.

   * Variant behavior of system calls is best identified with runtime
     tests if possible, but bug workarounds or obscure difficulties
     might have to be driven from `$host'.

   * Assembler code is inevitably highly CPU-specific and is best
     selected according to `$host_cpu'.

   * Assembler variations like underscore prefix on globals or ELF
     versus COFF type directives are however best determined by
     probing, perhaps even examining the compiler output.

   `$target' is for use by a package creating a compiler or similar.
For ordinary packages it's meaningless and should not be used.  It
indicates what the created compiler should generate code for, if it can
cross-compile.  `$target' generally selects various hard-coded CPU and
system conventions, since usually the compiler or tools under
construction themselves determine how the target works.


File: autoconf.info,  Node: Site Configuration,  Next: Running configure Scripts,  Prev: Manual Configuration,  Up: Top

15 Site Configuration
*********************

`configure' scripts support several kinds of local configuration
decisions.  There are ways for users to specify where external software
packages are, include or exclude optional features, install programs
under modified names, and set default values for `configure' options.

* Menu:

* Help Formatting::             Customizing `configure --help'
* External Software::           Working with other optional software
* Package Options::             Selecting optional features
* Pretty Help Strings::         Formatting help string
* Option Checking::             Controlling checking of `configure' options
* Site Details::                Configuring site details
* Transforming Names::          Changing program names when installing
* Site Defaults::               Giving `configure' local defaults


File: autoconf.info,  Node: Help Formatting,  Next: External Software,  Up: Site Configuration

15.1 Controlling Help Output
============================

Users consult `configure --help' to learn of configuration decisions
specific to your package.  By default, `configure' breaks this output
into sections for each type of option; within each section, help
strings appear in the order `configure.ac' defines them:

     Optional Features:
       ...
       --enable-bar            include bar

     Optional Packages:
       ...
       --with-foo              use foo

 -- Macro: AC_PRESERVE_HELP_ORDER
     Request an alternate `--help' format, in which options of all
     types appear together, in the order defined.  Call this macro
     before any `AC_ARG_ENABLE' or `AC_ARG_WITH'.

          Optional Features and Packages:
            ...
            --enable-bar            include bar
            --with-foo              use foo



File: autoconf.info,  Node: External Software,  Next: Package Options,  Prev: Help Formatting,  Up: Site Configuration

15.2 Working With External Software
===================================

Some packages require, or can optionally use, other software packages
that are already installed.  The user can give `configure' command line
options to specify which such external software to use.  The options
have one of these forms:

     --with-PACKAGE[=ARG]
     --without-PACKAGE

   For example, `--with-gnu-ld' means work with the GNU linker instead
of some other linker.  `--with-x' means work with The X Window System.

   The user can give an argument by following the package name with `='
and the argument.  Giving an argument of `no' is for packages that are
used by default; it says to _not_ use the package.  An argument that is
neither `yes' nor `no' could include a name or number of a version of
the other package, to specify more precisely which other package this
program is supposed to work with.  If no argument is given, it defaults
to `yes'.  `--without-PACKAGE' is equivalent to `--with-PACKAGE=no'.

   Normally `configure' scripts complain about `--with-PACKAGE' options
that they do not support.  *Note Option Checking::, for details, and
for how to override the defaults.

   For each external software package that may be used, `configure.ac'
should call `AC_ARG_WITH' to detect whether the `configure' user asked
to use it.  Whether each package is used or not by default, and which
arguments are valid, is up to you.

 -- Macro: AC_ARG_WITH (PACKAGE, HELP-STRING, [ACTION-IF-GIVEN],
          [ACTION-IF-NOT-GIVEN])
     If the user gave `configure' the option `--with-PACKAGE' or
     `--without-PACKAGE', run shell commands ACTION-IF-GIVEN.  If
     neither option was given, run shell commands ACTION-IF-NOT-GIVEN.
     The name PACKAGE indicates another software package that this
     program should work with.  It should consist only of alphanumeric
     characters, dashes, plus signs, and dots.

     The option's argument is available to the shell commands
     ACTION-IF-GIVEN in the shell variable `withval', which is actually
     just the value of the shell variable named `with_PACKAGE', with
     any non-alphanumeric characters in PACKAGE changed into `_'.  You
     may use that variable instead, if you wish.

     The argument HELP-STRING is a description of the option that looks
     like this:
            --with-readline         support fancy command line editing

     HELP-STRING may be more than one line long, if more detail is
     needed.  Just make sure the columns line up in `configure --help'.
     Avoid tabs in the help string.  The easiest way to provide the
     proper leading whitespace is to format your HELP-STRING with the
     macro `AS_HELP_STRING' (*note Pretty Help Strings::).

     The following example shows how to use the `AC_ARG_WITH' macro in
     a common situation.  You want to let the user decide whether to
     enable support for an external library (e.g., the readline
     library); if the user specified neither `--with-readline' nor
     `--without-readline', you want to enable support for readline only
     if the library is available on the system.

          AC_ARG_WITH([readline],
            [AS_HELP_STRING([--with-readline],
              [support fancy command line editing @<:@default=check@:>@])],
            [],
            [with_readline=check])

          LIBREADLINE=
          AS_IF([test "x$with_readline" != xno],
            [AC_CHECK_LIB([readline], [main],
              [AC_SUBST([LIBREADLINE], ["-lreadline -lncurses"])
               AC_DEFINE([HAVE_LIBREADLINE], [1],
                         [Define if you have libreadline])
              ],
              [if test "x$with_readline" != xcheck; then
                 AC_MSG_FAILURE(
                   [--with-readline was given, but test for readline failed])
               fi
              ], -lncurses)])

     The next example shows how to use `AC_ARG_WITH' to give the user
     the possibility to enable support for the readline library, in
     case it is still experimental and not well tested, and is
     therefore disabled by default.

          AC_ARG_WITH([readline],
            [AS_HELP_STRING([--with-readline],
              [enable experimental support for readline])],
            [],
            [with_readline=no])

          LIBREADLINE=
          AS_IF([test "x$with_readline" != xno],
            [AC_CHECK_LIB([readline], [main],
              [AC_SUBST([LIBREADLINE], ["-lreadline -lncurses"])
               AC_DEFINE([HAVE_LIBREADLINE], [1],
                         [Define if you have libreadline])
              ],
              [AC_MSG_FAILURE(
                 [--with-readline was given, but test for readline failed])],
              [-lncurses])])

     The last example shows how to use `AC_ARG_WITH' to give the user
     the possibility to disable support for the readline library, given
     that it is an important feature and that it should be enabled by
     default.

          AC_ARG_WITH([readline],
            [AS_HELP_STRING([--without-readline],
              [disable support for readline])],
            [],
            [with_readline=yes])

          LIBREADLINE=
          AS_IF([test "x$with_readline" != xno],
            [AC_CHECK_LIB([readline], [main],
              [AC_SUBST([LIBREADLINE], ["-lreadline -lncurses"])
               AC_DEFINE([HAVE_LIBREADLINE], [1],
                         [Define if you have libreadline])
              ],
              [AC_MSG_FAILURE(
                 [readline test failed (--without-readline to disable)])],
              [-lncurses])])

     These three examples can be easily adapted to the case where
     `AC_ARG_ENABLE' should be preferred to `AC_ARG_WITH' (see *note
     Package Options::).


File: autoconf.info,  Node: Package Options,  Next: Pretty Help Strings,  Prev: External Software,  Up: Site Configuration

15.3 Choosing Package Options
=============================

If a software package has optional compile-time features, the user can
give `configure' command line options to specify whether to compile
them.  The options have one of these forms:

     --enable-FEATURE[=ARG]
     --disable-FEATURE

   These options allow users to choose which optional features to build
and install.  `--enable-FEATURE' options should never make a feature
behave differently or cause one feature to replace another.  They
should only cause parts of the program to be built rather than left out.

   The user can give an argument by following the feature name with `='
and the argument.  Giving an argument of `no' requests that the feature
_not_ be made available.  A feature with an argument looks like
`--enable-debug=stabs'.  If no argument is given, it defaults to `yes'.
`--disable-FEATURE' is equivalent to `--enable-FEATURE=no'.

   Normally `configure' scripts complain about `--enable-PACKAGE'
options that they do not support.  *Note Option Checking::, for
details, and for how to override the defaults.

   For each optional feature, `configure.ac' should call
`AC_ARG_ENABLE' to detect whether the `configure' user asked to include
it.  Whether each feature is included or not by default, and which
arguments are valid, is up to you.

 -- Macro: AC_ARG_ENABLE (FEATURE, HELP-STRING, [ACTION-IF-GIVEN],
          [ACTION-IF-NOT-GIVEN])
     If the user gave `configure' the option `--enable-FEATURE' or
     `--disable-FEATURE', run shell commands ACTION-IF-GIVEN.  If
     neither option was given, run shell commands ACTION-IF-NOT-GIVEN.
     The name FEATURE indicates an optional user-level facility.  It
     should consist only of alphanumeric characters, dashes, plus
     signs, and dots.

     The option's argument is available to the shell commands
     ACTION-IF-GIVEN in the shell variable `enableval', which is
     actually just the value of the shell variable named
     `enable_FEATURE', with any non-alphanumeric characters in FEATURE
     changed into `_'.  You may use that variable instead, if you wish.
     The HELP-STRING argument is like that of `AC_ARG_WITH' (*note
     External Software::).

     You should format your HELP-STRING with the macro `AS_HELP_STRING'
     (*note Pretty Help Strings::).

     See the examples suggested with the definition of `AC_ARG_WITH'
     (*note External Software::) to get an idea of possible
     applications of `AC_ARG_ENABLE'.


File: autoconf.info,  Node: Pretty Help Strings,  Next: Option Checking,  Prev: Package Options,  Up: Site Configuration

15.4 Making Your Help Strings Look Pretty
=========================================

Properly formatting the `help strings' which are used in `AC_ARG_WITH'
(*note External Software::) and `AC_ARG_ENABLE' (*note Package
Options::) can be challenging.  Specifically, you want your own `help
strings' to line up in the appropriate columns of `configure --help'
just like the standard Autoconf `help strings' do.  This is the purpose
of the `AS_HELP_STRING' macro.

 -- Macro: AS_HELP_STRING (LEFT-HAND-SIDE, RIGHT-HAND-SIDE
          [INDENT-COLUMN = `26'], [WRAP-COLUMN = `79'])
     Expands into a help string that looks pretty when the user executes
     `configure --help'.  It is typically used in `AC_ARG_WITH' (*note
     External Software::) or `AC_ARG_ENABLE' (*note Package Options::).
     The following example makes this clearer.

          AC_ARG_WITH([foo],
            [AS_HELP_STRING([--with-foo],
               [use foo (default is no)])],
            [use_foo=$withval],
            [use_foo=no])

     Then the last few lines of `configure --help' appear like this:

          --enable and --with options recognized:
            --with-foo              use foo (default is no)

     Macro expansion is performed on the first argument.  However, the
     second argument of `AS_HELP_STRING' is treated as a whitespace
     separated list of text to be reformatted, and is not subject to
     macro expansion.  Since it is not expanded, it should not be
     double quoted.  *Note Autoconf Language::, for a more detailed
     explanation.

     The `AS_HELP_STRING' macro is particularly helpful when the
     LEFT-HAND-SIDE and/or RIGHT-HAND-SIDE are composed of macro
     arguments, as shown in the following example.  Be aware that
     LEFT-HAND-SIDE may not expand to unbalanced quotes, although
     quadrigraphs can be used.

          AC_DEFUN([MY_ARG_WITH],
            [AC_ARG_WITH(m4_translit([[$1]], [_], [-]),
               [AS_HELP_STRING([--with-m4_translit([$1], [_], [-])],
                               [use $1 (default is $2)])],
               [use_[]$1=$withval],
               [use_[]$1=$2])])
          MY_ARG_WITH([a_b], [no])
     Here, the last few lines of `configure --help' will include:

          --enable and --with options recognized:
            --with-a-b              use a_b (default is no)

     The parameters INDENT-COLUMN and WRAP-COLUMN were introduced in
     Autoconf 2.62.  Generally, they should not be specified; they exist
     for fine-tuning of the wrapping.
          AS_HELP_STRING([--option], [description of option])
          =>  --option                description of option
          AS_HELP_STRING([--option], [description of option], [15], [30])
          =>  --option     description of
          =>               option


File: autoconf.info,  Node: Option Checking,  Next: Site Details,  Prev: Pretty Help Strings,  Up: Site Configuration

15.5 Controlling Checking of `configure' Options
================================================

The `configure' script checks its command-line options against a list
of known options, like `--help' or `--config-cache'.  An unknown option
ordinarily indicates a mistake by the user and `configure' halts with
an error.  However, by default unknown `--with-PACKAGE' and
`--enable-FEATURE' options elicit only a warning, to support
configuring entire source trees.

   Source trees often contain multiple packages with a top-level
`configure' script that uses the `AC_CONFIG_SUBDIRS' macro (*note
Subdirectories::).  Because the packages generally support different
`--with-PACKAGE' and `--enable-FEATURE' options, the GNU Coding
Standards say they must accept unrecognized options without halting.
Even a warning message is undesirable here, so `AC_CONFIG_SUBDIRS'
automatically disables the warnings.

   This default behavior may be modified in two ways.  First, the
installer can invoke `configure --disable-option-checking' to disable
these warnings, or invoke `configure --enable-option-checking=fatal'
options to turn them into fatal errors, respectively.  Second, the
maintainer can use `AC_DISABLE_OPTION_CHECKING'.

 -- Macro: AC_DISABLE_OPTION_CHECKING
     By default, disable warnings related to any unrecognized
     `--with-PACKAGE' or `--enable-FEATURE' options.  This is implied
     by `AC_CONFIG_SUBDIRS'.

     The installer can override this behavior by passing
     `--enable-option-checking' (enable warnings) or
     `--enable-option-checking=fatal' (enable errors) to `configure'.


File: autoconf.info,  Node: Site Details,  Next: Transforming Names,  Prev: Option Checking,  Up: Site Configuration

15.6 Configuring Site Details
=============================

Some software packages require complex site-specific information.  Some
examples are host names to use for certain services, company names, and
email addresses to contact.  Since some configuration scripts generated
by Metaconfig ask for such information interactively, people sometimes
wonder how to get that information in Autoconf-generated configuration
scripts, which aren't interactive.

   Such site configuration information should be put in a file that is
edited _only by users_, not by programs.  The location of the file can
either be based on the `prefix' variable, or be a standard location
such as the user's home directory.  It could even be specified by an
environment variable.  The programs should examine that file at
runtime, rather than at compile time.  Runtime configuration is more
convenient for users and makes the configuration process simpler than
getting the information while configuring.  *Note Variables for
Installation Directories: (standards)Directory Variables, for more
information on where to put data files.


File: autoconf.info,  Node: Transforming Names,  Next: Site Defaults,  Prev: Site Details,  Up: Site Configuration

15.7 Transforming Program Names When Installing
===============================================

Autoconf supports changing the names of programs when installing them.
In order to use these transformations, `configure.ac' must call the
macro `AC_ARG_PROGRAM'.

 -- Macro: AC_ARG_PROGRAM
     Place in output variable `program_transform_name' a sequence of
     `sed' commands for changing the names of installed programs.

     If any of the options described below are given to `configure',
     program names are transformed accordingly.  Otherwise, if
     `AC_CANONICAL_TARGET' has been called and a `--target' value is
     given, the target type followed by a dash is used as a prefix.
     Otherwise, no program name transformation is done.

* Menu:

* Transformation Options::      `configure' options to transform names
* Transformation Examples::     Sample uses of transforming names
* Transformation Rules::        Makefile uses of transforming names


File: autoconf.info,  Node: Transformation Options,  Next: Transformation Examples,  Up: Transforming Names

15.7.1 Transformation Options
-----------------------------

You can specify name transformations by giving `configure' these
command line options:

`--program-prefix=PREFIX'
     prepend PREFIX to the names;

`--program-suffix=SUFFIX'
     append SUFFIX to the names;

`--program-transform-name=EXPRESSION'
     perform `sed' substitution EXPRESSION on the names.


File: autoconf.info,  Node: Transformation Examples,  Next: Transformation Rules,  Prev: Transformation Options,  Up: Transforming Names

15.7.2 Transformation Examples
------------------------------

These transformations are useful with programs that can be part of a
cross-compilation development environment.  For example, a
cross-assembler running on a Sun 4 configured with
`--target=i960-vxworks' is normally installed as `i960-vxworks-as',
rather than `as', which could be confused with a native Sun 4 assembler.

   You can force a program name to begin with `g', if you don't want
GNU programs installed on your system to shadow other programs with the
same name.  For example, if you configure GNU `diff' with
`--program-prefix=g', then when you run `make install' it is installed
as `/usr/local/bin/gdiff'.

   As a more sophisticated example, you could use

     --program-transform-name='s/^/g/; s/^gg/g/; s/^gless/less/'
   to prepend `g' to most of the program names in a source tree,
excepting those like `gdb' that already have one and those like `less'
and `lesskey' that aren't GNU programs.  (That is assuming that you
have a source tree containing those programs that is set up to use this
feature.)

   One way to install multiple versions of some programs simultaneously
is to append a version number to the name of one or both.  For example,
if you want to keep Autoconf version 1 around for awhile, you can
configure Autoconf version 2 using `--program-suffix=2' to install the
programs as `/usr/local/bin/autoconf2', `/usr/local/bin/autoheader2',
etc.  Nevertheless, pay attention that only the binaries are renamed,
therefore you'd have problems with the library files which might
overlap.


File: autoconf.info,  Node: Transformation Rules,  Prev: Transformation Examples,  Up: Transforming Names

15.7.3 Transformation Rules
---------------------------

Here is how to use the variable `program_transform_name' in a
`Makefile.in':

     PROGRAMS = cp ls rm
     transform = @program_transform_name@
     install:
             for p in $(PROGRAMS); do \
               $(INSTALL_PROGRAM) $$p $(DESTDIR)$(bindir)/`echo $$p | \
                                                   sed '$(transform)'`; \
             done

     uninstall:
             for p in $(PROGRAMS); do \
               rm -f $(DESTDIR)$(bindir)/`echo $$p | sed '$(transform)'`; \
             done

   It is guaranteed that `program_transform_name' is never empty, and
that there are no useless separators.  Therefore you may safely embed
`program_transform_name' within a sed program using `;':

     transform = @program_transform_name@
     transform_exe = s/$(EXEEXT)$$//;$(transform);s/$$/$(EXEEXT)/

   Whether to do the transformations on documentation files (Texinfo or
`man') is a tricky question; there seems to be no perfect answer, due
to the several reasons for name transforming.  Documentation is not
usually particular to a specific architecture, and Texinfo files do not
conflict with system documentation.  But they might conflict with
earlier versions of the same files, and `man' pages sometimes do
conflict with system documentation.  As a compromise, it is probably
best to do name transformations on `man' pages but not on Texinfo
manuals.


File: autoconf.info,  Node: Site Defaults,  Prev: Transforming Names,  Up: Site Configuration

15.8 Setting Site Defaults
==========================

Autoconf-generated `configure' scripts allow your site to provide
default values for some configuration values.  You do this by creating
site- and system-wide initialization files.

   If the environment variable `CONFIG_SITE' is set, `configure' uses
its value as the name of a shell script to read; it is recommended that
this be an absolute file name.  Otherwise, it reads the shell script
`PREFIX/share/config.site' if it exists, then `PREFIX/etc/config.site'
if it exists.  Thus, settings in machine-specific files override those
in machine-independent ones in case of conflict.

   Site files can be arbitrary shell scripts, but only certain kinds of
code are really appropriate to be in them.  Because `configure' reads
any cache file after it has read any site files, a site file can define
a default cache file to be shared between all Autoconf-generated
`configure' scripts run on that system (*note Cache Files::).  If you
set a default cache file in a site file, it is a good idea to also set
the output variable `CC' in that site file, because the cache file is
only valid for a particular compiler, but many systems have several
available.

   You can examine or override the value set by a command line option to
`configure' in a site file; options set shell variables that have the
same names as the options, with any dashes turned into underscores.
The exceptions are that `--without-' and `--disable-' options are like
giving the corresponding `--with-' or `--enable-' option and the value
`no'.  Thus, `--cache-file=localcache' sets the variable `cache_file'
to the value `localcache'; `--enable-warnings=no' or
`--disable-warnings' sets the variable `enable_warnings' to the value
`no'; `--prefix=/usr' sets the variable `prefix' to the value `/usr';
etc.

   Site files are also good places to set default values for other
output variables, such as `CFLAGS', if you need to give them non-default
values: anything you would normally do, repetitively, on the command
line.  If you use non-default values for PREFIX or EXEC_PREFIX
(wherever you locate the site file), you can set them in the site file
if you specify it with the `CONFIG_SITE' environment variable.

   You can set some cache values in the site file itself.  Doing this is
useful if you are cross-compiling, where it is impossible to check
features that require running a test program.  You could "prime the
cache" by setting those values correctly for that system in
`PREFIX/etc/config.site'.  To find out the names of the cache variables
you need to set, see the documentation of the respective Autoconf
macro.  If the variables or their semantics are undocumented, you may
need to look for shell variables with `_cv_' in their names in the
affected `configure' scripts, or in the Autoconf M4 source code for
those macros; but in that case, their name or semantics may change in a
future Autoconf version.

   The cache file is careful to not override any variables set in the
site files.  Similarly, you should not override command-line options in
the site files.  Your code should check that variables such as `prefix'
and `cache_file' have their default values (as set near the top of
`configure') before changing them.

   Here is a sample file `/usr/share/local/gnu/share/config.site'.  The
command `configure --prefix=/usr/share/local/gnu' would read this file
(if `CONFIG_SITE' is not set to a different file).

     # /usr/share/local/gnu/share/config.site for configure
     #
     # Change some defaults.
     test "$prefix" = NONE && prefix=/usr/share/local/gnu
     test "$exec_prefix" = NONE && exec_prefix=/usr/local/gnu
     test "$sharedstatedir" = '${prefix}/com' && sharedstatedir=/var
     test "$localstatedir" = '${prefix}/var' && localstatedir=/var

     # Give Autoconf 2.x generated configure scripts a shared default
     # cache file for feature test results, architecture-specific.
     if test "$cache_file" = /dev/null; then
       cache_file="$prefix/var/config.cache"
       # A cache file is only valid for one C compiler.
       CC=gcc
     fi

   Another use of `config.site' is for priming the directory variables
in a manner consistent with the Filesystem Hierarchy Standard (FHS).
Once the following file is installed at `/usr/share/config.site', a
user can execute simply `./configure --prefix=/usr' to get all the
directories chosen in the locations recommended by FHS.

     # /usr/share/config.site for FHS defaults when installing below /usr,
     # and the respective settings were not changed on the command line.
     if test "$prefix" = /usr; then
       test "$sysconfdir" = '${prefix}/etc' && sysconfdir=/etc
       test "$sharedstatedir" = '${prefix}/com' && sharedstatedir=/var
       test "$localstatedir" = '${prefix}/var' && localstatedir=/var
     fi

   Likewise, on platforms where 64-bit libraries are built by default,
then installed in `/usr/local/lib64' instead of `/usr/local/lib', it is
appropriate to install `/usr/local/share/config.site':

     # /usr/local/share/config.site for platforms that prefer
     # the directory /usr/local/lib64 over /usr/local/lib.
     test "$libdir" = '${exec_prefix}/lib' && libdir='${exec_prefix}/lib64'


File: autoconf.info,  Node: Running configure Scripts,  Next: config.status Invocation,  Prev: Site Configuration,  Up: Top

16 Running `configure' Scripts
******************************

Below are instructions on how to configure a package that uses a
`configure' script, suitable for inclusion as an `INSTALL' file in the
package.  A plain-text version of `INSTALL' which you may use comes
with Autoconf.

* Menu:

* Basic Installation::          Instructions for typical cases
* Compilers and Options::       Selecting compilers and optimization
* Multiple Architectures::      Compiling for multiple architectures at once
* Installation Names::          Installing in different directories
* Optional Features::           Selecting optional features
* Particular Systems::          Particular systems
* System Type::                 Specifying the system type
* Sharing Defaults::            Setting site-wide defaults for `configure'
* Defining Variables::          Specifying the compiler etc.
* configure Invocation::        Changing how `configure' runs


File: autoconf.info,  Node: Basic Installation,  Next: Compilers and Options,  Up: Running configure Scripts

16.1 Basic Installation
=======================

Briefly, the shell commands `./configure; make; make install' should
configure, build, and install this package.  The following
more-detailed instructions are generic; see the `README' file for
instructions specific to this package.  More recommendations for GNU
packages can be found in *note Makefile Conventions:
(standards)Makefile Conventions.

   The `configure' shell script attempts to guess correct values for
various system-dependent variables used during compilation.  It uses
those values to create a `Makefile' in each directory of the package.
It may also create one or more `.h' files containing system-dependent
definitions.  Finally, it creates a shell script `config.status' that
you can run in the future to recreate the current configuration, and a
file `config.log' containing compiler output (useful mainly for
debugging `configure').

   It can also use an optional file (typically called `config.cache'
and enabled with `--cache-file=config.cache' or simply `-C') that saves
the results of its tests to speed up reconfiguring.  Caching is
disabled by default to prevent problems with accidental use of stale
cache files.

   If you need to do unusual things to compile the package, please try
to figure out how `configure' could check whether to do them, and mail
diffs or instructions to the address given in the `README' so they can
be considered for the next release.  If you are using the cache, and at
some point `config.cache' contains results you don't want to keep, you
may remove or edit it.

   The file `configure.ac' (or `configure.in') is used to create
`configure' by a program called `autoconf'.  You need `configure.ac' if
you want to change it or regenerate `configure' using a newer version
of `autoconf'.

   The simplest way to compile this package is:

  1. `cd' to the directory containing the package's source code and type
     `./configure' to configure the package for your system.

     Running `configure' might take a while.  While running, it prints
     some messages telling which features it is checking for.

  2. Type `make' to compile the package.

  3. Optionally, type `make check' to run any self-tests that come with
     the package, generally using the just-built uninstalled binaries.

  4. Type `make install' to install the programs and any data files and
     documentation.  When installing into a prefix owned by root, it is
     recommended that the package be configured and built as a regular
     user, and only the `make install' phase executed with root
     privileges.

  5. Optionally, type `make installcheck' to repeat any self-tests, but
     this time using the binaries in their final installed location.
     This target does not install anything.  Running this target as a
     regular user, particularly if the prior `make install' required
     root privileges, verifies that the installation completed
     correctly.

  6. You can remove the program binaries and object files from the
     source code directory by typing `make clean'.  To also remove the
     files that `configure' created (so you can compile the package for
     a different kind of computer), type `make distclean'.  There is
     also a `make maintainer-clean' target, but that is intended mainly
     for the package's developers.  If you use it, you may have to get
     all sorts of other programs in order to regenerate files that came
     with the distribution.

  7. Often, you can also type `make uninstall' to remove the installed
     files again.  In practice, not all packages have tested that
     uninstallation works correctly, even though it is required by the
     GNU Coding Standards.

  8. Some packages, particularly those that use Automake, provide `make
     distcheck', which can by used by developers to test that all other
     targets like `make install' and `make uninstall' work correctly.
     This target is generally not run by end users.


File: autoconf.info,  Node: Compilers and Options,  Next: Multiple Architectures,  Prev: Basic Installation,  Up: Running configure Scripts

16.2 Compilers and Options
==========================

Some systems require unusual options for compilation or linking that the
`configure' script does not know about.  Run `./configure --help' for
details on some of the pertinent environment variables.

   You can give `configure' initial values for configuration parameters
by setting variables in the command line or in the environment.  Here
is an example:

     ./configure CC=c99 CFLAGS=-g LIBS=-lposix

   *Note Defining Variables::, for more details.


File: autoconf.info,  Node: Multiple Architectures,  Next: Installation Names,  Prev: Compilers and Options,  Up: Running configure Scripts

16.3 Compiling For Multiple Architectures
=========================================

You can compile the package for more than one kind of computer at the
same time, by placing the object files for each architecture in their
own directory.  To do this, you can use GNU `make'.  `cd' to the
directory where you want the object files and executables to go and run
the `configure' script.  `configure' automatically checks for the
source code in the directory that `configure' is in and in `..'.  This
is known as a "VPATH" build.

   With a non-GNU `make', it is safer to compile the package for one
architecture at a time in the source code directory.  After you have
installed the package for one architecture, use `make distclean' before
reconfiguring for another architecture.

   On MacOS X 10.5 and later systems, you can create libraries and
executables that work on multiple system types--known as "fat" or
"universal" binaries--by specifying multiple `-arch' options to the
compiler but only a single `-arch' option to the preprocessor.  Like
this:

     ./configure CC="gcc -arch i386 -arch x86_64 -arch ppc -arch ppc64" \
                 CXX="g++ -arch i386 -arch x86_64 -arch ppc -arch ppc64" \
                 CPP="gcc -E" CXXCPP="g++ -E"

   This is not guaranteed to produce working output in all cases, you
may have to build one architecture at a time and combine the results
using the `lipo' tool if you have problems.


File: autoconf.info,  Node: Installation Names,  Next: Optional Features,  Prev: Multiple Architectures,  Up: Running configure Scripts

16.4 Installation Names
=======================

By default, `make install' installs the package's commands under
`/usr/local/bin', include files under `/usr/local/include', etc.  You
can specify an installation prefix other than `/usr/local' by giving
`configure' the option `--prefix=PREFIX', where PREFIX must be an
absolute file name.

   You can specify separate installation prefixes for
architecture-specific files and architecture-independent files.  If you
pass the option `--exec-prefix=PREFIX' to `configure', the package uses
PREFIX as the prefix for installing programs and libraries.
Documentation and other data files still use the regular prefix.

   In addition, if you use an unusual directory layout you can give
options like `--bindir=DIR' to specify different values for particular
kinds of files.  Run `configure --help' for a list of the directories
you can set and what kinds of files go in them.  In general, the
default for these options is expressed in terms of `${prefix}', so that
specifying just `--prefix' will affect all of the other directory
specifications that were not explicitly provided.

   The most portable way to affect installation locations is to pass the
correct locations to `configure'; however, many packages provide one or
both of the following shortcuts of passing variable assignments to the
`make install' command line to change installation locations without
having to reconfigure or recompile.

   The first method involves providing an override variable for each
affected directory.  For example, `make install
prefix=/alternate/directory' will choose an alternate location for all
directory configuration variables that were expressed in terms of
`${prefix}'.  Any directories that were specified during `configure',
but not in terms of `${prefix}', must each be overridden at install
time for the entire installation to be relocated.  The approach of
makefile variable overrides for each directory variable is required by
the GNU Coding Standards, and ideally causes no recompilation.
However, some platforms have known limitations with the semantics of
shared libraries that end up requiring recompilation when using this
method, particularly noticeable in packages that use GNU Libtool.

   The second method involves providing the `DESTDIR' variable.  For
example, `make install DESTDIR=/alternate/directory' will prepend
`/alternate/directory' before all installation names.  The approach of
`DESTDIR' overrides is not required by the GNU Coding Standards, and
does not work on platforms that have drive letters.  On the other hand,
it does better at avoiding recompilation issues, and works well even
when some directory options were not specified in terms of `${prefix}'
at `configure' time.


File: autoconf.info,  Node: Optional Features,  Next: Particular Systems,  Prev: Installation Names,  Up: Running configure Scripts

16.5 Optional Features
======================

If the package supports it, you can cause programs to be installed with
an extra prefix or suffix on their names by giving `configure' the
option `--program-prefix=PREFIX' or `--program-suffix=SUFFIX'.

   Some packages pay attention to `--enable-FEATURE' options to
`configure', where FEATURE indicates an optional part of the package.
They may also pay attention to `--with-PACKAGE' options, where PACKAGE
is something like `gnu-as' or `x' (for the X Window System).  The
`README' should mention any `--enable-' and `--with-' options that the
package recognizes.

   For packages that use the X Window System, `configure' can usually
find the X include and library files automatically, but if it doesn't,
you can use the `configure' options `--x-includes=DIR' and
`--x-libraries=DIR' to specify their locations.

   Some packages offer the ability to configure how verbose the
execution of `make' will be.  For these packages, running `./configure
--enable-silent-rules' sets the default to minimal output, which can be
overridden with `make V=1'; while running `./configure
--disable-silent-rules' sets the default to verbose, which can be
overridden with `make V=0'.


File: autoconf.info,  Node: Particular Systems,  Next: System Type,  Prev: Optional Features,  Up: Running configure Scripts

16.6 Particular systems
=======================

On HP-UX, the default C compiler is not ANSI C compatible.  If GNU CC is
not installed, it is recommended to use the following options in order
to use an ANSI C compiler:

     ./configure CC="cc -Ae -D_XOPEN_SOURCE=500"

and if that doesn't work, install pre-built binaries of GCC for HP-UX.

   On OSF/1 a.k.a. Tru64, some versions of the default C compiler cannot
parse its `<wchar.h>' header file.  The option `-nodtk' can be used as
a workaround.  If GNU CC is not installed, it is therefore recommended
to try

     ./configure CC="cc"

and if that doesn't work, try

     ./configure CC="cc -nodtk"

   On Solaris, don't put `/usr/ucb' early in your `PATH'.  This
directory contains several dysfunctional programs; working variants of
these programs are available in `/usr/bin'.  So, if you need `/usr/ucb'
in your `PATH', put it _after_ `/usr/bin'.

   On Haiku, software installed for all users goes in `/boot/common',
not `/usr/local'.  It is recommended to use the following options:

     ./configure --prefix=/boot/common


File: autoconf.info,  Node: System Type,  Next: Sharing Defaults,  Prev: Particular Systems,  Up: Running configure Scripts

16.7 Specifying the System Type
===============================

There may be some features `configure' cannot figure out automatically,
but needs to determine by the type of machine the package will run on.
Usually, assuming the package is built to be run on the _same_
architectures, `configure' can figure that out, but if it prints a
message saying it cannot guess the machine type, give it the
`--build=TYPE' option.  TYPE can either be a short name for the system
type, such as `sun4', or a canonical name which has the form:

     CPU-COMPANY-SYSTEM

where SYSTEM can have one of these forms:

     OS
     KERNEL-OS

   See the file `config.sub' for the possible values of each field.  If
`config.sub' isn't included in this package, then this package doesn't
need to know the machine type.

   If you are _building_ compiler tools for cross-compiling, you should
use the option `--target=TYPE' to select the type of system they will
produce code for.

   If you want to _use_ a cross compiler, that generates code for a
platform different from the build platform, you should specify the
"host" platform (i.e., that on which the generated programs will
eventually be run) with `--host=TYPE'.


File: autoconf.info,  Node: Sharing Defaults,  Next: Defining Variables,  Prev: System Type,  Up: Running configure Scripts

16.8 Sharing Defaults
=====================

If you want to set default values for `configure' scripts to share, you
can create a site shell script called `config.site' that gives default
values for variables like `CC', `cache_file', and `prefix'.
`configure' looks for `PREFIX/share/config.site' if it exists, then
`PREFIX/etc/config.site' if it exists.  Or, you can set the
`CONFIG_SITE' environment variable to the location of the site script.
A warning: not all `configure' scripts look for a site script.


File: autoconf.info,  Node: Defining Variables,  Next: configure Invocation,  Prev: Sharing Defaults,  Up: Running configure Scripts

16.9 Defining Variables
=======================

Variables not defined in a site shell script can be set in the
environment passed to `configure'.  However, some packages may run
configure again during the build, and the customized values of these
variables may be lost.  In order to avoid this problem, you should set
them in the `configure' command line, using `VAR=value'.  For example:

     ./configure CC=/usr/local2/bin/gcc

causes the specified `gcc' to be used as the C compiler (unless it is
overridden in the site shell script).

Unfortunately, this technique does not work for `CONFIG_SHELL' due to
an Autoconf bug.  Until the bug is fixed you can use this workaround:

     CONFIG_SHELL=/bin/bash /bin/bash ./configure CONFIG_SHELL=/bin/bash


File: autoconf.info,  Node: configure Invocation,  Prev: Defining Variables,  Up: Running configure Scripts

16.10 `configure' Invocation
============================

`configure' recognizes the following options to control how it operates.

`--help'
`-h'
     Print a summary of all of the options to `configure', and exit.

`--help=short'
`--help=recursive'
     Print a summary of the options unique to this package's
     `configure', and exit.  The `short' variant lists options used
     only in the top level, while the `recursive' variant lists options
     also present in any nested packages.

`--version'
`-V'
     Print the version of Autoconf used to generate the `configure'
     script, and exit.

`--cache-file=FILE'
     Enable the cache: use and save the results of the tests in FILE,
     traditionally `config.cache'.  FILE defaults to `/dev/null' to
     disable caching.

`--config-cache'
`-C'
     Alias for `--cache-file=config.cache'.

`--quiet'
`--silent'
`-q'
     Do not print messages saying which checks are being made.  To
     suppress all normal output, redirect it to `/dev/null' (any error
     messages will still be shown).

`--srcdir=DIR'
     Look for the package's source code in directory DIR.  Usually
     `configure' can determine that directory automatically.

`--prefix=DIR'
     Use DIR as the installation prefix.  *note Installation Names::
     for more details, including other options available for fine-tuning
     the installation locations.

`--no-create'
`-n'
     Run the configure checks, but stop before creating any output
     files.

`configure' also accepts some other, not widely useful, options.  Run
`configure --help' for more details.


File: autoconf.info,  Node: config.status Invocation,  Next: Obsolete Constructs,  Prev: Running configure Scripts,  Up: Top

17 config.status Invocation
***************************

The `configure' script creates a file named `config.status', which
actually configures, "instantiates", the template files.  It also
records the configuration options that were specified when the package
was last configured in case reconfiguring is needed.

   Synopsis:
     ./config.status [OPTION]... [TAG]...

   It configures each TAG; if none are specified, all the templates are
instantiated.  A TAG refers to a file or other tag associated with a
configuration action, as specified by an `AC_CONFIG_ITEMS' macro (*note
Configuration Actions::).  The files must be specified without their
dependencies, as in

     ./config.status foobar

not

     ./config.status foobar:foo.in:bar.in

   The supported options are:

`--help'
`-h'
     Print a summary of the command line options, the list of the
     template files, and exit.

`--version'
`-V'
     Print the version number of Autoconf and the configuration
     settings, and exit.

`--config'
     Print the configuration settings in reusable way, quoted for the
     shell, and exit.  For example, for a debugging build that
     otherwise reuses the configuration from a different build
     directory BUILD-DIR of a package in SRC-DIR, you could use the
     following:

          args=`BUILD-DIR/config.status --config`
          eval SRC-DIR/configure "$args" CFLAGS=-g --srcdir=SRC-DIR

     Note that it may be necessary to override a `--srcdir' setting
     that was saved in the configuration, if the arguments are used in a
     different build directory.

`--silent'
`--quiet'
`-q'
     Do not print progress messages.

`--debug'
`-d'
     Don't remove the temporary files.

`--file=FILE[:TEMPLATE]'
     Require that FILE be instantiated as if
     `AC_CONFIG_FILES(FILE:TEMPLATE)' was used.  Both FILE and TEMPLATE
     may be `-' in which case the standard output and/or standard
     input, respectively, is used.  If a TEMPLATE file name is
     relative, it is first looked for in the build tree, and then in
     the source tree.  *Note Configuration Actions::, for more details.

     This option and the following ones provide one way for separately
     distributed packages to share the values computed by `configure'.
     Doing so can be useful if some of the packages need a superset of
     the features that one of them, perhaps a common library, does.
     These options allow a `config.status' file to create files other
     than the ones that its `configure.ac' specifies, so it can be used
     for a different package, or for extracting a subset of values.
     For example,

          echo '@CC@' | ./config.status --file=-

     provides the value of `@CC@' on standard output.

`--header=FILE[:TEMPLATE]'
     Same as `--file' above, but with `AC_CONFIG_HEADERS'.

`--recheck'
     Ask `config.status' to update itself and exit (no instantiation).
     This option is useful if you change `configure', so that the
     results of some tests might be different from the previous run.
     The `--recheck' option reruns `configure' with the same arguments
     you used before, plus the `--no-create' option, which prevents
     `configure' from running `config.status' and creating `Makefile'
     and other files, and the `--no-recursion' option, which prevents
     `configure' from running other `configure' scripts in
     subdirectories.  (This is so other Make rules can run
     `config.status' when it changes; *note Automatic Remaking::, for
     an example).

   `config.status' checks several optional environment variables that
can alter its behavior:

 -- Variable: CONFIG_SHELL
     The shell with which to run `configure' for the `--recheck'
     option.  It must be Bourne-compatible.  The default is a shell that
     supports `LINENO' if available, and `/bin/sh' otherwise.  Invoking
     `configure' by hand bypasses this setting, so you may need to use
     a command like `CONFIG_SHELL=/bin/bash /bin/bash ./configure' to
     insure that the same shell is used everywhere.  The absolute name
     of the shell should be passed.

 -- Variable: CONFIG_STATUS
     The file name to use for the shell script that records the
     configuration.  The default is `./config.status'.  This variable is
     useful when one package uses parts of another and the `configure'
     scripts shouldn't be merged because they are maintained separately.

   You can use `./config.status' in your makefiles.  For example, in
the dependencies given above (*note Automatic Remaking::),
`config.status' is run twice when `configure.ac' has changed.  If that
bothers you, you can make each run only regenerate the files for that
rule:
     config.h: stamp-h
     stamp-h: config.h.in config.status
             ./config.status config.h
             echo > stamp-h

     Makefile: Makefile.in config.status
             ./config.status Makefile

   The calling convention of `config.status' has changed; see *note
Obsolete config.status Use::, for details.


File: autoconf.info,  Node: Obsolete Constructs,  Next: Using Autotest,  Prev: config.status Invocation,  Up: Top

18 Obsolete Constructs
**********************

Autoconf changes, and throughout the years some constructs have been
obsoleted.  Most of the changes involve the macros, but in some cases
the tools themselves, or even some concepts, are now considered
obsolete.

   You may completely skip this chapter if you are new to Autoconf.  Its
intention is mainly to help maintainers updating their packages by
understanding how to move to more modern constructs.

* Menu:

* Obsolete config.status Use::  Obsolete convention for `config.status'
* acconfig Header::             Additional entries in `config.h.in'
* autoupdate Invocation::       Automatic update of `configure.ac'
* Obsolete Macros::             Backward compatibility macros
* Autoconf 1::                  Tips for upgrading your files
* Autoconf 2.13::               Some fresher tips


File: autoconf.info,  Node: Obsolete config.status Use,  Next: acconfig Header,  Up: Obsolete Constructs

18.1 Obsolete `config.status' Invocation
========================================

`config.status' now supports arguments to specify the files to
instantiate; see *note config.status Invocation::, for more details.
Before, environment variables had to be used.

 -- Variable: CONFIG_COMMANDS
     The tags of the commands to execute.  The default is the arguments
     given to `AC_OUTPUT' and `AC_CONFIG_COMMANDS' in `configure.ac'.

 -- Variable: CONFIG_FILES
     The files in which to perform `@VARIABLE@' substitutions.  The
     default is the arguments given to `AC_OUTPUT' and
     `AC_CONFIG_FILES' in `configure.ac'.

 -- Variable: CONFIG_HEADERS
     The files in which to substitute C `#define' statements.  The
     default is the arguments given to `AC_CONFIG_HEADERS'; if that
     macro was not called, `config.status' ignores this variable.

 -- Variable: CONFIG_LINKS
     The symbolic links to establish.  The default is the arguments
     given to `AC_CONFIG_LINKS'; if that macro was not called,
     `config.status' ignores this variable.

   In *note config.status Invocation::, using this old interface, the
example would be:

     config.h: stamp-h
     stamp-h: config.h.in config.status
             CONFIG_COMMANDS= CONFIG_LINKS= CONFIG_FILES= \
               CONFIG_HEADERS=config.h ./config.status
             echo > stamp-h

     Makefile: Makefile.in config.status
             CONFIG_COMMANDS= CONFIG_LINKS= CONFIG_HEADERS= \
               CONFIG_FILES=Makefile ./config.status

(If `configure.ac' does not call `AC_CONFIG_HEADERS', there is no need
to set `CONFIG_HEADERS' in the `make' rules.  Equally for
`CONFIG_COMMANDS', etc.)


File: autoconf.info,  Node: acconfig Header,  Next: autoupdate Invocation,  Prev: Obsolete config.status Use,  Up: Obsolete Constructs

18.2 `acconfig.h'
=================

In order to produce `config.h.in', `autoheader' needs to build or to
find templates for each symbol.  Modern releases of Autoconf use
`AH_VERBATIM' and `AH_TEMPLATE' (*note Autoheader Macros::), but in
older releases a file, `acconfig.h', contained the list of needed
templates.  `autoheader' copied comments and `#define' and `#undef'
statements from `acconfig.h' in the current directory, if present.
This file used to be mandatory if you `AC_DEFINE' any additional
symbols.

   Modern releases of Autoconf also provide `AH_TOP' and `AH_BOTTOM' if
you need to prepend/append some information to `config.h.in'.  Ancient
versions of Autoconf had a similar feature: if `./acconfig.h' contains
the string `@TOP@', `autoheader' copies the lines before the line
containing `@TOP@' into the top of the file that it generates.
Similarly, if `./acconfig.h' contains the string `@BOTTOM@',
`autoheader' copies the lines after that line to the end of the file it
generates.  Either or both of those strings may be omitted.  An even
older alternate way to produce the same effect in ancient versions of
Autoconf is to create the files `FILE.top' (typically `config.h.top')
and/or `FILE.bot' in the current directory.  If they exist,
`autoheader' copies them to the beginning and end, respectively, of its
output.

   In former versions of Autoconf, the files used in preparing a
software package for distribution were:
     configure.ac --.   .------> autoconf* -----> configure
                    +---+
     [aclocal.m4] --+   `---.
     [acsite.m4] ---'       |
                            +--> [autoheader*] -> [config.h.in]
     [acconfig.h] ----.     |
                      +-----'
     [config.h.top] --+
     [config.h.bot] --'

   Using only the `AH_' macros, `configure.ac' should be
self-contained, and should not depend upon `acconfig.h' etc.


File: autoconf.info,  Node: autoupdate Invocation,  Next: Obsolete Macros,  Prev: acconfig Header,  Up: Obsolete Constructs

18.3 Using `autoupdate' to Modernize `configure.ac'
===================================================

The `autoupdate' program updates a `configure.ac' file that calls
Autoconf macros by their old names to use the current macro names.  In
version 2 of Autoconf, most of the macros were renamed to use a more
uniform and descriptive naming scheme.  *Note Macro Names::, for a
description of the new scheme.  Although the old names still work
(*note Obsolete Macros::, for a list of the old macros and the
corresponding new names), you can make your `configure.ac' files more
readable and make it easier to use the current Autoconf documentation
if you update them to use the new macro names.

   If given no arguments, `autoupdate' updates `configure.ac', backing
up the original version with the suffix `~' (or the value of the
environment variable `SIMPLE_BACKUP_SUFFIX', if that is set).  If you
give `autoupdate' an argument, it reads that file instead of
`configure.ac' and writes the updated file to the standard output.

`autoupdate' accepts the following options:

`--help'
`-h'
     Print a summary of the command line options and exit.

`--version'
`-V'
     Print the version number of Autoconf and exit.

`--verbose'
`-v'
     Report processing steps.

`--debug'
`-d'
     Don't remove the temporary files.

`--force'
`-f'
     Force the update even if the file has not changed.  Disregard the
     cache.

`--include=DIR'
`-I DIR'
     Also look for input files in DIR.  Multiple invocations accumulate.
     Directories are browsed from last to first.

`--prepend-include=DIR'
`-B DIR'
     Prepend directory DIR to the search path.  This is used to include
     the language-specific files before any third-party macros.


File: autoconf.info,  Node: Obsolete Macros,  Next: Autoconf 1,  Prev: autoupdate Invocation,  Up: Obsolete Constructs

18.4 Obsolete Macros
====================

Several macros are obsoleted in Autoconf, for various reasons (typically
they failed to quote properly, couldn't be extended for more recent
issues, etc.).  They are still supported, but deprecated: their use
should be avoided.

   During the jump from Autoconf version 1 to version 2, most of the
macros were renamed to use a more uniform and descriptive naming scheme,
but their signature did not change.  *Note Macro Names::, for a
description of the new naming scheme.  Below, if there is just the
mapping from old names to new names for these macros, the reader is
invited to refer to the definition of the new macro for the signature
and the description.

 -- Macro: AC_AIX
     This macro is a platform-specific subset of
     `AC_USE_SYSTEM_EXTENSIONS' (*note AC_USE_SYSTEM_EXTENSIONS::).

 -- Macro: AC_ALLOCA
     Replaced by `AC_FUNC_ALLOCA' (*note AC_FUNC_ALLOCA::).

 -- Macro: AC_ARG_ARRAY
     Removed because of limited usefulness.

 -- Macro: AC_C_CROSS
     This macro is obsolete; it does nothing.

 -- Macro: AC_C_LONG_DOUBLE
     If the C compiler supports a working `long double' type with more
     range or precision than the `double' type, define
     `HAVE_LONG_DOUBLE'.

     You should use `AC_TYPE_LONG_DOUBLE' or
     `AC_TYPE_LONG_DOUBLE_WIDER' instead.  *Note Particular Types::.

 -- Macro: AC_CANONICAL_SYSTEM
     Determine the system type and set output variables to the names of
     the canonical system types.  *Note Canonicalizing::, for details
     about the variables this macro sets.

     The user is encouraged to use either `AC_CANONICAL_BUILD', or
     `AC_CANONICAL_HOST', or `AC_CANONICAL_TARGET', depending on the
     needs.  Using `AC_CANONICAL_TARGET' is enough to run the two other
     macros (*note Canonicalizing::).

 -- Macro: AC_CHAR_UNSIGNED
     Replaced by `AC_C_CHAR_UNSIGNED' (*note AC_C_CHAR_UNSIGNED::).

 -- Macro: AC_CHECK_TYPE (TYPE, DEFAULT)
     Autoconf, up to 2.13, used to provide this version of
     `AC_CHECK_TYPE', deprecated because of its flaws.  First, although
     it is a member of the `CHECK' clan, it does more than just
     checking.  Secondly, missing types are defined using `#define',
     not `typedef', and this can lead to problems in the case of
     pointer types.

     This use of `AC_CHECK_TYPE' is obsolete and discouraged; see *note
     Generic Types::, for the description of the current macro.

     If the type TYPE is not defined, define it to be the C (or C++)
     builtin type DEFAULT, e.g., `short int' or `unsigned int'.

     This macro is equivalent to:

          AC_CHECK_TYPE([TYPE], [],
            [AC_DEFINE_UNQUOTED([TYPE], [DEFAULT],
               [Define to `DEFAULT'
                if <sys/types.h> does not define.])])

     In order to keep backward compatibility, the two versions of
     `AC_CHECK_TYPE' are implemented, selected using these heuristics:

       1. If there are three or four arguments, the modern version is
          used.

       2. If the second argument appears to be a C or C++ type, then the
          obsolete version is used.  This happens if the argument is a
          C or C++ _builtin_ type or a C identifier ending in `_t',
          optionally followed by one of `[(* ' and then by a string of
          zero or more characters taken from the set `[]()* _a-zA-Z0-9'.

       3. If the second argument is spelled with the alphabet of valid
          C and C++ types, the user is warned and the modern version is
          used.

       4. Otherwise, the modern version is used.

     You are encouraged either to use a valid builtin type, or to use
     the equivalent modern code (see above), or better yet, to use
     `AC_CHECK_TYPES' together with

          #ifndef HAVE_LOFF_T
          typedef loff_t off_t;
          #endif

 -- Macro: AC_CHECKING (FEATURE-DESCRIPTION)
     Same as

          AC_MSG_NOTICE([checking FEATURE-DESCRIPTION...]

     *Note AC_MSG_NOTICE::.

 -- Macro: AC_COMPILE_CHECK (ECHO-TEXT, INCLUDES, FUNCTION-BODY,
          ACTION-IF-TRUE, [ACTION-IF-FALSE])
     This is an obsolete version of `AC_TRY_COMPILE' itself replaced by
     `AC_COMPILE_IFELSE' (*note Running the Compiler::), with the
     addition that it prints `checking for ECHO-TEXT' to the standard
     output first, if ECHO-TEXT is non-empty.  Use `AC_MSG_CHECKING'
     and `AC_MSG_RESULT' instead to print messages (*note Printing
     Messages::).

 -- Macro: AC_CONST
     Replaced by `AC_C_CONST' (*note AC_C_CONST::).

 -- Macro: AC_CROSS_CHECK
     Same as `AC_C_CROSS', which is obsolete too, and does nothing
     `:-)'.

 -- Macro: AC_CYGWIN
     Check for the Cygwin environment in which case the shell variable
     `CYGWIN' is set to `yes'.  Don't use this macro, the dignified
     means to check the nature of the host is using `AC_CANONICAL_HOST'
     (*note Canonicalizing::).  As a matter of fact this macro is
     defined as:

          AC_REQUIRE([AC_CANONICAL_HOST])[]dnl
          case $host_os in
            *cygwin* ) CYGWIN=yes;;
                   * ) CYGWIN=no;;
          esac

     Beware that the variable `CYGWIN' has a special meaning when
     running Cygwin, and should not be changed.  That's yet another
     reason not to use this macro.

 -- Macro: AC_DECL_SYS_SIGLIST
     Same as:

          AC_CHECK_DECLS([sys_siglist], [], [],
          [#include <signal.h>
          /* NetBSD declares sys_siglist in unistd.h.  */
          #ifdef HAVE_UNISTD_H
          # include <unistd.h>
          #endif
          ])

     *Note AC_CHECK_DECLS::.

 -- Macro: AC_DECL_YYTEXT
     Does nothing, now integrated in `AC_PROG_LEX' (*note
     AC_PROG_LEX::).

 -- Macro: AC_DIR_HEADER
     Like calling `AC_FUNC_CLOSEDIR_VOID' (*note
     AC_FUNC_CLOSEDIR_VOID::) and `AC_HEADER_DIRENT' (*note
     AC_HEADER_DIRENT::), but defines a different set of C preprocessor
     macros to indicate which header file is found:

     Header         Old Symbol   New Symbol
     `dirent.h'     `DIRENT'     `HAVE_DIRENT_H'
     `sys/ndir.h'   `SYSNDIR'    `HAVE_SYS_NDIR_H'
     `sys/dir.h'    `SYSDIR'     `HAVE_SYS_DIR_H'
     `ndir.h'       `NDIR'       `HAVE_NDIR_H'

 -- Macro: AC_DYNIX_SEQ
     If on DYNIX/ptx, add `-lseq' to output variable `LIBS'.  This
     macro used to be defined as

          AC_CHECK_LIB([seq], [getmntent], [LIBS="-lseq $LIBS"])

     now it is just `AC_FUNC_GETMNTENT' (*note AC_FUNC_GETMNTENT::).

 -- Macro: AC_EXEEXT
     Defined the output variable `EXEEXT' based on the output of the
     compiler, which is now done automatically.  Typically set to empty
     string if Posix and `.exe' if a DOS variant.

 -- Macro: AC_EMXOS2
     Similar to `AC_CYGWIN' but checks for the EMX environment on OS/2
     and sets `EMXOS2'.  Don't use this macro, the dignified means to
     check the nature of the host is using `AC_CANONICAL_HOST' (*note
     Canonicalizing::).

 -- Macro: AC_ENABLE (FEATURE, ACTION-IF-GIVEN, [ACTION-IF-NOT-GIVEN])
     This is an obsolete version of `AC_ARG_ENABLE' that does not
     support providing a help string (*note AC_ARG_ENABLE::).

 -- Macro: AC_ERROR
     Replaced by `AC_MSG_ERROR' (*note AC_MSG_ERROR::).

 -- Macro: AC_FIND_X
     Replaced by `AC_PATH_X' (*note AC_PATH_X::).

 -- Macro: AC_FIND_XTRA
     Replaced by `AC_PATH_XTRA' (*note AC_PATH_XTRA::).

 -- Macro: AC_FOREACH
     Replaced by `m4_foreach_w' (*note m4_foreach_w::).

 -- Macro: AC_FUNC_CHECK
     Replaced by `AC_CHECK_FUNC' (*note AC_CHECK_FUNC::).

 -- Macro: AC_FUNC_SETVBUF_REVERSED
     Do nothing.  Formerly, this macro checked whether `setvbuf' takes
     the buffering type as its second argument and the buffer pointer
     as the third, instead of the other way around, and defined
     `SETVBUF_REVERSED'.  However, the last systems to have the problem
     were those based on SVR2, which became obsolete in 1987, and the
     macro is no longer needed.

 -- Macro: AC_FUNC_WAIT3
     If `wait3' is found and fills in the contents of its third argument
     (a `struct rusage *'), which HP-UX does not do, define
     `HAVE_WAIT3'.

     These days portable programs should use `waitpid', not `wait3', as
     `wait3' has been removed from Posix.

 -- Macro: AC_GCC_TRADITIONAL
     Replaced by `AC_PROG_GCC_TRADITIONAL' (*note
     AC_PROG_GCC_TRADITIONAL::).

 -- Macro: AC_GETGROUPS_T
     Replaced by `AC_TYPE_GETGROUPS' (*note AC_TYPE_GETGROUPS::).

 -- Macro: AC_GETLOADAVG
     Replaced by `AC_FUNC_GETLOADAVG' (*note AC_FUNC_GETLOADAVG::).

 -- Macro: AC_GNU_SOURCE
     This macro is a platform-specific subset of
     `AC_USE_SYSTEM_EXTENSIONS' (*note AC_USE_SYSTEM_EXTENSIONS::).

 -- Macro: AC_HAVE_FUNCS
     Replaced by `AC_CHECK_FUNCS' (*note AC_CHECK_FUNCS::).

 -- Macro: AC_HAVE_HEADERS
     Replaced by `AC_CHECK_HEADERS' (*note AC_CHECK_HEADERS::).

 -- Macro: AC_HAVE_LIBRARY (LIBRARY, [ACTION-IF-FOUND],
          [ACTION-IF-NOT-FOUND], [OTHER-LIBRARIES])
     This macro is equivalent to calling `AC_CHECK_LIB' with a FUNCTION
     argument of `main'.  In addition, LIBRARY can be written as any of
     `foo', `-lfoo', or `libfoo.a'.  In all of those cases, the
     compiler is passed `-lfoo'.  However, LIBRARY cannot be a shell
     variable; it must be a literal name.  *Note AC_CHECK_LIB::.

 -- Macro: AC_HAVE_POUNDBANG
     Replaced by `AC_SYS_INTERPRETER' (*note AC_SYS_INTERPRETER::).

 -- Macro: AC_HEADER_CHECK
     Replaced by `AC_CHECK_HEADER' (*note AC_CHECK_HEADER::).

 -- Macro: AC_HEADER_EGREP
     Replaced by `AC_EGREP_HEADER' (*note AC_EGREP_HEADER::).

 -- Macro: AC_HELP_STRING
     Replaced by `AS_HELP_STRING' (*note AS_HELP_STRING::).

 -- Macro: AC_INIT (UNIQUE-FILE-IN-SOURCE-DIR)
     Formerly `AC_INIT' used to have a single argument, and was
     equivalent to:

          AC_INIT
          AC_CONFIG_SRCDIR(UNIQUE-FILE-IN-SOURCE-DIR)
     See *note AC_INIT:: and *note AC_CONFIG_SRCDIR::.

 -- Macro: AC_INLINE
     Replaced by `AC_C_INLINE' (*note AC_C_INLINE::).

 -- Macro: AC_INT_16_BITS
     If the C type `int' is 16 bits wide, define `INT_16_BITS'.  Use
     `AC_CHECK_SIZEOF(int)' instead (*note AC_CHECK_SIZEOF::).

 -- Macro: AC_IRIX_SUN
     If on IRIX (Silicon Graphics Unix), add `-lsun' to output `LIBS'.
     If you were using it to get `getmntent', use `AC_FUNC_GETMNTENT'
     instead.  If you used it for the NIS versions of the password and
     group functions, use `AC_CHECK_LIB(sun, getpwnam)'.  Up to
     Autoconf 2.13, it used to be

          AC_CHECK_LIB([sun], [getmntent], [LIBS="-lsun $LIBS"])

     now it is defined as

          AC_FUNC_GETMNTENT
          AC_CHECK_LIB([sun], [getpwnam])

     See *note AC_FUNC_GETMNTENT:: and *note AC_CHECK_LIB::.

 -- Macro: AC_ISC_POSIX
     This macro adds `-lcposix' to output variable `LIBS' if necessary
     for Posix facilities.  Sun dropped support for the obsolete
     INTERACTIVE Systems Corporation Unix on 2006-07-23.  New programs
     need not use this macro.  It is implemented as
     `AC_SEARCH_LIBS([strerror], [cposix])' (*note AC_SEARCH_LIBS::).

 -- Macro: AC_LANG_C
     Same as `AC_LANG([C])' (*note AC_LANG::).

 -- Macro: AC_LANG_CPLUSPLUS
     Same as `AC_LANG([C++])' (*note AC_LANG::).

 -- Macro: AC_LANG_FORTRAN77
     Same as `AC_LANG([Fortran 77])' (*note AC_LANG::).

 -- Macro: AC_LANG_RESTORE
     Select the LANGUAGE that is saved on the top of the stack, as set
     by `AC_LANG_SAVE', remove it from the stack, and call
     `AC_LANG(LANGUAGE)'.  *Note Language Choice::, for the preferred
     way to change languages.

 -- Macro: AC_LANG_SAVE
     Remember the current language (as set by `AC_LANG') on a stack.
     The current language does not change.  `AC_LANG_PUSH' is preferred
     (*note AC_LANG_PUSH::).

 -- Macro: AC_LINK_FILES (SOURCE..., DEST...)
     This is an obsolete version of `AC_CONFIG_LINKS' (*note
     AC_CONFIG_LINKS::.  An updated version of:

          AC_LINK_FILES(config/$machine.h config/$obj_format.h,
                        host.h            object.h)

     is:

          AC_CONFIG_LINKS([host.h:config/$machine.h
                          object.h:config/$obj_format.h])

 -- Macro: AC_LN_S
     Replaced by `AC_PROG_LN_S' (*note AC_PROG_LN_S::).

 -- Macro: AC_LONG_64_BITS
     Define `LONG_64_BITS' if the C type `long int' is 64 bits wide.
     Use the generic macro `AC_CHECK_SIZEOF([long int])' instead (*note
     AC_CHECK_SIZEOF::).

 -- Macro: AC_LONG_DOUBLE
     If the C compiler supports a working `long double' type with more
     range or precision than the `double' type, define
     `HAVE_LONG_DOUBLE'.

     You should use `AC_TYPE_LONG_DOUBLE' or
     `AC_TYPE_LONG_DOUBLE_WIDER' instead.  *Note Particular Types::.

 -- Macro: AC_LONG_FILE_NAMES
     Replaced by
          AC_SYS_LONG_FILE_NAMES
     *Note AC_SYS_LONG_FILE_NAMES::.

 -- Macro: AC_MAJOR_HEADER
     Replaced by `AC_HEADER_MAJOR' (*note AC_HEADER_MAJOR::).

 -- Macro: AC_MEMORY_H
     Used to define `NEED_MEMORY_H' if the `mem' functions were defined
     in `memory.h'.  Today it is equivalent to
     `AC_CHECK_HEADERS([memory.h])' (*note AC_CHECK_HEADERS::).  Adjust
     your code to depend upon `HAVE_MEMORY_H', not `NEED_MEMORY_H'; see
     *note Standard Symbols::.

 -- Macro: AC_MINGW32
     Similar to `AC_CYGWIN' but checks for the MinGW compiler
     environment and sets `MINGW32'.  Don't use this macro, the
     dignified means to check the nature of the host is using
     `AC_CANONICAL_HOST' (*note Canonicalizing::).

 -- Macro: AC_MINIX
     This macro is a platform-specific subset of
     `AC_USE_SYSTEM_EXTENSIONS' (*note AC_USE_SYSTEM_EXTENSIONS::).

 -- Macro: AC_MINUS_C_MINUS_O
     Replaced by `AC_PROG_CC_C_O' (*note AC_PROG_CC_C_O::).

 -- Macro: AC_MMAP
     Replaced by `AC_FUNC_MMAP' (*note AC_FUNC_MMAP::).

 -- Macro: AC_MODE_T
     Replaced by `AC_TYPE_MODE_T' (*note AC_TYPE_MODE_T::).

 -- Macro: AC_OBJEXT
     Defined the output variable `OBJEXT' based on the output of the
     compiler, after .c files have been excluded.  Typically set to `o'
     if Posix, `obj' if a DOS variant.  Now the compiler checking
     macros handle this automatically.

 -- Macro: AC_OBSOLETE (THIS-MACRO-NAME, [SUGGESTION])
     Make M4 print a message to the standard error output warning that
     THIS-MACRO-NAME is obsolete, and giving the file and line number
     where it was called.  THIS-MACRO-NAME should be the name of the
     macro that is calling `AC_OBSOLETE'.  If SUGGESTION is given, it
     is printed at the end of the warning message; for example, it can
     be a suggestion for what to use instead of THIS-MACRO-NAME.

     For instance

          AC_OBSOLETE([$0], [; use AC_CHECK_HEADERS(unistd.h) instead])dnl

     You are encouraged to use `AU_DEFUN' instead, since it gives better
     services to the user (*note AU_DEFUN::).

 -- Macro: AC_OFF_T
     Replaced by `AC_TYPE_OFF_T' (*note AC_TYPE_OFF_T::).

 -- Macro: AC_OUTPUT ([FILE]..., [EXTRA-CMDS], [INIT-CMDS])
     The use of `AC_OUTPUT' with arguments is deprecated.  This
     obsoleted interface is equivalent to:

          AC_CONFIG_FILES(FILE...)
          AC_CONFIG_COMMANDS([default],
                             EXTRA-CMDS, INIT-CMDS)
          AC_OUTPUT

     See *note AC_CONFIG_FILES::, *note AC_CONFIG_COMMANDS::, and *note
     AC_OUTPUT::.

 -- Macro: AC_OUTPUT_COMMANDS (EXTRA-CMDS, [INIT-CMDS])
     Specify additional shell commands to run at the end of
     `config.status', and shell commands to initialize any variables
     from `configure'.  This macro may be called multiple times.  It is
     obsolete, replaced by `AC_CONFIG_COMMANDS' (*note
     AC_CONFIG_COMMANDS::).

     Here is an unrealistic example:

          fubar=27
          AC_OUTPUT_COMMANDS([echo this is extra $fubar, and so on.],
                             [fubar=$fubar])
          AC_OUTPUT_COMMANDS([echo this is another, extra, bit],
                             [echo init bit])

     Aside from the fact that `AC_CONFIG_COMMANDS' requires an
     additional key, an important difference is that
     `AC_OUTPUT_COMMANDS' is quoting its arguments twice, unlike
     `AC_CONFIG_COMMANDS'.  This means that `AC_CONFIG_COMMANDS' can
     safely be given macro calls as arguments:

          AC_CONFIG_COMMANDS(foo, [my_FOO()])

     Conversely, where one level of quoting was enough for literal
     strings with `AC_OUTPUT_COMMANDS', you need two with
     `AC_CONFIG_COMMANDS'.  The following lines are equivalent:

          AC_OUTPUT_COMMANDS([echo "Square brackets: []"])
          AC_CONFIG_COMMANDS([default], [[echo "Square brackets: []"]])

 -- Macro: AC_PID_T
     Replaced by `AC_TYPE_PID_T' (*note AC_TYPE_PID_T::).

 -- Macro: AC_PREFIX
     Replaced by `AC_PREFIX_PROGRAM' (*note AC_PREFIX_PROGRAM::).

 -- Macro: AC_PROGRAMS_CHECK
     Replaced by `AC_CHECK_PROGS' (*note AC_CHECK_PROGS::).

 -- Macro: AC_PROGRAMS_PATH
     Replaced by `AC_PATH_PROGS' (*note AC_PATH_PROGS::).

 -- Macro: AC_PROGRAM_CHECK
     Replaced by `AC_CHECK_PROG' (*note AC_CHECK_PROG::).

 -- Macro: AC_PROGRAM_EGREP
     Replaced by `AC_EGREP_CPP' (*note AC_EGREP_CPP::).

 -- Macro: AC_PROGRAM_PATH
     Replaced by `AC_PATH_PROG' (*note AC_PATH_PROG::).

 -- Macro: AC_REMOTE_TAPE
     Removed because of limited usefulness.

 -- Macro: AC_RESTARTABLE_SYSCALLS
     This macro was renamed `AC_SYS_RESTARTABLE_SYSCALLS'.  However,
     these days portable programs should use `sigaction' with
     `SA_RESTART' if they want restartable system calls.  They should
     not rely on `HAVE_RESTARTABLE_SYSCALLS', since nowadays whether a
     system call is restartable is a dynamic issue, not a
     configuration-time issue.

 -- Macro: AC_RETSIGTYPE
     Replaced by `AC_TYPE_SIGNAL' (*note AC_TYPE_SIGNAL::), which itself
     is obsolete when assuming C89 or better.

 -- Macro: AC_RSH
     Removed because of limited usefulness.

 -- Macro: AC_SCO_INTL
     If on SCO Unix, add `-lintl' to output variable `LIBS'.  This
     macro used to do this:

          AC_CHECK_LIB([intl], [strftime], [LIBS="-lintl $LIBS"])

     Now it just calls `AC_FUNC_STRFTIME' instead (*note
     AC_FUNC_STRFTIME::).

 -- Macro: AC_SETVBUF_REVERSED
     Replaced by
          AC_FUNC_SETVBUF_REVERSED
     *Note AC_FUNC_SETVBUF_REVERSED::.

 -- Macro: AC_SET_MAKE
     Replaced by `AC_PROG_MAKE_SET' (*note AC_PROG_MAKE_SET::).

 -- Macro: AC_SIZEOF_TYPE
     Replaced by `AC_CHECK_SIZEOF' (*note AC_CHECK_SIZEOF::).

 -- Macro: AC_SIZE_T
     Replaced by `AC_TYPE_SIZE_T' (*note AC_TYPE_SIZE_T::).

 -- Macro: AC_STAT_MACROS_BROKEN
     Replaced by `AC_HEADER_STAT' (*note AC_HEADER_STAT::).

 -- Macro: AC_STDC_HEADERS
     Replaced by `AC_HEADER_STDC' (*note AC_HEADER_STDC::).

 -- Macro: AC_STRCOLL
     Replaced by `AC_FUNC_STRCOLL' (*note AC_FUNC_STRCOLL::).

 -- Macro: AC_STRUCT_ST_BLKSIZE
     If `struct stat' contains an `st_blksize' member, define
     `HAVE_STRUCT_STAT_ST_BLKSIZE'.  The former name, `HAVE_ST_BLKSIZE'
     is to be avoided, as its support will cease in the future.  This
     macro is obsoleted, and should be replaced by

          AC_CHECK_MEMBERS([struct stat.st_blksize])
     *Note AC_CHECK_MEMBERS::.

 -- Macro: AC_STRUCT_ST_RDEV
     If `struct stat' contains an `st_rdev' member, define
     `HAVE_STRUCT_STAT_ST_RDEV'.  The former name for this macro,
     `HAVE_ST_RDEV', is to be avoided as it will cease to be supported
     in the future.  Actually, even the new macro is obsolete and
     should be replaced by:
          AC_CHECK_MEMBERS([struct stat.st_rdev])
     *Note AC_CHECK_MEMBERS::.

 -- Macro: AC_ST_BLKSIZE
     Replaced by `AC_CHECK_MEMBERS' (*note AC_CHECK_MEMBERS::).

 -- Macro: AC_ST_BLOCKS
     Replaced by `AC_STRUCT_ST_BLOCKS' (*note AC_STRUCT_ST_BLOCKS::).

 -- Macro: AC_ST_RDEV
     Replaced by `AC_CHECK_MEMBERS' (*note AC_CHECK_MEMBERS::).

 -- Macro: AC_SYS_RESTARTABLE_SYSCALLS
     If the system automatically restarts a system call that is
     interrupted by a signal, define `HAVE_RESTARTABLE_SYSCALLS'.  This
     macro does not check whether system calls are restarted in
     general--it checks whether a signal handler installed with
     `signal' (but not `sigaction') causes system calls to be
     restarted.  It does not check whether system calls can be
     restarted when interrupted by signals that have no handler.

     These days portable programs should use `sigaction' with
     `SA_RESTART' if they want restartable system calls.  They should
     not rely on `HAVE_RESTARTABLE_SYSCALLS', since nowadays whether a
     system call is restartable is a dynamic issue, not a
     configuration-time issue.

 -- Macro: AC_SYS_SIGLIST_DECLARED
     This macro was renamed `AC_DECL_SYS_SIGLIST'.  However, even that
     name is obsolete, as the same functionality is now acheived via
     `AC_CHECK_DECLS' (*note AC_CHECK_DECLS::).

 -- Macro: AC_TEST_CPP
     This macro was renamed `AC_TRY_CPP', which in turn was replaced by
     `AC_PREPROC_IFELSE' (*note AC_PREPROC_IFELSE::).

 -- Macro: AC_TEST_PROGRAM
     This macro was renamed `AC_TRY_RUN', which in turn was replaced by
     `AC_RUN_IFELSE' (*note AC_RUN_IFELSE::).

 -- Macro: AC_TIMEZONE
     Replaced by `AC_STRUCT_TIMEZONE' (*note AC_STRUCT_TIMEZONE::).

 -- Macro: AC_TIME_WITH_SYS_TIME
     Replaced by `AC_HEADER_TIME' (*note AC_HEADER_TIME::).

 -- Macro: AC_TRY_COMPILE (INCLUDES, FUNCTION-BODY, [ACTION-IF-TRUE],
          [ACTION-IF-FALSE])
     Same as:

          AC_COMPILE_IFELSE(
            [AC_LANG_PROGRAM([[INCLUDES]],
               [[FUNCTION-BODY]])],
            [ACTION-IF-TRUE],
            [ACTION-IF-FALSE])

     *Note Running the Compiler::.

     This macro double quotes both INCLUDES and FUNCTION-BODY.

     For C and C++, INCLUDES is any `#include' statements needed by the
     code in FUNCTION-BODY (INCLUDES is ignored if the currently
     selected language is Fortran or Fortran 77).  The compiler and
     compilation flags are determined by the current language (*note
     Language Choice::).

 -- Macro: AC_TRY_CPP (INPUT, [ACTION-IF-TRUE], [ACTION-IF-FALSE])
     Same as:

          AC_PREPROC_IFELSE(
            [AC_LANG_SOURCE([[INPUT]])],
            [ACTION-IF-TRUE],
            [ACTION-IF-FALSE])

     *Note Running the Preprocessor::.

     This macro double quotes the INPUT.

 -- Macro: AC_TRY_LINK (INCLUDES, FUNCTION-BODY, [ACTION-IF-TRUE],
          [ACTION-IF-FALSE])
     Same as:

          AC_LINK_IFELSE(
            [AC_LANG_PROGRAM([[INCLUDES]],
               [[FUNCTION-BODY]])],
            [ACTION-IF-TRUE],
            [ACTION-IF-FALSE])

     *Note Running the Compiler::.

     This macro double quotes both INCLUDES and FUNCTION-BODY.

     Depending on the current language (*note Language Choice::),
     create a test program to see whether a function whose body
     consists of FUNCTION-BODY can be compiled and linked.  If the file
     compiles and links successfully, run shell commands
     ACTION-IF-FOUND, otherwise run ACTION-IF-NOT-FOUND.

     This macro double quotes both INCLUDES and FUNCTION-BODY.

     For C and C++, INCLUDES is any `#include' statements needed by the
     code in FUNCTION-BODY (INCLUDES is ignored if the currently
     selected language is Fortran or Fortran 77).  The compiler and
     compilation flags are determined by the current language (*note
     Language Choice::), and in addition `LDFLAGS' and `LIBS' are used
     for linking.

 -- Macro: AC_TRY_LINK_FUNC (FUNCTION, [ACTION-IF-FOUND],
          [ACTION-IF-NOT-FOUND])
     This macro is equivalent to
          AC_LINK_IFELSE([AC_LANG_CALL([], [FUNCTION])],
            [ACTION-IF-FOUND], [ACTION-IF-NOT-FOUND])
     *Note AC_LINK_IFELSE::.

 -- Macro: AC_TRY_RUN (PROGRAM, [ACTION-IF-TRUE], [ACTION-IF-FALSE],
          [ACTION-IF-CROSS-COMPILING])
     Same as:

          AC_RUN_IFELSE(
            [AC_LANG_SOURCE([[PROGRAM]])],
            [ACTION-IF-TRUE],
            [ACTION-IF-FALSE],
            [ACTION-IF-CROSS-COMPILING])

     *Note Runtime::.

 -- Macro: AC_TYPE_SIGNAL
     If `signal.h' declares `signal' as returning a pointer to a
     function returning `void', define `RETSIGTYPE' to be `void';
     otherwise, define it to be `int'.  These days, it is portable to
     assume C89, and that signal handlers return `void', without
     needing to use this macro or `RETSIGTYPE'.

     When targetting older K&R C, it is possible to define signal
     handlers as returning type `RETSIGTYPE', and omit a return
     statement:

          RETSIGTYPE
          hup_handler ()
          {
          ...
          }

 -- Macro: AC_UID_T
     Replaced by `AC_TYPE_UID_T' (*note AC_TYPE_UID_T::).

 -- Macro: AC_UNISTD_H
     Same as `AC_CHECK_HEADERS([unistd.h])' (*note AC_CHECK_HEADERS::).

 -- Macro: AC_USG
     Define `USG' if the BSD string functions are defined in
     `strings.h'.  You should no longer depend upon `USG', but on
     `HAVE_STRING_H'; see *note Standard Symbols::.

 -- Macro: AC_UTIME_NULL
     Replaced by `AC_FUNC_UTIME_NULL' (*note AC_FUNC_UTIME_NULL::).

 -- Macro: AC_VALIDATE_CACHED_SYSTEM_TUPLE ([CMD])
     If the cache file is inconsistent with the current host, target and
     build system types, it used to execute CMD or print a default
     error message.  This is now handled by default.

 -- Macro: AC_VERBOSE (RESULT-DESCRIPTION)
     Replaced by `AC_MSG_RESULT' (*note AC_MSG_RESULT::).

 -- Macro: AC_VFORK
     Replaced by `AC_FUNC_FORK' (*note AC_FUNC_FORK::).

 -- Macro: AC_VPRINTF
     Replaced by `AC_FUNC_VPRINTF' (*note AC_FUNC_VPRINTF::).

 -- Macro: AC_WAIT3
     This macro was renamed `AC_FUNC_WAIT3'.  However, these days
     portable programs should use `waitpid', not `wait3', as `wait3'
     has been removed from Posix.

 -- Macro: AC_WARN
     Replaced by `AC_MSG_WARN' (*note AC_MSG_WARN::).

 -- Macro: AC_WITH (PACKAGE, ACTION-IF-GIVEN, [ACTION-IF-NOT-GIVEN])
     This is an obsolete version of `AC_ARG_WITH' that does not support
     providing a help string (*note AC_ARG_WITH::).

 -- Macro: AC_WORDS_BIGENDIAN
     Replaced by `AC_C_BIGENDIAN' (*note AC_C_BIGENDIAN::).

 -- Macro: AC_XENIX_DIR
     This macro used to add `-lx' to output variable `LIBS' if on
     Xenix.  Also, if `dirent.h' is being checked for, added `-ldir' to
     `LIBS'.  Now it is merely an alias of `AC_HEADER_DIRENT' instead,
     plus some code to detect whether running XENIX on which you should
     not depend:

          AC_MSG_CHECKING([for Xenix])
          AC_EGREP_CPP([yes],
          [#if defined M_XENIX && !defined M_UNIX
            yes
          #endif],
                       [AC_MSG_RESULT([yes]); XENIX=yes],
                       [AC_MSG_RESULT([no]); XENIX=])
     Don't use this macro, the dignified means to check the nature of
     the host is using `AC_CANONICAL_HOST' (*note Canonicalizing::).

 -- Macro: AC_YYTEXT_POINTER
     This macro was renamed `AC_DECL_YYTEXT', which in turn was
     integrated into `AC_PROG_LEX' (*note AC_PROG_LEX::).


File: autoconf.info,  Node: Autoconf 1,  Next: Autoconf 2.13,  Prev: Obsolete Macros,  Up: Obsolete Constructs

18.5 Upgrading From Version 1
=============================

Autoconf version 2 is mostly backward compatible with version 1.
However, it introduces better ways to do some things, and doesn't
support some of the ugly things in version 1.  So, depending on how
sophisticated your `configure.ac' files are, you might have to do some
manual work in order to upgrade to version 2.  This chapter points out
some problems to watch for when upgrading.  Also, perhaps your
`configure' scripts could benefit from some of the new features in
version 2; the changes are summarized in the file `NEWS' in the
Autoconf distribution.

* Menu:

* Changed File Names::          Files you might rename
* Changed Makefiles::           New things to put in `Makefile.in'
* Changed Macros::              Macro calls you might replace
* Changed Results::             Changes in how to check test results
* Changed Macro Writing::       Better ways to write your own macros


File: autoconf.info,  Node: Changed File Names,  Next: Changed Makefiles,  Up: Autoconf 1

18.5.1 Changed File Names
-------------------------

If you have an `aclocal.m4' installed with Autoconf (as opposed to in a
particular package's source directory), you must rename it to
`acsite.m4'.  *Note autoconf Invocation::.

   If you distribute `install.sh' with your package, rename it to
`install-sh' so `make' builtin rules don't inadvertently create a file
called `install' from it.  `AC_PROG_INSTALL' looks for the script under
both names, but it is best to use the new name.

   If you were using `config.h.top', `config.h.bot', or `acconfig.h',
you still can, but you have less clutter if you use the `AH_' macros.
*Note Autoheader Macros::.


File: autoconf.info,  Node: Changed Makefiles,  Next: Changed Macros,  Prev: Changed File Names,  Up: Autoconf 1

18.5.2 Changed Makefiles
------------------------

Add `@CFLAGS@', `@CPPFLAGS@', and `@LDFLAGS@' in your `Makefile.in'
files, so they can take advantage of the values of those variables in
the environment when `configure' is run.  Doing this isn't necessary,
but it's a convenience for users.

   Also add `@configure_input@' in a comment to each input file for
`AC_OUTPUT', so that the output files contain a comment saying they
were produced by `configure'.  Automatically selecting the right
comment syntax for all the kinds of files that people call `AC_OUTPUT'
on became too much work.

   Add `config.log' and `config.cache' to the list of files you remove
in `distclean' targets.

   If you have the following in `Makefile.in':

     prefix = /usr/local
     exec_prefix = $(prefix)

you must change it to:

     prefix = @prefix@
     exec_prefix = @exec_prefix@

The old behavior of replacing those variables without `@' characters
around them has been removed.


File: autoconf.info,  Node: Changed Macros,  Next: Changed Results,  Prev: Changed Makefiles,  Up: Autoconf 1

18.5.3 Changed Macros
---------------------

Many of the macros were renamed in Autoconf version 2.  You can still
use the old names, but the new ones are clearer, and it's easier to find
the documentation for them.  *Note Obsolete Macros::, for a table
showing the new names for the old macros.  Use the `autoupdate' program
to convert your `configure.ac' to using the new macro names.  *Note
autoupdate Invocation::.

   Some macros have been superseded by similar ones that do the job
better, but are not call-compatible.  If you get warnings about calling
obsolete macros while running `autoconf', you may safely ignore them,
but your `configure' script generally works better if you follow the
advice that is printed about what to replace the obsolete macros with.
In particular, the mechanism for reporting the results of tests has
changed.  If you were using `echo' or `AC_VERBOSE' (perhaps via
`AC_COMPILE_CHECK'), your `configure' script's output looks better if
you switch to `AC_MSG_CHECKING' and `AC_MSG_RESULT'.  *Note Printing
Messages::.  Those macros work best in conjunction with cache
variables.  *Note Caching Results::.


File: autoconf.info,  Node: Changed Results,  Next: Changed Macro Writing,  Prev: Changed Macros,  Up: Autoconf 1

18.5.4 Changed Results
----------------------

If you were checking the results of previous tests by examining the
shell variable `DEFS', you need to switch to checking the values of the
cache variables for those tests.  `DEFS' no longer exists while
`configure' is running; it is only created when generating output
files.  This difference from version 1 is because properly quoting the
contents of that variable turned out to be too cumbersome and
inefficient to do every time `AC_DEFINE' is called.  *Note Cache
Variable Names::.

   For example, here is a `configure.ac' fragment written for Autoconf
version 1:

     AC_HAVE_FUNCS(syslog)
     case "$DEFS" in
     *-DHAVE_SYSLOG*) ;;
     *) # syslog is not in the default libraries.  See if it's in some other.
       saved_LIBS="$LIBS"
       for lib in bsd socket inet; do
         AC_CHECKING(for syslog in -l$lib)
         LIBS="-l$lib $saved_LIBS"
         AC_HAVE_FUNCS(syslog)
         case "$DEFS" in
         *-DHAVE_SYSLOG*) break ;;
         *) ;;
         esac
         LIBS="$saved_LIBS"
       done ;;
     esac

   Here is a way to write it for version 2:

     AC_CHECK_FUNCS([syslog])
     if test "x$ac_cv_func_syslog" = xno; then
       # syslog is not in the default libraries.  See if it's in some other.
       for lib in bsd socket inet; do
         AC_CHECK_LIB([$lib], [syslog], [AC_DEFINE([HAVE_SYSLOG])
           LIBS="-l$lib $LIBS"; break])
       done
     fi

   If you were working around bugs in `AC_DEFINE_UNQUOTED' by adding
backslashes before quotes, you need to remove them.  It now works
predictably, and does not treat quotes (except back quotes) specially.
*Note Setting Output Variables::.

   All of the Boolean shell variables set by Autoconf macros now use
`yes' for the true value.  Most of them use `no' for false, though for
backward compatibility some use the empty string instead.  If you were
relying on a shell variable being set to something like 1 or `t' for
true, you need to change your tests.


File: autoconf.info,  Node: Changed Macro Writing,  Prev: Changed Results,  Up: Autoconf 1

18.5.5 Changed Macro Writing
----------------------------

When defining your own macros, you should now use `AC_DEFUN' instead of
`define'.  `AC_DEFUN' automatically calls `AC_PROVIDE' and ensures that
macros called via `AC_REQUIRE' do not interrupt other macros, to
prevent nested `checking...' messages on the screen.  There's no actual
harm in continuing to use the older way, but it's less convenient and
attractive.  *Note Macro Definitions::.

   You probably looked at the macros that came with Autoconf as a guide
for how to do things.  It would be a good idea to take a look at the new
versions of them, as the style is somewhat improved and they take
advantage of some new features.

   If you were doing tricky things with undocumented Autoconf internals
(macros, variables, diversions), check whether you need to change
anything to account for changes that have been made.  Perhaps you can
even use an officially supported technique in version 2 instead of
kludging.  Or perhaps not.

   To speed up your locally written feature tests, add caching to them.
See whether any of your tests are of general enough usefulness to
encapsulate them into macros that you can share.


File: autoconf.info,  Node: Autoconf 2.13,  Prev: Autoconf 1,  Up: Obsolete Constructs

18.6 Upgrading From Version 2.13
================================

The introduction of the previous section (*note Autoconf 1::) perfectly
suits this section...

     Autoconf version 2.50 is mostly backward compatible with version
     2.13.  However, it introduces better ways to do some things, and
     doesn't support some of the ugly things in version 2.13.  So,
     depending on how sophisticated your `configure.ac' files are, you
     might have to do some manual work in order to upgrade to version
     2.50.  This chapter points out some problems to watch for when
     upgrading.  Also, perhaps your `configure' scripts could benefit
     from some of the new features in version 2.50; the changes are
     summarized in the file `NEWS' in the Autoconf distribution.

* Menu:

* Changed Quotation::           Broken code which used to work
* New Macros::                  Interaction with foreign macros
* Hosts and Cross-Compilation::  Bugward compatibility kludges
* AC_LIBOBJ vs LIBOBJS::        LIBOBJS is a forbidden token
* AC_ACT_IFELSE vs AC_TRY_ACT::  A more generic scheme for testing sources


File: autoconf.info,  Node: Changed Quotation,  Next: New Macros,  Up: Autoconf 2.13

18.6.1 Changed Quotation
------------------------

The most important changes are invisible to you: the implementation of
most macros have completely changed.  This allowed more factorization of
the code, better error messages, a higher uniformity of the user's
interface etc.  Unfortunately, as a side effect, some construct which
used to (miraculously) work might break starting with Autoconf 2.50.
The most common culprit is bad quotation.

   For instance, in the following example, the message is not properly
quoted:

     AC_INIT
     AC_CHECK_HEADERS(foo.h, ,
       AC_MSG_ERROR(cannot find foo.h, bailing out))
     AC_OUTPUT

Autoconf 2.13 simply ignores it:

     $ autoconf-2.13; ./configure --silent
     creating cache ./config.cache
     configure: error: cannot find foo.h
     $

while Autoconf 2.50 produces a broken `configure':

     $ autoconf-2.50; ./configure --silent
     configure: error: cannot find foo.h
     ./configure: exit: bad non-numeric arg `bailing'
     ./configure: exit: bad non-numeric arg `bailing'
     $

   The message needs to be quoted, and the `AC_MSG_ERROR' invocation
too!

     AC_INIT([Example], [1.0], [bug-example@example.org])
     AC_CHECK_HEADERS([foo.h], [],
       [AC_MSG_ERROR([cannot find foo.h, bailing out])])
     AC_OUTPUT

   Many many (and many more) Autoconf macros were lacking proper
quotation, including no less than... `AC_DEFUN' itself!

     $ cat configure.in
     AC_DEFUN([AC_PROG_INSTALL],
     [# My own much better version
     ])
     AC_INIT
     AC_PROG_INSTALL
     AC_OUTPUT
     $ autoconf-2.13
     autoconf: Undefined macros:
     ***BUG in Autoconf--please report*** AC_FD_MSG
     ***BUG in Autoconf--please report*** AC_EPI
     configure.in:1:AC_DEFUN([AC_PROG_INSTALL],
     configure.in:5:AC_PROG_INSTALL
     $ autoconf-2.50
     $


File: autoconf.info,  Node: New Macros,  Next: Hosts and Cross-Compilation,  Prev: Changed Quotation,  Up: Autoconf 2.13

18.6.2 New Macros
-----------------

While Autoconf was relatively dormant in the late 1990s, Automake
provided Autoconf-like macros for a while.  Starting with Autoconf 2.50
in 2001, Autoconf provided versions of these macros, integrated in the
`AC_' namespace, instead of `AM_'.  But in order to ease the upgrading
via `autoupdate', bindings to such `AM_' macros are provided.

   Unfortunately older versions of Automake (e.g., Automake 1.4) did
not quote the names of these macros.  Therefore, when `m4' finds
something like `AC_DEFUN(AM_TYPE_PTRDIFF_T, ...)' in `aclocal.m4',
`AM_TYPE_PTRDIFF_T' is expanded, replaced with its Autoconf definition.

   Fortunately Autoconf catches pre-`AC_INIT' expansions, and
complains, in its own words:

     $ cat configure.ac
     AC_INIT([Example], [1.0], [bug-example@example.org])
     AM_TYPE_PTRDIFF_T
     $ aclocal-1.4
     $ autoconf
     aclocal.m4:17: error: m4_defn: undefined macro: _m4_divert_diversion
     aclocal.m4:17: the top level
     autom4te: m4 failed with exit status: 1
     $

   Modern versions of Automake no longer define most of these macros,
and properly quote the names of the remaining macros.  If you must use
an old Automake, do not depend upon macros from Automake as it is
simply not its job to provide macros (but the one it requires itself):

     $ cat configure.ac
     AC_INIT([Example], [1.0], [bug-example@example.org])
     AM_TYPE_PTRDIFF_T
     $ rm aclocal.m4
     $ autoupdate
     autoupdate: `configure.ac' is updated
     $ cat configure.ac
     AC_INIT([Example], [1.0], [bug-example@example.org])
     AC_CHECK_TYPES([ptrdiff_t])
     $ aclocal-1.4
     $ autoconf
     $


File: autoconf.info,  Node: Hosts and Cross-Compilation,  Next: AC_LIBOBJ vs LIBOBJS,  Prev: New Macros,  Up: Autoconf 2.13

18.6.3 Hosts and Cross-Compilation
----------------------------------

Based on the experience of compiler writers, and after long public
debates, many aspects of the cross-compilation chain have changed:

   - the relationship between the build, host, and target architecture
     types,

   - the command line interface for specifying them to `configure',

   - the variables defined in `configure',

   - the enabling of cross-compilation mode.


   The relationship between build, host, and target have been cleaned
up: the chain of default is now simply: target defaults to host, host to
build, and build to the result of `config.guess'.  Nevertheless, in
order to ease the transition from 2.13 to 2.50, the following
transition scheme is implemented.  _Do not rely on it_, as it will be
completely disabled in a couple of releases (we cannot keep it, as it
proves to cause more problems than it cures).

   They all default to the result of running `config.guess', unless you
specify either `--build' or `--host'.  In this case, the default
becomes the system type you specified.  If you specify both, and
they're different, `configure' enters cross compilation mode, so it
doesn't run any tests that require execution.

   Hint: if you mean to override the result of `config.guess', prefer
`--build' over `--host'.  In the future, `--host' will not override the
name of the build system type.  Whenever you specify `--host', be sure
to specify `--build' too.


   For backward compatibility, `configure' accepts a system type as an
option by itself.  Such an option overrides the defaults for build,
host, and target system types.  The following configure statement
configures a cross toolchain that runs on NetBSD/alpha but generates
code for GNU Hurd/sparc, which is also the build platform.

     ./configure --host=alpha-netbsd sparc-gnu


   In Autoconf 2.13 and before, the variables `build', `host', and
`target' had a different semantics before and after the invocation of
`AC_CANONICAL_BUILD' etc.  Now, the argument of `--build' is strictly
copied into `build_alias', and is left empty otherwise.  After the
`AC_CANONICAL_BUILD', `build' is set to the canonicalized build type.
To ease the transition, before, its contents is the same as that of
`build_alias'.  Do _not_ rely on this broken feature.

   For consistency with the backward compatibility scheme exposed above,
when `--host' is specified but `--build' isn't, the build system is
assumed to be the same as `--host', and `build_alias' is set to that
value.  Eventually, this historically incorrect behavior will go away.


   The former scheme to enable cross-compilation proved to cause more
harm than good, in particular, it used to be triggered too easily,
leaving regular end users puzzled in front of cryptic error messages.
`configure' could even enter cross-compilation mode only because the
compiler was not functional.  This is mainly because `configure' used
to try to detect cross-compilation, instead of waiting for an explicit
flag from the user.

   Now, `configure' enters cross-compilation mode if and only if
`--host' is passed.

   That's the short documentation.  To ease the transition between 2.13
and its successors, a more complicated scheme is implemented.  _Do not
rely on the following_, as it will be removed in the near future.

   If you specify `--host', but not `--build', when `configure'
performs the first compiler test it tries to run an executable produced
by the compiler.  If the execution fails, it enters cross-compilation
mode.  This is fragile.  Moreover, by the time the compiler test is
performed, it may be too late to modify the build-system type: other
tests may have already been performed.  Therefore, whenever you specify
`--host', be sure to specify `--build' too.

     ./configure --build=i686-pc-linux-gnu --host=m68k-coff

enters cross-compilation mode.  The former interface, which consisted
in setting the compiler to a cross-compiler without informing
`configure' is obsolete.  For instance, `configure' fails if it can't
run the code generated by the specified compiler if you configure as
follows:

     ./configure CC=m68k-coff-gcc


File: autoconf.info,  Node: AC_LIBOBJ vs LIBOBJS,  Next: AC_ACT_IFELSE vs AC_TRY_ACT,  Prev: Hosts and Cross-Compilation,  Up: Autoconf 2.13

18.6.4 `AC_LIBOBJ' vs. `LIBOBJS'
--------------------------------

Up to Autoconf 2.13, the replacement of functions was triggered via the
variable `LIBOBJS'.  Since Autoconf 2.50, the macro `AC_LIBOBJ' should
be used instead (*note Generic Functions::).  Starting at Autoconf
2.53, the use of `LIBOBJS' is an error.

   This change is mandated by the unification of the GNU Build System
components.  In particular, the various fragile techniques used to parse
a `configure.ac' are all replaced with the use of traces.  As a
consequence, any action must be traceable, which obsoletes critical
variable assignments.  Fortunately, `LIBOBJS' was the only problem, and
it can even be handled gracefully (read, "without your having to change
something").

   There were two typical uses of `LIBOBJS': asking for a replacement
function, and adjusting `LIBOBJS' for Automake and/or Libtool.


   As for function replacement, the fix is immediate: use `AC_LIBOBJ'.
For instance:

     LIBOBJS="$LIBOBJS fnmatch.o"
     LIBOBJS="$LIBOBJS malloc.$ac_objext"

should be replaced with:

     AC_LIBOBJ([fnmatch])
     AC_LIBOBJ([malloc])


   When used with Automake 1.10 or newer, a suitable value for
`LIBOBJDIR' is set so that the `LIBOBJS' and `LTLIBOBJS' can be
referenced from any `Makefile.am'.  Even without Automake, arranging
for `LIBOBJDIR' to be set correctly enables referencing `LIBOBJS' and
`LTLIBOBJS' in another directory.  The `LIBOBJDIR' feature is
experimental.


File: autoconf.info,  Node: AC_ACT_IFELSE vs AC_TRY_ACT,  Prev: AC_LIBOBJ vs LIBOBJS,  Up: Autoconf 2.13

18.6.5 `AC_ACT_IFELSE' vs. `AC_TRY_ACT'
---------------------------------------

Since Autoconf 2.50, internal codes uses `AC_PREPROC_IFELSE',
`AC_COMPILE_IFELSE', `AC_LINK_IFELSE', and `AC_RUN_IFELSE' on one hand
and `AC_LANG_SOURCE', and `AC_LANG_PROGRAM' on the other hand instead
of the deprecated `AC_TRY_CPP', `AC_TRY_COMPILE', `AC_TRY_LINK', and
`AC_TRY_RUN'.  The motivations where:
   - a more consistent interface: `AC_TRY_COMPILE' etc. were double
     quoting their arguments;

   - the combinatoric explosion is solved by decomposing on the one
     hand the generation of sources, and on the other hand executing
     the program;

   - this scheme helps supporting more languages than plain C and C++.

   In addition to the change of syntax, the philosophy has changed too:
while emphasis was put on speed at the expense of accuracy, today's
Autoconf promotes accuracy of the testing framework at, ahem..., the
expense of speed.

   As a perfect example of what is _not_ to be done, here is how to
find out whether a header file contains a particular declaration, such
as a typedef, a structure, a structure member, or a function.  Use
`AC_EGREP_HEADER' instead of running `grep' directly on the header
file; on some systems the symbol might be defined in another header
file that the file you are checking includes.

   As a (bad) example, here is how you should not check for C
preprocessor symbols, either defined by header files or predefined by
the C preprocessor: using `AC_EGREP_CPP':

     AC_EGREP_CPP(yes,
     [#ifdef _AIX
       yes
     #endif
     ], is_aix=yes, is_aix=no)

   The above example, properly written would (i) use `AC_LANG_PROGRAM',
and (ii) run the compiler:

     AC_COMPILE_IFELSE([AC_LANG_PROGRAM(
     [[#ifndef _AIX
      error: This isn't AIX!
     #endif
     ]])],
                        [is_aix=yes],
                        [is_aix=no])


File: autoconf.info,  Node: Using Autotest,  Next: FAQ,  Prev: Obsolete Constructs,  Up: Top

19 Generating Test Suites with Autotest
***************************************

     *N.B.: This section describes a feature which is still
     stabilizing.  Although we believe that Autotest is useful as-is, this
     documentation describes an interface which might change in the future:
     do not depend upon Autotest without subscribing to the Autoconf mailing
     lists.*

   It is paradoxical that portable projects depend on nonportable tools
to run their test suite.  Autoconf by itself is the paragon of this
problem: although it aims at perfectly portability, up to 2.13 its test
suite was using DejaGNU, a rich and complex testing framework, but
which is far from being standard on Posix systems.  Worse yet, it was
likely to be missing on the most fragile platforms, the very platforms
that are most likely to torture Autoconf and exhibit deficiencies.

   To circumvent this problem, many package maintainers have developed
their own testing framework, based on simple shell scripts whose sole
outputs are exit status values describing whether the test succeeded.
Most of these tests share common patterns, and this can result in lots
of duplicated code and tedious maintenance.

   Following exactly the same reasoning that yielded to the inception of
Autoconf, Autotest provides a test suite generation framework, based on
M4 macros building a portable shell script.  The suite itself is
equipped with automatic logging and tracing facilities which greatly
diminish the interaction with bug reporters, and simple timing reports.

   Autoconf itself has been using Autotest for years, and we do attest
that it has considerably improved the strength of the test suite and the
quality of bug reports.  Other projects are known to use some generation
of Autotest, such as Bison, Free Recode, Free Wdiff, GNU Tar, each of
them with different needs, and this usage has validated Autotest as a
general testing framework.

   Nonetheless, compared to DejaGNU, Autotest is inadequate for
interactive tool testing, which is probably its main limitation.

* Menu:

* Using an Autotest Test Suite::  Autotest and the user
* Writing Testsuites::          Autotest macros
* testsuite Invocation::        Running `testsuite' scripts
* Making testsuite Scripts::    Using autom4te to create `testsuite'


File: autoconf.info,  Node: Using an Autotest Test Suite,  Next: Writing Testsuites,  Up: Using Autotest

19.1 Using an Autotest Test Suite
=================================

* Menu:

* testsuite Scripts::           The concepts of Autotest
* Autotest Logs::               Their contents


File: autoconf.info,  Node: testsuite Scripts,  Next: Autotest Logs,  Up: Using an Autotest Test Suite

19.1.1 `testsuite' Scripts
--------------------------

Generating testing or validation suites using Autotest is rather easy.
The whole validation suite is held in a file to be processed through
`autom4te', itself using GNU M4 under the hood, to produce a
stand-alone Bourne shell script which then gets distributed.  Neither
`autom4te' nor GNU M4 are needed at the installer's end.

   Each test of the validation suite should be part of some test group.
A "test group" is a sequence of interwoven tests that ought to be
executed together, usually because one test in the group creates data
files than a later test in the same group needs to read.  Complex test
groups make later debugging more tedious.  It is much better to keep
only a few tests per test group.  Ideally there is only one test per
test group.

   For all but the simplest packages, some file such as `testsuite.at'
does not fully hold all test sources, as these are often easier to
maintain in separate files.  Each of these separate files holds a single
test group, or a sequence of test groups all addressing some common
functionality in the package.  In such cases, `testsuite.at' merely
initializes the validation suite, and sometimes does elementary health
checking, before listing include statements for all other test files.
The special file `package.m4', containing the identification of the
package, is automatically included if found.

   A convenient alternative consists in moving all the global issues
(local Autotest macros, elementary health checking, and `AT_INIT'
invocation) into the file `local.at', and making `testsuite.at' be a
simple list of `m4_include' of sub test suites.  In such case,
generating the whole test suite or pieces of it is only a matter of
choosing the `autom4te' command line arguments.

   The validation scripts that Autotest produces are by convention
called `testsuite'.  When run, `testsuite' executes each test group in
turn, producing only one summary line per test to say if that
particular test succeeded or failed.  At end of all tests, summarizing
counters get printed.  One debugging directory is left for each test
group which failed, if any: such directories are named
`testsuite.dir/NN', where NN is the sequence number of the test group,
and they include:

   * a debugging script named `run' which reruns the test in "debug
     mode" (*note testsuite Invocation::).  The automatic generation of
     debugging scripts has the purpose of easing the chase for bugs.

   * all the files created with `AT_DATA'

   * all the Erlang source code files created with `AT_CHECK_EUNIT'

   * a log of the run, named `testsuite.log'

   In the ideal situation, none of the tests fail, and consequently no
debugging directory is left behind for validation.

   It often happens in practice that individual tests in the validation
suite need to get information coming out of the configuration process.
Some of this information, common for all validation suites, is provided
through the file `atconfig', automatically created by
`AC_CONFIG_TESTDIR'.  For configuration informations which your testing
environment specifically needs, you might prepare an optional file
named `atlocal.in', instantiated by `AC_CONFIG_FILES'.  The
configuration process produces `atconfig' and `atlocal' out of these
two input files, and these two produced files are automatically read by
the `testsuite' script.

   Here is a diagram showing the relationship between files.

Files used in preparing a software package for distribution:

                     [package.m4] -->.
                                      \
     subfile-1.at ->.  [local.at] ---->+
         ...         \                  \
     subfile-i.at ---->-- testsuite.at -->-- autom4te* -->testsuite
         ...         /
     subfile-n.at ->'

Files used in configuring a software package:

                                          .--> atconfig
                                         /
     [atlocal.in] -->  config.status* --<
                                         \
                                          `--> [atlocal]

Files created during test suite execution:

     atconfig -->.                    .--> testsuite.log
                  \                  /
                   >-- testsuite* --<
                  /                  \
     [atlocal] ->'                    `--> [testsuite.dir]


File: autoconf.info,  Node: Autotest Logs,  Prev: testsuite Scripts,  Up: Using an Autotest Test Suite

19.1.2 Autotest Logs
--------------------

When run, the test suite creates a log file named after itself, e.g., a
test suite named `testsuite' creates `testsuite.log'.  It contains a
lot of information, usually more than maintainers actually need, but
therefore most of the time it contains all that is needed:

command line arguments
     A bad but unfortunately widespread habit consists of setting
     environment variables before the command, such as in
     `CC=my-home-grown-cc ./testsuite'.  The test suite does not know
     this change, hence (i) it cannot report it to you, and (ii) it
     cannot preserve the value of `CC' for subsequent runs.  Autoconf
     faced exactly the same problem, and solved it by asking users to
     pass the variable definitions as command line arguments.  Autotest
     requires this rule, too, but has no means to enforce it; the log
     then contains a trace of the variables that were changed by the
     user.

`ChangeLog' excerpts
     The topmost lines of all the `ChangeLog' files found in the source
     hierarchy.  This is especially useful when bugs are reported
     against development versions of the package, since the version
     string does not provide sufficient information to know the exact
     state of the sources the user compiled.  Of course, this relies on
     the use of a `ChangeLog'.

build machine
     Running a test suite in a cross-compile environment is not an easy
     task, since it would mean having the test suite run on a machine
     BUILD, while running programs on a machine HOST.  It is much
     simpler to run both the test suite and the programs on HOST, but
     then, from the point of view of the test suite, there remains a
     single environment, HOST = BUILD.  The log contains relevant
     information on the state of the BUILD machine, including some
     important environment variables.

tested programs
     The absolute file name and answers to `--version' of the tested
     programs (see *note Writing Testsuites::, `AT_TESTED').

configuration log
     The contents of `config.log', as created by `configure', are
     appended.  It contains the configuration flags and a detailed
     report on the configuration itself.


File: autoconf.info,  Node: Writing Testsuites,  Next: testsuite Invocation,  Prev: Using an Autotest Test Suite,  Up: Using Autotest

19.2 Writing `testsuite.at'
===========================

The `testsuite.at' is a Bourne shell script making use of special
Autotest M4 macros.  It often contains a call to `AT_INIT' near its
beginning followed by one call to `m4_include' per source file for
tests.  Each such included file, or the remainder of `testsuite.at' if
include files are not used, contain a sequence of test groups.  Each
test group begins with a call to `AT_SETUP', then an arbitrary number
of shell commands or calls to `AT_CHECK', and then completes with a
call to `AT_CLEANUP'.  Multiple test groups can be categorized by a
call to `AT_BANNER'.

   All of the public Autotest macros have all-uppercase names in the
namespace `^AT_' to prevent them from accidentally conflicting with
other text; Autoconf also reserves the namespace `^_AT_' for internal
macros.  All shell variables used in the testsuite for internal
purposes have mostly-lowercase names starting with `at_'.  Autotest
also uses here-document delimiters in the namespace `^_AT[A-Z]', and
makes use of the file system namespace `^at-'.

   Since Autoconf is built on top of M4sugar (*note Programming in
M4sugar::) and M4sh (*note Programming in M4sh::), you must also be
aware of those namespaces (`^_?\(m4\|AS\)_').  In general, you _should
not use_ the namespace of a package that does not own the macro or
shell code you are writing.

 -- Macro: AT_INIT ([NAME])
     Initialize Autotest.  Giving a NAME to the test suite is
     encouraged if your package includes several test suites.  Before
     this macro is called, `AT_PACKAGE_STRING' and
     `AT_PACKAGE_BUGREPORT' must be defined, which are used to display
     information about the testsuite to the user.  Typically, these
     macros are provided by a file `package.m4' built by `make' (*note
     Making testsuite Scripts::), in order to inherit the package name,
     version, and bug reporting address from `configure.ac'.

 -- Macro: AT_COPYRIGHT (COPYRIGHT-NOTICE)
     State that, in addition to the Free Software Foundation's
     copyright on the Autotest macros, parts of your test suite are
     covered by COPYRIGHT-NOTICE.

     The COPYRIGHT-NOTICE shows up in both the head of `testsuite' and
     in `testsuite --version'.

 -- Macro: AT_ARG_OPTION (OPTIONS, HELP-TEXT, [ACTION-IF-GIVEN],
          [ACTION-IF-NOT-GIVEN])
     Accept options from the space-separated list OPTIONS, a list that
     has leading dashes removed from the options.  Long options will be
     prefixed with `--', single-character options with `-'.  The first
     word in this list is the primary OPTION, any others are assumed to
     be short-hand aliases.  The variable associated with it is
     `at_arg_OPTION', with any dashes in OPTION replaced with
     underscores.

     If the user passes `--OPTION' to the `testsuite', the variable
     will be set to `:'.  If the user does not pass the option, or
     passes `--no-OPTION', then the variable will be set to `false'.

     ACTION-IF-GIVEN is run each time the option is encountered; here,
     the variable `at_optarg' will be set to `:' or `false' as
     appropriate.  `at_optarg' is actually just a copy of
     `at_arg_OPTION'.

     ACTION-IF-NOT-GIVEN will be run once after option parsing is
     complete and if no option from OPTIONS was used.

     HELP-TEXT is added to the end of the list of options shown in
     `testsuite --help' (*note AS_HELP_STRING::).

     It it recommended that you use a package-specific prefix to OPTIONS
     names in order to avoid clashes with future Autotest built-in
     options.

 -- Macro: AT_ARG_OPTION_ARG (OPTIONS, HELP-TEXT, [ACTION-IF-GIVEN],
          [ACTION-IF-NOT-GIVEN])
     Accept options with arguments from the space-separated list
     OPTIONS, a list that has leading dashes removed from the options.
     Long options will be prefixed with `--', single-character options
     with `-'.  The first word in this list is the primary OPTION, any
     others are assumed to be short-hand aliases.  The variable
     associated with it is `at_arg_OPTION', with any dashes in OPTION
     replaced with underscores.

     If the user passes `--OPTION=ARG' or `--OPTION ARG' to the
     `testsuite', the variable will be set to `ARG'.

     ACTION-IF-GIVEN is run each time the option is encountered; here,
     the variable `at_optarg' will be set to `ARG'.  `at_optarg' is
     actually just a copy of `at_arg_OPTION'.

     ACTION-IF-NOT-GIVEN will be run once after option parsing is
     complete and if no option from OPTIONS was used.

     HELP-TEXT is added to the end of the list of options shown in
     `testsuite --help' (*note AS_HELP_STRING::).

     It it recommended that you use a package-specific prefix to OPTIONS
     names in order to avoid clashes with future Autotest built-in
     options.

 -- Macro: AT_COLOR_TESTS
     Enable colored test results by default when the output is
     connected to a terminal.

 -- Macro: AT_TESTED (EXECUTABLES)
     Log the file name and answer to `--version' of each program in
     space-separated list EXECUTABLES.  Several invocations register
     new executables, in other words, don't fear registering one program
     several times.

     Autotest test suites rely on `PATH' to find the tested program.
     This avoids the need to generate absolute names of the various
     tools, and makes it possible to test installed programs.
     Therefore, knowing which programs are being exercised is crucial
     to understanding problems in the test suite itself, or its
     occasional misuses.  It is a good idea to also subscribe foreign
     programs you depend upon, to avoid incompatible diagnostics.


 -- Macro: AT_BANNER (TEST-CATEGORY-NAME)
     This macro identifies the start of a category of related test
     groups.  When the resulting `testsuite' is invoked with more than
     one test group to run, its output will include a banner containing
     TEST-CATEGORY-NAME prior to any tests run from that category.  The
     banner should be no more than about 40 or 50 characters.  A blank
     banner indicates uncategorized tests; an empty line will be
     inserted after tests from an earlier category, effectively ending
     that category.

 -- Macro: AT_SETUP (TEST-GROUP-NAME)
     This macro starts a group of related tests, all to be executed in
     the same subshell.  It accepts a single argument, which holds a
     few words (no more than about 30 or 40 characters) quickly
     describing the purpose of the test group being started.
     TEST-GROUP-NAME must not expand to unbalanced quotes, although
     quadrigraphs can be used.

 -- Macro: AT_KEYWORDS (KEYWORDS)
     Associate the space-separated list of KEYWORDS to the enclosing
     test group.  This makes it possible to run "slices" of the test
     suite.  For instance, if some of your test groups exercise some
     `foo' feature, then using `AT_KEYWORDS(foo)' lets you run
     `./testsuite -k foo' to run exclusively these test groups.  The
     TEST-GROUP-NAME of the test group is automatically recorded to
     `AT_KEYWORDS'.

     Several invocations within a test group accumulate new keywords.
     In other words, don't fear registering the same keyword several
     times in a test group.

 -- Macro: AT_CAPTURE_FILE (FILE)
     If the current test group fails, log the contents of FILE.
     Several identical calls within one test group have no additional
     effect.

 -- Macro: AT_FAIL_IF (SHELL-CONDITION)
     Make the test group fail and skip the rest of its execution, if
     SHELL-CONDITION is true.  SHELL-CONDITION is a shell expression
     such as a `test' command.  Tests before `AT_FAIL_IF' will be
     executed and may still cause the test group to be skipped.  You
     can instantiate this macro many times from within the same test
     group.

     You should use this macro only for very simple failure conditions.
     If the SHELL-CONDITION could emit any kind of output you should
     instead use `AT_CHECK' like
          AT_CHECK([if SHELL-CONDITION; then exit 99; fi])
     so that such output is properly recorded in the `testsuite.log'
     file.

 -- Macro: AT_SKIP_IF (SHELL-CONDITION)
     Determine whether the test should be skipped because it requires
     features that are unsupported on the machine under test.
     SHELL-CONDITION is a shell expression such as a `test' command.
     Tests before `AT_SKIP_IF' will be executed and may still cause the
     test group to fail.  You can instantiate this macro many times
     from within the same test group.

     You should use this macro only for very simple skip conditions.
     If the SHELL-CONDITION could emit any kind of output you should
     instead use `AT_CHECK' like
          AT_CHECK([if SHELL-CONDITION; then exit 77; fi])
     so that such output is properly recorded in the `testsuite.log'
     file.

 -- Macro: AT_XFAIL_IF (SHELL-CONDITION)
     Determine whether the test is expected to fail because it is a
     known bug (for unsupported features, you should skip the test).
     SHELL-CONDITION is a shell expression such as a `test' command;
     you can instantiate this macro many times from within the same
     test group, and one of the conditions is enough to turn the test
     into an expected failure.

 -- Macro: AT_CLEANUP
     End the current test group.


 -- Macro: AT_DATA (FILE, CONTENTS)
     Initialize an input data FILE with given CONTENTS.  Of course, the
     CONTENTS have to be properly quoted between square brackets to
     protect against included commas or spurious M4 expansion.
     CONTENTS must be empty or end with a newline.  FILE must be a
     single shell word that expands into a single file name.

 -- Macro: AT_CHECK (COMMANDS, [STATUS = `0'], [STDOUT], [STDERR],
          [RUN-IF-FAIL], [RUN-IF-PASS])
 -- Macro: AT_CHECK_UNQUOTED (COMMANDS, [STATUS = `0'], [STDOUT],
          [STDERR], [RUN-IF-FAIL], [RUN-IF-PASS])
     Execute a test by performing given shell COMMANDS in a subshell.
     COMMANDS is output as-is, so shell expansions are honored.  These
     commands should normally exit with STATUS, while producing expected
     STDOUT and STDERR contents.  If COMMANDS exit with unexpected
     status 77, then the rest of the test group is skipped.  If
     COMMANDS exit with unexpected status 99, then the test group is
     immediately failed.  Otherwise, if this test fails, run shell
     commands RUN-IF-FAIL or, if this test passes, run shell commands
     RUN-IF-PASS, both inside the current shell execution environment.
     At the beginning of RUN-IF-FAIL and RUN-IF-PASS, the status of
     COMMANDS is available in the `at_status' shell variable.

     This macro must be invoked in between `AT_SETUP' and `AT_CLEANUP'.

     If STATUS is the literal `ignore', then the corresponding exit
     status is not checked, except for the special cases of 77 (skip)
     and 99 (hard failure).  The existence of hard failures allows one
     to mark a test as an expected failure with `AT_XFAIL_IF' because a
     feature has not yet been implemented, but to still distinguish
     between gracefully handling the missing feature and dumping core.
     A hard failure also inhibits post-test actions in RUN-IF-FAIL.

     If the value of the STDOUT or STDERR parameter is one of the
     literals in the following table, then the test treats the output
     according to the rules of that literal.  Otherwise, the value of
     the parameter is treated as text that must exactly match the
     output given by COMMANDS on standard output and standard error
     (including an empty parameter for no output); any differences are
     captured in the testsuite log and the test is failed (unless an
     unexpected exit status of 77 skipped the test instead).  The
     difference between `AT_CHECK' and `AT_CHECK_UNQUOTED' is that only
     the latter performs shell variable expansion (`$'), command
     substitution (``'), and backslash escaping (`\') on comparison
     text given in the STDOUT and STDERR arguments; if the text
     includes a trailing newline, this would be the same as if it were
     specified via an unquoted here-document.  (However, there is no
     difference in the interpretation of COMMANDS).

    `ignore'
          The content of the output is ignored, but still captured in
          the test group log (if the testsuite is run with option `-v',
          the test group log is displayed as the test is run; if the
          test group later fails, the test group log is also copied
          into the overall testsuite log).  This action is valid for
          both STDOUT and STDERR.

    `ignore-nolog'
          The content of the output is ignored, and nothing is captured
          in the log files.  If COMMANDS are likely to produce binary
          output (including long lines) or large amounts of output,
          then logging the output can make it harder to locate details
          related to subsequent tests within the group, and could
          potentially corrupt terminal display of a user running
          `testsuite -v'.

    `stdout'
          For the STDOUT parameter, capture the content of standard
          output to both the file `stdout' and the test group log.
          Subsequent commands in the test group can then post-process
          the file.  This action is often used when it is desired to
          use `grep' to look for a substring in the output, or when the
          output must be post-processed to normalize error messages
          into a common form.

    `stderr'
          Like `stdout', except that it only works for the STDERR
          parameter, and the standard error capture file will be named
          `stderr'.

    `stdout-nolog'
    `stderr-nolog'
          Like `stdout' or `stderr', except that the captured output is
          not duplicated into the test group log.  This action is
          particularly useful for an intermediate check that produces
          large amounts of data, which will be followed by another
          check that filters down to the relevant data, as it makes it
          easier to locate details in the log.

    `expout'
          For the STDOUT parameter, compare standard output contents
          with the previously created file `expout', and list any
          differences in the testsuite log.

    `experr'
          Like `expout', except that it only works for the STDERR
          parameter, and the standard error contents are compared with
          `experr'.

 -- Macro: AT_CHECK_EUNIT (MODULE, TEST-SPEC, [ERLFLAGS],
          [RUN-IF-FAIL], [RUN-IF-PASS])
     Initialize and execute an Erlang module named MODULE that performs
     tests following the TEST-SPEC EUnit test specification.  TEST-SPEC
     must be a valid EUnit test specification, as defined in the EUnit
     Reference Manual (http://erlang.org/doc/apps/eunit/index.html).
     ERLFLAGS are optional command-line options passed to the Erlang
     interpreter to execute the test Erlang module.  Typically,
     ERLFLAGS defines at least the paths to directories containing the
     compiled Erlang modules under test, as `-pa path1 path2 ...'.

     For example, the unit tests associated with Erlang module `testme',
     which compiled code is in subdirectory `src', can be performed
     with:

          AT_CHECK_EUNIT([testme_testsuite], [{module, testme}],
                         [-pa "${abs_top_builddir}/src"])

     This macro must be invoked in between `AT_SETUP' and `AT_CLEANUP'.

     Variables `ERL', `ERLC', and (optionally) `ERLCFLAGS' must be
     defined as the path of the Erlang interpreter, the path of the
     Erlang compiler, and the command-line flags to pass to the
     compiler, respectively.  Those variables should be configured in
     `configure.ac' using the `AC_ERLANG_PATH_ERL' and
     `AC_ERLANG_PATH_ERLC' macros, and the configured values of those
     variables are automatically defined in the testsuite.  If `ERL' or
     `ERLC' is not defined, the test group is skipped.

     If the EUnit library cannot be found, i.e. if module `eunit' cannot
     be loaded, the test group is skipped.  Otherwise, if TEST-SPEC is
     an invalid EUnit test specification, the test group fails.
     Otherwise, if the EUnit test passes, shell commands RUN-IF-PASS
     are executed or, if the EUnit test fails, shell commands
     RUN-IF-FAIL are executed and the test group fails.

     Only the generated test Erlang module is automatically compiled and
     executed.  If TEST-SPEC involves testing other Erlang modules,
     e.g. module `testme' in the example above, those modules must be
     already compiled.

     If the testsuite is run in verbose mode, with option `--verbose',
     EUnit is also run in verbose mode to output more details about
     individual unit tests.


File: autoconf.info,  Node: testsuite Invocation,  Next: Making testsuite Scripts,  Prev: Writing Testsuites,  Up: Using Autotest

19.3 Running `testsuite' Scripts
================================

Autotest test suites support the following options:

`--help'
`-h'
     Display the list of options and exit successfully.

`--version'
`-V'
     Display the version of the test suite and exit successfully.

`--directory=DIR'
`-C DIR'
     Change the current directory to DIR before creating any files.
     Useful for running the testsuite in a subdirectory from a top-level
     Makefile.

`--jobs[=N]'
`-j[N]'
     Run N tests in parallel, if possible.  If N is not given, run all
     given tests in parallel.  Note that there should be no space
     before the argument to `-j', as `-j NUMBER' denotes the separate
     arguments `-j' and `NUMBER', see below.

     In parallel mode, the standard input device of the testsuite
     script is not available to commands inside a test group.
     Furthermore, banner lines are not printed, and the summary line
     for each test group is output after the test group completes.
     Summary lines may appear unordered.  If verbose and trace output
     are enabled (see below), they may appear intermixed from
     concurrently running tests.

     Parallel mode requires the `mkfifo' command to work, and will be
     silently disabled otherwise.

`--clean'
`-c'
     Remove all the files the test suite might have created and exit.
     Meant for `clean' Make targets.

`--list'
`-l'
     List all the tests (or only the selection), including their
     possible keywords.


   By default all tests are performed (or described with `--list')
silently in the default environment, but the environment, set of tests,
and verbosity level can be tuned:

`VARIABLE=VALUE'
     Set the environment VARIABLE to VALUE.  Use this rather than
     `FOO=foo ./testsuite' as debugging scripts would then run in a
     different environment.

     The variable `AUTOTEST_PATH' specifies the testing path to prepend
     to `PATH'.  Relative directory names (not starting with `/') are
     considered to be relative to the top level of the package being
     built.  All directories are made absolute, first starting from the
     top level _build_ tree, then from the _source_ tree.  For instance
     `./testsuite AUTOTEST_PATH=tests:bin' for a `/src/foo-1.0' source
     package built in `/tmp/foo' results in
     `/tmp/foo/tests:/tmp/foo/bin' and then
     `/src/foo-1.0/tests:/src/foo-1.0/bin' being prepended to `PATH'.

`NUMBER'
`NUMBER-NUMBER'
`NUMBER-'
`-NUMBER'
     Add the corresponding test groups, with obvious semantics, to the
     selection.

`--keywords=KEYWORDS'
`-k KEYWORDS'
     Add to the selection the test groups with title or keywords
     (arguments to `AT_SETUP' or `AT_KEYWORDS') that match _all_
     keywords of the comma separated list KEYWORDS, case-insensitively.
     Use `!' immediately before the keyword to invert the selection for
     this keyword.  By default, the keywords match whole words; enclose
     them in `.*' to also match parts of words.

     For example, running

          ./testsuite -k 'autoupdate,.*FUNC.*'

     selects all tests tagged `autoupdate' _and_ with tags containing
     `FUNC' (as in `AC_CHECK_FUNC', `AC_FUNC_ALLOCA', etc.), while

          ./testsuite -k '!autoupdate' -k '.*FUNC.*'

     selects all tests not tagged `autoupdate' _or_ with tags
     containing `FUNC'.

`--errexit'
`-e'
     If any test fails, immediately abort testing.  This implies
     `--debug': post test group clean up, and top-level logging are
     inhibited.  This option is meant for the full test suite, it is
     not really useful for generated debugging scripts.  If the
     testsuite is run in parallel mode using `--jobs', then
     concurrently running tests will finish before exiting.

`--verbose'
`-v'
     Force more verbosity in the detailed output of what is being done.
     This is the default for debugging scripts.

`--color'
`--color[=never|auto|always]'
     Enable colored test results.  Without an argument, or with
     `always', test results will be colored.  With `never', color mode
     is turned off.  Otherwise, if either the macro `AT_COLOR_TESTS' is
     used by the testsuite author, or the argument `auto' is given,
     then test results are colored if standard output is connected to a
     terminal.

`--debug'
`-d'
     Do not remove the files after a test group was performed--but they
     are still removed _before_, therefore using this option is sane
     when running several test groups.  Create debugging scripts.  Do
     not overwrite the top-level log (in order to preserve a supposedly
     existing full log file).  This is the default for debugging
     scripts, but it can also be useful to debug the testsuite itself.

`--recheck'
     Add to the selection all test groups that failed or passed
     unexpectedly during the last non-debugging test run.

`--trace'
`-x'
     Trigger shell tracing of the test groups.

   Besides these options accepted by every Autotest testsuite, the
testsuite author might have added package-specific options via the
`AT_ARG_OPTION' and `AT_ARG_OPTION_ARG' macros (*note Writing
Testsuites::); refer to `testsuite --help' and the package
documentation for details.


File: autoconf.info,  Node: Making testsuite Scripts,  Prev: testsuite Invocation,  Up: Using Autotest

19.4 Making `testsuite' Scripts
===============================

For putting Autotest into movement, you need some configuration and
makefile machinery.  We recommend, at least if your package uses deep or
shallow hierarchies, that you use `tests/' as the name of the directory
holding all your tests and their makefile.  Here is a check list of
things to do.

   - Make sure to create the file `package.m4', which defines the
     identity of the package.  It must define `AT_PACKAGE_STRING', the
     full signature of the package, and `AT_PACKAGE_BUGREPORT', the
     address to which bug reports should be sent.  For sake of
     completeness, we suggest that you also define `AT_PACKAGE_NAME',
     `AT_PACKAGE_TARNAME', `AT_PACKAGE_VERSION', and `AT_PACKAGE_URL'.
     *Note Initializing configure::, for a description of these
     variables.  Be sure to distribute `package.m4' and to put it into
     the source hierarchy: the test suite ought to be shipped!  See
     below for an example `Makefile' excerpt.

   - Invoke `AC_CONFIG_TESTDIR'.

      -- Macro: AC_CONFIG_TESTDIR (DIRECTORY, [TEST-PATH = `directory'])
          An Autotest test suite is to be configured in DIRECTORY.  This
          macro causes `DIRECTORY/atconfig' to be created by
          `config.status' and sets the default `AUTOTEST_PATH' to
          TEST-PATH (*note testsuite Invocation::).

   - Still within `configure.ac', as appropriate, ensure that some
     `AC_CONFIG_FILES' command includes substitution for
     `tests/atlocal'.

   - The appropriate `Makefile' should be modified so the validation in
     your package is triggered by `make check'.  An example is provided
     below.

   With Automake, here is a minimal example for inclusion in
`tests/Makefile.am', in order to link `make check' with a validation
suite.

     # The `:;' works around a Bash 3.2 bug when the output is not writeable.
     $(srcdir)/package.m4: $(top_srcdir)/configure.ac
             :;{ \
               echo '# Signature of the current package.' && \
               echo 'm4_define([AT_PACKAGE_NAME],' && \
               echo '  [$(PACKAGE_NAME)])' && \
               echo 'm4_define([AT_PACKAGE_TARNAME],' && \
               echo '  [$(PACKAGE_TARNAME)])' && \
               echo 'm4_define([AT_PACKAGE_VERSION],' && \
               echo '  [$(PACKAGE_VERSION)])' && \
               echo 'm4_define([AT_PACKAGE_STRING],' && \
               echo '  [$(PACKAGE_STRING)])' && \
               echo 'm4_define([AT_PACKAGE_BUGREPORT],' && \
               echo '  [$(PACKAGE_BUGREPORT)])'; \
               echo 'm4_define([AT_PACKAGE_URL],' && \
               echo '  [$(PACKAGE_URL)])'; \
             } >'$(srcdir)/package.m4'

     EXTRA_DIST = testsuite.at $(srcdir)/package.m4 $(TESTSUITE) atlocal.in
     TESTSUITE = $(srcdir)/testsuite

     check-local: atconfig atlocal $(TESTSUITE)
             $(SHELL) '$(TESTSUITE)' $(TESTSUITEFLAGS)

     installcheck-local: atconfig atlocal $(TESTSUITE)
             $(SHELL) '$(TESTSUITE)' AUTOTEST_PATH='$(bindir)' \
               $(TESTSUITEFLAGS)

     clean-local:
             test ! -f '$(TESTSUITE)' || \
              $(SHELL) '$(TESTSUITE)' --clean

     AUTOM4TE = $(SHELL) $(srcdir)/build-aux/missing --run autom4te
     AUTOTEST = $(AUTOM4TE) --language=autotest
     $(TESTSUITE): $(srcdir)/testsuite.at $(srcdir)/package.m4
             $(AUTOTEST) -I '$(srcdir)' -o $@.tmp $@.at
             mv $@.tmp $@

   Note that the built testsuite is distributed; this is necessary
because users might not have Autoconf installed, and thus would not be
able to rebuild it.  Likewise, the use of `missing' provides the user
with a nicer error message if they modify a source file to the
testsuite, and accidentally trigger the rebuild rules.

   You might want to list explicitly the dependencies, i.e., the list of
the files `testsuite.at' includes.

   If you don't use Automake, you should include the above example in
`tests/Makefile.in', along with additional lines inspired from the
following:

     subdir = tests
     PACKAGE_NAME = @PACKAGE_NAME@
     PACKAGE_TARNAME = @PACKAGE_TARNAME@
     PACKAGE_VERSION = @PACKAGE_VERSION@
     PACKAGE_STRING = @PACKAGE_STRING@
     PACKAGE_BUGREPORT = @PACKAGE_BUGREPORT@
     PACKAGE_URL = @PACKAGE_URL@

     atconfig: $(top_builddir)/config.status
             cd $(top_builddir) && \
                $(SHELL) ./config.status $(subdir)/$@

     atlocal: $(srcdir)/atlocal.in $(top_builddir)/config.status
             cd $(top_builddir) && \
                $(SHELL) ./config.status $(subdir)/$@

and manage to have `$(EXTRA_DIST)' distributed.  You will also want to
distribute the file `build-aux/missing' from the Automake project; a
copy of this file resides in the Autoconf source tree.

   With all this in place, and if you have not initialized
`TESTSUITEFLAGS' within your makefile, you can fine-tune test suite
execution with this variable, for example:

     make check TESTSUITEFLAGS='-v -d -x 75 -k AC_PROG_CC CFLAGS=-g'


File: autoconf.info,  Node: FAQ,  Next: History,  Prev: Using Autotest,  Up: Top

20 Frequent Autoconf Questions, with answers
********************************************

Several questions about Autoconf come up occasionally.  Here some of
them are addressed.

* Menu:

* Distributing::                Distributing `configure' scripts
* Why GNU M4::                  Why not use the standard M4?
* Bootstrapping::               Autoconf and GNU M4 require each other?
* Why Not Imake::               Why GNU uses `configure' instead of Imake
* Defining Directories::        Passing `datadir' to program
* Autom4te Cache::              What is it?  Can I remove it?
* Present But Cannot Be Compiled::  Compiler and Preprocessor Disagree
* Expanded Before Required::    Expanded Before Required
* Debugging::                   Debugging `configure' scripts


File: autoconf.info,  Node: Distributing,  Next: Why GNU M4,  Up: FAQ

20.1 Distributing `configure' Scripts
=====================================

     What are the restrictions on distributing `configure'
     scripts that Autoconf generates?  How does that affect my
     programs that use them?

   There are no restrictions on how the configuration scripts that
Autoconf produces may be distributed or used.  In Autoconf version 1,
they were covered by the GNU General Public License.  We still encourage
software authors to distribute their work under terms like those of the
GPL, but doing so is not required to use Autoconf.

   Of the other files that might be used with `configure',
`config.h.in' is under whatever copyright you use for your
`configure.ac'.  `config.sub' and `config.guess' have an exception to
the GPL when they are used with an Autoconf-generated `configure'
script, which permits you to distribute them under the same terms as
the rest of your package.  `install-sh' is from the X Consortium and is
not copyrighted.


File: autoconf.info,  Node: Why GNU M4,  Next: Bootstrapping,  Prev: Distributing,  Up: FAQ

20.2 Why Require GNU M4?
========================

     Why does Autoconf require GNU M4?

   Many M4 implementations have hard-coded limitations on the size and
number of macros that Autoconf exceeds.  They also lack several builtin
macros that it would be difficult to get along without in a
sophisticated application like Autoconf, including:

     m4_builtin
     m4_indir
     m4_bpatsubst
     __file__
     __line__

   Autoconf requires version 1.4.6 or later of GNU M4.

   Since only software maintainers need to use Autoconf, and since GNU
M4 is simple to configure and install, it seems reasonable to require
GNU M4 to be installed also.  Many maintainers of GNU and other free
software already have most of the GNU utilities installed, since they
prefer them.


File: autoconf.info,  Node: Bootstrapping,  Next: Why Not Imake,  Prev: Why GNU M4,  Up: FAQ

20.3 How Can I Bootstrap?
=========================

     If Autoconf requires GNU M4 and GNU M4 has an Autoconf
     `configure' script, how do I bootstrap?  It seems like a chicken
     and egg problem!

   This is a misunderstanding.  Although GNU M4 does come with a
`configure' script produced by Autoconf, Autoconf is not required in
order to run the script and install GNU M4.  Autoconf is only required
if you want to change the M4 `configure' script, which few people have
to do (mainly its maintainer).


File: autoconf.info,  Node: Why Not Imake,  Next: Defining Directories,  Prev: Bootstrapping,  Up: FAQ

20.4 Why Not Imake?
===================

     Why not use Imake instead of `configure' scripts?

   Several people have written addressing this question, so I include
adaptations of their explanations here.

   The following answer is based on one written by Richard Pixley:

     Autoconf generated scripts frequently work on machines that it has
     never been set up to handle before.  That is, it does a good job of
     inferring a configuration for a new system.  Imake cannot do this.

     Imake uses a common database of host specific data.  For X11, this
     makes sense because the distribution is made as a collection of
     tools, by one central authority who has control over the database.

     GNU tools are not released this way.  Each GNU tool has a
     maintainer; these maintainers are scattered across the world.
     Using a common database would be a maintenance nightmare.
     Autoconf may appear to be this kind of database, but in fact it is
     not.  Instead of listing host dependencies, it lists program
     requirements.

     If you view the GNU suite as a collection of native tools, then the
     problems are similar.  But the GNU development tools can be
     configured as cross tools in almost any host+target permutation.
     All of these configurations can be installed concurrently.  They
     can even be configured to share host independent files across
     hosts.  Imake doesn't address these issues.

     Imake templates are a form of standardization.  The GNU coding
     standards address the same issues without necessarily imposing the
     same restrictions.

   Here is some further explanation, written by Per Bothner:

     One of the advantages of Imake is that it easy to generate large
     makefiles using the `#include' and macro mechanisms of `cpp'.
     However, `cpp' is not programmable: it has limited conditional
     facilities, and no looping.  And `cpp' cannot inspect its
     environment.

     All of these problems are solved by using `sh' instead of `cpp'.
     The shell is fully programmable, has macro substitution, can
     execute (or source) other shell scripts, and can inspect its
     environment.

   Paul Eggert elaborates more:

     With Autoconf, installers need not assume that Imake itself is
     already installed and working well.  This may not seem like much
     of an advantage to people who are accustomed to Imake.  But on
     many hosts Imake is not installed or the default installation is
     not working well, and requiring Imake to install a package hinders
     the acceptance of that package on those hosts.  For example, the
     Imake template and configuration files might not be installed
     properly on a host, or the Imake build procedure might wrongly
     assume that all source files are in one big directory tree, or the
     Imake configuration might assume one compiler whereas the package
     or the installer needs to use another, or there might be a version
     mismatch between the Imake expected by the package and the Imake
     supported by the host.  These problems are much rarer with
     Autoconf, where each package comes with its own independent
     configuration processor.

     Also, Imake often suffers from unexpected interactions between
     `make' and the installer's C preprocessor.  The fundamental problem
     here is that the C preprocessor was designed to preprocess C
     programs, not makefiles.  This is much less of a problem with
     Autoconf, which uses the general-purpose preprocessor M4, and
     where the package's author (rather than the installer) does the
     preprocessing in a standard way.

   Finally, Mark Eichin notes:

     Imake isn't all that extensible, either.  In order to add new
     features to Imake, you need to provide your own project template,
     and duplicate most of the features of the existing one.  This
     means that for a sophisticated project, using the vendor-provided
     Imake templates fails to provide any leverage--since they don't
     cover anything that your own project needs (unless it is an X11
     program).

     On the other side, though:

     The one advantage that Imake has over `configure': `Imakefile'
     files tend to be much shorter (likewise, less redundant) than
     `Makefile.in' files.  There is a fix to this, however--at least
     for the Kerberos V5 tree, we've modified things to call in common
     `post.in' and `pre.in' makefile fragments for the entire tree.
     This means that a lot of common things don't have to be
     duplicated, even though they normally are in `configure' setups.


File: autoconf.info,  Node: Defining Directories,  Next: Autom4te Cache,  Prev: Why Not Imake,  Up: FAQ

20.5 How Do I `#define' Installation Directories?
=================================================

     My program needs library files, installed in `datadir' and
     similar.  If I use
          AC_DEFINE_UNQUOTED([DATADIR], [$datadir],
            [Define to the read-only architecture-independent
             data directory.])

     I get
          #define DATADIR "${prefix}/share"

As already explained, this behavior is on purpose, mandated by the GNU
Coding Standards, see *note Installation Directory Variables::.  There
are several means to achieve a similar goal:

   - Do not use `AC_DEFINE' but use your makefile to pass the actual
     value of `datadir' via compilation flags.  *Note Installation
     Directory Variables::, for the details.

   - This solution can be simplified when compiling a program: you may
     either extend the `CPPFLAGS':

          CPPFLAGS = -DDATADIR='"$(datadir)"' @CPPFLAGS@

     If you are using Automake, you should use `AM_CPPFLAGS' instead:

          AM_CPPFLAGS = -DDATADIR='"$(datadir)"'

     Alternatively, create a dedicated header file:

          DISTCLEANFILES = myprog-paths.h
          myprog-paths.h: Makefile
                  echo '#define DATADIR "$(datadir)"' >$@

   - Use `AC_DEFINE' but have `configure' compute the literal value of
     `datadir' and others.  Many people have wrapped macros to automate
     this task; for an example, see the macro `AC_DEFINE_DIR' from the
     Autoconf Macro Archive
     (http://www.gnu.org/software/autoconf-archive/).

     This solution does not conform to the GNU Coding Standards.

   - Note that all the previous solutions hard wire the absolute name of
     these directories in the executables, which is not a good
     property.  You may try to compute the names relative to `prefix',
     and try to find `prefix' at runtime, this way your package is
     relocatable.


File: autoconf.info,  Node: Autom4te Cache,  Next: Present But Cannot Be Compiled,  Prev: Defining Directories,  Up: FAQ

20.6 What is `autom4te.cache'?
==============================

     What is this directory `autom4te.cache'?  Can I safely remove it?

   In the GNU Build System, `configure.ac' plays a central role and is
read by many tools: `autoconf' to create `configure', `autoheader' to
create `config.h.in', `automake' to create `Makefile.in', `autoscan' to
check the completeness of `configure.ac', `autoreconf' to check the GNU
Build System components that are used.  To "read `configure.ac'"
actually means to compile it with M4, which can be a long process for
complex `configure.ac'.

   This is why all these tools, instead of running directly M4, invoke
`autom4te' (*note autom4te Invocation::) which, while answering to a
specific demand, stores additional information in `autom4te.cache' for
future runs.  For instance, if you run `autoconf', behind the scenes,
`autom4te' also stores information for the other tools, so that when
you invoke `autoheader' or `automake' etc., reprocessing `configure.ac'
is not needed.  The speed up is frequently 30%, and is increasing with
the size of `configure.ac'.

   But it is and remains being simply a cache: you can safely remove it.


     Can I permanently get rid of it?

   The creation of this cache can be disabled from `~/.autom4te.cfg',
see *note Customizing autom4te::, for more details.  You should be
aware that disabling the cache slows down the Autoconf test suite by
40%.  The more GNU Build System components are used, the more the cache
is useful; for instance running `autoreconf -f' on the Core Utilities
is twice slower without the cache _although `--force' implies that the
cache is not fully exploited_, and eight times slower than without
`--force'.


File: autoconf.info,  Node: Present But Cannot Be Compiled,  Next: Expanded Before Required,  Prev: Autom4te Cache,  Up: FAQ

20.7 Header Present But Cannot Be Compiled
==========================================

The most important guideline to bear in mind when checking for features
is to mimic as much as possible the intended use.  Unfortunately, old
versions of `AC_CHECK_HEADER' and `AC_CHECK_HEADERS' failed to follow
this idea, and called the preprocessor, instead of the compiler, to
check for headers.  As a result, incompatibilities between headers went
unnoticed during configuration, and maintainers finally had to deal
with this issue elsewhere.

   The transition began with Autoconf 2.56.  As of Autoconf 2.64 both
checks are performed, and `configure' complains loudly if the compiler
and the preprocessor do not agree.  However, only the compiler result
is considered.

   Consider the following example:

     $ cat number.h
     typedef int number;
     $ cat pi.h
     const number pi = 3;
     $ cat configure.ac
     AC_INIT([Example], [1.0], [bug-example@example.org])
     AC_CHECK_HEADERS([pi.h])
     $ autoconf -Wall
     $ ./configure
     checking for gcc... gcc
     checking for C compiler default output file name... a.out
     checking whether the C compiler works... yes
     checking whether we are cross compiling... no
     checking for suffix of executables...
     checking for suffix of object files... o
     checking whether we are using the GNU C compiler... yes
     checking whether gcc accepts -g... yes
     checking for gcc option to accept ISO C89... none needed
     checking how to run the C preprocessor... gcc -E
     checking for grep that handles long lines and -e... grep
     checking for egrep... grep -E
     checking for ANSI C header files... yes
     checking for sys/types.h... yes
     checking for sys/stat.h... yes
     checking for stdlib.h... yes
     checking for string.h... yes
     checking for memory.h... yes
     checking for strings.h... yes
     checking for inttypes.h... yes
     checking for stdint.h... yes
     checking for unistd.h... yes
     checking pi.h usability... no
     checking pi.h presence... yes
     configure: WARNING: pi.h: present but cannot be compiled
     configure: WARNING: pi.h:     check for missing prerequisite headers?
     configure: WARNING: pi.h: see the Autoconf documentation
     configure: WARNING: pi.h:     section "Present But Cannot Be Compiled"
     configure: WARNING: pi.h: proceeding with the compiler's result
     configure: WARNING:     ## -------------------------------------- ##
     configure: WARNING:     ## Report this to bug-example@example.org ##
     configure: WARNING:     ## -------------------------------------- ##
     checking for pi.h... yes

The proper way the handle this case is using the fourth argument (*note
Generic Headers::):

     $ cat configure.ac
     AC_INIT([Example], [1.0], [bug-example@example.org])
     AC_CHECK_HEADERS([number.h pi.h], [], [],
     [[#ifdef HAVE_NUMBER_H
     # include <number.h>
     #endif
     ]])
     $ autoconf -Wall
     $ ./configure
     checking for gcc... gcc
     checking for C compiler default output... a.out
     checking whether the C compiler works... yes
     checking whether we are cross compiling... no
     checking for suffix of executables...
     checking for suffix of object files... o
     checking whether we are using the GNU C compiler... yes
     checking whether gcc accepts -g... yes
     checking for gcc option to accept ANSI C... none needed
     checking for number.h... yes
     checking for pi.h... yes

   See *note Particular Headers::, for a list of headers with their
prerequisites.


File: autoconf.info,  Node: Expanded Before Required,  Next: Debugging,  Prev: Present But Cannot Be Compiled,  Up: FAQ

20.8 Expanded Before Required
=============================

Older versions of Autoconf silently built files with incorrect ordering
between dependent macros if an outer macro first expanded, then later
indirectly required, an inner macro.  Starting with Autoconf 2.64, this
situation no longer generates out-of-order code, but results in
duplicate output and a syntax warning:

     $ cat configure.ac
     =>AC_DEFUN([TESTA], [[echo in A
     =>if test -n "$SEEN_A" ; then echo duplicate ; fi
     =>SEEN_A=:]])
     =>AC_DEFUN([TESTB], [AC_REQUIRE([TESTA])[echo in B
     =>if test -z "$SEEN_A" ; then echo bug ; fi]])
     =>AC_DEFUN([TESTC], [AC_REQUIRE([TESTB])[echo in C]])
     =>AC_DEFUN([OUTER], [[echo in OUTER]
     =>TESTA
     =>TESTC])
     =>AC_INIT
     =>OUTER
     =>AC_OUTPUT
     $ autoconf
     =>configure.ac:11: warning: AC_REQUIRE:
     => `TESTA' was expanded before it was required
     =>configure.ac:4: TESTB is expanded from...
     =>configure.ac:6: TESTC is expanded from...
     =>configure.ac:7: OUTER is expanded from...
     =>configure.ac:11: the top level

To avoid this warning, decide what purpose the macro in question serves.
If it only needs to be expanded once (for example, if it provides
initialization text used by later macros), then the simplest fix is to
change the macro to be declared with `AC_DEFUN_ONCE' (*note One-Shot
Macros::), although this only works in Autoconf 2.64 and newer.  A more
portable fix is to change all instances of direct calls to instead go
through `AC_REQUIRE' (*note Prerequisite Macros::).  If, instead, the
macro is parameterized by arguments or by the current definition of
other macros in the m4 environment, then the macro should always be
directly expanded instead of required.

   For another case study, consider this example trimmed down from an
actual package.  Originally, the package contained shell code and
multiple macro invocations at the top level of `configure.ac':

     AC_DEFUN([FOO], [AC_COMPILE_IFELSE([...])])
     foobar=
     AC_PROG_CC
     FOO

but that was getting complex, so the author wanted to offload some of
the text into a new macro in another file included via `aclocal.m4'.
The nai"ve approach merely wraps the text in a new macro:

     AC_DEFUN([FOO], [AC_COMPILE_IFELSE([...])])
     AC_DEFUN([BAR], [
     foobar=
     AC_PROG_CC
     FOO
     ])
     BAR

With older versions of Autoconf, the setting of `foobar=' occurs before
the single compiler check, as the author intended.  But with Autoconf
2.64, this issues the "expanded before it was required" warning for
`AC_PROG_CC', and outputs two copies of the compiler check, one before
`foobar=', and one after.  To understand why this is happening,
remember that the use of `AC_COMPILE_IFELSE' includes a call to
`AC_REQUIRE([AC_PROG_CC])' under the hood.  According to the documented
semantics of `AC_REQUIRE', this means that `AC_PROG_CC' _must_ occur
before the body of the outermost `AC_DEFUN', which in this case is
`BAR', thus preceeding the use of `foobar='.  The older versions of
Autoconf were broken with regards to the rules of `AC_REQUIRE', which
explains why the code changed from one over to two copies of
`AC_PROG_CC' when upgrading autoconf.  In other words, the author was
unknowingly relying on a bug exploit to get the desired results, and
that exploit broke once the bug was fixed.

   So, what recourse does the author have, to restore their intended
semantics of setting `foobar=' prior to a single compiler check,
regardless of whether Autoconf 2.63 or 2.64 is used?  One idea is to
remember that only `AC_DEFUN' is impacted by `AC_REQUIRE'; there is
always the possibility of using the lower-level `m4_define':

     AC_DEFUN([FOO], [AC_COMPILE_IFELSE([...])])
     m4_define([BAR], [
     foobar=
     AC_PROG_CC
     FOO
     ])
     BAR

This works great if everything is in the same file.  However, it does
not help in the case where the author wants to have `aclocal' find the
definition of `BAR' from its own file, since `aclocal' requires the use
of `AC_DEFUN'.  In this case, a better fix is to recognize that if
`BAR' also uses `AC_REQUIRE', then there will no longer be direct
expansion prior to a subsequent require.  Then, by creating yet another
helper macro, the author can once again guarantee a single invocation of
`AC_PROG_CC', which will still occur after `foobar='.  The author can
also use `AC_BEFORE' to make sure no other macro appearing before `BAR'
has triggered an unwanted expansion of `AC_PROG_CC'.

     AC_DEFUN([FOO], [AC_COMPILE_IFELSE([...])])
     AC_DEFUN([BEFORE_CC], [
     foobar=
     ])
     AC_DEFUN([BAR], [
     AC_BEFORE([$0], [AC_PROG_CC])dnl
     AC_REQUIRE([BEFORE_CC])dnl
     AC_REQUIRE([AC_PROG_CC])dnl
     FOO
     ])
     BAR


File: autoconf.info,  Node: Debugging,  Prev: Expanded Before Required,  Up: FAQ

20.9 Debugging `configure' scripts
==================================

While in general, `configure' scripts generated by Autoconf strive to
be fairly portable to various systems, compilers, shells, and other
tools, it may still be necessary to debug a failing test, broken script
or makefile, or fix or override an incomplete, faulty, or erroneous
test, especially during macro development.  Failures can occur at all
levels, in M4 syntax or semantics, shell script issues, or due to bugs
in the test or the tools invoked by `configure'.  Together with the
rather arcane error message that `m4' and `make' may produce when their
input contains syntax errors, this can make debugging rather painful.

   Nevertheless, here is a list of hints and strategies that may help:

   * When `autoconf' fails, common causes for error include:

        * mismatched or unbalanced parentheses or braces (*note
          Balancing Parentheses::),

        * under- or overquoted macro arguments (*note Autoconf
          Language::, *note Quoting and Parameters::, *note Quotation
          and Nested Macros::),

        * spaces between macro name and opening parenthesis (*note
          Autoconf Language::).

     Typically, it helps to go back to the last working version of the
     input and compare the differences for each of these errors.
     Another possibility is to sprinkle pairs of `m4_traceon' and
     `m4_traceoff' judiciously in the code, either without a parameter
     or listing some macro names and watch `m4' expand its input
     verbosely (*note Debugging via autom4te::).

   * Sometimes `autoconf' succeeds but the generated `configure' script
     has invalid shell syntax.  You can detect this case by running
     `bash -n configure' or `sh -n configure'.  If this command fails,
     the same tips apply, as if `autoconf' had failed.

   * Debugging `configure' script execution may be done by sprinkling
     pairs of `set -x' and `set +x' into the shell script before and
     after the region that contains a bug.  Running the whole script
     with `SHELL ./configure -vx 2>&1 | tee LOG-FILE' with a decent
     SHELL may work, but produces lots of output.  Here, it can help to
     search for markers like `checking for' a particular test in the
     LOG-FILE.

   * Alternatively, you might use a shell with debugging capabilities
     like bashdb (http://bashdb.sourceforge.net/).

   * When `configure' tests produce invalid results for your system, it
     may be necessary to override them:

        * For programs, tools or libraries variables, preprocessor,
          compiler, or linker flags, it is often sufficient to override
          them at `make' run time with some care (*note Macros and
          Submakes::).  Since this normally won't cause `configure' to
          be run again with these changed settings, it may fail if the
          changed variable would have caused different test results
          from `configure', so this may work only for simple
          differences.

        * Most tests which produce their result in a substituted
          variable allow to override the test by setting the variable
          on the `configure' command line (*note Compilers and
          Options::, *note Defining Variables::, *note Particular
          Systems::).

        * Many tests store their result in a cache variable (*note
          Caching Results::).  This lets you override them either on the
          `configure' command line as above, or through a primed cache
          or site file (*note Cache Files::, *note Site Defaults::).
          The name of a cache variable is documented with a test macro
          or may be inferred from *note Cache Variable Names::; the
          precise semantics of undocumented variables are often
          internal details, subject to change.

   * Alternatively, `configure' may produce invalid results because of
     uncaught programming errors, in your package or in an upstream
     library package.  For example, when `AC_CHECK_LIB' fails to find a
     library with a specified function, always check `config.log'.  This
     will reveal the exact error that produced the failing result: the
     library linked by `AC_CHECK_LIB' probably has a fatal bug.

   Conversely, as macro author, you can make it easier for users of your
macro:

   * by minimizing dependencies between tests and between test results
     as far as possible,

   * by using `make' variables to factorize and allow override of
     settings at `make' run time,

   * by honoring the GNU Coding Standards and not overriding flags
     reserved for the user except temporarily during `configure' tests,

   * by not requiring users of your macro to use the cache variables.
     Instead, expose the result of the test via RUN-IF-TRUE and
     RUN-IF-FALSE parameters.  If the result is not a boolean, then
     provide it through documented shell variables.


File: autoconf.info,  Node: History,  Next: GNU Free Documentation License,  Prev: FAQ,  Up: Top

21 History of Autoconf
**********************

You may be wondering, Why was Autoconf originally written?  How did it
get into its present form?  (Why does it look like gorilla spit?)  If
you're not wondering, then this chapter contains no information useful
to you, and you might as well skip it.  If you _are_ wondering, then
let there be light...

* Menu:

* Genesis::                     Prehistory and naming of `configure'
* Exodus::                      The plagues of M4 and Perl
* Leviticus::                   The priestly code of portability arrives
* Numbers::                     Growth and contributors
* Deuteronomy::                 Approaching the promises of easy configuration


File: autoconf.info,  Node: Genesis,  Next: Exodus,  Up: History

21.1 Genesis
============

In June 1991 I was maintaining many of the GNU utilities for the Free
Software Foundation.  As they were ported to more platforms and more
programs were added, the number of `-D' options that users had to
select in the makefile (around 20) became burdensome.  Especially for
me--I had to test each new release on a bunch of different systems.  So
I wrote a little shell script to guess some of the correct settings for
the fileutils package, and released it as part of fileutils 2.0.  That
`configure' script worked well enough that the next month I adapted it
(by hand) to create similar `configure' scripts for several other GNU
utilities packages.  Brian Berliner also adapted one of my scripts for
his CVS revision control system.

   Later that summer, I learned that Richard Stallman and Richard Pixley
were developing similar scripts to use in the GNU compiler tools; so I
adapted my `configure' scripts to support their evolving interface:
using the file name `Makefile.in' as the templates; adding `+srcdir',
the first option (of many); and creating `config.status' files.


File: autoconf.info,  Node: Exodus,  Next: Leviticus,  Prev: Genesis,  Up: History

21.2 Exodus
===========

As I got feedback from users, I incorporated many improvements, using
Emacs to search and replace, cut and paste, similar changes in each of
the scripts.  As I adapted more GNU utilities packages to use
`configure' scripts, updating them all by hand became impractical.
Rich Murphey, the maintainer of the GNU graphics utilities, sent me
mail saying that the `configure' scripts were great, and asking if I
had a tool for generating them that I could send him.  No, I thought,
but I should!  So I started to work out how to generate them.  And the
journey from the slavery of hand-written `configure' scripts to the
abundance and ease of Autoconf began.

   Cygnus `configure', which was being developed at around that time,
is table driven; it is meant to deal mainly with a discrete number of
system types with a small number of mainly unguessable features (such as
details of the object file format).  The automatic configuration system
that Brian Fox had developed for Bash takes a similar approach.  For
general use, it seems to me a hopeless cause to try to maintain an
up-to-date database of which features each variant of each operating
system has.  It's easier and more reliable to check for most features on
the fly--especially on hybrid systems that people have hacked on
locally or that have patches from vendors installed.

   I considered using an architecture similar to that of Cygnus
`configure', where there is a single `configure' script that reads
pieces of `configure.in' when run.  But I didn't want to have to
distribute all of the feature tests with every package, so I settled on
having a different `configure' made from each `configure.in' by a
preprocessor.  That approach also offered more control and flexibility.

   I looked briefly into using the Metaconfig package, by Larry Wall,
Harlan Stenn, and Raphael Manfredi, but I decided not to for several
reasons.  The `Configure' scripts it produces are interactive, which I
find quite inconvenient; I didn't like the ways it checked for some
features (such as library functions); I didn't know that it was still
being maintained, and the `Configure' scripts I had seen didn't work on
many modern systems (such as System V R4 and NeXT); it wasn't flexible
in what it could do in response to a feature's presence or absence; I
found it confusing to learn; and it was too big and complex for my
needs (I didn't realize then how much Autoconf would eventually have to
grow).

   I considered using Perl to generate my style of `configure' scripts,
but decided that M4 was better suited to the job of simple textual
substitutions: it gets in the way less, because output is implicit.
Plus, everyone already has it.  (Initially I didn't rely on the GNU
extensions to M4.)  Also, some of my friends at the University of
Maryland had recently been putting M4 front ends on several programs,
including `tvtwm', and I was interested in trying out a new language.


File: autoconf.info,  Node: Leviticus,  Next: Numbers,  Prev: Exodus,  Up: History

21.3 Leviticus
==============

Since my `configure' scripts determine the system's capabilities
automatically, with no interactive user intervention, I decided to call
the program that generates them Autoconfig.  But with a version number
tacked on, that name would be too long for old Unix file systems, so I
shortened it to Autoconf.

   In the fall of 1991 I called together a group of fellow questers
after the Holy Grail of portability (er, that is, alpha testers) to
give me feedback as I encapsulated pieces of my handwritten scripts in
M4 macros and continued to add features and improve the techniques used
in the checks.  Prominent among the testers were Franc,ois Pinard, who
came up with the idea of making an Autoconf shell script to run M4 and
check for unresolved macro calls; Richard Pixley, who suggested running
the compiler instead of searching the file system to find include files
and symbols, for more accurate results; Karl Berry, who got Autoconf to
configure TeX and added the macro index to the documentation; and Ian
Lance Taylor, who added support for creating a C header file as an
alternative to putting `-D' options in a makefile, so he could use
Autoconf for his UUCP package.  The alpha testers cheerfully adjusted
their files again and again as the names and calling conventions of the
Autoconf macros changed from release to release.  They all contributed
many specific checks, great ideas, and bug fixes.


File: autoconf.info,  Node: Numbers,  Next: Deuteronomy,  Prev: Leviticus,  Up: History

21.4 Numbers
============

In July 1992, after months of alpha testing, I released Autoconf 1.0,
and converted many GNU packages to use it.  I was surprised by how
positive the reaction to it was.  More people started using it than I
could keep track of, including people working on software that wasn't
part of the GNU Project (such as TCL, FSP, and Kerberos V5).  Autoconf
continued to improve rapidly, as many people using the `configure'
scripts reported problems they encountered.

   Autoconf turned out to be a good torture test for M4 implementations.
Unix M4 started to dump core because of the length of the macros that
Autoconf defined, and several bugs showed up in GNU M4 as well.
Eventually, we realized that we needed to use some features that only
GNU M4 has.  4.3BSD M4, in particular, has an impoverished set of
builtin macros; the System V version is better, but still doesn't
provide everything we need.

   More development occurred as people put Autoconf under more stresses
(and to uses I hadn't anticipated).  Karl Berry added checks for X11.
david zuhn contributed C++ support.  Franc,ois Pinard made it diagnose
invalid arguments.  Jim Blandy bravely coerced it into configuring GNU
Emacs, laying the groundwork for several later improvements.  Roland
McGrath got it to configure the GNU C Library, wrote the `autoheader'
script to automate the creation of C header file templates, and added a
`--verbose' option to `configure'.  Noah Friedman added the
`--autoconf-dir' option and `AC_MACRODIR' environment variable.  (He
also coined the term "autoconfiscate" to mean "adapt a software package
to use Autoconf".)  Roland and Noah improved the quoting protection in
`AC_DEFINE' and fixed many bugs, especially when I got sick of dealing
with portability problems from February through June, 1993.


File: autoconf.info,  Node: Deuteronomy,  Prev: Numbers,  Up: History

21.5 Deuteronomy
================

A long wish list for major features had accumulated, and the effect of
several years of patching by various people had left some residual
cruft.  In April 1994, while working for Cygnus Support, I began a major
revision of Autoconf.  I added most of the features of the Cygnus
`configure' that Autoconf had lacked, largely by adapting the relevant
parts of Cygnus `configure' with the help of david zuhn and Ken
Raeburn.  These features include support for using `config.sub',
`config.guess', `--host', and `--target'; making links to files; and
running `configure' scripts in subdirectories.  Adding these features
enabled Ken to convert GNU `as', and Rob Savoye to convert DejaGNU, to
using Autoconf.

   I added more features in response to other peoples' requests.  Many
people had asked for `configure' scripts to share the results of the
checks between runs, because (particularly when configuring a large
source tree, like Cygnus does) they were frustratingly slow.  Mike
Haertel suggested adding site-specific initialization scripts.  People
distributing software that had to unpack on MS-DOS asked for a way to
override the `.in' extension on the file names, which produced file
names like `config.h.in' containing two dots.  Jim Avera did an
extensive examination of the problems with quoting in `AC_DEFINE' and
`AC_SUBST'; his insights led to significant improvements.  Richard
Stallman asked that compiler output be sent to `config.log' instead of
`/dev/null', to help people debug the Emacs `configure' script.

   I made some other changes because of my dissatisfaction with the
quality of the program.  I made the messages showing results of the
checks less ambiguous, always printing a result.  I regularized the
names of the macros and cleaned up coding style inconsistencies.  I
added some auxiliary utilities that I had developed to help convert
source code packages to use Autoconf.  With the help of Franc,ois
Pinard, I made the macros not interrupt each others' messages.  (That
feature revealed some performance bottlenecks in GNU M4, which he
hastily corrected!)  I reorganized the documentation around problems
people want to solve.  And I began a test suite, because experience had
shown that Autoconf has a pronounced tendency to regress when we change
it.

   Again, several alpha testers gave invaluable feedback, especially
Franc,ois Pinard, Jim Meyering, Karl Berry, Rob Savoye, Ken Raeburn,
and Mark Eichin.

   Finally, version 2.0 was ready.  And there was much rejoicing.  (And
I have free time again.  I think.  Yeah, right.)


This is gawk.info, produced by makeinfo version 4.13 from
/d/home/arnold/Gnu/gawk/gendocs/gawk-4.0.0/doc/gawk.texi.

INFO-DIR-SECTION Text creation and manipulation
START-INFO-DIR-ENTRY
* Gawk: (gawk).                 A text scanning and processing language.
END-INFO-DIR-ENTRY
INFO-DIR-SECTION Individual utilities
START-INFO-DIR-ENTRY
* awk: (gawk)Invoking gawk.                     Text scanning and processing.
END-INFO-DIR-ENTRY

   Copyright (C) 1989, 1991, 1992, 1993, 1996, 1997, 1998, 1999, 2000,
2001, 2002, 2003, 2004, 2005, 2007, 2009, 2010, 2011 Free Software
Foundation, Inc.


   This is Edition 4 of `GAWK: Effective AWK Programming: A User's
Guide for GNU Awk', for the 4.0.0 (or later) version of the GNU
implementation of AWK.

   Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with the
Invariant Sections being "GNU General Public License", the Front-Cover
texts being (a) (see below), and with the Back-Cover Texts being (b)
(see below).  A copy of the license is included in the section entitled
"GNU Free Documentation License".

  a. "A GNU Manual"

  b. "You have the freedom to copy and modify this GNU manual.  Buying
     copies from the FSF supports it in developing GNU and promoting
     software freedom."


File: gawk.info,  Node: Assert Function,  Next: Round Function,  Prev: Strtonum Function,  Up: General Functions

12.2.2 Assertions
-----------------

When writing large programs, it is often useful to know that a
condition or set of conditions is true.  Before proceeding with a
particular computation, you make a statement about what you believe to
be the case.  Such a statement is known as an "assertion".  The C
language provides an `<assert.h>' header file and corresponding
`assert()' macro that the programmer can use to make assertions.  If an
assertion fails, the `assert()' macro arranges to print a diagnostic
message describing the condition that should have been true but was
not, and then it kills the program.  In C, using `assert()' looks this:

     #include <assert.h>

     int myfunc(int a, double b)
     {
          assert(a <= 5 && b >= 17.1);
          ...
     }

   If the assertion fails, the program prints a message similar to this:

     prog.c:5: assertion failed: a <= 5 && b >= 17.1

   The C language makes it possible to turn the condition into a string
for use in printing the diagnostic message.  This is not possible in
`awk', so this `assert()' function also requires a string version of
the condition that is being tested.  Following is the function:

     # assert --- assert that a condition is true. Otherwise exit.

     function assert(condition, string)
     {
         if (! condition) {
             printf("%s:%d: assertion failed: %s\n",
                 FILENAME, FNR, string) > "/dev/stderr"
             _assert_exit = 1
             exit 1
         }
     }

     END {
         if (_assert_exit)
             exit 1
     }

   The `assert()' function tests the `condition' parameter. If it is
false, it prints a message to standard error, using the `string'
parameter to describe the failed condition.  It then sets the variable
`_assert_exit' to one and executes the `exit' statement.  The `exit'
statement jumps to the `END' rule. If the `END' rules finds
`_assert_exit' to be true, it exits immediately.

   The purpose of the test in the `END' rule is to keep any other `END'
rules from running.  When an assertion fails, the program should exit
immediately.  If no assertions fail, then `_assert_exit' is still false
when the `END' rule is run normally, and the rest of the program's
`END' rules execute.  For all of this to work correctly, `assert.awk'
must be the first source file read by `awk'.  The function can be used
in a program in the following way:

     function myfunc(a, b)
     {
          assert(a <= 5 && b >= 17.1, "a <= 5 && b >= 17.1")
          ...
     }

If the assertion fails, you see a message similar to the following:

     mydata:1357: assertion failed: a <= 5 && b >= 17.1

   There is a small problem with this version of `assert()'.  An `END'
rule is automatically added to the program calling `assert()'.
Normally, if a program consists of just a `BEGIN' rule, the input files
and/or standard input are not read. However, now that the program has
an `END' rule, `awk' attempts to read the input data files or standard
input (*note Using BEGIN/END::), most likely causing the program to
hang as it waits for input.

   There is a simple workaround to this: make sure that such a `BEGIN'
rule always ends with an `exit' statement.


File: gawk.info,  Node: Round Function,  Next: Cliff Random Function,  Prev: Assert Function,  Up: General Functions

12.2.3 Rounding Numbers
-----------------------

The way `printf' and `sprintf()' (*note Printf::) perform rounding
often depends upon the system's C `sprintf()' subroutine.  On many
machines, `sprintf()' rounding is "unbiased," which means it doesn't
always round a trailing `.5' up, contrary to naive expectations.  In
unbiased rounding, `.5' rounds to even, rather than always up, so 1.5
rounds to 2 but 4.5 rounds to 4.  This means that if you are using a
format that does rounding (e.g., `"%.0f"'), you should check what your
system does.  The following function does traditional rounding; it
might be useful if your `awk''s `printf' does unbiased rounding:

     # round.awk --- do normal rounding

     function round(x,   ival, aval, fraction)
     {
        ival = int(x)    # integer part, int() truncates

        # see if fractional part
        if (ival == x)   # no fraction
           return ival   # ensure no decimals

        if (x < 0) {
           aval = -x     # absolute value
           ival = int(aval)
           fraction = aval - ival
           if (fraction >= .5)
              return int(x) - 1   # -2.5 --> -3
           else
              return int(x)       # -2.3 --> -2
        } else {
           fraction = x - ival
           if (fraction >= .5)
              return ival + 1
           else
              return ival
        }
     }

     # test harness
     { print $0, round($0) }


File: gawk.info,  Node: Cliff Random Function,  Next: Ordinal Functions,  Prev: Round Function,  Up: General Functions

12.2.4 The Cliff Random Number Generator
----------------------------------------

The Cliff random number generator
(http://mathworld.wolfram.com/CliffRandomNumberGenerator.html) is a
very simple random number generator that "passes the noise sphere test
for randomness by showing no structure."  It is easily programmed, in
less than 10 lines of `awk' code:

     # cliff_rand.awk --- generate Cliff random numbers

     BEGIN { _cliff_seed = 0.1 }

     function cliff_rand()
     {
         _cliff_seed = (100 * log(_cliff_seed)) % 1
         if (_cliff_seed < 0)
             _cliff_seed = - _cliff_seed
         return _cliff_seed
     }

   This algorithm requires an initial "seed" of 0.1.  Each new value
uses the current seed as input for the calculation.  If the built-in
`rand()' function (*note Numeric Functions::) isn't random enough, you
might try using this function instead.


File: gawk.info,  Node: Ordinal Functions,  Next: Join Function,  Prev: Cliff Random Function,  Up: General Functions

12.2.5 Translating Between Characters and Numbers
-------------------------------------------------

One commercial implementation of `awk' supplies a built-in function,
`ord()', which takes a character and returns the numeric value for that
character in the machine's character set.  If the string passed to
`ord()' has more than one character, only the first one is used.

   The inverse of this function is `chr()' (from the function of the
same name in Pascal), which takes a number and returns the
corresponding character.  Both functions are written very nicely in
`awk'; there is no real reason to build them into the `awk' interpreter:

     # ord.awk --- do ord and chr

     # Global identifiers:
     #    _ord_:        numerical values indexed by characters
     #    _ord_init:    function to initialize _ord_

     BEGIN    { _ord_init() }

     function _ord_init(    low, high, i, t)
     {
         low = sprintf("%c", 7) # BEL is ascii 7
         if (low == "\a") {    # regular ascii
             low = 0
             high = 127
         } else if (sprintf("%c", 128 + 7) == "\a") {
             # ascii, mark parity
             low = 128
             high = 255
         } else {        # ebcdic(!)
             low = 0
             high = 255
         }

         for (i = low; i <= high; i++) {
             t = sprintf("%c", i)
             _ord_[t] = i
         }
     }

   Some explanation of the numbers used by `chr' is worthwhile.  The
most prominent character set in use today is ASCII.(1) Although an
8-bit byte can hold 256 distinct values (from 0 to 255), ASCII only
defines characters that use the values from 0 to 127.(2) In the now
distant past, at least one minicomputer manufacturer used ASCII, but
with mark parity, meaning that the leftmost bit in the byte is always
1.  This means that on those systems, characters have numeric values
from 128 to 255.  Finally, large mainframe systems use the EBCDIC
character set, which uses all 256 values.  While there are other
character sets in use on some older systems, they are not really worth
worrying about:

     function ord(str,    c)
     {
         # only first character is of interest
         c = substr(str, 1, 1)
         return _ord_[c]
     }

     function chr(c)
     {
         # force c to be numeric by adding 0
         return sprintf("%c", c + 0)
     }

     #### test code ####
     # BEGIN    \
     # {
     #    for (;;) {
     #        printf("enter a character: ")
     #        if (getline var <= 0)
     #            break
     #        printf("ord(%s) = %d\n", var, ord(var))
     #    }
     # }

   An obvious improvement to these functions is to move the code for the
`_ord_init' function into the body of the `BEGIN' rule.  It was written
this way initially for ease of development.  There is a "test program"
in a `BEGIN' rule, to test the function.  It is commented out for
production use.

   ---------- Footnotes ----------

   (1) This is changing; many systems use Unicode, a very large
character set that includes ASCII as a subset.  On systems with full
Unicode support, a character can occupy up to 32 bits, making simple
tests such as used here prohibitively expensive.

   (2) ASCII has been extended in many countries to use the values from
128 to 255 for country-specific characters.  If your  system uses these
extensions, you can simplify `_ord_init' to loop from 0 to 255.


File: gawk.info,  Node: Join Function,  Next: Gettimeofday Function,  Prev: Ordinal Functions,  Up: General Functions

12.2.6 Merging an Array into a String
-------------------------------------

When doing string processing, it is often useful to be able to join all
the strings in an array into one long string.  The following function,
`join()', accomplishes this task.  It is used later in several of the
application programs (*note Sample Programs::).

   Good function design is important; this function needs to be general
but it should also have a reasonable default behavior.  It is called
with an array as well as the beginning and ending indices of the
elements in the array to be merged.  This assumes that the array
indices are numeric--a reasonable assumption since the array was likely
created with `split()' (*note String Functions::):

     # join.awk --- join an array into a string

     function join(array, start, end, sep,    result, i)
     {
         if (sep == "")
            sep = " "
         else if (sep == SUBSEP) # magic value
            sep = ""
         result = array[start]
         for (i = start + 1; i <= end; i++)
             result = result sep array[i]
         return result
     }

   An optional additional argument is the separator to use when joining
the strings back together.  If the caller supplies a nonempty value,
`join()' uses it; if it is not supplied, it has a null value.  In this
case, `join()' uses a single space as a default separator for the
strings.  If the value is equal to `SUBSEP', then `join()' joins the
strings with no separator between them.  `SUBSEP' serves as a "magic"
value to indicate that there should be no separation between the
component strings.(1)

   ---------- Footnotes ----------

   (1) It would be nice if `awk' had an assignment operator for
concatenation.  The lack of an explicit operator for concatenation
makes string operations more difficult than they really need to be.


File: gawk.info,  Node: Gettimeofday Function,  Prev: Join Function,  Up: General Functions

12.2.7 Managing the Time of Day
-------------------------------

The `systime()' and `strftime()' functions described in *note Time
Functions::, provide the minimum functionality necessary for dealing
with the time of day in human readable form.  While `strftime()' is
extensive, the control formats are not necessarily easy to remember or
intuitively obvious when reading a program.

   The following function, `gettimeofday()', populates a user-supplied
array with preformatted time information.  It returns a string with the
current time formatted in the same way as the `date' utility:

     # gettimeofday.awk --- get the time of day in a usable format

     # Returns a string in the format of output of date(1)
     # Populates the array argument time with individual values:
     #    time["second"]       -- seconds (0 - 59)
     #    time["minute"]       -- minutes (0 - 59)
     #    time["hour"]         -- hours (0 - 23)
     #    time["althour"]      -- hours (0 - 12)
     #    time["monthday"]     -- day of month (1 - 31)
     #    time["month"]        -- month of year (1 - 12)
     #    time["monthname"]    -- name of the month
     #    time["shortmonth"]   -- short name of the month
     #    time["year"]         -- year modulo 100 (0 - 99)
     #    time["fullyear"]     -- full year
     #    time["weekday"]      -- day of week (Sunday = 0)
     #    time["altweekday"]   -- day of week (Monday = 0)
     #    time["dayname"]      -- name of weekday
     #    time["shortdayname"] -- short name of weekday
     #    time["yearday"]      -- day of year (0 - 365)
     #    time["timezone"]     -- abbreviation of timezone name
     #    time["ampm"]         -- AM or PM designation
     #    time["weeknum"]      -- week number, Sunday first day
     #    time["altweeknum"]   -- week number, Monday first day

     function gettimeofday(time,    ret, now, i)
     {
         # get time once, avoids unnecessary system calls
         now = systime()

         # return date(1)-style output
         ret = strftime("%a %b %e %H:%M:%S %Z %Y", now)

         # clear out target array
         delete time

         # fill in values, force numeric values to be
         # numeric by adding 0
         time["second"]       = strftime("%S", now) + 0
         time["minute"]       = strftime("%M", now) + 0
         time["hour"]         = strftime("%H", now) + 0
         time["althour"]      = strftime("%I", now) + 0
         time["monthday"]     = strftime("%d", now) + 0
         time["month"]        = strftime("%m", now) + 0
         time["monthname"]    = strftime("%B", now)
         time["shortmonth"]   = strftime("%b", now)
         time["year"]         = strftime("%y", now) + 0
         time["fullyear"]     = strftime("%Y", now) + 0
         time["weekday"]      = strftime("%w", now) + 0
         time["altweekday"]   = strftime("%u", now) + 0
         time["dayname"]      = strftime("%A", now)
         time["shortdayname"] = strftime("%a", now)
         time["yearday"]      = strftime("%j", now) + 0
         time["timezone"]     = strftime("%Z", now)
         time["ampm"]         = strftime("%p", now)
         time["weeknum"]      = strftime("%U", now) + 0
         time["altweeknum"]   = strftime("%W", now) + 0

         return ret
     }

   The string indices are easier to use and read than the various
formats required by `strftime()'.  The `alarm' program presented in
*note Alarm Program::, uses this function.  A more general design for
the `gettimeofday()' function would have allowed the user to supply an
optional timestamp value to use instead of the current time.


File: gawk.info,  Node: Data File Management,  Next: Getopt Function,  Prev: General Functions,  Up: Library Functions

12.3 Data File Management
=========================

This minor node presents functions that are useful for managing
command-line data files.

* Menu:

* Filetrans Function::          A function for handling data file transitions.
* Rewind Function::             A function for rereading the current file.
* File Checking::               Checking that data files are readable.
* Empty Files::                 Checking for zero-length files.
* Ignoring Assigns::            Treating assignments as file names.


File: gawk.info,  Node: Filetrans Function,  Next: Rewind Function,  Up: Data File Management

12.3.1 Noting Data File Boundaries
----------------------------------

The `BEGIN' and `END' rules are each executed exactly once at the
beginning and end of your `awk' program, respectively (*note
BEGIN/END::).  We (the `gawk' authors) once had a user who mistakenly
thought that the `BEGIN' rule is executed at the beginning of each data
file and the `END' rule is executed at the end of each data file.

   When informed that this was not the case, the user requested that we
add new special patterns to `gawk', named `BEGIN_FILE' and `END_FILE',
that would have the desired behavior.  He even supplied us the code to
do so.

   Adding these special patterns to `gawk' wasn't necessary; the job
can be done cleanly in `awk' itself, as illustrated by the following
library program.  It arranges to call two user-supplied functions,
`beginfile()' and `endfile()', at the beginning and end of each data
file.  Besides solving the problem in only nine(!) lines of code, it
does so _portably_; this works with any implementation of `awk':

     # transfile.awk
     #
     # Give the user a hook for filename transitions
     #
     # The user must supply functions beginfile() and endfile()
     # that each take the name of the file being started or
     # finished, respectively.

     FILENAME != _oldfilename \
     {
         if (_oldfilename != "")
             endfile(_oldfilename)
         _oldfilename = FILENAME
         beginfile(FILENAME)
     }

     END   { endfile(FILENAME) }

   This file must be loaded before the user's "main" program, so that
the rule it supplies is executed first.

   This rule relies on `awk''s `FILENAME' variable that automatically
changes for each new data file.  The current file name is saved in a
private variable, `_oldfilename'.  If `FILENAME' does not equal
`_oldfilename', then a new data file is being processed and it is
necessary to call `endfile()' for the old file.  Because `endfile()'
should only be called if a file has been processed, the program first
checks to make sure that `_oldfilename' is not the null string.  The
program then assigns the current file name to `_oldfilename' and calls
`beginfile()' for the file.  Because, like all `awk' variables,
`_oldfilename' is initialized to the null string, this rule executes
correctly even for the first data file.

   The program also supplies an `END' rule to do the final processing
for the last file.  Because this `END' rule comes before any `END' rules
supplied in the "main" program, `endfile()' is called first.  Once
again the value of multiple `BEGIN' and `END' rules should be clear.

   If the same data file occurs twice in a row on the command line, then
`endfile()' and `beginfile()' are not executed at the end of the first
pass and at the beginning of the second pass.  The following version
solves the problem:

     # ftrans.awk --- handle data file transitions
     #
     # user supplies beginfile() and endfile() functions

     FNR == 1 {
         if (_filename_ != "")
             endfile(_filename_)
         _filename_ = FILENAME
         beginfile(FILENAME)
     }

     END  { endfile(_filename_) }

   *note Wc Program::, shows how this library function can be used and
how it simplifies writing the main program.

Advanced Notes: So Why Does `gawk' have `BEGINFILE' and `ENDFILE'?
------------------------------------------------------------------

You are probably wondering, if `beginfile()' and `endfile()' functions
can do the job, why does `gawk' have `BEGINFILE' and `ENDFILE' patterns
(*note BEGINFILE/ENDFILE::)?

   Good question.  Normally, if `awk' cannot open a file, this causes
an immediate fatal error.  In this case, there is no way for a
user-defined function to deal with the problem, since the mechanism for
calling it relies on the file being open and at the first record.  Thus,
the main reason for `BEGINFILE' is to give you a "hook" to catch files
that cannot be processed.  `ENDFILE' exists for symmetry, and because
it provides an easy way to do per-file cleanup processing.


File: gawk.info,  Node: Rewind Function,  Next: File Checking,  Prev: Filetrans Function,  Up: Data File Management

12.3.2 Rereading the Current File
---------------------------------

Another request for a new built-in function was for a `rewind()'
function that would make it possible to reread the current file.  The
requesting user didn't want to have to use `getline' (*note Getline::)
inside a loop.

   However, as long as you are not in the `END' rule, it is quite easy
to arrange to immediately close the current input file and then start
over with it from the top.  For lack of a better name, we'll call it
`rewind()':

     # rewind.awk --- rewind the current file and start over

     function rewind(    i)
     {
         # shift remaining arguments up
         for (i = ARGC; i > ARGIND; i--)
             ARGV[i] = ARGV[i-1]

         # make sure gawk knows to keep going
         ARGC++

         # make current file next to get done
         ARGV[ARGIND+1] = FILENAME

         # do it
         nextfile
     }

   This code relies on the `ARGIND' variable (*note Auto-set::), which
is specific to `gawk'.  If you are not using `gawk', you can use ideas
presented in *note Filetrans Function::, to either update `ARGIND' on
your own or modify this code as appropriate.

   The `rewind()' function also relies on the `nextfile' keyword (*note
Nextfile Statement::).


File: gawk.info,  Node: File Checking,  Next: Empty Files,  Prev: Rewind Function,  Up: Data File Management

12.3.3 Checking for Readable Data Files
---------------------------------------

Normally, if you give `awk' a data file that isn't readable, it stops
with a fatal error.  There are times when you might want to just ignore
such files and keep going.  You can do this by prepending the following
program to your `awk' program:

     # readable.awk --- library file to skip over unreadable files

     BEGIN {
         for (i = 1; i < ARGC; i++) {
             if (ARGV[i] ~ /^[[:alpha:]_][[:alnum:]_]*=.*/ \
                 || ARGV[i] == "-" || ARGV[i] == "/dev/stdin")
                 continue    # assignment or standard input
             else if ((getline junk < ARGV[i]) < 0) # unreadable
                 delete ARGV[i]
             else
                 close(ARGV[i])
         }
     }

   This works, because the `getline' won't be fatal.  Removing the
element from `ARGV' with `delete' skips the file (since it's no longer
in the list).  See also *note ARGC and ARGV::.


File: gawk.info,  Node: Empty Files,  Next: Ignoring Assigns,  Prev: File Checking,  Up: Data File Management

12.3.4 Checking For Zero-length Files
-------------------------------------

All known `awk' implementations silently skip over zero-length files.
This is a by-product of `awk''s implicit
read-a-record-and-match-against-the-rules loop: when `awk' tries to
read a record from an empty file, it immediately receives an end of
file indication, closes the file, and proceeds on to the next
command-line data file, _without_ executing any user-level `awk'
program code.

   Using `gawk''s `ARGIND' variable (*note Built-in Variables::), it is
possible to detect when an empty data file has been skipped.  Similar
to the library file presented in *note Filetrans Function::, the
following library file calls a function named `zerofile()' that the
user must provide.  The arguments passed are the file name and the
position in `ARGV' where it was found:

     # zerofile.awk --- library file to process empty input files

     BEGIN { Argind = 0 }

     ARGIND > Argind + 1 {
         for (Argind++; Argind < ARGIND; Argind++)
             zerofile(ARGV[Argind], Argind)
     }

     ARGIND != Argind { Argind = ARGIND }

     END {
         if (ARGIND > Argind)
             for (Argind++; Argind <= ARGIND; Argind++)
                 zerofile(ARGV[Argind], Argind)
     }

   The user-level variable `Argind' allows the `awk' program to track
its progress through `ARGV'.  Whenever the program detects that
`ARGIND' is greater than `Argind + 1', it means that one or more empty
files were skipped.  The action then calls `zerofile()' for each such
file, incrementing `Argind' along the way.

   The `Argind != ARGIND' rule simply keeps `Argind' up to date in the
normal case.

   Finally, the `END' rule catches the case of any empty files at the
end of the command-line arguments.  Note that the test in the condition
of the `for' loop uses the `<=' operator, not `<'.

   As an exercise, you might consider whether this same problem can be
solved without relying on `gawk''s `ARGIND' variable.

   As a second exercise, revise this code to handle the case where an
intervening value in `ARGV' is a variable assignment.


File: gawk.info,  Node: Ignoring Assigns,  Prev: Empty Files,  Up: Data File Management

12.3.5 Treating Assignments as File Names
-----------------------------------------

Occasionally, you might not want `awk' to process command-line variable
assignments (*note Assignment Options::).  In particular, if you have a
file name that contain an `=' character, `awk' treats the file name as
an assignment, and does not process it.

   Some users have suggested an additional command-line option for
`gawk' to disable command-line assignments.  However, some simple
programming with a library file does the trick:

     # noassign.awk --- library file to avoid the need for a
     # special option that disables command-line assignments

     function disable_assigns(argc, argv,    i)
     {
         for (i = 1; i < argc; i++)
             if (argv[i] ~ /^[[:alpha:]_][[:alnum:]_]*=.*/)
                 argv[i] = ("./" argv[i])
     }

     BEGIN {
         if (No_command_assign)
             disable_assigns(ARGC, ARGV)
     }

   You then run your program this way:

     awk -v No_command_assign=1 -f noassign.awk -f yourprog.awk *

   The function works by looping through the arguments.  It prepends
`./' to any argument that matches the form of a variable assignment,
turning that argument into a file name.

   The use of `No_command_assign' allows you to disable command-line
assignments at invocation time, by giving the variable a true value.
When not set, it is initially zero (i.e., false), so the command-line
arguments are left alone.


File: gawk.info,  Node: Getopt Function,  Next: Passwd Functions,  Prev: Data File Management,  Up: Library Functions

12.4 Processing Command-Line Options
====================================

Most utilities on POSIX compatible systems take options on the command
line that can be used to change the way a program behaves.  `awk' is an
example of such a program (*note Options::).  Often, options take
"arguments"; i.e., data that the program needs to correctly obey the
command-line option.  For example, `awk''s `-F' option requires a
string to use as the field separator.  The first occurrence on the
command line of either `--' or a string that does not begin with `-'
ends the options.

   Modern Unix systems provide a C function named `getopt()' for
processing command-line arguments.  The programmer provides a string
describing the one-letter options. If an option requires an argument,
it is followed in the string with a colon.  `getopt()' is also passed
the count and values of the command-line arguments and is called in a
loop.  `getopt()' processes the command-line arguments for option
letters.  Each time around the loop, it returns a single character
representing the next option letter that it finds, or `?' if it finds
an invalid option.  When it returns -1, there are no options left on
the command line.

   When using `getopt()', options that do not take arguments can be
grouped together.  Furthermore, options that take arguments require
that the argument be present.  The argument can immediately follow the
option letter, or it can be a separate command-line argument.

   Given a hypothetical program that takes three command-line options,
`-a', `-b', and `-c', where `-b' requires an argument, all of the
following are valid ways of invoking the program:

     prog -a -b foo -c data1 data2 data3
     prog -ac -bfoo -- data1 data2 data3
     prog -acbfoo data1 data2 data3

   Notice that when the argument is grouped with its option, the rest of
the argument is considered to be the option's argument.  In this
example, `-acbfoo' indicates that all of the `-a', `-b', and `-c'
options were supplied, and that `foo' is the argument to the `-b'
option.

   `getopt()' provides four external variables that the programmer can
use:

`optind'
     The index in the argument value array (`argv') where the first
     nonoption command-line argument can be found.

`optarg'
     The string value of the argument to an option.

`opterr'
     Usually `getopt()' prints an error message when it finds an invalid
     option.  Setting `opterr' to zero disables this feature.  (An
     application might want to print its own error message.)

`optopt'
     The letter representing the command-line option.

   The following C fragment shows how `getopt()' might process
command-line arguments for `awk':

     int
     main(int argc, char *argv[])
     {
         ...
         /* print our own message */
         opterr = 0;
         while ((c = getopt(argc, argv, "v:f:F:W:")) != -1) {
             switch (c) {
             case 'f':    /* file */
                 ...
                 break;
             case 'F':    /* field separator */
                 ...
                 break;
             case 'v':    /* variable assignment */
                 ...
                 break;
             case 'W':    /* extension */
                 ...
                 break;
             case '?':
             default:
                 usage();
                 break;
             }
         }
         ...
     }

   As a side point, `gawk' actually uses the GNU `getopt_long()'
function to process both normal and GNU-style long options (*note
Options::).

   The abstraction provided by `getopt()' is very useful and is quite
handy in `awk' programs as well.  Following is an `awk' version of
`getopt()'.  This function highlights one of the greatest weaknesses in
`awk', which is that it is very poor at manipulating single characters.
Repeated calls to `substr()' are necessary for accessing individual
characters (*note String Functions::).(1)

   The discussion that follows walks through the code a bit at a time:

     # getopt.awk --- Do C library getopt(3) function in awk

     # External variables:
     #    Optind -- index in ARGV of first nonoption argument
     #    Optarg -- string value of argument to current option
     #    Opterr -- if nonzero, print our own diagnostic
     #    Optopt -- current option letter

     # Returns:
     #    -1     at end of options
     #    "?"    for unrecognized option
     #    <c>    a character representing the current option

     # Private Data:
     #    _opti  -- index in multi-flag option, e.g., -abc

   The function starts out with comments presenting a list of the
global variables it uses, what the return values are, what they mean,
and any global variables that are "private" to this library function.
Such documentation is essential for any program, and particularly for
library functions.

   The `getopt()' function first checks that it was indeed called with
a string of options (the `options' parameter).  If `options' has a zero
length, `getopt()' immediately returns -1:

     function getopt(argc, argv, options,    thisopt, i)
     {
         if (length(options) == 0)    # no options given
             return -1

         if (argv[Optind] == "--") {  # all done
             Optind++
             _opti = 0
             return -1
         } else if (argv[Optind] !~ /^-[^:[:space:]]/) {
             _opti = 0
             return -1
         }

   The next thing to check for is the end of the options.  A `--' ends
the command-line options, as does any command-line argument that does
not begin with a `-'.  `Optind' is used to step through the array of
command-line arguments; it retains its value across calls to
`getopt()', because it is a global variable.

   The regular expression that is used, `/^-[^:[:space:]/', checks for
a `-' followed by anything that is not whitespace and not a colon.  If
the current command-line argument does not match this pattern, it is
not an option, and it ends option processing. Continuing on:

         if (_opti == 0)
             _opti = 2
         thisopt = substr(argv[Optind], _opti, 1)
         Optopt = thisopt
         i = index(options, thisopt)
         if (i == 0) {
             if (Opterr)
                 printf("%c -- invalid option\n",
                                       thisopt) > "/dev/stderr"
             if (_opti >= length(argv[Optind])) {
                 Optind++
                 _opti = 0
             } else
                 _opti++
             return "?"
         }

   The `_opti' variable tracks the position in the current command-line
argument (`argv[Optind]').  If multiple options are grouped together
with one `-' (e.g., `-abx'), it is necessary to return them to the user
one at a time.

   If `_opti' is equal to zero, it is set to two, which is the index in
the string of the next character to look at (we skip the `-', which is
at position one).  The variable `thisopt' holds the character, obtained
with `substr()'.  It is saved in `Optopt' for the main program to use.

   If `thisopt' is not in the `options' string, then it is an invalid
option.  If `Opterr' is nonzero, `getopt()' prints an error message on
the standard error that is similar to the message from the C version of
`getopt()'.

   Because the option is invalid, it is necessary to skip it and move
on to the next option character.  If `_opti' is greater than or equal
to the length of the current command-line argument, it is necessary to
move on to the next argument, so `Optind' is incremented and `_opti' is
reset to zero. Otherwise, `Optind' is left alone and `_opti' is merely
incremented.

   In any case, because the option is invalid, `getopt()' returns `"?"'.
The main program can examine `Optopt' if it needs to know what the
invalid option letter actually is. Continuing on:

         if (substr(options, i + 1, 1) == ":") {
             # get option argument
             if (length(substr(argv[Optind], _opti + 1)) > 0)
                 Optarg = substr(argv[Optind], _opti + 1)
             else
                 Optarg = argv[++Optind]
             _opti = 0
         } else
             Optarg = ""

   If the option requires an argument, the option letter is followed by
a colon in the `options' string.  If there are remaining characters in
the current command-line argument (`argv[Optind]'), then the rest of
that string is assigned to `Optarg'.  Otherwise, the next command-line
argument is used (`-xFOO' versus `-x FOO'). In either case, `_opti' is
reset to zero, because there are no more characters left to examine in
the current command-line argument. Continuing:

         if (_opti == 0 || _opti >= length(argv[Optind])) {
             Optind++
             _opti = 0
         } else
             _opti++
         return thisopt
     }

   Finally, if `_opti' is either zero or greater than the length of the
current command-line argument, it means this element in `argv' is
through being processed, so `Optind' is incremented to point to the
next element in `argv'.  If neither condition is true, then only
`_opti' is incremented, so that the next option letter can be processed
on the next call to `getopt()'.

   The `BEGIN' rule initializes both `Opterr' and `Optind' to one.
`Opterr' is set to one, since the default behavior is for `getopt()' to
print a diagnostic message upon seeing an invalid option.  `Optind' is
set to one, since there's no reason to look at the program name, which
is in `ARGV[0]':

     BEGIN {
         Opterr = 1    # default is to diagnose
         Optind = 1    # skip ARGV[0]

         # test program
         if (_getopt_test) {
             while ((_go_c = getopt(ARGC, ARGV, "ab:cd")) != -1)
                 printf("c = <%c>, optarg = <%s>\n",
                                            _go_c, Optarg)
             printf("non-option arguments:\n")
             for (; Optind < ARGC; Optind++)
                 printf("\tARGV[%d] = <%s>\n",
                                         Optind, ARGV[Optind])
         }
     }

   The rest of the `BEGIN' rule is a simple test program.  Here is the
result of two sample runs of the test program:

     $ awk -f getopt.awk -v _getopt_test=1 -- -a -cbARG bax -x
     -| c = <a>, optarg = <>
     -| c = <c>, optarg = <>
     -| c = <b>, optarg = <ARG>
     -| non-option arguments:
     -|         ARGV[3] = <bax>
     -|         ARGV[4] = <-x>

     $ awk -f getopt.awk -v _getopt_test=1 -- -a -x -- xyz abc
     -| c = <a>, optarg = <>
     error--> x -- invalid option
     -| c = <?>, optarg = <>
     -| non-option arguments:
     -|         ARGV[4] = <xyz>
     -|         ARGV[5] = <abc>

   In both runs, the first `--' terminates the arguments to `awk', so
that it does not try to interpret the `-a', etc., as its own options.

     NOTE: After `getopt()' is through, it is the responsibility of the
     user level code to clear out all the elements of `ARGV' from 1 to
     `Optind', so that `awk' does not try to process the command-line
     options as file names.

   Several of the sample programs presented in *note Sample Programs::,
use `getopt()' to process their arguments.

   ---------- Footnotes ----------

   (1) This function was written before `gawk' acquired the ability to
split strings into single characters using `""' as the separator.  We
have left it alone, since using `substr()' is more portable.


File: gawk.info,  Node: Passwd Functions,  Next: Group Functions,  Prev: Getopt Function,  Up: Library Functions

12.5 Reading the User Database
==============================

The `PROCINFO' array (*note Built-in Variables::) provides access to
the current user's real and effective user and group ID numbers, and if
available, the user's supplementary group set.  However, because these
are numbers, they do not provide very useful information to the average
user.  There needs to be some way to find the user information
associated with the user and group ID numbers.  This minor node
presents a suite of functions for retrieving information from the user
database.  *Note Group Functions::, for a similar suite that retrieves
information from the group database.

   The POSIX standard does not define the file where user information is
kept.  Instead, it provides the `<pwd.h>' header file and several C
language subroutines for obtaining user information.  The primary
function is `getpwent()', for "get password entry."  The "password"
comes from the original user database file, `/etc/passwd', which stores
user information, along with the encrypted passwords (hence the name).

   While an `awk' program could simply read `/etc/passwd' directly,
this file may not contain complete information about the system's set
of users.(1) To be sure you are able to produce a readable and complete
version of the user database, it is necessary to write a small C
program that calls `getpwent()'.  `getpwent()' is defined as returning
a pointer to a `struct passwd'.  Each time it is called, it returns the
next entry in the database.  When there are no more entries, it returns
`NULL', the null pointer.  When this happens, the C program should call
`endpwent()' to close the database.  Following is `pwcat', a C program
that "cats" the password database:

     /*
      * pwcat.c
      *
      * Generate a printable version of the password database
      */
     #include <stdio.h>
     #include <pwd.h>

     int
     main(int argc, char **argv)
     {
         struct passwd *p;

         while ((p = getpwent()) != NULL)
             printf("%s:%s:%ld:%ld:%s:%s:%s\n",
                 p->pw_name, p->pw_passwd, (long) p->pw_uid,
                 (long) p->pw_gid, p->pw_gecos, p->pw_dir, p->pw_shell);

         endpwent();
         return 0;
     }

   If you don't understand C, don't worry about it.  The output from
`pwcat' is the user database, in the traditional `/etc/passwd' format
of colon-separated fields.  The fields are:

Login name
     The user's login name.

Encrypted password
     The user's encrypted password.  This may not be available on some
     systems.

User-ID
     The user's numeric user ID number.  (On some systems it's a C
     `long', and not an `int'.  Thus we cast it to `long' for all
     cases.)

Group-ID
     The user's numeric group ID number.  (Similar comments about
     `long' vs. `int' apply here.)

Full name
     The user's full name, and perhaps other information associated
     with the user.

Home directory
     The user's login (or "home") directory (familiar to shell
     programmers as `$HOME').

Login shell
     The program that is run when the user logs in.  This is usually a
     shell, such as Bash.

   A few lines representative of `pwcat''s output are as follows:

     $ pwcat
     -| root:3Ov02d5VaUPB6:0:1:Operator:/:/bin/sh
     -| nobody:*:65534:65534::/:
     -| daemon:*:1:1::/:
     -| sys:*:2:2::/:/bin/csh
     -| bin:*:3:3::/bin:
     -| arnold:xyzzy:2076:10:Arnold Robbins:/home/arnold:/bin/sh
     -| miriam:yxaay:112:10:Miriam Robbins:/home/miriam:/bin/sh
     -| andy:abcca2:113:10:Andy Jacobs:/home/andy:/bin/sh
     ...

   With that introduction, following is a group of functions for
getting user information.  There are several functions here,
corresponding to the C functions of the same names:

     # passwd.awk --- access password file information

     BEGIN {
         # tailor this to suit your system
         _pw_awklib = "/usr/local/libexec/awk/"
     }

     function _pw_init(    oldfs, oldrs, olddol0, pwcat, using_fw, using_fpat)
     {
         if (_pw_inited)
             return

         oldfs = FS
         oldrs = RS
         olddol0 = $0
         using_fw = (PROCINFO["FS"] == "FIELDWIDTHS")
         using_fpat = (PROCINFO["FS"] == "FPAT")
         FS = ":"
         RS = "\n"

         pwcat = _pw_awklib "pwcat"
         while ((pwcat | getline) > 0) {
             _pw_byname[$1] = $0
             _pw_byuid[$3] = $0
             _pw_bycount[++_pw_total] = $0
         }
         close(pwcat)
         _pw_count = 0
         _pw_inited = 1
         FS = oldfs
         if (using_fw)
             FIELDWIDTHS = FIELDWIDTHS
         else if (using_fpat)
             FPAT = FPAT
         RS = oldrs
         $0 = olddol0
     }

   The `BEGIN' rule sets a private variable to the directory where
`pwcat' is stored.  Because it is used to help out an `awk' library
routine, we have chosen to put it in `/usr/local/libexec/awk'; however,
you might want it to be in a different directory on your system.

   The function `_pw_init()' keeps three copies of the user information
in three associative arrays.  The arrays are indexed by username
(`_pw_byname'), by user ID number (`_pw_byuid'), and by order of
occurrence (`_pw_bycount').  The variable `_pw_inited' is used for
efficiency, since `_pw_init()' needs to be called only once.

   Because this function uses `getline' to read information from
`pwcat', it first saves the values of `FS', `RS', and `$0'.  It notes
in the variable `using_fw' whether field splitting with `FIELDWIDTHS'
is in effect or not.  Doing so is necessary, since these functions
could be called from anywhere within a user's program, and the user may
have his or her own way of splitting records and fields.

   The `using_fw' variable checks `PROCINFO["FS"]', which is
`"FIELDWIDTHS"' if field splitting is being done with `FIELDWIDTHS'.
This makes it possible to restore the correct field-splitting mechanism
later.  The test can only be true for `gawk'.  It is false if using
`FS' or `FPAT', or on some other `awk' implementation.

   The code that checks for using `FPAT', using `using_fpat' and
`PROCINFO["FS"]' is similar.

   The main part of the function uses a loop to read database lines,
split the line into fields, and then store the line into each array as
necessary.  When the loop is done, `_pw_init()' cleans up by closing
the pipeline, setting `_pw_inited' to one, and restoring `FS' (and
`FIELDWIDTHS' or `FPAT' if necessary), `RS', and `$0'.  The use of
`_pw_count' is explained shortly.

   The `getpwnam()' function takes a username as a string argument. If
that user is in the database, it returns the appropriate line.
Otherwise, it relies on the array reference to a nonexistent element to
create the element with the null string as its value:

     function getpwnam(name)
     {
         _pw_init()
         return _pw_byname[name]
     }

   Similarly, the `getpwuid' function takes a user ID number argument.
If that user number is in the database, it returns the appropriate
line. Otherwise, it returns the null string:

     function getpwuid(uid)
     {
         _pw_init()
         return _pw_byuid[uid]
     }

   The `getpwent()' function simply steps through the database, one
entry at a time.  It uses `_pw_count' to track its current position in
the `_pw_bycount' array:

     function getpwent()
     {
         _pw_init()
         if (_pw_count < _pw_total)
             return _pw_bycount[++_pw_count]
         return ""
     }

   The `endpwent()' function resets `_pw_count' to zero, so that
subsequent calls to `getpwent()' start over again:

     function endpwent()
     {
         _pw_count = 0
     }

   A conscious design decision in this suite is that each subroutine
calls `_pw_init()' to initialize the database arrays.  The overhead of
running a separate process to generate the user database, and the I/O
to scan it, are only incurred if the user's main program actually calls
one of these functions.  If this library file is loaded along with a
user's program, but none of the routines are ever called, then there is
no extra runtime overhead.  (The alternative is move the body of
`_pw_init()' into a `BEGIN' rule, which always runs `pwcat'.  This
simplifies the code but runs an extra process that may never be needed.)

   In turn, calling `_pw_init()' is not too expensive, because the
`_pw_inited' variable keeps the program from reading the data more than
once.  If you are worried about squeezing every last cycle out of your
`awk' program, the check of `_pw_inited' could be moved out of
`_pw_init()' and duplicated in all the other functions.  In practice,
this is not necessary, since most `awk' programs are I/O-bound, and
such a change would clutter up the code.

   The `id' program in *note Id Program::, uses these functions.

   ---------- Footnotes ----------

   (1) It is often the case that password information is stored in a
network database.


File: gawk.info,  Node: Group Functions,  Next: Walking Arrays,  Prev: Passwd Functions,  Up: Library Functions

12.6 Reading the Group Database
===============================

Much of the discussion presented in *note Passwd Functions::, applies
to the group database as well.  Although there has traditionally been a
well-known file (`/etc/group') in a well-known format, the POSIX
standard only provides a set of C library routines (`<grp.h>' and
`getgrent()') for accessing the information.  Even though this file may
exist, it may not have complete information.  Therefore, as with the
user database, it is necessary to have a small C program that generates
the group database as its output.  `grcat', a C program that "cats" the
group database, is as follows:

     /*
      * grcat.c
      *
      * Generate a printable version of the group database
      */
     #include <stdio.h>
     #include <grp.h>

     int
     main(int argc, char **argv)
     {
         struct group *g;
         int i;

         while ((g = getgrent()) != NULL) {
             printf("%s:%s:%ld:", g->gr_name, g->gr_passwd,
                                          (long) g->gr_gid);
             for (i = 0; g->gr_mem[i] != NULL; i++) {
                 printf("%s", g->gr_mem[i]);
                 if (g->gr_mem[i+1] != NULL)
                     putchar(',');
             }
             putchar('\n');
         }
         endgrent();
         return 0;
     }

   Each line in the group database represents one group.  The fields are
separated with colons and represent the following information:

Group Name
     The group's name.

Group Password
     The group's encrypted password. In practice, this field is never
     used; it is usually empty or set to `*'.

Group ID Number
     The group's numeric group ID number; this number must be unique
     within the file.  (On some systems it's a C `long', and not an
     `int'.  Thus we cast it to `long' for all cases.)

Group Member List
     A comma-separated list of user names.  These users are members of
     the group.  Modern Unix systems allow users to be members of
     several groups simultaneously.  If your system does, then there
     are elements `"group1"' through `"groupN"' in `PROCINFO' for those
     group ID numbers.  (Note that `PROCINFO' is a `gawk' extension;
     *note Built-in Variables::.)

   Here is what running `grcat' might produce:

     $ grcat
     -| wheel:*:0:arnold
     -| nogroup:*:65534:
     -| daemon:*:1:
     -| kmem:*:2:
     -| staff:*:10:arnold,miriam,andy
     -| other:*:20:
     ...

   Here are the functions for obtaining information from the group
database.  There are several, modeled after the C library functions of
the same names:

     # group.awk --- functions for dealing with the group file

     BEGIN    \
     {
         # Change to suit your system
         _gr_awklib = "/usr/local/libexec/awk/"
     }

     function _gr_init(    oldfs, oldrs, olddol0, grcat,
                                  using_fw, using_fpat, n, a, i)
     {
         if (_gr_inited)
             return

         oldfs = FS
         oldrs = RS
         olddol0 = $0
         using_fw = (PROCINFO["FS"] == "FIELDWIDTHS")
         using_fpat = (PROCINFO["FS"] == "FPAT")
         FS = ":"
         RS = "\n"

         grcat = _gr_awklib "grcat"
         while ((grcat | getline) > 0) {
             if ($1 in _gr_byname)
                 _gr_byname[$1] = _gr_byname[$1] "," $4
             else
                 _gr_byname[$1] = $0
             if ($3 in _gr_bygid)
                 _gr_bygid[$3] = _gr_bygid[$3] "," $4
             else
                 _gr_bygid[$3] = $0

             n = split($4, a, "[ \t]*,[ \t]*")
             for (i = 1; i <= n; i++)
                 if (a[i] in _gr_groupsbyuser)
                     _gr_groupsbyuser[a[i]] = \
                         _gr_groupsbyuser[a[i]] " " $1
                 else
                     _gr_groupsbyuser[a[i]] = $1

             _gr_bycount[++_gr_count] = $0
         }
         close(grcat)
         _gr_count = 0
         _gr_inited++
         FS = oldfs
         if (using_fw)
             FIELDWIDTHS = FIELDWIDTHS
         else if (using_fpat)
             FPAT = FPAT
         RS = oldrs
         $0 = olddol0
     }

   The `BEGIN' rule sets a private variable to the directory where
`grcat' is stored.  Because it is used to help out an `awk' library
routine, we have chosen to put it in `/usr/local/libexec/awk'.  You
might want it to be in a different directory on your system.

   These routines follow the same general outline as the user database
routines (*note Passwd Functions::).  The `_gr_inited' variable is used
to ensure that the database is scanned no more than once.  The
`_gr_init()' function first saves `FS', `RS', and `$0', and then sets
`FS' and `RS' to the correct values for scanning the group information.
It also takes care to note whether `FIELDWIDTHS' or `FPAT' is being
used, and to restore the appropriate field splitting mechanism.

   The group information is stored is several associative arrays.  The
arrays are indexed by group name (`_gr_byname'), by group ID number
(`_gr_bygid'), and by position in the database (`_gr_bycount').  There
is an additional array indexed by user name (`_gr_groupsbyuser'), which
is a space-separated list of groups to which each user belongs.

   Unlike the user database, it is possible to have multiple records in
the database for the same group.  This is common when a group has a
large number of members.  A pair of such entries might look like the
following:

     tvpeople:*:101:johnny,jay,arsenio
     tvpeople:*:101:david,conan,tom,joan

   For this reason, `_gr_init()' looks to see if a group name or group
ID number is already seen.  If it is, then the user names are simply
concatenated onto the previous list of users.  (There is actually a
subtle problem with the code just presented.  Suppose that the first
time there were no names. This code adds the names with a leading
comma. It also doesn't check that there is a `$4'.)

   Finally, `_gr_init()' closes the pipeline to `grcat', restores `FS'
(and `FIELDWIDTHS' or `FPAT' if necessary), `RS', and `$0', initializes
`_gr_count' to zero (it is used later), and makes `_gr_inited' nonzero.

   The `getgrnam()' function takes a group name as its argument, and if
that group exists, it is returned.  Otherwise, it relies on the array
reference to a nonexistent element to create the element with the null
string as its value:

     function getgrnam(group)
     {
         _gr_init()
         return _gr_byname[group]
     }

   The `getgrgid()' function is similar; it takes a numeric group ID and
looks up the information associated with that group ID:

     function getgrgid(gid)
     {
         _gr_init()
         return _gr_bygid[gid]
     }

   The `getgruser()' function does not have a C counterpart. It takes a
user name and returns the list of groups that have the user as a member:

     function getgruser(user)
     {
         _gr_init()
         return _gr_groupsbyuser[user]
     }

   The `getgrent()' function steps through the database one entry at a
time.  It uses `_gr_count' to track its position in the list:

     function getgrent()
     {
         _gr_init()
         if (++_gr_count in _gr_bycount)
             return _gr_bycount[_gr_count]
         return ""
     }

   The `endgrent()' function resets `_gr_count' to zero so that
`getgrent()' can start over again:

     function endgrent()
     {
         _gr_count = 0
     }

   As with the user database routines, each function calls `_gr_init()'
to initialize the arrays.  Doing so only incurs the extra overhead of
running `grcat' if these functions are used (as opposed to moving the
body of `_gr_init()' into a `BEGIN' rule).

   Most of the work is in scanning the database and building the various
associative arrays.  The functions that the user calls are themselves
very simple, relying on `awk''s associative arrays to do work.

   The `id' program in *note Id Program::, uses these functions.


File: gawk.info,  Node: Walking Arrays,  Prev: Group Functions,  Up: Library Functions

12.7 Traversing Arrays of Arrays
================================

*note Arrays of Arrays::, described how `gawk' provides arrays of
arrays.  In particular, any element of an array may be either a scalar,
or another array. The `isarray()' function (*note Type Functions::)
lets you distinguish an array from a scalar.  The following function,
`walk_array()', recursively traverses an array, printing each element's
indices and value.  You call it with the array and a string
representing the name of the array:

     function walk_array(arr, name,      i)
     {
         for (i in arr) {
             if (isarray(arr[i]))
                 walk_array(arr[i], (name "[" i "]"))
             else
                 printf("%s[%s] = %s\n", name, i, arr[i])
         }
     }

It works by looping over each element of the array. If any given
element is itself an array, the function calls itself recursively,
passing the subarray and a new string representing the current index.
Otherwise, the function simply prints the element's name, index, and
value.  Here is a main program to demonstrate:

     BEGIN {
         a[1] = 1
         a[2][1] = 21
         a[2][2] = 22
         a[3] = 3
         a[4][1][1] = 411
         a[4][2] = 42

         walk_array(a, "a")
     }

   When run, the program produces the following output:

     $ gawk -f walk_array.awk
     -| a[4][1][1] = 411
     -| a[4][2] = 42
     -| a[1] = 1
     -| a[2][1] = 21
     -| a[2][2] = 22
     -| a[3] = 3


File: gawk.info,  Node: Sample Programs,  Next: Debugger,  Prev: Library Functions,  Up: Top

13 Practical `awk' Programs
***************************

*note Library Functions::, presents the idea that reading programs in a
language contributes to learning that language.  This major node
continues that theme, presenting a potpourri of `awk' programs for your
reading enjoyment.

   Many of these programs use library functions presented in *note
Library Functions::.

* Menu:

* Running Examples::            How to run these examples.
* Clones::                      Clones of common utilities.
* Miscellaneous Programs::      Some interesting `awk' programs.


File: gawk.info,  Node: Running Examples,  Next: Clones,  Up: Sample Programs

13.1 Running the Example Programs
=================================

To run a given program, you would typically do something like this:

     awk -f PROGRAM -- OPTIONS FILES

Here, PROGRAM is the name of the `awk' program (such as `cut.awk'),
OPTIONS are any command-line options for the program that start with a
`-', and FILES are the actual data files.

   If your system supports the `#!' executable interpreter mechanism
(*note Executable Scripts::), you can instead run your program directly:

     cut.awk -c1-8 myfiles > results

   If your `awk' is not `gawk', you may instead need to use this:

     cut.awk -- -c1-8 myfiles > results


File: gawk.info,  Node: Clones,  Next: Miscellaneous Programs,  Prev: Running Examples,  Up: Sample Programs

13.2 Reinventing Wheels for Fun and Profit
==========================================

This minor node presents a number of POSIX utilities implemented in
`awk'.  Reinventing these programs in `awk' is often enjoyable, because
the algorithms can be very clearly expressed, and the code is usually
very concise and simple.  This is true because `awk' does so much for
you.

   It should be noted that these programs are not necessarily intended
to replace the installed versions on your system.  Nor may all of these
programs be fully compliant with the most recent POSIX standard.  This
is not a problem; their purpose is to illustrate `awk' language
programming for "real world" tasks.

   The programs are presented in alphabetical order.

* Menu:

* Cut Program::                 The `cut' utility.
* Egrep Program::               The `egrep' utility.
* Id Program::                  The `id' utility.
* Split Program::               The `split' utility.
* Tee Program::                 The `tee' utility.
* Uniq Program::                The `uniq' utility.
* Wc Program::                  The `wc' utility.


File: gawk.info,  Node: Cut Program,  Next: Egrep Program,  Up: Clones

13.2.1 Cutting out Fields and Columns
-------------------------------------

The `cut' utility selects, or "cuts," characters or fields from its
standard input and sends them to its standard output.  Fields are
separated by TABs by default, but you may supply a command-line option
to change the field "delimiter" (i.e., the field-separator character).
`cut''s definition of fields is less general than `awk''s.

   A common use of `cut' might be to pull out just the login name of
logged-on users from the output of `who'.  For example, the following
pipeline generates a sorted, unique list of the logged-on users:

     who | cut -c1-8 | sort | uniq

   The options for `cut' are:

`-c LIST'
     Use LIST as the list of characters to cut out.  Items within the
     list may be separated by commas, and ranges of characters can be
     separated with dashes.  The list `1-8,15,22-35' specifies
     characters 1 through 8, 15, and 22 through 35.

`-f LIST'
     Use LIST as the list of fields to cut out.

`-d DELIM'
     Use DELIM as the field-separator character instead of the TAB
     character.

`-s'
     Suppress printing of lines that do not contain the field delimiter.

   The `awk' implementation of `cut' uses the `getopt()' library
function (*note Getopt Function::) and the `join()' library function
(*note Join Function::).

   The program begins with a comment describing the options, the library
functions needed, and a `usage()' function that prints out a usage
message and exits.  `usage()' is called if invalid arguments are
supplied:

     # cut.awk --- implement cut in awk

     # Options:
     #    -f list     Cut fields
     #    -d c        Field delimiter character
     #    -c list     Cut characters
     #
     #    -s          Suppress lines without the delimiter
     #
     # Requires getopt() and join() library functions

     function usage(    e1, e2)
     {
         e1 = "usage: cut [-f list] [-d c] [-s] [files...]"
         e2 = "usage: cut [-c list] [files...]"
         print e1 > "/dev/stderr"
         print e2 > "/dev/stderr"
         exit 1
     }

The variables `e1' and `e2' are used so that the function fits nicely
on the screen.

   Next comes a `BEGIN' rule that parses the command-line options.  It
sets `FS' to a single TAB character, because that is `cut''s default
field separator. The rule then sets the output field separator to be the
same as the input field separator.  A loop using `getopt()' steps
through the command-line options.  Exactly one of the variables
`by_fields' or `by_chars' is set to true, to indicate that processing
should be done by fields or by characters, respectively.  When cutting
by characters, the output field separator is set to the null string:

     BEGIN    \
     {
         FS = "\t"    # default
         OFS = FS
         while ((c = getopt(ARGC, ARGV, "sf:c:d:")) != -1) {
             if (c == "f") {
                 by_fields = 1
                 fieldlist = Optarg
             } else if (c == "c") {
                 by_chars = 1
                 fieldlist = Optarg
                 OFS = ""
             } else if (c == "d") {
                 if (length(Optarg) > 1) {
                     printf("Using first character of %s" \
                            " for delimiter\n", Optarg) > "/dev/stderr"
                     Optarg = substr(Optarg, 1, 1)
                 }
                 FS = Optarg
                 OFS = FS
                 if (FS == " ")    # defeat awk semantics
                     FS = "[ ]"
             } else if (c == "s")
                 suppress++
             else
                 usage()
         }

         # Clear out options
         for (i = 1; i < Optind; i++)
             ARGV[i] = ""

   The code must take special care when the field delimiter is a space.
Using a single space (`" "') for the value of `FS' is incorrect--`awk'
would separate fields with runs of spaces, TABs, and/or newlines, and
we want them to be separated with individual spaces.  Also remember
that after `getopt()' is through (as described in *note Getopt
Function::), we have to clear out all the elements of `ARGV' from 1 to
`Optind', so that `awk' does not try to process the command-line options
as file names.

   After dealing with the command-line options, the program verifies
that the options make sense.  Only one or the other of `-c' and `-f'
should be used, and both require a field list.  Then the program calls
either `set_fieldlist()' or `set_charlist()' to pull apart the list of
fields or characters:

         if (by_fields && by_chars)
             usage()

         if (by_fields == 0 && by_chars == 0)
             by_fields = 1    # default

         if (fieldlist == "") {
             print "cut: needs list for -c or -f" > "/dev/stderr"
             exit 1
         }

         if (by_fields)
             set_fieldlist()
         else
             set_charlist()
     }

   `set_fieldlist()' splits the field list apart at the commas into an
array.  Then, for each element of the array, it looks to see if the
element is actually a range, and if so, splits it apart.  The function
checks the range to make sure that the first number is smaller than the
second.  Each number in the list is added to the `flist' array, which
simply lists the fields that will be printed.  Normal field splitting
is used.  The program lets `awk' handle the job of doing the field
splitting:

     function set_fieldlist(        n, m, i, j, k, f, g)
     {
         n = split(fieldlist, f, ",")
         j = 1    # index in flist
         for (i = 1; i <= n; i++) {
             if (index(f[i], "-") != 0) { # a range
                 m = split(f[i], g, "-")
                 if (m != 2 || g[1] >= g[2]) {
                     printf("bad field list: %s\n",
                                       f[i]) > "/dev/stderr"
                     exit 1
                 }
                 for (k = g[1]; k <= g[2]; k++)
                     flist[j++] = k
             } else
                 flist[j++] = f[i]
         }
         nfields = j - 1
     }

   The `set_charlist()' function is more complicated than
`set_fieldlist()'.  The idea here is to use `gawk''s `FIELDWIDTHS'
variable (*note Constant Size::), which describes constant-width input.
When using a character list, that is exactly what we have.

   Setting up `FIELDWIDTHS' is more complicated than simply listing the
fields that need to be printed.  We have to keep track of the fields to
print and also the intervening characters that have to be skipped.  For
example, suppose you wanted characters 1 through 8, 15, and 22 through
35.  You would use `-c 1-8,15,22-35'.  The necessary value for
`FIELDWIDTHS' is `"8 6 1 6 14"'.  This yields five fields, and the
fields to print are `$1', `$3', and `$5'.  The intermediate fields are
"filler", which is stuff in between the desired data.  `flist' lists
the fields to print, and `t' tracks the complete field list, including
filler fields:

     function set_charlist(    field, i, j, f, g, t,
                               filler, last, len)
     {
         field = 1   # count total fields
         n = split(fieldlist, f, ",")
         j = 1       # index in flist
         for (i = 1; i <= n; i++) {
             if (index(f[i], "-") != 0) { # range
                 m = split(f[i], g, "-")
                 if (m != 2 || g[1] >= g[2]) {
                     printf("bad character list: %s\n",
                                    f[i]) > "/dev/stderr"
                     exit 1
                 }
                 len = g[2] - g[1] + 1
                 if (g[1] > 1)  # compute length of filler
                     filler = g[1] - last - 1
                 else
                     filler = 0
                 if (filler)
                     t[field++] = filler
                 t[field++] = len  # length of field
                 last = g[2]
                 flist[j++] = field - 1
             } else {
                 if (f[i] > 1)
                     filler = f[i] - last - 1
                 else
                     filler = 0
                 if (filler)
                     t[field++] = filler
                 t[field++] = 1
                 last = f[i]
                 flist[j++] = field - 1
             }
         }
         FIELDWIDTHS = join(t, 1, field - 1)
         nfields = j - 1
     }

   Next is the rule that actually processes the data.  If the `-s'
option is given, then `suppress' is true.  The first `if' statement
makes sure that the input record does have the field separator.  If
`cut' is processing fields, `suppress' is true, and the field separator
character is not in the record, then the record is skipped.

   If the record is valid, then `gawk' has split the data into fields,
either using the character in `FS' or using fixed-length fields and
`FIELDWIDTHS'.  The loop goes through the list of fields that should be
printed.  The corresponding field is printed if it contains data.  If
the next field also has data, then the separator character is written
out between the fields:

     {
         if (by_fields && suppress && index($0, FS) != 0)
             next

         for (i = 1; i <= nfields; i++) {
             if ($flist[i] != "") {
                 printf "%s", $flist[i]
                 if (i < nfields && $flist[i+1] != "")
                     printf "%s", OFS
             }
         }
         print ""
     }

   This version of `cut' relies on `gawk''s `FIELDWIDTHS' variable to
do the character-based cutting.  While it is possible in other `awk'
implementations to use `substr()' (*note String Functions::), it is
also extremely painful.  The `FIELDWIDTHS' variable supplies an elegant
solution to the problem of picking the input line apart by characters.


File: gawk.info,  Node: Egrep Program,  Next: Id Program,  Prev: Cut Program,  Up: Clones

13.2.2 Searching for Regular Expressions in Files
-------------------------------------------------

The `egrep' utility searches files for patterns.  It uses regular
expressions that are almost identical to those available in `awk'
(*note Regexp::).  You invoke it as follows:

     egrep [ OPTIONS ] 'PATTERN' FILES ...

   The PATTERN is a regular expression.  In typical usage, the regular
expression is quoted to prevent the shell from expanding any of the
special characters as file name wildcards.  Normally, `egrep' prints
the lines that matched.  If multiple file names are provided on the
command line, each output line is preceded by the name of the file and
a colon.

   The options to `egrep' are as follows:

`-c'
     Print out a count of the lines that matched the pattern, instead
     of the lines themselves.

`-s'
     Be silent.  No output is produced and the exit value indicates
     whether the pattern was matched.

`-v'
     Invert the sense of the test. `egrep' prints the lines that do
     _not_ match the pattern and exits successfully if the pattern is
     not matched.

`-i'
     Ignore case distinctions in both the pattern and the input data.

`-l'
     Only print (list) the names of the files that matched, not the
     lines that matched.

`-e PATTERN'
     Use PATTERN as the regexp to match.  The purpose of the `-e'
     option is to allow patterns that start with a `-'.

   This version uses the `getopt()' library function (*note Getopt
Function::) and the file transition library program (*note Filetrans
Function::).

   The program begins with a descriptive comment and then a `BEGIN' rule
that processes the command-line arguments with `getopt()'.  The `-i'
(ignore case) option is particularly easy with `gawk'; we just use the
`IGNORECASE' built-in variable (*note Built-in Variables::):

     # egrep.awk --- simulate egrep in awk
     #
     # Options:
     #    -c    count of lines
     #    -s    silent - use exit value
     #    -v    invert test, success if no match
     #    -i    ignore case
     #    -l    print filenames only
     #    -e    argument is pattern
     #
     # Requires getopt and file transition library functions

     BEGIN {
         while ((c = getopt(ARGC, ARGV, "ce:svil")) != -1) {
             if (c == "c")
                 count_only++
             else if (c == "s")
                 no_print++
             else if (c == "v")
                 invert++
             else if (c == "i")
                 IGNORECASE = 1
             else if (c == "l")
                 filenames_only++
             else if (c == "e")
                 pattern = Optarg
             else
                 usage()
         }

   Next comes the code that handles the `egrep'-specific behavior. If no
pattern is supplied with `-e', the first nonoption on the command line
is used.  The `awk' command-line arguments up to `ARGV[Optind]' are
cleared, so that `awk' won't try to process them as files.  If no files
are specified, the standard input is used, and if multiple files are
specified, we make sure to note this so that the file names can precede
the matched lines in the output:

         if (pattern == "")
             pattern = ARGV[Optind++]

         for (i = 1; i < Optind; i++)
             ARGV[i] = ""
         if (Optind >= ARGC) {
             ARGV[1] = "-"
             ARGC = 2
         } else if (ARGC - Optind > 1)
             do_filenames++

     #    if (IGNORECASE)
     #        pattern = tolower(pattern)
     }

   The last two lines are commented out, since they are not needed in
`gawk'.  They should be uncommented if you have to use another version
of `awk'.

   The next set of lines should be uncommented if you are not using
`gawk'.  This rule translates all the characters in the input line into
lowercase if the `-i' option is specified.(1) The rule is commented out
since it is not necessary with `gawk':

     #{
     #    if (IGNORECASE)
     #        $0 = tolower($0)
     #}

   The `beginfile()' function is called by the rule in `ftrans.awk'
when each new file is processed.  In this case, it is very simple; all
it does is initialize a variable `fcount' to zero. `fcount' tracks how
many lines in the current file matched the pattern.  Naming the
parameter `junk' shows we know that `beginfile()' is called with a
parameter, but that we're not interested in its value:

     function beginfile(junk)
     {
         fcount = 0
     }

   The `endfile()' function is called after each file has been
processed.  It affects the output only when the user wants a count of
the number of lines that matched.  `no_print' is true only if the exit
status is desired.  `count_only' is true if line counts are desired.
`egrep' therefore only prints line counts if printing and counting are
enabled.  The output format must be adjusted depending upon the number
of files to process.  Finally, `fcount' is added to `total', so that we
know the total number of lines that matched the pattern:

     function endfile(file)
     {
         if (! no_print && count_only) {
             if (do_filenames)
                 print file ":" fcount
             else
                 print fcount
         }

         total += fcount
     }

   The following rule does most of the work of matching lines. The
variable `matches' is true if the line matched the pattern. If the user
wants lines that did not match, the sense of `matches' is inverted
using the `!' operator. `fcount' is incremented with the value of
`matches', which is either one or zero, depending upon a successful or
unsuccessful match.  If the line does not match, the `next' statement
just moves on to the next record.

   A number of additional tests are made, but they are only done if we
are not counting lines.  First, if the user only wants exit status
(`no_print' is true), then it is enough to know that _one_ line in this
file matched, and we can skip on to the next file with `nextfile'.
Similarly, if we are only printing file names, we can print the file
name, and then skip to the next file with `nextfile'.  Finally, each
line is printed, with a leading file name and colon if necessary:

     {
         matches = ($0 ~ pattern)
         if (invert)
             matches = ! matches

         fcount += matches    # 1 or 0

         if (! matches)
             next

         if (! count_only) {
             if (no_print)
                 nextfile

             if (filenames_only) {
                 print FILENAME
                 nextfile
             }

             if (do_filenames)
                 print FILENAME ":" $0
             else
                 print
         }
     }

   The `END' rule takes care of producing the correct exit status. If
there are no matches, the exit status is one; otherwise it is zero:

     END    \
     {
         if (total == 0)
             exit 1
         exit 0
     }

   The `usage()' function prints a usage message in case of invalid
options, and then exits:

     function usage(    e)
     {
         e = "Usage: egrep [-csvil] [-e pat] [files ...]"
         e = e "\n\tegrep [-csvil] pat [files ...]"
         print e > "/dev/stderr"
         exit 1
     }

   The variable `e' is used so that the function fits nicely on the
printed page.

   Just a note on programming style: you may have noticed that the `END'
rule uses backslash continuation, with the open brace on a line by
itself.  This is so that it more closely resembles the way functions
are written.  Many of the examples in this major node use this style.
You can decide for yourself if you like writing your `BEGIN' and `END'
rules this way or not.

   ---------- Footnotes ----------

   (1) It also introduces a subtle bug; if a match happens, we output
the translated line, not the original.


File: gawk.info,  Node: Id Program,  Next: Split Program,  Prev: Egrep Program,  Up: Clones

13.2.3 Printing out User Information
------------------------------------

The `id' utility lists a user's real and effective user ID numbers,
real and effective group ID numbers, and the user's group set, if any.
`id' only prints the effective user ID and group ID if they are
different from the real ones.  If possible, `id' also supplies the
corresponding user and group names.  The output might look like this:

     $ id
     -| uid=500(arnold) gid=500(arnold) groups=6(disk),7(lp),19(floppy)

   This information is part of what is provided by `gawk''s `PROCINFO'
array (*note Built-in Variables::).  However, the `id' utility provides
a more palatable output than just individual numbers.

   Here is a simple version of `id' written in `awk'.  It uses the user
database library functions (*note Passwd Functions::) and the group
database library functions (*note Group Functions::):

   The program is fairly straightforward.  All the work is done in the
`BEGIN' rule.  The user and group ID numbers are obtained from
`PROCINFO'.  The code is repetitive.  The entry in the user database
for the real user ID number is split into parts at the `:'. The name is
the first field.  Similar code is used for the effective user ID number
and the group numbers:

     # id.awk --- implement id in awk
     #
     # Requires user and group library functions
     # output is:
     # uid=12(foo) euid=34(bar) gid=3(baz) \
     #             egid=5(blat) groups=9(nine),2(two),1(one)

     BEGIN    \
     {
         uid = PROCINFO["uid"]
         euid = PROCINFO["euid"]
         gid = PROCINFO["gid"]
         egid = PROCINFO["egid"]

         printf("uid=%d", uid)
         pw = getpwuid(uid)
         if (pw != "") {
             split(pw, a, ":")
             printf("(%s)", a[1])
         }

         if (euid != uid) {
             printf(" euid=%d", euid)
             pw = getpwuid(euid)
             if (pw != "") {
                 split(pw, a, ":")
                 printf("(%s)", a[1])
             }
         }

         printf(" gid=%d", gid)
         pw = getgrgid(gid)
         if (pw != "") {
             split(pw, a, ":")
             printf("(%s)", a[1])
         }

         if (egid != gid) {
             printf(" egid=%d", egid)
             pw = getgrgid(egid)
             if (pw != "") {
                 split(pw, a, ":")
                 printf("(%s)", a[1])
             }
         }

         for (i = 1; ("group" i) in PROCINFO; i++) {
             if (i == 1)
                 printf(" groups=")
             group = PROCINFO["group" i]
             printf("%d", group)
             pw = getgrgid(group)
             if (pw != "") {
                 split(pw, a, ":")
                 printf("(%s)", a[1])
             }
             if (("group" (i+1)) in PROCINFO)
                 printf(",")
         }

         print ""
     }

   The test in the `for' loop is worth noting.  Any supplementary
groups in the `PROCINFO' array have the indices `"group1"' through
`"groupN"' for some N, i.e., the total number of supplementary groups.
However, we don't know in advance how many of these groups there are.

   This loop works by starting at one, concatenating the value with
`"group"', and then using `in' to see if that value is in the array.
Eventually, `i' is incremented past the last group in the array and the
loop exits.

   The loop is also correct if there are _no_ supplementary groups;
then the condition is false the first time it's tested, and the loop
body never executes.


File: gawk.info,  Node: Split Program,  Next: Tee Program,  Prev: Id Program,  Up: Clones

13.2.4 Splitting a Large File into Pieces
-----------------------------------------

The `split' program splits large text files into smaller pieces.  Usage
is as follows:(1)

     split [-COUNT] file [ PREFIX ]

   By default, the output files are named `xaa', `xab', and so on. Each
file has 1000 lines in it, with the likely exception of the last file.
To change the number of lines in each file, supply a number on the
command line preceded with a minus; e.g., `-500' for files with 500
lines in them instead of 1000.  To change the name of the output files
to something like `myfileaa', `myfileab', and so on, supply an
additional argument that specifies the file name prefix.

   Here is a version of `split' in `awk'. It uses the `ord()' and
`chr()' functions presented in *note Ordinal Functions::.

   The program first sets its defaults, and then tests to make sure
there are not too many arguments.  It then looks at each argument in
turn.  The first argument could be a minus sign followed by a number.
If it is, this happens to look like a negative number, so it is made
positive, and that is the count of lines.  The data file name is
skipped over and the final argument is used as the prefix for the
output file names:

     # split.awk --- do split in awk
     #
     # Requires ord() and chr() library functions
     # usage: split [-num] [file] [outname]

     BEGIN {
         outfile = "x"    # default
         count = 1000
         if (ARGC > 4)
             usage()

         i = 1
         if (ARGV[i] ~ /^-[[:digit:]]+$/) {
             count = -ARGV[i]
             ARGV[i] = ""
             i++
         }
         # test argv in case reading from stdin instead of file
         if (i in ARGV)
             i++    # skip data file name
         if (i in ARGV) {
             outfile = ARGV[i]
             ARGV[i] = ""
         }

         s1 = s2 = "a"
         out = (outfile s1 s2)
     }

   The next rule does most of the work. `tcount' (temporary count)
tracks how many lines have been printed to the output file so far. If
it is greater than `count', it is time to close the current file and
start a new one.  `s1' and `s2' track the current suffixes for the file
name. If they are both `z', the file is just too big.  Otherwise, `s1'
moves to the next letter in the alphabet and `s2' starts over again at
`a':

     {
         if (++tcount > count) {
             close(out)
             if (s2 == "z") {
                 if (s1 == "z") {
                     printf("split: %s is too large to split\n",
                            FILENAME) > "/dev/stderr"
                     exit 1
                 }
                 s1 = chr(ord(s1) + 1)
                 s2 = "a"
             }
             else
                 s2 = chr(ord(s2) + 1)
             out = (outfile s1 s2)
             tcount = 1
         }
         print > out
     }

The `usage()' function simply prints an error message and exits:

     function usage(   e)
     {
         e = "usage: split [-num] [file] [outname]"
         print e > "/dev/stderr"
         exit 1
     }

The variable `e' is used so that the function fits nicely on the screen.

   This program is a bit sloppy; it relies on `awk' to automatically
close the last file instead of doing it in an `END' rule.  It also
assumes that letters are contiguous in the character set, which isn't
true for EBCDIC systems.

   ---------- Footnotes ----------

   (1) This is the traditional usage. The POSIX usage is different, but
not relevant for what the program aims to demonstrate.


File: gawk.info,  Node: Tee Program,  Next: Uniq Program,  Prev: Split Program,  Up: Clones

13.2.5 Duplicating Output into Multiple Files
---------------------------------------------

The `tee' program is known as a "pipe fitting."  `tee' copies its
standard input to its standard output and also duplicates it to the
files named on the command line.  Its usage is as follows:

     tee [-a] file ...

   The `-a' option tells `tee' to append to the named files, instead of
truncating them and starting over.

   The `BEGIN' rule first makes a copy of all the command-line arguments
into an array named `copy'.  `ARGV[0]' is not copied, since it is not
needed.  `tee' cannot use `ARGV' directly, since `awk' attempts to
process each file name in `ARGV' as input data.

   If the first argument is `-a', then the flag variable `append' is
set to true, and both `ARGV[1]' and `copy[1]' are deleted. If `ARGC' is
less than two, then no file names were supplied and `tee' prints a
usage message and exits.  Finally, `awk' is forced to read the standard
input by setting `ARGV[1]' to `"-"' and `ARGC' to two:

     # tee.awk --- tee in awk
     #
     # Copy standard input to all named output files.
     # Append content if -a option is supplied.
     #
     BEGIN    \
     {
         for (i = 1; i < ARGC; i++)
             copy[i] = ARGV[i]

         if (ARGV[1] == "-a") {
             append = 1
             delete ARGV[1]
             delete copy[1]
             ARGC--
         }
         if (ARGC < 2) {
             print "usage: tee [-a] file ..." > "/dev/stderr"
             exit 1
         }
         ARGV[1] = "-"
         ARGC = 2
     }

   The following single rule does all the work.  Since there is no
pattern, it is executed for each line of input.  The body of the rule
simply prints the line into each file on the command line, and then to
the standard output:

     {
         # moving the if outside the loop makes it run faster
         if (append)
             for (i in copy)
                 print >> copy[i]
         else
             for (i in copy)
                 print > copy[i]
         print
     }

It is also possible to write the loop this way:

     for (i in copy)
         if (append)
             print >> copy[i]
         else
             print > copy[i]

This is more concise but it is also less efficient.  The `if' is tested
for each record and for each output file.  By duplicating the loop
body, the `if' is only tested once for each input record.  If there are
N input records and M output files, the first method only executes N
`if' statements, while the second executes N`*'M `if' statements.

   Finally, the `END' rule cleans up by closing all the output files:

     END    \
     {
         for (i in copy)
             close(copy[i])
     }


File: gawk.info,  Node: Uniq Program,  Next: Wc Program,  Prev: Tee Program,  Up: Clones

13.2.6 Printing Nonduplicated Lines of Text
-------------------------------------------

The `uniq' utility reads sorted lines of data on its standard input,
and by default removes duplicate lines.  In other words, it only prints
unique lines--hence the name.  `uniq' has a number of options. The
usage is as follows:

     uniq [-udc [-N]] [+N] [ INPUT FILE [ OUTPUT FILE ]]

   The options for `uniq' are:

`-d'
     Print only repeated lines.

`-u'
     Print only nonrepeated lines.

`-c'
     Count lines. This option overrides `-d' and `-u'.  Both repeated
     and nonrepeated lines are counted.

`-N'
     Skip N fields before comparing lines.  The definition of fields is
     similar to `awk''s default: nonwhitespace characters separated by
     runs of spaces and/or TABs.

`+N'
     Skip N characters before comparing lines.  Any fields specified
     with `-N' are skipped first.

`INPUT FILE'
     Data is read from the input file named on the command line,
     instead of from the standard input.

`OUTPUT FILE'
     The generated output is sent to the named output file, instead of
     to the standard output.

   Normally `uniq' behaves as if both the `-d' and `-u' options are
provided.

   `uniq' uses the `getopt()' library function (*note Getopt Function::)
and the `join()' library function (*note Join Function::).

   The program begins with a `usage()' function and then a brief
outline of the options and their meanings in comments.  The `BEGIN'
rule deals with the command-line arguments and options. It uses a trick
to get `getopt()' to handle options of the form `-25', treating such an
option as the option letter `2' with an argument of `5'. If indeed two
or more digits are supplied (`Optarg' looks like a number), `Optarg' is
concatenated with the option digit and then the result is added to zero
to make it into a number.  If there is only one digit in the option,
then `Optarg' is not needed. In this case, `Optind' must be decremented
so that `getopt()' processes it next time.  This code is admittedly a
bit tricky.

   If no options are supplied, then the default is taken, to print both
repeated and nonrepeated lines.  The output file, if provided, is
assigned to `outputfile'.  Early on, `outputfile' is initialized to the
standard output, `/dev/stdout':

     # uniq.awk --- do uniq in awk
     #
     # Requires getopt() and join() library functions

     function usage(    e)
     {
         e = "Usage: uniq [-udc [-n]] [+n] [ in [ out ]]"
         print e > "/dev/stderr"
         exit 1
     }

     # -c    count lines. overrides -d and -u
     # -d    only repeated lines
     # -u    only nonrepeated lines
     # -n    skip n fields
     # +n    skip n characters, skip fields first

     BEGIN   \
     {
         count = 1
         outputfile = "/dev/stdout"
         opts = "udc0:1:2:3:4:5:6:7:8:9:"
         while ((c = getopt(ARGC, ARGV, opts)) != -1) {
             if (c == "u")
                 non_repeated_only++
             else if (c == "d")
                 repeated_only++
             else if (c == "c")
                 do_count++
             else if (index("0123456789", c) != 0) {
                 # getopt requires args to options
                 # this messes us up for things like -5
                 if (Optarg ~ /^[[:digit:]]+$/)
                     fcount = (c Optarg) + 0
                 else {
                     fcount = c + 0
                     Optind--
                 }
             } else
                 usage()
         }

         if (ARGV[Optind] ~ /^\+[[:digit:]]+$/) {
             charcount = substr(ARGV[Optind], 2) + 0
             Optind++
         }

         for (i = 1; i < Optind; i++)
             ARGV[i] = ""

         if (repeated_only == 0 && non_repeated_only == 0)
             repeated_only = non_repeated_only = 1

         if (ARGC - Optind == 2) {
             outputfile = ARGV[ARGC - 1]
             ARGV[ARGC - 1] = ""
         }
     }

   The following function, `are_equal()', compares the current line,
`$0', to the previous line, `last'.  It handles skipping fields and
characters.  If no field count and no character count are specified,
`are_equal()' simply returns one or zero depending upon the result of a
simple string comparison of `last' and `$0'.  Otherwise, things get more
complicated.  If fields have to be skipped, each line is broken into an
array using `split()' (*note String Functions::); the desired fields
are then joined back into a line using `join()'.  The joined lines are
stored in `clast' and `cline'.  If no fields are skipped, `clast' and
`cline' are set to `last' and `$0', respectively.  Finally, if
characters are skipped, `substr()' is used to strip off the leading
`charcount' characters in `clast' and `cline'.  The two strings are
then compared and `are_equal()' returns the result:

     function are_equal(    n, m, clast, cline, alast, aline)
     {
         if (fcount == 0 && charcount == 0)
             return (last == $0)

         if (fcount > 0) {
             n = split(last, alast)
             m = split($0, aline)
             clast = join(alast, fcount+1, n)
             cline = join(aline, fcount+1, m)
         } else {
             clast = last
             cline = $0
         }
         if (charcount) {
             clast = substr(clast, charcount + 1)
             cline = substr(cline, charcount + 1)
         }

         return (clast == cline)
     }

   The following two rules are the body of the program.  The first one
is executed only for the very first line of data.  It sets `last' equal
to `$0', so that subsequent lines of text have something to be compared
to.

   The second rule does the work. The variable `equal' is one or zero,
depending upon the results of `are_equal()''s comparison. If `uniq' is
counting repeated lines, and the lines are equal, then it increments
the `count' variable.  Otherwise, it prints the line and resets `count',
since the two lines are not equal.

   If `uniq' is not counting, and if the lines are equal, `count' is
incremented.  Nothing is printed, since the point is to remove
duplicates.  Otherwise, if `uniq' is counting repeated lines and more
than one line is seen, or if `uniq' is counting nonrepeated lines and
only one line is seen, then the line is printed, and `count' is reset.

   Finally, similar logic is used in the `END' rule to print the final
line of input data:

     NR == 1 {
         last = $0
         next
     }

     {
         equal = are_equal()

         if (do_count) {    # overrides -d and -u
             if (equal)
                 count++
             else {
                 printf("%4d %s\n", count, last) > outputfile
                 last = $0
                 count = 1    # reset
             }
             next
         }

         if (equal)
             count++
         else {
             if ((repeated_only && count > 1) ||
                 (non_repeated_only && count == 1))
                     print last > outputfile
             last = $0
             count = 1
         }
     }

     END {
         if (do_count)
             printf("%4d %s\n", count, last) > outputfile
         else if ((repeated_only && count > 1) ||
                 (non_repeated_only && count == 1))
             print last > outputfile
         close(outputfile)
     }


File: gawk.info,  Node: Wc Program,  Prev: Uniq Program,  Up: Clones

13.2.7 Counting Things
----------------------

The `wc' (word count) utility counts lines, words, and characters in
one or more input files. Its usage is as follows:

     wc [-lwc] [ FILES ... ]

   If no files are specified on the command line, `wc' reads its
standard input. If there are multiple files, it also prints total
counts for all the files.  The options and their meanings are shown in
the following list:

`-l'
     Count only lines.

`-w'
     Count only words.  A "word" is a contiguous sequence of
     nonwhitespace characters, separated by spaces and/or TABs.
     Luckily, this is the normal way `awk' separates fields in its
     input data.

`-c'
     Count only characters.

   Implementing `wc' in `awk' is particularly elegant, since `awk' does
a lot of the work for us; it splits lines into words (i.e., fields) and
counts them, it counts lines (i.e., records), and it can easily tell us
how long a line is.

   This program uses the `getopt()' library function (*note Getopt
Function::) and the file-transition functions (*note Filetrans
Function::).

   This version has one notable difference from traditional versions of
`wc': it always prints the counts in the order lines, words, and
characters.  Traditional versions note the order of the `-l', `-w', and
`-c' options on the command line, and print the counts in that order.

   The `BEGIN' rule does the argument processing.  The variable
`print_total' is true if more than one file is named on the command
line:

     # wc.awk --- count lines, words, characters

     # Options:
     #    -l    only count lines
     #    -w    only count words
     #    -c    only count characters
     #
     # Default is to count lines, words, characters
     #
     # Requires getopt() and file transition library functions

     BEGIN {
         # let getopt() print a message about
         # invalid options. we ignore them
         while ((c = getopt(ARGC, ARGV, "lwc")) != -1) {
             if (c == "l")
                 do_lines = 1
             else if (c == "w")
                 do_words = 1
             else if (c == "c")
                 do_chars = 1
         }
         for (i = 1; i < Optind; i++)
             ARGV[i] = ""

         # if no options, do all
         if (! do_lines && ! do_words && ! do_chars)
             do_lines = do_words = do_chars = 1

         print_total = (ARGC - i > 2)
     }

   The `beginfile()' function is simple; it just resets the counts of
lines, words, and characters to zero, and saves the current file name in
`fname':

     function beginfile(file)
     {
         lines = words = chars = 0
         fname = FILENAME
     }

   The `endfile()' function adds the current file's numbers to the
running totals of lines, words, and characters.(1)  It then prints out
those numbers for the file that was just read. It relies on
`beginfile()' to reset the numbers for the following data file:

     function endfile(file)
     {
         tlines += lines
         twords += words
         tchars += chars
         if (do_lines)
             printf "\t%d", lines
         if (do_words)
             printf "\t%d", words
         if (do_chars)
             printf "\t%d", chars
         printf "\t%s\n", fname
     }

   There is one rule that is executed for each line. It adds the length
of the record, plus one, to `chars'.(2) Adding one plus the record
length is needed because the newline character separating records (the
value of `RS') is not part of the record itself, and thus not included
in its length.  Next, `lines' is incremented for each line read, and
`words' is incremented by the value of `NF', which is the number of
"words" on this line:

     # do per line
     {
         chars += length($0) + 1    # get newline
         lines++
         words += NF
     }

   Finally, the `END' rule simply prints the totals for all the files:

     END {
         if (print_total) {
             if (do_lines)
                 printf "\t%d", tlines
             if (do_words)
                 printf "\t%d", twords
             if (do_chars)
                 printf "\t%d", tchars
             print "\ttotal"
         }
     }

   ---------- Footnotes ----------

   (1) `wc' can't just use the value of `FNR' in `endfile()'. If you
examine the code in *note Filetrans Function::, you will see that `FNR'
has already been reset by the time `endfile()' is called.

   (2) Since `gawk' understands multibyte locales, this code counts
characters, not bytes.


File: gawk.info,  Node: Miscellaneous Programs,  Prev: Clones,  Up: Sample Programs

13.3 A Grab Bag of `awk' Programs
=================================

This minor node is a large "grab bag" of miscellaneous programs.  We
hope you find them both interesting and enjoyable.

* Menu:

* Dupword Program::             Finding duplicated words in a document.
* Alarm Program::               An alarm clock.
* Translate Program::           A program similar to the `tr' utility.
* Labels Program::              Printing mailing labels.
* Word Sorting::                A program to produce a word usage count.
* History Sorting::             Eliminating duplicate entries from a history
                                file.
* Extract Program::             Pulling out programs from Texinfo source
                                files.
* Simple Sed::                  A Simple Stream Editor.
* Igawk Program::               A wrapper for `awk' that includes
                                files.
* Anagram Program::             Finding anagrams from a dictionary.
* Signature Program::           People do amazing things with too much time on
                                their hands.


File: gawk.info,  Node: Dupword Program,  Next: Alarm Program,  Up: Miscellaneous Programs

13.3.1 Finding Duplicated Words in a Document
---------------------------------------------

A common error when writing large amounts of prose is to accidentally
duplicate words.  Typically you will see this in text as something like
"the the program does the following..."  When the text is online, often
the duplicated words occur at the end of one line and the beginning of
another, making them very difficult to spot.

   This program, `dupword.awk', scans through a file one line at a time
and looks for adjacent occurrences of the same word.  It also saves the
last word on a line (in the variable `prev') for comparison with the
first word on the next line.

   The first two statements make sure that the line is all lowercase,
so that, for example, "The" and "the" compare equal to each other.  The
next statement replaces nonalphanumeric and nonwhitespace characters
with spaces, so that punctuation does not affect the comparison either.
The characters are replaced with spaces so that formatting controls
don't create nonsense words (e.g., the Texinfo `@code{NF}' becomes
`codeNF' if punctuation is simply deleted).  The record is then resplit
into fields, yielding just the actual words on the line, and ensuring
that there are no empty fields.

   If there are no fields left after removing all the punctuation, the
current record is skipped.  Otherwise, the program loops through each
word, comparing it to the previous one:

     # dupword.awk --- find duplicate words in text
     {
         $0 = tolower($0)
         gsub(/[^[:alnum:][:blank:]]/, " ");
         $0 = $0         # re-split
         if (NF == 0)
             next
         if ($1 == prev)
             printf("%s:%d: duplicate %s\n",
                 FILENAME, FNR, $1)
         for (i = 2; i <= NF; i++)
             if ($i == $(i-1))
                 printf("%s:%d: duplicate %s\n",
                     FILENAME, FNR, $i)
         prev = $NF
     }


File: gawk.info,  Node: Alarm Program,  Next: Translate Program,  Prev: Dupword Program,  Up: Miscellaneous Programs

13.3.2 An Alarm Clock Program
-----------------------------

     Nothing cures insomnia like a ringing alarm clock.
     Arnold Robbins

   The following program is a simple "alarm clock" program.  You give
it a time of day and an optional message.  At the specified time, it
prints the message on the standard output. In addition, you can give it
the number of times to repeat the message as well as a delay between
repetitions.

   This program uses the `gettimeofday()' function from *note
Gettimeofday Function::.

   All the work is done in the `BEGIN' rule.  The first part is argument
checking and setting of defaults: the delay, the count, and the message
to print.  If the user supplied a message without the ASCII BEL
character (known as the "alert" character, `"\a"'), then it is added to
the message.  (On many systems, printing the ASCII BEL generates an
audible alert. Thus when the alarm goes off, the system calls attention
to itself in case the user is not looking at the computer.)  Just for a
change, this program uses a `switch' statement (*note Switch
Statement::), but the processing could be done with a series of
`if'-`else' statements instead.  Here is the program:

     # alarm.awk --- set an alarm
     #
     # Requires gettimeofday() library function
     # usage: alarm time [ "message" [ count [ delay ] ] ]

     BEGIN    \
     {
         # Initial argument sanity checking
         usage1 = "usage: alarm time ['message' [count [delay]]]"
         usage2 = sprintf("\t(%s) time ::= hh:mm", ARGV[1])

         if (ARGC < 2) {
             print usage1 > "/dev/stderr"
             print usage2 > "/dev/stderr"
             exit 1
         }
         switch (ARGC) {
         case 5:
             delay = ARGV[4] + 0
             # fall through
         case 4:
             count = ARGV[3] + 0
             # fall through
         case 3:
             message = ARGV[2]
             break
         default:
             if (ARGV[1] !~ /[[:digit:]]?[[:digit:]]:[[:digit:]]{2}/) {
                 print usage1 > "/dev/stderr"
                 print usage2 > "/dev/stderr"
                 exit 1
             }
             break
         }

         # set defaults for once we reach the desired time
         if (delay == 0)
             delay = 180    # 3 minutes
         if (count == 0)
             count = 5
         if (message == "")
             message = sprintf("\aIt is now %s!\a", ARGV[1])
         else if (index(message, "\a") == 0)
             message = "\a" message "\a"

   The next minor node of code turns the alarm time into hours and
minutes, converts it (if necessary) to a 24-hour clock, and then turns
that time into a count of the seconds since midnight.  Next it turns
the current time into a count of seconds since midnight.  The
difference between the two is how long to wait before setting off the
alarm:

         # split up alarm time
         split(ARGV[1], atime, ":")
         hour = atime[1] + 0    # force numeric
         minute = atime[2] + 0  # force numeric

         # get current broken down time
         gettimeofday(now)

         # if time given is 12-hour hours and it's after that
         # hour, e.g., `alarm 5:30' at 9 a.m. means 5:30 p.m.,
         # then add 12 to real hour
         if (hour < 12 && now["hour"] > hour)
             hour += 12

         # set target time in seconds since midnight
         target = (hour * 60 * 60) + (minute * 60)

         # get current time in seconds since midnight
         current = (now["hour"] * 60 * 60) + \
                    (now["minute"] * 60) + now["second"]

         # how long to sleep for
         naptime = target - current
         if (naptime <= 0) {
             print "time is in the past!" > "/dev/stderr"
             exit 1
         }

   Finally, the program uses the `system()' function (*note I/O
Functions::) to call the `sleep' utility.  The `sleep' utility simply
pauses for the given number of seconds.  If the exit status is not zero,
the program assumes that `sleep' was interrupted and exits. If `sleep'
exited with an OK status (zero), then the program prints the message in
a loop, again using `sleep' to delay for however many seconds are
necessary:

         # zzzzzz..... go away if interrupted
         if (system(sprintf("sleep %d", naptime)) != 0)
             exit 1

         # time to notify!
         command = sprintf("sleep %d", delay)
         for (i = 1; i <= count; i++) {
             print message
             # if sleep command interrupted, go away
             if (system(command) != 0)
                 break
         }

         exit 0
     }


File: gawk.info,  Node: Translate Program,  Next: Labels Program,  Prev: Alarm Program,  Up: Miscellaneous Programs

13.3.3 Transliterating Characters
---------------------------------

The system `tr' utility transliterates characters.  For example, it is
often used to map uppercase letters into lowercase for further
processing:

     GENERATE DATA | tr 'A-Z' 'a-z' | PROCESS DATA ...

   `tr' requires two lists of characters.(1)  When processing the
input, the first character in the first list is replaced with the first
character in the second list, the second character in the first list is
replaced with the second character in the second list, and so on.  If
there are more characters in the "from" list than in the "to" list, the
last character of the "to" list is used for the remaining characters in
the "from" list.

   Some time ago, a user proposed that a transliteration function should
be added to `gawk'.  The following program was written to prove that
character transliteration could be done with a user-level function.
This program is not as complete as the system `tr' utility but it does
most of the job.

   The `translate' program demonstrates one of the few weaknesses of
standard `awk': dealing with individual characters is very painful,
requiring repeated use of the `substr()', `index()', and `gsub()'
built-in functions (*note String Functions::).(2) There are two
functions.  The first, `stranslate()', takes three arguments:

`from'
     A list of characters from which to translate.

`to'
     A list of characters to which to translate.

`target'
     The string on which to do the translation.

   Associative arrays make the translation part fairly easy. `t_ar'
holds the "to" characters, indexed by the "from" characters.  Then a
simple loop goes through `from', one character at a time.  For each
character in `from', if the character appears in `target', it is
replaced with the corresponding `to' character.

   The `translate()' function simply calls `stranslate()' using `$0' as
the target.  The main program sets two global variables, `FROM' and
`TO', from the command line, and then changes `ARGV' so that `awk'
reads from the standard input.

   Finally, the processing rule simply calls `translate()' for each
record:

     # translate.awk --- do tr-like stuff
     # Bugs: does not handle things like: tr A-Z a-z, it has
     # to be spelled out. However, if `to' is shorter than `from',
     # the last character in `to' is used for the rest of `from'.

     function stranslate(from, to, target,     lf, lt, ltarget, t_ar, i, c,
                                                                    result)
     {
         lf = length(from)
         lt = length(to)
         ltarget = length(target)
         for (i = 1; i <= lt; i++)
             t_ar[substr(from, i, 1)] = substr(to, i, 1)
         if (lt < lf)
             for (; i <= lf; i++)
                 t_ar[substr(from, i, 1)] = substr(to, lt, 1)
         for (i = 1; i <= ltarget; i++) {
             c = substr(target, i, 1)
             if (c in t_ar)
                 c = t_ar[c]
             result = result c
         }
         return result
     }

     function translate(from, to)
     {
         return $0 = stranslate(from, to, $0)
     }

     # main program
     BEGIN {
         if (ARGC < 3) {
             print "usage: translate from to" > "/dev/stderr"
             exit
         }
         FROM = ARGV[1]
         TO = ARGV[2]
         ARGC = 2
         ARGV[1] = "-"
     }

     {
         translate(FROM, TO)
         print
     }

   While it is possible to do character transliteration in a user-level
function, it is not necessarily efficient, and we (the `gawk' authors)
started to consider adding a built-in function.  However, shortly after
writing this program, we learned that the System V Release 4 `awk' had
added the `toupper()' and `tolower()' functions (*note String
Functions::).  These functions handle the vast majority of the cases
where character transliteration is necessary, and so we chose to simply
add those functions to `gawk' as well and then leave well enough alone.

   An obvious improvement to this program would be to set up the `t_ar'
array only once, in a `BEGIN' rule. However, this assumes that the
"from" and "to" lists will never change throughout the lifetime of the
program.

   ---------- Footnotes ----------

   (1) On some older systems, `tr' may require that the lists be
written as range expressions enclosed in square brackets (`[a-z]') and
quoted, to prevent the shell from attempting a file name expansion.
This is not a feature.

   (2) This program was written before `gawk' acquired the ability to
split each character in a string into separate array elements.


File: gawk.info,  Node: Labels Program,  Next: Word Sorting,  Prev: Translate Program,  Up: Miscellaneous Programs

13.3.4 Printing Mailing Labels
------------------------------

Here is a "real world"(1) program.  This script reads lists of names and
addresses and generates mailing labels.  Each page of labels has 20
labels on it, two across and 10 down.  The addresses are guaranteed to
be no more than five lines of data.  Each address is separated from the
next by a blank line.

   The basic idea is to read 20 labels worth of data.  Each line of
each label is stored in the `line' array.  The single rule takes care
of filling the `line' array and printing the page when 20 labels have
been read.

   The `BEGIN' rule simply sets `RS' to the empty string, so that `awk'
splits records at blank lines (*note Records::).  It sets `MAXLINES' to
100, since 100 is the maximum number of lines on the page (20 * 5 =
100).

   Most of the work is done in the `printpage()' function.  The label
lines are stored sequentially in the `line' array.  But they have to
print horizontally; `line[1]' next to `line[6]', `line[2]' next to
`line[7]', and so on.  Two loops are used to accomplish this.  The
outer loop, controlled by `i', steps through every 10 lines of data;
this is each row of labels.  The inner loop, controlled by `j', goes
through the lines within the row.  As `j' goes from 0 to 4, `i+j' is
the `j'-th line in the row, and `i+j+5' is the entry next to it.  The
output ends up looking something like this:

     line 1          line 6
     line 2          line 7
     line 3          line 8
     line 4          line 9
     line 5          line 10
     ...

The `printf' format string `%-41s' left-aligns the data and prints it
within a fixed-width field.

   As a final note, an extra blank line is printed at lines 21 and 61,
to keep the output lined up on the labels.  This is dependent on the
particular brand of labels in use when the program was written.  You
will also note that there are two blank lines at the top and two blank
lines at the bottom.

   The `END' rule arranges to flush the final page of labels; there may
not have been an even multiple of 20 labels in the data:

     # labels.awk --- print mailing labels

     # Each label is 5 lines of data that may have blank lines.
     # The label sheets have 2 blank lines at the top and 2 at
     # the bottom.

     BEGIN    { RS = "" ; MAXLINES = 100 }

     function printpage(    i, j)
     {
         if (Nlines <= 0)
             return

         printf "\n\n"        # header

         for (i = 1; i <= Nlines; i += 10) {
             if (i == 21 || i == 61)
                 print ""
             for (j = 0; j < 5; j++) {
                 if (i + j > MAXLINES)
                     break
                 printf "   %-41s %s\n", line[i+j], line[i+j+5]
             }
             print ""
         }

         printf "\n\n"        # footer

         delete line
     }

     # main rule
     {
         if (Count >= 20) {
             printpage()
             Count = 0
             Nlines = 0
         }
         n = split($0, a, "\n")
         for (i = 1; i <= n; i++)
             line[++Nlines] = a[i]
         for (; i <= 5; i++)
             line[++Nlines] = ""
         Count++
     }

     END    \
     {
         printpage()
     }

   ---------- Footnotes ----------

   (1) "Real world" is defined as "a program actually used to get
something done."


File: gawk.info,  Node: Word Sorting,  Next: History Sorting,  Prev: Labels Program,  Up: Miscellaneous Programs

13.3.5 Generating Word-Usage Counts
-----------------------------------

When working with large amounts of text, it can be interesting to know
how often different words appear.  For example, an author may overuse
certain words, in which case she might wish to find synonyms to
substitute for words that appear too often. This node develops a
program for counting words and presenting the frequency information in
a useful format.

   At first glance, a program like this would seem to do the job:

     # Print list of word frequencies

     {
         for (i = 1; i <= NF; i++)
             freq[$i]++
     }

     END {
         for (word in freq)
             printf "%s\t%d\n", word, freq[word]
     }

   The program relies on `awk''s default field splitting mechanism to
break each line up into "words," and uses an associative array named
`freq', indexed by each word, to count the number of times the word
occurs. In the `END' rule, it prints the counts.

   This program has several problems that prevent it from being useful
on real text files:

   * The `awk' language considers upper- and lowercase characters to be
     distinct.  Therefore, "bartender" and "Bartender" are not treated
     as the same word.  This is undesirable, since in normal text, words
     are capitalized if they begin sentences, and a frequency analyzer
     should not be sensitive to capitalization.

   * Words are detected using the `awk' convention that fields are
     separated just by whitespace.  Other characters in the input
     (except newlines) don't have any special meaning to `awk'.  This
     means that punctuation characters count as part of words.

   * The output does not come out in any useful order.  You're more
     likely to be interested in which words occur most frequently or in
     having an alphabetized table of how frequently each word occurs.

   The first problem can be solved by using `tolower()' to remove case
distinctions.  The second problem can be solved by using `gsub()' to
remove punctuation characters.  Finally, we solve the third problem by
using the system `sort' utility to process the output of the `awk'
script.  Here is the new version of the program:

     # wordfreq.awk --- print list of word frequencies

     {
         $0 = tolower($0)    # remove case distinctions
         # remove punctuation
         gsub(/[^[:alnum:]_[:blank:]]/, "", $0)
         for (i = 1; i <= NF; i++)
             freq[$i]++
     }

     END {
         for (word in freq)
             printf "%s\t%d\n", word, freq[word]
     }

   Assuming we have saved this program in a file named `wordfreq.awk',
and that the data is in `file1', the following pipeline:

     awk -f wordfreq.awk file1 | sort -k 2nr

produces a table of the words appearing in `file1' in order of
decreasing frequency.

   The `awk' program suitably massages the data and produces a word
frequency table, which is not ordered.  The `awk' script's output is
then sorted by the `sort' utility and printed on the screen.

   The options given to `sort' specify a sort that uses the second
field of each input line (skipping one field), that the sort keys
should be treated as numeric quantities (otherwise `15' would come
before `5'), and that the sorting should be done in descending
(reverse) order.

   The `sort' could even be done from within the program, by changing
the `END' action to:

     END {
         sort = "sort -k 2nr"
         for (word in freq)
             printf "%s\t%d\n", word, freq[word] | sort
         close(sort)
     }

   This way of sorting must be used on systems that do not have true
pipes at the command-line (or batch-file) level.  See the general
operating system documentation for more information on how to use the
`sort' program.


File: gawk.info,  Node: History Sorting,  Next: Extract Program,  Prev: Word Sorting,  Up: Miscellaneous Programs

13.3.6 Removing Duplicates from Unsorted Text
---------------------------------------------

The `uniq' program (*note Uniq Program::), removes duplicate lines from
_sorted_ data.

   Suppose, however, you need to remove duplicate lines from a data
file but that you want to preserve the order the lines are in.  A good
example of this might be a shell history file.  The history file keeps
a copy of all the commands you have entered, and it is not unusual to
repeat a command several times in a row.  Occasionally you might want
to compact the history by removing duplicate entries.  Yet it is
desirable to maintain the order of the original commands.

   This simple program does the job.  It uses two arrays.  The `data'
array is indexed by the text of each line.  For each line, `data[$0]'
is incremented.  If a particular line has not been seen before, then
`data[$0]' is zero.  In this case, the text of the line is stored in
`lines[count]'.  Each element of `lines' is a unique command, and the
indices of `lines' indicate the order in which those lines are
encountered.  The `END' rule simply prints out the lines, in order:

     # histsort.awk --- compact a shell history file
     # Thanks to Byron Rakitzis for the general idea

     {
         if (data[$0]++ == 0)
             lines[++count] = $0
     }

     END {
         for (i = 1; i <= count; i++)
             print lines[i]
     }

   This program also provides a foundation for generating other useful
information.  For example, using the following `print' statement in the
`END' rule indicates how often a particular command is used:

     print data[lines[i]], lines[i]

   This works because `data[$0]' is incremented each time a line is
seen.


File: gawk.info,  Node: Extract Program,  Next: Simple Sed,  Prev: History Sorting,  Up: Miscellaneous Programs

13.3.7 Extracting Programs from Texinfo Source Files
----------------------------------------------------

The nodes *note Library Functions::, and *note Sample Programs::, are
the top level nodes for a large number of `awk' programs.  If you want
to experiment with these programs, it is tedious to have to type them
in by hand.  Here we present a program that can extract parts of a
Texinfo input file into separate files.

This Info file is written in Texinfo (http://texinfo.org), the GNU
project's document formatting language.  A single Texinfo source file
can be used to produce both printed and online documentation.  The
Texinfo language is described fully, starting with *note (Texinfo)Top::
texinfo,Texinfo--The GNU Documentation Format.

   For our purposes, it is enough to know three things about Texinfo
input files:

   * The "at" symbol (`@') is special in Texinfo, much as the backslash
     (`\') is in C or `awk'.  Literal `@' symbols are represented in
     Texinfo source files as `@@'.

   * Comments start with either `@c' or `@comment'.  The
     file-extraction program works by using special comments that start
     at the beginning of a line.

   * Lines containing `@group' and `@end group' commands bracket
     example text that should not be split across a page boundary.
     (Unfortunately, TeX isn't always smart enough to do things exactly
     right, so we have to give it some help.)

   The following program, `extract.awk', reads through a Texinfo source
file and does two things, based on the special comments.  Upon seeing
`@c system ...', it runs a command, by extracting the command text from
the control line and passing it on to the `system()' function (*note
I/O Functions::).  Upon seeing `@c file FILENAME', each subsequent line
is sent to the file FILENAME, until `@c endfile' is encountered.  The
rules in `extract.awk' match either `@c' or `@comment' by letting the
`omment' part be optional.  Lines containing `@group' and `@end group'
are simply removed.  `extract.awk' uses the `join()' library function
(*note Join Function::).

   The example programs in the online Texinfo source for `GAWK:
Effective AWK Programming' (`gawk.texi') have all been bracketed inside
`file' and `endfile' lines.  The `gawk' distribution uses a copy of
`extract.awk' to extract the sample programs and install many of them
in a standard directory where `gawk' can find them.  The Texinfo file
looks something like this:

     ...
     This program has a @code{BEGIN} rule,
     that prints a nice message:

     @example
     @c file examples/messages.awk
     BEGIN @{ print "Don't panic!" @}
     @c end file
     @end example

     It also prints some final advice:

     @example
     @c file examples/messages.awk
     END @{ print "Always avoid bored archeologists!" @}
     @c end file
     @end example
     ...

   `extract.awk' begins by setting `IGNORECASE' to one, so that mixed
upper- and lowercase letters in the directives won't matter.

   The first rule handles calling `system()', checking that a command is
given (`NF' is at least three) and also checking that the command exits
with a zero exit status, signifying OK:

     # extract.awk --- extract files and run programs
     #                 from texinfo files

     BEGIN    { IGNORECASE = 1 }

     /^@c(omment)?[ \t]+system/    \
     {
         if (NF < 3) {
             e = (FILENAME ":" FNR)
             e = (e  ": badly formed `system' line")
             print e > "/dev/stderr"
             next
         }
         $1 = ""
         $2 = ""
         stat = system($0)
         if (stat != 0) {
             e = (FILENAME ":" FNR)
             e = (e ": warning: system returned " stat)
             print e > "/dev/stderr"
         }
     }

The variable `e' is used so that the rule fits nicely on the screen.

   The second rule handles moving data into files.  It verifies that a
file name is given in the directive.  If the file named is not the
current file, then the current file is closed.  Keeping the current file
open until a new file is encountered allows the use of the `>'
redirection for printing the contents, keeping open file management
simple.

   The `for' loop does the work.  It reads lines using `getline' (*note
Getline::).  For an unexpected end of file, it calls the
`unexpected_eof()' function.  If the line is an "endfile" line, then it
breaks out of the loop.  If the line is an `@group' or `@end group'
line, then it ignores it and goes on to the next line.  Similarly,
comments within examples are also ignored.

   Most of the work is in the following few lines.  If the line has no
`@' symbols, the program can print it directly.  Otherwise, each
leading `@' must be stripped off.  To remove the `@' symbols, the line
is split into separate elements of the array `a', using the `split()'
function (*note String Functions::).  The `@' symbol is used as the
separator character.  Each element of `a' that is empty indicates two
successive `@' symbols in the original line.  For each two empty
elements (`@@' in the original file), we have to add a single `@'
symbol back in.(1)

   When the processing of the array is finished, `join()' is called
with the value of `SUBSEP', to rejoin the pieces back into a single
line.  That line is then printed to the output file:

     /^@c(omment)?[ \t]+file/    \
     {
         if (NF != 3) {
             e = (FILENAME ":" FNR ": badly formed `file' line")
             print e > "/dev/stderr"
             next
         }
         if ($3 != curfile) {
             if (curfile != "")
                 close(curfile)
             curfile = $3
         }

         for (;;) {
             if ((getline line) <= 0)
                 unexpected_eof()
             if (line ~ /^@c(omment)?[ \t]+endfile/)
                 break
             else if (line ~ /^@(end[ \t]+)?group/)
                 continue
             else if (line ~ /^@c(omment+)?[ \t]+/)
                 continue
             if (index(line, "@") == 0) {
                 print line > curfile
                 continue
             }
             n = split(line, a, "@")
             # if a[1] == "", means leading @,
             # don't add one back in.
             for (i = 2; i <= n; i++) {
                 if (a[i] == "") { # was an @@
                     a[i] = "@"
                     if (a[i+1] == "")
                         i++
                 }
             }
             print join(a, 1, n, SUBSEP) > curfile
         }
     }

   An important thing to note is the use of the `>' redirection.
Output done with `>' only opens the file once; it stays open and
subsequent output is appended to the file (*note Redirection::).  This
makes it easy to mix program text and explanatory prose for the same
sample source file (as has been done here!) without any hassle.  The
file is only closed when a new data file name is encountered or at the
end of the input file.

   Finally, the function `unexpected_eof()' prints an appropriate error
message and then exits.  The `END' rule handles the final cleanup,
closing the open file:

     function unexpected_eof()
     {
         printf("%s:%d: unexpected EOF or error\n",
             FILENAME, FNR) > "/dev/stderr"
         exit 1
     }

     END {
         if (curfile)
             close(curfile)
     }

   ---------- Footnotes ----------

   (1) This program was written before `gawk' had the `gensub()'
function. Consider how you might use it to simplify the code.


File: gawk.info,  Node: Simple Sed,  Next: Igawk Program,  Prev: Extract Program,  Up: Miscellaneous Programs

13.3.8 A Simple Stream Editor
-----------------------------

The `sed' utility is a stream editor, a program that reads a stream of
data, makes changes to it, and passes it on.  It is often used to make
global changes to a large file or to a stream of data generated by a
pipeline of commands.  While `sed' is a complicated program in its own
right, its most common use is to perform global substitutions in the
middle of a pipeline:

     command1 < orig.data | sed 's/old/new/g' | command2 > result

   Here, `s/old/new/g' tells `sed' to look for the regexp `old' on each
input line and globally replace it with the text `new', i.e., all the
occurrences on a line.  This is similar to `awk''s `gsub()' function
(*note String Functions::).

   The following program, `awksed.awk', accepts at least two
command-line arguments: the pattern to look for and the text to replace
it with. Any additional arguments are treated as data file names to
process. If none are provided, the standard input is used:

     # awksed.awk --- do s/foo/bar/g using just print
     #    Thanks to Michael Brennan for the idea

     function usage()
     {
         print "usage: awksed pat repl [files...]" > "/dev/stderr"
         exit 1
     }

     BEGIN {
         # validate arguments
         if (ARGC < 3)
             usage()

         RS = ARGV[1]
         ORS = ARGV[2]

         # don't use arguments as files
         ARGV[1] = ARGV[2] = ""
     }

     # look ma, no hands!
     {
         if (RT == "")
             printf "%s", $0
         else
             print
     }

   The program relies on `gawk''s ability to have `RS' be a regexp, as
well as on the setting of `RT' to the actual text that terminates the
record (*note Records::).

   The idea is to have `RS' be the pattern to look for. `gawk'
automatically sets `$0' to the text between matches of the pattern.
This is text that we want to keep, unmodified.  Then, by setting `ORS'
to the replacement text, a simple `print' statement outputs the text we
want to keep, followed by the replacement text.

   There is one wrinkle to this scheme, which is what to do if the last
record doesn't end with text that matches `RS'.  Using a `print'
statement unconditionally prints the replacement text, which is not
correct.  However, if the file did not end in text that matches `RS',
`RT' is set to the null string.  In this case, we can print `$0' using
`printf' (*note Printf::).

   The `BEGIN' rule handles the setup, checking for the right number of
arguments and calling `usage()' if there is a problem. Then it sets
`RS' and `ORS' from the command-line arguments and sets `ARGV[1]' and
`ARGV[2]' to the null string, so that they are not treated as file names
(*note ARGC and ARGV::).

   The `usage()' function prints an error message and exits.  Finally,
the single rule handles the printing scheme outlined above, using
`print' or `printf' as appropriate, depending upon the value of `RT'.


File: gawk.info,  Node: Igawk Program,  Next: Anagram Program,  Prev: Simple Sed,  Up: Miscellaneous Programs

13.3.9 An Easy Way to Use Library Functions
-------------------------------------------

In *note Include Files::, we saw how `gawk' provides a built-in
file-inclusion capability.  However, this is a `gawk' extension.  This
minor node provides the motivation for making file inclusion available
for standard `awk', and shows how to do it using a combination of shell
and `awk' programming.

   Using library functions in `awk' can be very beneficial. It
encourages code reuse and the writing of general functions. Programs are
smaller and therefore clearer.  However, using library functions is
only easy when writing `awk' programs; it is painful when running them,
requiring multiple `-f' options.  If `gawk' is unavailable, then so too
is the `AWKPATH' environment variable and the ability to put `awk'
functions into a library directory (*note Options::).  It would be nice
to be able to write programs in the following manner:

     # library functions
     @include getopt.awk
     @include join.awk
     ...

     # main program
     BEGIN {
         while ((c = getopt(ARGC, ARGV, "a:b:cde")) != -1)
             ...
         ...
     }

   The following program, `igawk.sh', provides this service.  It
simulates `gawk''s searching of the `AWKPATH' variable and also allows
"nested" includes; i.e., a file that is included with `@include' can
contain further `@include' statements.  `igawk' makes an effort to only
include files once, so that nested includes don't accidentally include
a library function twice.

   `igawk' should behave just like `gawk' externally.  This means it
should accept all of `gawk''s command-line arguments, including the
ability to have multiple source files specified via `-f', and the
ability to mix command-line and library source files.

   The program is written using the POSIX Shell (`sh') command
language.(1) It works as follows:

  1. Loop through the arguments, saving anything that doesn't represent
     `awk' source code for later, when the expanded program is run.

  2. For any arguments that do represent `awk' text, put the arguments
     into a shell variable that will be expanded.  There are two cases:

       a. Literal text, provided with `--source' or `--source='.  This
          text is just appended directly.

       b. Source file names, provided with `-f'.  We use a neat trick
          and append `@include FILENAME' to the shell variable's
          contents.  Since the file-inclusion program works the way
          `gawk' does, this gets the text of the file included into the
          program at the correct point.

  3. Run an `awk' program (naturally) over the shell variable's
     contents to expand `@include' statements.  The expanded program is
     placed in a second shell variable.

  4. Run the expanded program with `gawk' and any other original
     command-line arguments that the user supplied (such as the data
     file names).

   This program uses shell variables extensively: for storing
command-line arguments, the text of the `awk' program that will expand
the user's program, for the user's original program, and for the
expanded program.  Doing so removes some potential problems that might
arise were we to use temporary files instead, at the cost of making the
script somewhat more complicated.

   The initial part of the program turns on shell tracing if the first
argument is `debug'.

   The next part loops through all the command-line arguments.  There
are several cases of interest:

`--'
     This ends the arguments to `igawk'.  Anything else should be
     passed on to the user's `awk' program without being evaluated.

`-W'
     This indicates that the next option is specific to `gawk'.  To make
     argument processing easier, the `-W' is appended to the front of
     the remaining arguments and the loop continues.  (This is an `sh'
     programming trick.  Don't worry about it if you are not familiar
     with `sh'.)

`-v, -F'
     These are saved and passed on to `gawk'.

`-f, --file, --file=, -Wfile='
     The file name is appended to the shell variable `program' with an
     `@include' statement.  The `expr' utility is used to remove the
     leading option part of the argument (e.g., `--file=').  (Typical
     `sh' usage would be to use the `echo' and `sed' utilities to do
     this work.  Unfortunately, some versions of `echo' evaluate escape
     sequences in their arguments, possibly mangling the program text.
     Using `expr' avoids this problem.)

`--source, --source=, -Wsource='
     The source text is appended to `program'.

`--version, -Wversion'
     `igawk' prints its version number, runs `gawk --version' to get
     the `gawk' version information, and then exits.

   If none of the `-f', `--file', `-Wfile', `--source', or `-Wsource'
arguments are supplied, then the first nonoption argument should be the
`awk' program.  If there are no command-line arguments left, `igawk'
prints an error message and exits.  Otherwise, the first argument is
appended to `program'.  In any case, after the arguments have been
processed, `program' contains the complete text of the original `awk'
program.

   The program is as follows:

     #! /bin/sh
     # igawk --- like gawk but do @include processing

     if [ "$1" = debug ]
     then
         set -x
         shift
     fi

     # A literal newline, so that program text is formatted correctly
     n='
     '

     # Initialize variables to empty
     program=
     opts=

     while [ $# -ne 0 ] # loop over arguments
     do
         case $1 in
         --)     shift
                 break ;;

         -W)     shift
                 # The ${x?'message here'} construct prints a
                 # diagnostic if $x is the null string
                 set -- -W"${@?'missing operand'}"
                 continue ;;

         -[vF])  opts="$opts $1 '${2?'missing operand'}'"
                 shift ;;

         -[vF]*) opts="$opts '$1'" ;;

         -f)     program="$program$n@include ${2?'missing operand'}"
                 shift ;;

         -f*)    f=$(expr "$1" : '-f\(.*\)')
                 program="$program$n@include $f" ;;

         -[W-]file=*)
                 f=$(expr "$1" : '-.file=\(.*\)')
                 program="$program$n@include $f" ;;

         -[W-]file)
                 program="$program$n@include ${2?'missing operand'}"
                 shift ;;

         -[W-]source=*)
                 t=$(expr "$1" : '-.source=\(.*\)')
                 program="$program$n$t" ;;

         -[W-]source)
                 program="$program$n${2?'missing operand'}"
                 shift ;;

         -[W-]version)
                 echo igawk: version 3.0 1>&2
                 gawk --version
                 exit 0 ;;

         -[W-]*) opts="$opts '$1'" ;;

         *)      break ;;
         esac
         shift
     done

     if [ -z "$program" ]
     then
          program=${1?'missing program'}
          shift
     fi

     # At this point, `program' has the program.

   The `awk' program to process `@include' directives is stored in the
shell variable `expand_prog'.  Doing this keeps the shell script
readable.  The `awk' program reads through the user's program, one line
at a time, using `getline' (*note Getline::).  The input file names and
`@include' statements are managed using a stack.  As each `@include' is
encountered, the current file name is "pushed" onto the stack and the
file named in the `@include' directive becomes the current file name.
As each file is finished, the stack is "popped," and the previous input
file becomes the current input file again.  The process is started by
making the original file the first one on the stack.

   The `pathto()' function does the work of finding the full path to a
file.  It simulates `gawk''s behavior when searching the `AWKPATH'
environment variable (*note AWKPATH Variable::).  If a file name has a
`/' in it, no path search is done.  Similarly, if the file name is
`"-"', then that string is used as-is.  Otherwise, the file name is
concatenated with the name of each directory in the path, and an
attempt is made to open the generated file name.  The only way to test
if a file can be read in `awk' is to go ahead and try to read it with
`getline'; this is what `pathto()' does.(2) If the file can be read, it
is closed and the file name is returned:

     expand_prog='

     function pathto(file,    i, t, junk)
     {
         if (index(file, "/") != 0)
             return file

         if (file == "-")
             return file

         for (i = 1; i <= ndirs; i++) {
             t = (pathlist[i] "/" file)
             if ((getline junk < t) > 0) {
                 # found it
                 close(t)
                 return t
             }
         }
         return ""
     }

   The main program is contained inside one `BEGIN' rule.  The first
thing it does is set up the `pathlist' array that `pathto()' uses.
After splitting the path on `:', null elements are replaced with `"."',
which represents the current directory:

     BEGIN {
         path = ENVIRON["AWKPATH"]
         ndirs = split(path, pathlist, ":")
         for (i = 1; i <= ndirs; i++) {
             if (pathlist[i] == "")
                 pathlist[i] = "."
         }

   The stack is initialized with `ARGV[1]', which will be `/dev/stdin'.
The main loop comes next.  Input lines are read in succession. Lines
that do not start with `@include' are printed verbatim.  If the line
does start with `@include', the file name is in `$2'.  `pathto()' is
called to generate the full path.  If it cannot, then the program
prints an error message and continues.

   The next thing to check is if the file is included already.  The
`processed' array is indexed by the full file name of each included
file and it tracks this information for us.  If the file is seen again,
a warning message is printed. Otherwise, the new file name is pushed
onto the stack and processing continues.

   Finally, when `getline' encounters the end of the input file, the
file is closed and the stack is popped.  When `stackptr' is less than
zero, the program is done:

         stackptr = 0
         input[stackptr] = ARGV[1] # ARGV[1] is first file

         for (; stackptr >= 0; stackptr--) {
             while ((getline < input[stackptr]) > 0) {
                 if (tolower($1) != "@include") {
                     print
                     continue
                 }
                 fpath = pathto($2)
                 if (fpath == "") {
                     printf("igawk:%s:%d: cannot find %s\n",
                         input[stackptr], FNR, $2) > "/dev/stderr"
                     continue
                 }
                 if (! (fpath in processed)) {
                     processed[fpath] = input[stackptr]
                     input[++stackptr] = fpath  # push onto stack
                 } else
                     print $2, "included in", input[stackptr],
                         "already included in",
                         processed[fpath] > "/dev/stderr"
             }
             close(input[stackptr])
         }
     }'  # close quote ends `expand_prog' variable

     processed_program=$(gawk -- "$expand_prog" /dev/stdin << EOF
     $program
     EOF
     )

   The shell construct `COMMAND << MARKER' is called a "here document".
Everything in the shell script up to the MARKER is fed to COMMAND as
input.  The shell processes the contents of the here document for
variable and command substitution (and possibly other things as well,
depending upon the shell).

   The shell construct `$(...)' is called "command substitution".  The
output of the command inside the parentheses is substituted into the
command line.  Because the result is used in a variable assignment, it
is saved as a single string, even if the results contain whitespace.

   The expanded program is saved in the variable `processed_program'.
It's done in these steps:

  1. Run `gawk' with the `@include'-processing program (the value of
     the `expand_prog' shell variable) on standard input.

  2. Standard input is the contents of the user's program, from the
     shell variable `program'.  Its contents are fed to `gawk' via a
     here document.

  3. The results of this processing are saved in the shell variable
     `processed_program' by using command substitution.

   The last step is to call `gawk' with the expanded program, along
with the original options and command-line arguments that the user
supplied.

     eval gawk $opts -- '"$processed_program"' '"$@"'

   The `eval' command is a shell construct that reruns the shell's
parsing process.  This keeps things properly quoted.

   This version of `igawk' represents my fifth version of this program.
There are four key simplifications that make the program work better:

   * Using `@include' even for the files named with `-f' makes building
     the initial collected `awk' program much simpler; all the
     `@include' processing can be done once.

   * Not trying to save the line read with `getline' in the `pathto()'
     function when testing for the file's accessibility for use with
     the main program simplifies things considerably.

   * Using a `getline' loop in the `BEGIN' rule does it all in one
     place.  It is not necessary to call out to a separate loop for
     processing nested `@include' statements.

   * Instead of saving the expanded program in a temporary file,
     putting it in a shell variable avoids some potential security
     problems.  This has the disadvantage that the script relies upon
     more features of the `sh' language, making it harder to follow for
     those who aren't familiar with `sh'.

   Also, this program illustrates that it is often worthwhile to combine
`sh' and `awk' programming together.  You can usually accomplish quite
a lot, without having to resort to low-level programming in C or C++,
and it is frequently easier to do certain kinds of string and argument
manipulation using the shell than it is in `awk'.

   Finally, `igawk' shows that it is not always necessary to add new
features to a program; they can often be layered on top.

   As an additional example of this, consider the idea of having two
files in a directory in the search path:

`default.awk'
     This file contains a set of default library functions, such as
     `getopt()' and `assert()'.

`site.awk'
     This file contains library functions that are specific to a site or
     installation; i.e., locally developed functions.  Having a
     separate file allows `default.awk' to change with new `gawk'
     releases, without requiring the system administrator to update it
     each time by adding the local functions.

   One user suggested that `gawk' be modified to automatically read
these files upon startup.  Instead, it would be very simple to modify
`igawk' to do this. Since `igawk' can process nested `@include'
directives, `default.awk' could simply contain `@include' statements
for the desired library functions.

   ---------- Footnotes ----------

   (1) Fully explaining the `sh' language is beyond the scope of this
book. We provide some minimal explanations, but see a good shell
programming book if you wish to understand things in more depth.

   (2) On some very old versions of `awk', the test `getline junk < t'
can loop forever if the file exists but is empty.  Caveat emptor.


File: gawk.info,  Node: Anagram Program,  Next: Signature Program,  Prev: Igawk Program,  Up: Miscellaneous Programs

13.3.10 Finding Anagrams From A Dictionary
------------------------------------------

An interesting programming challenge is to search for "anagrams" in a
word list (such as `/usr/share/dict/words' on many GNU/Linux systems).
One word is an anagram of another if both words contain the same letters
(for example, "babbling" and "blabbing").

   An elegant algorithm is presented in Column 2, Problem C of Jon
Bentley's `Programming Pearls', second edition.  The idea is to give
words that are anagrams a common signature, sort all the words together
by their signature, and then print them.  Dr. Bentley observes that
taking the letters in each word and sorting them produces that common
signature.

   The following program uses arrays of arrays to bring together words
with the same signature and array sorting to print the words in sorted
order.

     # anagram.awk --- An implementation of the anagram finding algorithm
     #                 from Jon Bentley's "Programming Pearls", 2nd edition.
     #                 Addison Wesley, 2000, ISBN 0-201-65788-0.
     #                 Column 2, Problem C, section 2.8, pp 18-20.

     /'s$/   { next }        # Skip possessives

   The program starts with a header, and then a rule to skip
possessives in the dictionary file. The next rule builds up the data
structure. The first dimension of the array is indexed by the
signature; the second dimension is the word itself:

     {
         key = word2key($1)  # Build signature
         data[key][$1] = $1  # Store word with signature
     }

   The `word2key()' function creates the signature.  It splits the word
apart into individual letters, sorts the letters, and then joins them
back together:

     # word2key --- split word apart into letters, sort, joining back together

     function word2key(word,     a, i, n, result)
     {
         n = split(word, a, "")
         asort(a)

         for (i = 1; i <= n; i++)
             result = result a[i]

         return result
     }

   Finally, the `END' rule traverses the array and prints out the
anagram lists.  It sends the output to the system `sort' command, since
otherwise the anagrams would appear in arbitrary order:

     END {
         sort = "sort"
         for (key in data) {
             # Sort words with same key
             nwords = asorti(data[key], words)
             if (nwords == 1)
                 continue

             # And print. Minor glitch: trailing space at end of each line
             for (j = 1; j <= nwords; j++)
                 printf("%s ", words[j]) | sort
             print "" | sort
         }
         close(sort)
     }

   Here is some partial output when the program is run:

     $ gawk -f anagram.awk /usr/share/dict/words | grep '^b'
     ...
     babbled blabbed
     babbler blabber brabble
     babblers blabbers brabbles
     babbling blabbing
     babbly blabby
     babel bable
     babels beslab
     babery yabber
     ...


File: gawk.info,  Node: Signature Program,  Prev: Anagram Program,  Up: Miscellaneous Programs

13.3.11 And Now For Something Completely Different
--------------------------------------------------

The following program was written by Davide Brini and is published on
his website (http://backreference.org/2011/02/03/obfuscated-awk/).  It
serves as his signature in the Usenet group `comp.lang.awk'.  He
supplies the following copyright terms:

     Copyright (C) 2008 Davide Brini

     Copying and distribution of the code published in this page, with
     or without modification, are permitted in any medium without
     royalty provided the copyright notice and this notice are
     preserved.

   Here is the program:

     awk 'BEGIN{O="~"~"~";o="=="=="==";o+=+o;x=O""O;while(X++<=x+o+o)c=c"%c";
     printf c,(x-O)*(x-O),x*(x-o)-o,x*(x-O)+x-O-o,+x*(x-O)-x+o,X*(o*o+O)+x-O,
     X*(X-x)-o*o,(x+X)*o*o+o,x*(X-x)-O-O,x-O+(O+o+X+x)*(o+O),X*X-X*(x-O)-x+O,
     O+X*(o*(o+O)+O),+x+O+X*o,x*(x-o),(o+X+x)*o*o-(x-O-O),O+(X-x)*(X+O),x-O}'

   We leave it to you to determine what the program does.


File: gawk.info,  Node: Debugger,  Next: Language History,  Prev: Sample Programs,  Up: Top

14 `dgawk': The `awk' Debugger
******************************

It would be nice if computer programs worked perfectly the first time
they were run, but in real life, this rarely happens for programs of
any complexity.  Thus, most programming languages have facilities
available for "debugging" programs, and now `awk' is no exception.

   The `dgawk' debugger is purposely modeled after the GNU Debugger
(GDB) (http://www.gnu.org/software/gdb/) command-line debugger.  If you
are familiar with GDB, learning `dgawk' is easy.

* Menu:

* Debugging::                   Introduction to `dgawk'.
* Sample dgawk session::        Sample `dgawk' session.
* List of Debugger Commands::   Main `dgawk' Commands.
* Readline Support::            Readline Support.
* Dgawk Limitations::           Limitations and future plans.


File: gawk.info,  Node: Debugging,  Next: Sample dgawk session,  Up: Debugger

14.1 Introduction to `dgawk'
============================

This minor node introduces debugging in general and begins the
discussion of debugging in `gawk'.

* Menu:

* Debugging Concepts::          Debugging In General.
* Debugging Terms::             Additional Debugging Concepts.
* Awk Debugging::               Awk Debugging.


File: gawk.info,  Node: Debugging Concepts,  Next: Debugging Terms,  Up: Debugging

14.1.1 Debugging In General
---------------------------

(If you have used debuggers in other languages, you may want to skip
ahead to the next section on the specific features of the `awk'
debugger.)

   Of course, a debugging program cannot remove bugs for you, since it
has no way of knowing what you or your users consider a "bug" and what
is a "feature."  (Sometimes, we humans have a hard time with this
ourselves.)  In that case, what can you expect from such a tool?  The
answer to that depends on the language being debugged, but in general,
you can expect at least the following:

   * The ability to watch a program execute its instructions one by one,
     giving you, the programmer, the opportunity to think about what is
     happening on a time scale of seconds, minutes, or hours, rather
     than the nanosecond time scale at which the code usually runs.

   * The opportunity to not only passively observe the operation of your
     program, but to control it and try different paths of execution,
     without having to change your source files.

   * The chance to see the values of data in the program at any point in
     execution, and also to change that data on the fly, to see how that
     affects what happens afterwards.  (This often includes the ability
     to look at internal data structures besides the variables you
     actually defined in your code.)

   * The ability to obtain additional information about your program's
     state or even its internal structure.

   All of these tools provide a great amount of help in using your own
skills and understanding of the goals of your program to find where it
is going wrong (or, for that matter, to better comprehend a perfectly
functional program that you or someone else wrote).


File: gawk.info,  Node: Debugging Terms,  Next: Awk Debugging,  Prev: Debugging Concepts,  Up: Debugging

14.1.2 Additional Debugging Concepts
------------------------------------

Before diving in to the details, we need to introduce several important
concepts that apply to just about all debuggers, including `dgawk'.
The following list defines terms used throughout the rest of this
major node.

"Stack Frame"
     Programs generally call functions during the course of their
     execution.  One function can call another, or a function can call
     itself (recursion).  You can view the chain of called functions
     (main program calls A, which calls B, which calls C), as a stack
     of executing functions: the currently running function is the
     topmost one on the stack, and when it finishes (returns), the next
     one down then becomes the active function.  Such a stack is termed
     a "call stack".

     For each function on the call stack, the system maintains a data
     area that contains the function's parameters, local variables, and
     return value, as well as any other "bookkeeping" information
     needed to manage the call stack.  This data area is termed a
     "stack frame".

     `gawk' also follows this model, and `dgawk' gives you access to
     the call stack and to each stack frame. You can see the call
     stack, as well as from where each function on the stack was
     invoked. Commands that print the call stack print information about
     each stack frame (as detailed later on).

"Breakpoint"
     During debugging, you often wish to let the program run until it
     reaches a certain point, and then continue execution from there one
     statement (or instruction) at a time.  The way to do this is to set
     a "breakpoint" within the program.  A breakpoint is where the
     execution of the program should break off (stop), so that you can
     take over control of the program's execution.  You can add and
     remove as many breakpoints as you like.

"Watchpoint"
     A watchpoint is similar to a breakpoint.  The difference is that
     breakpoints are oriented around the code: stop when a certain
     point in the code is reached.  A watchpoint, however, specifies
     that program execution should stop when a _data value_ is changed.
     This is useful, since sometimes it happens that a variable
     receives an erroneous value, and it's hard to track down where
     this happens just by looking at the code.  By using a watchpoint,
     you can stop whenever a variable is assigned to, and usually find
     the errant code quite quickly.


File: gawk.info,  Node: Awk Debugging,  Prev: Debugging Terms,  Up: Debugging

14.1.3 Awk Debugging
--------------------

Debugging an `awk' program has some specific aspects that are not
shared with other programming languages.

   First of all, the fact that `awk' programs usually take input
line-by-line from a file or files and operate on those lines using
specific rules makes it especially useful to organize viewing the
execution of the program in terms of these rules.  As we will see, each
`awk' rule is treated almost like a function call, with its own
specific block of instructions.

   In addition, since `awk' is by design a very concise language, it is
easy to lose sight of everything that is going on "inside" each line of
`awk' code.  The debugger provides the opportunity to look at the
individual primitive instructions carried out by the higher-level `awk'
commands.


File: gawk.info,  Node: Sample dgawk session,  Next: List of Debugger Commands,  Prev: Debugging,  Up: Debugger

14.2 Sample `dgawk' session
===========================

In order to illustrate the use of `dgawk', let's look at a sample
debugging session.  We will use the `awk' implementation of the POSIX
`uniq' command described earlier (*note Uniq Program::) as our example.

* Menu:

* dgawk invocation::            `dgawk' Invocation.
* Finding The Bug::             Finding The Bug.


File: gawk.info,  Node: dgawk invocation,  Next: Finding The Bug,  Up: Sample dgawk session

14.2.1 `dgawk' Invocation
-------------------------

Starting `dgawk' is exactly like running `awk'.  The file(s) containing
the program and any supporting code are given on the command line as
arguments to one or more `-f' options.  (`dgawk' is not designed to
debug command-line programs, only programs contained in files.)  In our
case, we call `dgawk' like this:

     $ dgawk -f getopt.awk -f join.awk -f uniq.awk inputfile

where both `getopt.awk' and `uniq.awk' are in `$AWKPATH'.  (Experienced
users of GDB or similar debuggers should note that this syntax is
slightly different from what they are used to.  With `dgawk', the
arguments for running the program are given in the command line to the
debugger rather than as part of the `run' command at the debugger
prompt.)

   Instead of immediately running the program on `inputfile', as `gawk'
would ordinarily do, `dgawk' merely loads all the program source files,
compiles them internally, and then gives us a prompt:

     dgawk>

from which we can issue commands to the debugger.  At this point, no
code has been executed.


File: gawk.info,  Node: Finding The Bug,  Prev: dgawk invocation,  Up: Sample dgawk session

14.2.2 Finding The Bug
----------------------

Let's say that we are having a problem using (a faulty version of)
`uniq.awk' in the "field-skipping" mode, and it doesn't seem to be
catching lines which should be identical when skipping the first field,
such as:

     awk is a wonderful program!
     gawk is a wonderful program!

   This could happen if we were thinking (C-like) of the fields in a
record as being numbered in a zero-based fashion, so instead of the
lines:

     clast = join(alast, fcount+1, n)
     cline = join(aline, fcount+1, m)

we wrote:

     clast = join(alast, fcount, n)
     cline = join(aline, fcount, m)

   The first thing we usually want to do when trying to investigate a
problem like this is to put a breakpoint in the program so that we can
watch it at work and catch what it is doing wrong.  A reasonable spot
for a breakpoint in `uniq.awk' is at the beginning of the function
`are_equal()', which compares the current line with the previous one.
To set the breakpoint, use the `b' (breakpoint) command:

     dgawk> b are_equal
     -| Breakpoint 1 set at file `awklib/eg/prog/uniq.awk', line 64

   The debugger tells us the file and line number where the breakpoint
is.  Now type `r' or `run' and the program runs until it hits the
breakpoint for the first time:

     dgawk> r
     -| Starting program:
     -| Stopping in Rule ...
     -| Breakpoint 1, are_equal(n, m, clast, cline, alast, aline)
              at `awklib/eg/prog/uniq.awk':64
     -| 64          if (fcount == 0 && charcount == 0)
     dgawk>

   Now we can look at what's going on inside our program.  First of all,
let's see how we got to where we are.  At the prompt, we type `bt'
(short for "backtrace"), and `dgawk' responds with a listing of the
current stack frames:

     dgawk> bt
     -| #0  are_equal(n, m, clast, cline, alast, aline)
              at `awklib/eg/prog/uniq.awk':69
     -| #1  in main() at `awklib/eg/prog/uniq.awk':89

   This tells us that `are_equal()' was called by the main program at
line 89 of `uniq.awk'.  (This is not a big surprise, since this is the
only call to `are_equal()' in the program, but in more complex
programs, knowing who called a function and with what parameters can be
the key to finding the source of the problem.)

   Now that we're in `are_equal()', we can start looking at the values
of some variables.  Let's say we type `p n' (`p' is short for "print").
We would expect to see the value of `n', a parameter to `are_equal()'.
Actually, `dgawk' gives us:

     dgawk> p n
     -| n = untyped variable

In this case, `n' is an uninitialized local variable, since the
function was called without arguments (*note Function Calls::).

   A more useful variable to display might be the current record:

     dgawk> p $0
     -| $0 = string ("gawk is a wonderful program!")

This might be a bit puzzling at first since this is the second line of
our test input above.  Let's look at `NR':

     dgawk> p NR
     -| NR = number (2)

So we can see that `are_equal()' was only called for the second record
of the file.  Of course, this is because our program contained a rule
for `NR == 1':

     NR == 1 {
         last = $0
         next
     }

   OK, let's just check that that rule worked correctly:

     dgawk> p last
     -| last = string ("awk is a wonderful program!")

   Everything we have done so far has verified that the program has
worked as planned, up to and including the call to `are_equal()', so
the problem must be inside this function.  To investigate further, we
must begin "stepping through" the lines of `are_equal()'.  We start by
typing `n' (for "next"):

     dgawk> n
     -| 67          if (fcount > 0) {

   This tells us that `gawk' is now ready to execute line 67, which
decides whether to give the lines the special "field skipping" treatment
indicated by the `-f' command-line option.  (Notice that we skipped
from where we were before at line 64 to here, since the condition in
line 64

     if (fcount == 0 && charcount == 0)

was false.)

   Continuing to step, we now get to the splitting of the current and
last records:

     dgawk> n
     -| 68              n = split(last, alast)
     dgawk> n
     -| 69              m = split($0, aline)

   At this point, we should be curious to see what our records were
split into, so we try to look:

     dgawk> p n m alast aline
     -| n = number (5)
     -| m = number (5)
     -| alast = array, 5 elements
     -| aline = array, 5 elements

(The `p' command can take more than one argument, similar to `awk''s
`print' statement.)

   This is kind of disappointing, though.  All we found out is that
there are five elements in each of our arrays.  Useful enough (we now
know that none of the words were accidentally left out), but what if we
want to see inside the array?

   The first choice would be to use subscripts:

     dgawk> p alast[0]
     -| "0" not in array `alast'

Oops!

     dgawk> p alast[1]
     -| alast["1"] = string ("awk")

   This would be kind of slow for a 100-member array, though, so
`dgawk' provides a shortcut (reminiscent of another language not to be
mentioned):

     dgawk> p @alast
     -| alast["1"] = string ("awk")
     -| alast["2"] = string ("is")
     -| alast["3"] = string ("a")
     -| alast["4"] = string ("wonderful")
     -| alast["5"] = string ("program!")

   It looks like we got this far OK.  Let's take another step or two:

     dgawk> n
     -| 70              clast = join(alast, fcount, n)
     dgawk> n
     -| 71              cline = join(aline, fcount, m)

   Well, here we are at our error (sorry to spoil the suspense).  What
we had in mind was to join the fields starting from the second one to
make the virtual record to compare, and if the first field was numbered
zero, this would work.  Let's look at what we've got:

     dgawk> p cline clast
     -| cline = string ("gawk is a wonderful program!")
     -| clast = string ("awk is a wonderful program!")

   Hey, those look pretty familiar!  They're just our original,
unaltered, input records.  A little thinking (the human brain is still
the best debugging tool), and we realize that we were off by one!

   We get out of `dgawk':

     dgawk> q
     -| The program is running. Exit anyway (y/n)? y

Then we get into an editor:

     clast = join(alast, fcount+1, n)
     cline = join(aline, fcount+1, m)

and problem solved!


File: gawk.info,  Node: List of Debugger Commands,  Next: Readline Support,  Prev: Sample dgawk session,  Up: Debugger

14.3 Main `dgawk' Commands
==========================

The `dgawk' command set can be divided into the following categories:

   * Breakpoint control

   * Execution control

   * Viewing and changing data

   * Working with the stack

   * Getting information

   * Miscellaneous

   Each of these are discussed in the following subsections.  In the
following descriptions, commands which may be abbreviated show the
abbreviation on a second description line.  A `dgawk' command name may
also be truncated if that partial name is unambiguous. `dgawk' has the
built-in capability to automatically repeat the previous command when
just hitting <Enter>.  This works for the commands `list', `next',
`nexti', `step', `stepi' and `continue' executed without any argument.

* Menu:

* Breakpoint Control::          Control of breakpoints.
* Dgawk Execution Control::     Control of execution.
* Viewing And Changing Data::   Viewing and changing data.
* Dgawk Stack::                 Dealing with the stack.
* Dgawk Info::                  Obtaining information about the program and
                                the debugger state.
* Miscellaneous Dgawk Commands:: Miscellaneous Commands.


File: gawk.info,  Node: Breakpoint Control,  Next: Dgawk Execution Control,  Up: List of Debugger Commands

14.3.1 Control Of Breakpoints
-----------------------------

As we saw above, the first thing you probably want to do in a debugging
session is to get your breakpoints set up, since otherwise your program
will just run as if it was not under the debugger.  The commands for
controlling breakpoints are:

`break' [[FILENAME`:']N | FUNCTION] [`"EXPRESSION"']
`b' [[FILENAME`:']N | FUNCTION] [`"EXPRESSION"']
     Without any argument, set a breakpoint at the next instruction to
     be executed in the selected stack frame.  Arguments can be one of
     the following:

    N
          Set a breakpoint at line number N in the current source file.

    FILENAME`:'N
          Set a breakpoint at line number N in source file FILENAME.

    FUNCTION
          Set a breakpoint at entry to (the first instruction of)
          function FUNCTION.

     Each breakpoint is assigned a number which can be used to delete
     it from the breakpoint list using the `delete' command.

     With a breakpoint, you may also supply a condition.  This is an
     `awk' expression (enclosed in double quotes) that `dgawk'
     evaluates whenever the breakpoint is reached. If the condition is
     true, then `dgawk' stops execution and prompts for a command.
     Otherwise, `dgawk' continues executing the program.

`clear' [[FILENAME`:']N | FUNCTION]
     Without any argument, delete any breakpoint at the next instruction
     to be executed in the selected stack frame. If the program stops at
     a breakpoint, this deletes that breakpoint so that the program
     does not stop at that location again.  Arguments can be one of the
     following:

    N
          Delete breakpoint(s) set at line number N in the current
          source file.

    FILENAME`:'N
          Delete breakpoint(s) set at line number N in source file
          FILENAME.

    FUNCTION
          Delete breakpoint(s) set at entry to function FUNCTION.

`condition' N `"EXPRESSION"'
     Add a condition to existing breakpoint or watchpoint N. The
     condition is an `awk' expression that `dgawk' evaluates whenever
     the breakpoint or watchpoint is reached. If the condition is true,
     then `dgawk' stops execution and prompts for a command. Otherwise,
     `dgawk' continues executing the program. If the condition
     expression is not specified, any existing condition is removed;
     i.e., the breakpoint or watchpoint is made unconditional.

`delete' [N1 N2 ...] [N-M]
`d' [N1 N2 ...] [N-M]
     Delete specified breakpoints or a range of breakpoints. Deletes
     all defined breakpoints if no argument is supplied.

`disable' [N1 N2 ... | N-M]
     Disable specified breakpoints or a range of breakpoints. Without
     any argument, disables all breakpoints.

`enable' [`del' | `once'] [N1 N2 ...] [N-M]
`e' [`del' | `once'] [N1 N2 ...] [N-M]
     Enable specified breakpoints or a range of breakpoints. Without
     any argument, enables all breakpoints.  Optionally, you can
     specify how to enable the breakpoint:

    `del'
          Enable the breakpoint(s) temporarily, then delete it when the
          program stops at the breakpoint.

    `once'
          Enable the breakpoint(s) temporarily, then disable it when
          the program stops at the breakpoint.

`ignore' N COUNT
     Ignore breakpoint number N the next COUNT times it is hit.

`tbreak' [[FILENAME`:']N | FUNCTION]
`t' [[FILENAME`:']N | FUNCTION]
     Set a temporary breakpoint (enabled for only one stop).  The
     arguments are the same as for `break'.


File: gawk.info,  Node: Dgawk Execution Control,  Next: Viewing And Changing Data,  Prev: Breakpoint Control,  Up: List of Debugger Commands

14.3.2 Control of Execution
---------------------------

Now that your breakpoints are ready, you can start running the program
and observing its behavior.  There are more commands for controlling
execution of the program than we saw in our earlier example:

`commands' [N]
`silent'
...
`end'
     Set a list of commands to be executed upon stopping at a
     breakpoint or watchpoint. N is the breakpoint or watchpoint number.
     Without a number, the last one set is used. The actual commands
     follow, starting on the next line, and terminated by the `end'
     command.  If the command `silent' is in the list, the usual
     messages about stopping at a breakpoint and the source line are
     not printed. Any command in the list that resumes execution (e.g.,
     `continue') terminates the list (an implicit `end'), and
     subsequent commands are ignored.  For example:

          dgawk> commands
          > silent
          > printf "A silent breakpoint; i = %d\n", i
          > info locals
          > set i = 10
          > continue
          > end
          dgawk>

`continue' [COUNT]
`c' [COUNT]
     Resume program execution. If continued from a breakpoint and COUNT
     is specified, ignores the breakpoint at that location the next
     COUNT times before stopping.

`finish'
     Execute until the selected stack frame returns.  Print the
     returned value.

`next' [COUNT]
`n' [COUNT]
     Continue execution to the next source line, stepping over function
     calls.  The argument COUNT controls how many times to repeat the
     action, as in `step'.

`nexti' [COUNT]
`ni' [COUNT]
     Execute one (or COUNT) instruction(s), stepping over function
     calls.

`return' [VALUE]
     Cancel execution of a function call. If VALUE (either a string or a
     number) is specified, it is used as the function's return value.
     If used in a frame other than the innermost one (the currently
     executing function, i.e., frame number 0), discard all inner
     frames in addition to the selected one, and the caller of that
     frame becomes the innermost frame.

`run'
`r'
     Start/restart execution of the program. When restarting, `dgawk'
     retains the current breakpoints, watchpoints, command history,
     automatic display variables, and debugger options.

`step' [COUNT]
`s' [COUNT]
     Continue execution until control reaches a different source line
     in the current stack frame. `step' steps inside any function
     called within the line.  If the argument COUNT is supplied, steps
     that many times before stopping, unless it encounters a breakpoint
     or watchpoint.

`stepi' [COUNT]
`si' [COUNT]
     Execute one (or COUNT) instruction(s), stepping inside function
     calls.  (For illustration of what is meant by an "instruction" in
     `gawk', see the output shown under `dump' in *note Miscellaneous
     Dgawk Commands::.)

`until' [[FILENAME`:']N | FUNCTION]
`u' [[FILENAME`:']N | FUNCTION]
     Without any argument, continue execution until a line past the
     current line in current stack frame is reached. With an argument,
     continue execution until the specified location is reached, or the
     current stack frame returns.


File: gawk.info,  Node: Viewing And Changing Data,  Next: Dgawk Stack,  Prev: Dgawk Execution Control,  Up: List of Debugger Commands

14.3.3 Viewing and Changing Data
--------------------------------

The commands for viewing and changing variables inside of `gawk' are:

`display' [VAR | `$'N]
     Add variable VAR (or field `$N') to the display list.  The value
     of the variable or field is displayed each time the program stops.
     Each variable added to the list is identified by a unique number:

          dgawk> display x
          -| 10: x = 1

     displays the assigned item number, the variable name and its
     current value.  If the display variable refers to a function
     parameter, it is silently deleted from the list as soon as the
     execution reaches a context where no such variable of the given
     name exists.  Without argument, `display' displays the current
     values of items on the list.

`eval "AWK STATEMENTS"'
     Evaluate AWK STATEMENTS in the context of the running program.
     You can do anything that an `awk' program would do: assign values
     to variables, call functions, and so on.

`eval' PARAM, ...
AWK STATEMENTS
`end'
     This form of `eval' is similar, but it allows you to define "local
     variables" that exist in the context of the AWK STATEMENTS,
     instead of using variables or function parameters defined by the
     program.

`print' VAR1[`,' VAR2 ...]
`p' VAR1[`,' VAR2 ...]
     Print the value of a `gawk' variable or field.  Fields must be
     referenced by constants:

          dgawk> print $3

     This prints the third field in the input record (if the specified
     field does not exist, it prints `Null field'). A variable can be
     an array element, with the subscripts being constant values. To
     print the contents of an array, prefix the name of the array with
     the `@' symbol:

          gawk> print @a

     This prints the indices and the corresponding values for all
     elements in the array `a'.

`printf' FORMAT [`,' ARG ...]
     Print formatted text. The FORMAT may include escape sequences,
     such as `\n' (*note Escape Sequences::).  No newline is printed
     unless one is specified.

`set' VAR`='VALUE
     Assign a constant (number or string) value to an `awk' variable or
     field.  String values must be enclosed between double quotes
     (`"..."').

     You can also set special `awk' variables, such as `FS', `NF',
     `NR', etc.

`watch' VAR | `$'N [`"EXPRESSION"']
`w' VAR | `$'N [`"EXPRESSION"']
     Add variable VAR (or field `$N') to the watch list.  `dgawk' then
     stops whenever the value of the variable or field changes. Each
     watched item is assigned a number which can be used to delete it
     from the watch list using the `unwatch' command.

     With a watchpoint, you may also supply a condition.  This is an
     `awk' expression (enclosed in double quotes) that `dgawk'
     evaluates whenever the watchpoint is reached. If the condition is
     true, then `dgawk' stops execution and prompts for a command.
     Otherwise, `dgawk' continues executing the program.

`undisplay' [N]
     Remove item number N (or all items, if no argument) from the
     automatic display list.

`unwatch' [N]
     Remove item number N (or all items, if no argument) from the watch
     list.



File: gawk.info,  Node: Dgawk Stack,  Next: Dgawk Info,  Prev: Viewing And Changing Data,  Up: List of Debugger Commands

14.3.4 Dealing With The Stack
-----------------------------

Whenever you run a program which contains any function calls, `gawk'
maintains a stack of all of the function calls leading up to where the
program is right now.  You can see how you got to where you are, and
also move around in the stack to see what the state of things was in the
functions which called the one you are in.  The commands for doing this
are:

`backtrace' [COUNT]
`bt' [COUNT]
     Print a backtrace of all function calls (stack frames), or
     innermost COUNT frames if COUNT > 0. Print the outermost COUNT
     frames if COUNT < 0.  The backtrace displays the name and
     arguments to each function, the source file name, and the line
     number.

`down' [COUNT]
     Move COUNT (default 1) frames down the stack toward the innermost
     frame.  Then select and print the frame.

`frame' [N]
`f' [N]
     Select and print (frame number, function and argument names,
     source file, and the source line) stack frame N. Frame 0 is the
     currently executing, or "innermost", frame (function call), frame
     1 is the frame that called the innermost one. The highest numbered
     frame is the one for the main program.

`up' [COUNT]
     Move COUNT (default 1) frames up the stack toward the outermost
     frame.  Then select and print the frame.


File: gawk.info,  Node: Dgawk Info,  Next: Miscellaneous Dgawk Commands,  Prev: Dgawk Stack,  Up: List of Debugger Commands

14.3.5 Obtaining Information About The Program and The Debugger State
---------------------------------------------------------------------

Besides looking at the values of variables, there is often a need to get
other sorts of information about the state of your program and of the
debugging environment itself.  `dgawk' has one command which provides
this information, appropriately called `info'.  `info' is used with one
of a number of arguments that tell it exactly what you want to know:

`info' WHAT
`i' WHAT
     The value for WHAT should be one of the following:

    `args'
          Arguments of the selected frame.

    `break'
          List all currently set breakpoints.

    `display'
          List all items in the automatic display list.

    `frame'
          Description of the selected stack frame.

    `functions'
          List all function definitions including source file names and
          line numbers.

    `locals'
          Local variables of the selected frame.

    `source'
          The name of the current source file. Each time the program
          stops, the current source file is the file containing the
          current instruction.  When `dgawk' first starts, the current
          source file is the first file included via the `-f' option.
          The `list FILENAME:LINENO' command can be used at any time to
          change the current source.

    `sources'
          List all program sources.

    `variables'
          List all global variables.

    `watch'
          List all items in the watch list.

   Additional commands give you control over the debugger, the ability
to save the debugger's state, and the ability to run debugger commands
from a file.  The commands are:

`option' [NAME[`='VALUE]]
`o' [NAME[`='VALUE]]
     Without an argument, display the available debugger options and
     their current values. `option NAME' shows the current value of the
     named option. `option NAME=VALUE' assigns a new value to the named
     option.  The available options are:

    `history_size'
          The maximum number of lines to keep in the history file
          `./.dgawk_history'.  The default is 100.

    `listsize'
          The number of lines that `list' prints. The default is 15.

    `outfile'
          Send `gawk' output to a file; debugger output still goes to
          standard output. An empty string (`""') resets output to
          standard output.

    `prompt'
          The debugger prompt. The default is `dgawk> '.

    `save_history [on | off]'
          Save command history to file `./.dgawk_history'.  The default
          is `on'.

    `save_options [on | off]'
          Save current options to file `./.dgawkrc' upon exit.  The
          default is `on'.  Options are read back in to the next
          session upon startup.

    `trace [on | off]'
          Turn instruction tracing on or off. The default is `off'.

`save' FILENAME
     Save the commands from the current session to the given file name,
     so that they can be replayed using the `source' command.

`source' FILENAME
     Run command(s) from a file; an error in any command does not
     terminate execution of subsequent commands. Comments (lines
     starting with `#') are allowed in a command file.  Empty lines are
     ignored; they do _not_ repeat the last command.  You can't restart
     the program by having more than one `run' command in the file.
     Also, the list of commands may include additional `source'
     commands; however, `dgawk' will not source the same file more than
     once in order to avoid infinite recursion.

     In addition to, or instead of the `source' command, you can use
     the `-R FILE' or `--command=FILE' command-line options to execute
     commands from a file non-interactively (*note Options::.


File: gawk.info,  Node: Miscellaneous Dgawk Commands,  Prev: Dgawk Info,  Up: List of Debugger Commands

14.3.6 Miscellaneous Commands
-----------------------------

There are a few more commands which do not fit into the previous
categories, as follows:

`dump' [FILENAME]
     Dump bytecode of the program to standard output or to the file
     named in FILENAME.  This prints a representation of the internal
     instructions which `gawk' executes to implement the `awk' commands
     in a program.  This can be very enlightening, as the following
     partial dump of Davide Brini's obfuscated code (*note Signature
     Program::) demonstrates:

          dgawk> dump
          -|        # BEGIN
          -|
          -| [     2:0x89faef4] Op_rule             : [in_rule = BEGIN] [source_file = brini.awk]
          -| [     3:0x89fa428] Op_push_i           : "~" [PERM|STRING|STRCUR]
          -| [     3:0x89fa464] Op_push_i           : "~" [PERM|STRING|STRCUR]
          -| [     3:0x89fa450] Op_match            :
          -| [     3:0x89fa3ec] Op_store_var        : O [do_reference = FALSE]
          -| [     4:0x89fa48c] Op_push_i           : "==" [PERM|STRING|STRCUR]
          -| [     4:0x89fa4c8] Op_push_i           : "==" [PERM|STRING|STRCUR]
          -| [     4:0x89fa4b4] Op_equal            :
          -| [     4:0x89fa400] Op_store_var        : o [do_reference = FALSE]
          -| [     5:0x89fa4f0] Op_push             : o
          -| [     5:0x89fa4dc] Op_plus_i           : 0 [PERM|NUMCUR|NUMBER]
          -| [     5:0x89fa414] Op_push_lhs         : o [do_reference = TRUE]
          -| [     5:0x89fa4a0] Op_assign_plus      :
          -| [      :0x89fa478] Op_pop              :
          -| [     6:0x89fa540] Op_push             : O
          -| [     6:0x89fa554] Op_push_i           : "" [PERM|STRING|STRCUR]
          -| [      :0x89fa5a4] Op_no_op            :
          -| [     6:0x89fa590] Op_push             : O
          -| [      :0x89fa5b8] Op_concat           : [expr_count = 3] [concat_flag = 0]
          -| [     6:0x89fa518] Op_store_var        : x [do_reference = FALSE]
          -| [     7:0x89fa504] Op_push_loop        : [target_continue = 0x89fa568] [target_break = 0x89fa680]
          -| [     7:0x89fa568] Op_push_lhs         : X [do_reference = TRUE]
          -| [     7:0x89fa52c] Op_postincrement    :
          -| [     7:0x89fa5e0] Op_push             : x
          -| [     7:0x89fa61c] Op_push             : o
          -| [     7:0x89fa5f4] Op_plus             :
          -| [     7:0x89fa644] Op_push             : o
          -| [     7:0x89fa630] Op_plus             :
          -| [     7:0x89fa5cc] Op_leq              :
          -| [      :0x89fa57c] Op_jmp_false        : [target_jmp = 0x89fa680]
          -| [     7:0x89fa694] Op_push_i           : "%c" [PERM|STRING|STRCUR]
          -| [      :0x89fa6d0] Op_no_op            :
          -| [     7:0x89fa608] Op_assign_concat    : c
          -| [      :0x89fa6a8] Op_jmp              : [target_jmp = 0x89fa568]
          -| [      :0x89fa680] Op_pop_loop         :
          -|
          ...
          -|
          -| [     8:0x89fa658] Op_K_printf         : [expr_count = 17] [redir_type = ""]
          -| [      :0x89fa374] Op_no_op            :
          -| [      :0x89fa3d8] Op_atexit           :
          -| [      :0x89fa6bc] Op_stop             :
          -| [      :0x89fa39c] Op_no_op            :
          -| [      :0x89fa3b0] Op_after_beginfile  :
          -| [      :0x89fa388] Op_no_op            :
          -| [      :0x89fa3c4] Op_after_endfile    :
          dgawk>

`help'
`h'
     Print a list of all of the `dgawk' commands with a short summary
     of their usage.  `help COMMAND' prints the information about the
     command COMMAND.

`list' [`-' | `+' | N | FILENAME`:'N | N-M | FUNCTION]
`l' [`-' | `+' | N | FILENAME`:'N | N-M | FUNCTION]
     Print the specified lines (default 15) from the current source file
     or the file named FILENAME. The possible arguments to `list' are
     as follows:

    `-'
          Print lines before the lines last printed.

    `+'
          Print lines after the lines last printed.  `list' without any
          argument does the same thing.

    N
          Print lines centered around line number N.

    N-M
          Print lines from N to M.

    FILENAME`:'N
          Print lines centered around line number N in source file
          FILENAME. This command may change the current source file.

    FUNCTION
          Print lines centered around beginning of the function
          FUNCTION. This command may change the current source file.

`quit'
`q'
     Exit the debugger.  Debugging is great fun, but sometimes we all
     have to tend to other obligations in life, and sometimes we find
     the bug, and are free to go on to the next one!  As we saw above,
     if you are running a program, `dgawk' warns you if you
     accidentally type `q' or `quit', to make sure you really want to
     quit.

`trace' `on' | `off'
     Turn on or off a continuous printing of instructions which are
     about to be executed, along with printing the `awk' line which they
     implement.  The default is `off'.

     It is to be hoped that most of the "opcodes" in these instructions
     are fairly self-explanatory, and using `stepi' and `nexti' while
     `trace' is on will make them into familiar friends.



File: gawk.info,  Node: Readline Support,  Next: Dgawk Limitations,  Prev: List of Debugger Commands,  Up: Debugger

14.4 Readline Support
=====================

If `dgawk' is compiled with the `readline' library, you can take
advantage of that library's command completion and history expansion
features. The following types of completion are available:

Command completion
     Command names.

Source file name completion
     Source file names. Relevant commands are `break', `clear', `list',
     `tbreak', and `until'.

Argument completion
     Non-numeric arguments to a command.  Relevant commands are
     `enable' and `info'.

Variable name completion
     Global variable names, and function arguments in the current
     context if the program is running. Relevant commands are `display',
     `print', `set', and `watch'.



File: gawk.info,  Node: Dgawk Limitations,  Prev: Readline Support,  Up: Debugger

14.5 Limitations and Future Plans
=================================

We hope you find `dgawk' useful and enjoyable to work with, but as with
any program, especially in its early releases, it still has some
limitations.  A few which are worth being aware of are:

   * At this point, `dgawk' does not give a detailed explanation of
     what you did wrong when you type in something it doesn't like.
     Rather, it just responds `syntax error'.  When you do figure out
     what your mistake was, though, you'll feel like a real guru.

   * If you perused the dump of opcodes in *note Miscellaneous Dgawk
     Commands::, (or if you are already familiar with `gawk' internals),
     you will realize that much of the internal manipulation of data in
     `gawk', as in many interpreters, is done on a stack.  `Op_push',
     `Op_pop', etc., are the "bread and butter" of most `gawk' code.
     Unfortunately, as of now, `dgawk' does not allow you to examine
     the stack's contents.

     That is, the intermediate results of expression evaluation are on
     the stack, but cannot be printed.  Rather, only variables which
     are defined in the program can be printed.  Of course, a
     workaround for this is to use more explicit variables at the
     debugging stage and then change back to obscure, perhaps more
     optimal code later.

   * There is no way to look "inside" the process of compiling regular
     expressions to see if you got it right.  As an `awk' programmer,
     you are expected to know what `/[^[:alnum:][:blank:]]/' means.

   * `dgawk' is designed to be used by running a program (with all its
     parameters) on the command line, as described in *note dgawk
     invocation::.  There is no way (as of now) to attach or "break in"
     to a running program.  This seems reasonable for a language which
     is used mainly for quickly executing, short programs.

   * `dgawk' only accepts source supplied with the `-f' option.

   Look forward to a future release when these and other missing
features may be added, and of course feel free to try to add them
yourself!


File: gawk.info,  Node: Language History,  Next: Installation,  Prev: Debugger,  Up: Top

Appendix A The Evolution of the `awk' Language
**********************************************

This Info file describes the GNU implementation of `awk', which follows
the POSIX specification.  Many long-time `awk' users learned `awk'
programming with the original `awk' implementation in Version 7 Unix.
(This implementation was the basis for `awk' in Berkeley Unix, through
4.3-Reno.  Subsequent versions of Berkeley Unix, and some systems
derived from 4.4BSD-Lite, use various versions of `gawk' for their
`awk'.)  This major node briefly describes the evolution of the `awk'
language, with cross-references to other parts of the Info file where
you can find more information.

* Menu:

* V7/SVR3.1::                   The major changes between V7 and System V
                                Release 3.1.
* SVR4::                        Minor changes between System V Releases 3.1
                                and 4.
* POSIX::                       New features from the POSIX standard.
* BTL::                         New features from Brian Kernighan's version of
                                `awk'.
* POSIX/GNU::                   The extensions in `gawk' not in POSIX
                                `awk'.
* Common Extensions::           Common Extensions Summary.
* Ranges and Locales::          How locales used to affect regexp ranges.
* Contributors::                The major contributors to `gawk'.


File: gawk.info,  Node: V7/SVR3.1,  Next: SVR4,  Up: Language History

A.1 Major Changes Between V7 and SVR3.1
=======================================

The `awk' language evolved considerably between the release of Version
7 Unix (1978) and the new version that was first made generally
available in System V Release 3.1 (1987).  This minor node summarizes
the changes, with cross-references to further details:

   * The requirement for `;' to separate rules on a line (*note
     Statements/Lines::).

   * User-defined functions and the `return' statement (*note
     User-defined::).

   * The `delete' statement (*note Delete::).

   * The `do'-`while' statement (*note Do Statement::).

   * The built-in functions `atan2()', `cos()', `sin()', `rand()', and
     `srand()' (*note Numeric Functions::).

   * The built-in functions `gsub()', `sub()', and `match()' (*note
     String Functions::).

   * The built-in functions `close()' and `system()' (*note I/O
     Functions::).

   * The `ARGC', `ARGV', `FNR', `RLENGTH', `RSTART', and `SUBSEP'
     built-in variables (*note Built-in Variables::).

   * Assignable `$0' (*note Changing Fields::).

   * The conditional expression using the ternary operator `?:' (*note
     Conditional Exp::).

   * The expression `INDEX-VARIABLE in ARRAY' outside of `for'
     statements (*note Reference to Elements::).

   * The exponentiation operator `^' (*note Arithmetic Ops::) and its
     assignment operator form `^=' (*note Assignment Ops::).

   * C-compatible operator precedence, which breaks some old `awk'
     programs (*note Precedence::).

   * Regexps as the value of `FS' (*note Field Separators::) and as the
     third argument to the `split()' function (*note String
     Functions::), rather than using only the first character of `FS'.

   * Dynamic regexps as operands of the `~' and `!~' operators (*note
     Regexp Usage::).

   * The escape sequences `\b', `\f', and `\r' (*note Escape
     Sequences::).  (Some vendors have updated their old versions of
     `awk' to recognize `\b', `\f', and `\r', but this is not something
     you can rely on.)

   * Redirection of input for the `getline' function (*note Getline::).

   * Multiple `BEGIN' and `END' rules (*note BEGIN/END::).

   * Multidimensional arrays (*note Multi-dimensional::).


File: gawk.info,  Node: SVR4,  Next: POSIX,  Prev: V7/SVR3.1,  Up: Language History

A.2 Changes Between SVR3.1 and SVR4
===================================

The System V Release 4 (1989) version of Unix `awk' added these features
(some of which originated in `gawk'):

   * The `ENVIRON' array (*note Built-in Variables::).

   * Multiple `-f' options on the command line (*note Options::).

   * The `-v' option for assigning variables before program execution
     begins (*note Options::).

   * The `--' option for terminating command-line options.

   * The `\a', `\v', and `\x' escape sequences (*note Escape
     Sequences::).

   * A defined return value for the `srand()' built-in function (*note
     Numeric Functions::).

   * The `toupper()' and `tolower()' built-in string functions for case
     translation (*note String Functions::).

   * A cleaner specification for the `%c' format-control letter in the
     `printf' function (*note Control Letters::).

   * The ability to dynamically pass the field width and precision
     (`"%*.*d"') in the argument list of the `printf' function (*note
     Control Letters::).

   * The use of regexp constants, such as `/foo/', as expressions, where
     they are equivalent to using the matching operator, as in `$0 ~
     /foo/' (*note Using Constant Regexps::).

   * Processing of escape sequences inside command-line variable
     assignments (*note Assignment Options::).


File: gawk.info,  Node: POSIX,  Next: BTL,  Prev: SVR4,  Up: Language History

A.3 Changes Between SVR4 and POSIX `awk'
========================================

The POSIX Command Language and Utilities standard for `awk' (1992)
introduced the following changes into the language:

   * The use of `-W' for implementation-specific options (*note
     Options::).

   * The use of `CONVFMT' for controlling the conversion of numbers to
     strings (*note Conversion::).

   * The concept of a numeric string and tighter comparison rules to go
     with it (*note Typing and Comparison::).

   * The use of built-in variables as function parameter names is
     forbidden (*note Definition Syntax::.

   * More complete documentation of many of the previously undocumented
     features of the language.

   *Note Common Extensions::, for a list of common extensions not
permitted by the POSIX standard.

   The 2008 POSIX standard can be found online at
`http://www.opengroup.org/onlinepubs/9699919799/'.


File: gawk.info,  Node: BTL,  Next: POSIX/GNU,  Prev: POSIX,  Up: Language History

A.4 Extensions in Brian Kernighan's `awk'
=========================================

Brian Kernighan has made his version available via his home page (*note
Other Versions::).

   This minor node describes common extensions that originally appeared
in his version of `awk'.

   * The `**' and `**=' operators (*note Arithmetic Ops:: and *note
     Assignment Ops::).

   * The use of `func' as an abbreviation for `function' (*note
     Definition Syntax::).

   * The `fflush()' built-in function for flushing buffered output
     (*note I/O Functions::).


   *Note Common Extensions::, for a full list of the extensions
available in his `awk'.


File: gawk.info,  Node: POSIX/GNU,  Next: Common Extensions,  Prev: BTL,  Up: Language History

A.5 Extensions in `gawk' Not in POSIX `awk'
===========================================

The GNU implementation, `gawk', adds a large number of features.  They
can all be disabled with either the `--traditional' or `--posix' options
(*note Options::).

   A number of features have come and gone over the years. This minor
node summarizes the additional features over POSIX `awk' that are in
the current version of `gawk'.

   * Additional built-in variables:

        - The `ARGIND' `BINMODE', `ERRNO', `FIELDWIDTHS', `FPAT',
          `IGNORECASE', `LINT', `PROCINFO', `RT', and `TEXTDOMAIN'
          variables (*note Built-in Variables::).

   * Special files in I/O redirections:

        - The `/dev/stdin', `/dev/stdout', `/dev/stderr' and
          `/dev/fd/N' special file names (*note Special Files::).

        - The `/inet', `/inet4', and `/inet6' special files for TCP/IP
          networking using `|&' to specify which version of the IP
          protocol to use.  (*note TCP/IP Networking::).

   * Changes and/or additions to the language:

        - The `\x' escape sequence (*note Escape Sequences::).

        - Full support for both POSIX and GNU regexps (*note Regexp::).

        - The ability for `FS' and for the third argument to `split()'
          to be null strings (*note Single Character Fields::).

        - The ability for `RS' to be a regexp (*note Records::).

        - The ability to use octal and hexadecimal constants in `awk'
          program source code (*note Nondecimal-numbers::).

        - The `|&' operator for two-way I/O to a coprocess (*note
          Two-way I/O::).

        - Indirect function calls (*note Indirect Calls::).

        - Directories on the command line produce a warning and are
          skipped (*note Command line directories::).

   * New keywords:

        - The `BEGINFILE' and `ENDFILE' special patterns.  (*note
          BEGINFILE/ENDFILE::).

        - The ability to delete all of an array at once with `delete
          ARRAY' (*note Delete::).

        - The `nextfile' statement (*note Nextfile Statement::).

        - The `switch' statement (*note Switch Statement::).

   * Changes to standard `awk' functions:

        - The optional second argument to `close()' that allows closing
          one end of a two-way pipe to a coprocess (*note Two-way
          I/O::).

        - POSIX compliance for `gsub()' and `sub()'.

        - The `length()' function accepts an array argument and returns
          the number of elements in the array (*note String
          Functions::).

        - The optional third argument to the `match()' function for
          capturing text-matching subexpressions within a regexp (*note
          String Functions::).

        - Positional specifiers in `printf' formats for making
          translations easier (*note Printf Ordering::).

        - The `split()' function's additional optional fourth argument
          which is an array to hold the text of the field separators.
          (*note String Functions::).

   * Additional functions only in `gawk':

        - The `and()', `compl()', `lshift()', `or()', `rshift()', and
          `xor()' functions for bit manipulation (*note Bitwise
          Functions::).

        - The `asort()' and `asorti()' functions for sorting arrays
          (*note Array Sorting::).

        - The `bindtextdomain()', `dcgettext()' and `dcngettext()'
          functions for internationalization (*note Programmer i18n::).

        - The `extension()' built-in function and the ability to add
          new functions dynamically (*note Dynamic Extensions::).

        - The `fflush()' function from Brian Kernighan's version of
          `awk' (*note I/O Functions::).

        - The `gensub()', `patsplit()', and `strtonum()' functions for
          more powerful text manipulation (*note String Functions::).

        - The `mktime()', `systime()', and `strftime()' functions for
          working with timestamps (*note Time Functions::).

   * Changes and/or additions in the command-line options:

        - The `AWKPATH' environment variable for specifying a path
          search for the `-f' command-line option (*note Options::).

        - The ability to use GNU-style long-named options that start
          with `--' and the `--characters-as-bytes', `--compat',
          `--dump-variables', `--exec', `--gen-pot', `--lint',
          `--lint-old', `--non-decimal-data', `--posix', `--profile',
          `--re-interval', `--sandbox', `--source', `--traditional', and
          `--use-lc-numeric' options (*note Options::).

   * Support for the following obsolete systems was removed from the
     code and the documentation for `gawk' version 4.0:

        - Amiga

        - Atari

        - BeOS

        - Cray

        - MIPS RiscOS

        - MS-DOS with the Microsoft Compiler

        - MS-Windows with the Microsoft Compiler

        - NeXT

        - SunOS 3.x, Sun 386 (Road Runner)

        - Tandem (non-POSIX)

        - Prestandard VAX C compiler for VAX/VMS




File: gawk.info,  Node: Common Extensions,  Next: Ranges and Locales,  Prev: POSIX/GNU,  Up: Language History

A.6 Common Extensions Summary
=============================

This minor node summarizes the common extensions supported by `gawk',
Brian Kernighan's `awk', and `mawk', the three most widely-used freely
available versions of `awk' (*note Other Versions::).

Feature                      BWK Awk   Mawk   GNU Awk
-------------------------------------------------------- 
`\x' Escape sequence         X         X      X
`RS' as regexp                         X      X
`FS' as null string          X         X      X
`/dev/stdin' special file    X                X
`/dev/stdout' special file   X         X      X
`/dev/stderr' special file   X         X      X
`**' and `**=' operators     X                X
`func' keyword               X                X
`nextfile' statement         X         X      X
`delete' without subscript   X         X      X
`length()' of an array       X                X
`fflush()' function          X         X      X
`BINMODE' variable                     X      X


File: gawk.info,  Node: Ranges and Locales,  Next: Contributors,  Prev: Common Extensions,  Up: Language History

A.7 Regexp Ranges and Locales: A Long Sad Story
===============================================

This minor node describes the confusing history of ranges within
regular expressions and their interactions with locales, and how this
affected different versions of `gawk'.

   The original Unix tools that worked with regular expressions defined
character ranges (such as `[a-z]') to match any character between the
first character in the range and the last character in the range,
inclusive.  Ordering was based on the numeric value of each character
in the machine's native character set.  Thus, on ASCII-based systems,
`[a-z]' matched all the lowercase letters, and only the lowercase
letters, since the numeric values for the letters from `a' through `z'
were contigous.  (On an EBCDIC system, the range `[a-z]' includes
additional, non-alphabetic characters as well.)

   Almost all introductory Unix literature explained range expressions
as working in this fashion, and in particular, would teach that the
"correct" way to match lowercase letters was with `[a-z]', and that
`[A-Z]' was the the "correct" way to match uppercase letters.  And
indeed, this was true.

   The 1993 POSIX standard introduced the idea of locales (*note
Locales::).  Since many locales include other letters besides the plain
twenty-six letters of the American English alphabet, the POSIX standard
added character classes (*note Bracket Expressions::) as a way to match
different kinds of characters besides the traditional ones in the ASCII
character set.

   However, the standard _changed_ the interpretation of range
expressions.  In the `"C"' and `"POSIX"' locales, a range expression
like `[a-dx-z]' is still equivalent to `[abcdxyz]', as in ASCII.  But
outside those locales, the ordering was defined to be based on
"collation order".

   In many locales, `A' and `a' are both less than `B'.  In other
words, these locales sort characters in dictionary order, and
`[a-dx-z]' is typically not equivalent to `[abcdxyz]'; instead it might
be equivalent to `[aBbCcdXxYyz]', for example.

   This point needs to be emphasized: Much literature teaches that you
should use `[a-z]' to match a lowercase character.  But on systems with
non-ASCII locales, this also matched all of the uppercase characters
except `Z'!  This was a continuous cause of confusion, even well into
the twenty-first century.

   To demonstrate these issues, the following example uses the `sub()'
function, which does text replacement (*note String Functions::).  Here,
the intent is to remove trailing uppercase characters:

     $ echo something1234abc | gawk-3.1.8 '{ sub("[A-Z]*$", ""); print }'
     -| something1234a

This output is unexpected, since the `bc' at the end of
`something1234abc' should not normally match `[A-Z]*'.  This result is
due to the locale setting (and thus you may not see it on your system).

   Similar considerations apply to other ranges.  For example, `["-/]'
is perfectly valid in ASCII, but is not valid in many Unicode locales,
such as `en_US.UTF-8'.

   Early versions of `gawk' used regexp matching code that was not
locale aware, so ranges had their traditional interpretation.

   When `gawk' switched to using locale-aware regexp matchers, the
problems began; especially as both GNU/Linux and commercial Unix
vendors started implementing non-ASCII locales, _and making them the
default_.  Perhaps the most frequently asked question became something
like "why does `[A-Z]' match lowercase letters?!?"

   This situation existed for close to 10 years, if not more, and the
`gawk' maintainer grew weary of trying to explain that `gawk' was being
nicely standards-compliant, and that the issue was in the user's
locale.  During the development of version 4.0, he modified `gawk' to
always treat ranges in the original, pre-POSIX fashion, unless
`--posix' was used (*note Options::).

   Fortunately, shortly before the final release of `gawk' 4.0, the
maintainer learned that the 2008 standard had changed the definition of
ranges, such that outside the `"C"' and `"POSIX"' locales, the meaning
of range expressions was _undefined_.(1)

   By using this lovely technical term, the standard gives license to
implementors to implement ranges in whatever way they choose.  The
`gawk' maintainer chose to apply the pre-POSIX meaning in all cases:
the default regexp matching; with `--traditional', and with `--posix';
in all cases, `gawk' remains POSIX compliant.

   ---------- Footnotes ----------

   (1) See the standard
(http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03_05)
and its rationale
(http://pubs.opengroup.org/onlinepubs/9699919799/xrat/V4_xbd_chap09.html#tag_21_09_03_05).


File: gawk.info,  Node: Contributors,  Prev: Ranges and Locales,  Up: Language History

A.8 Major Contributors to `gawk'
================================

     Always give credit where credit is due.
     Anonymous

   This minor node names the major contributors to `gawk' and/or this
Info file, in approximate chronological order:

   * Dr. Alfred V. Aho, Dr. Peter J. Weinberger, and Dr. Brian W.
     Kernighan, all of Bell Laboratories, designed and implemented Unix
     `awk', from which `gawk' gets the majority of its feature set.

   * Paul Rubin did the initial design and implementation in 1986, and
     wrote the first draft (around 40 pages) of this Info file.

   * Jay Fenlason finished the initial implementation.

   * Diane Close revised the first draft of this Info file, bringing it
     to around 90 pages.

   * Richard Stallman helped finish the implementation and the initial
     draft of this Info file.  He is also the founder of the FSF and
     the GNU project.

   * John Woods contributed parts of the code (mostly fixes) in the
     initial version of `gawk'.

   * In 1988, David Trueman took over primary maintenance of `gawk',
     making it compatible with "new" `awk', and greatly improving its
     performance.

   * Conrad Kwok, Scott Garfinkle, and Kent Williams did the initial
     ports to MS-DOS with various versions of MSC.

   * Pat Rankin provided the VMS port and its documentation.

   * Hal Peterson provided help in porting `gawk' to Cray systems.
     (This is no longer supported.)

   * Kai Uwe Rommel provided the initial port to OS/2 and its
     documentation.

   * Michal Jaegermann provided the port to Atari systems and its
     documentation.  (This port is no longer supported.)  He continues
     to provide portability checking with DEC Alpha systems, and has
     done a lot of work to make sure `gawk' works on non-32-bit systems.

   * Fred Fish provided the port to Amiga systems and its documentation.
     (With Fred's sad passing, this is no longer supported.)

   * Scott Deifik currently maintains the MS-DOS port using DJGPP.

   * Eli Zaretskii currently maintains the MS-Windows port using MinGW.

   * Juan Grigera provided a port to Windows32 systems.  (This is no
     longer supported.)

   * For many years, Dr. Darrel Hankerson acted as coordinator for the
     various ports to different PC platforms and created binary
     distributions for various PC operating systems.  He was also
     instrumental in keeping the documentation up to date for the
     various PC platforms.

   * Christos Zoulas provided the `extension()' built-in function for
     dynamically adding new modules.

   * Ju"rgen Kahrs contributed the initial version of the TCP/IP
     networking code and documentation, and motivated the inclusion of
     the `|&' operator.

   * Stephen Davies provided the initial port to Tandem systems and its
     documentation.  (However, this is no longer supported.)  He was
     also instrumental in the initial work to integrate the byte-code
     internals into the `gawk' code base.

   * Matthew Woehlke provided improvements for Tandem's POSIX-compliant
     systems.

   * Martin Brown provided the port to BeOS and its documentation.
     (This is no longer supported.)

   * Arno Peters did the initial work to convert `gawk' to use GNU
     Automake and GNU `gettext'.

   * Alan J. Broder provided the initial version of the `asort()'
     function as well as the code for the optional third argument to the
     `match()' function.

   * Andreas Buening updated the `gawk' port for OS/2.

   * Isamu Hasegawa, of IBM in Japan, contributed support for multibyte
     characters.

   * Michael Benzinger contributed the initial code for `switch'
     statements.

   * Patrick T.J. McPhee contributed the code for dynamic loading in
     Windows32 environments.  (This is no longer supported)

   * John Haque reworked the `gawk' internals to use a byte-code engine,
     providing the `dgawk' debugger for `awk' programs.

   * Efraim Yawitz contributed the original text for *note Debugger::.

   * Arnold Robbins has been working on `gawk' since 1988, at first
     helping David Trueman, and as the primary maintainer since around
     1994.


File: gawk.info,  Node: Installation,  Next: Notes,  Prev: Language History,  Up: Top

Appendix B Installing `gawk'
****************************

This appendix provides instructions for installing `gawk' on the
various platforms that are supported by the developers.  The primary
developer supports GNU/Linux (and Unix), whereas the other ports are
contributed.  *Note Bugs::, for the electronic mail addresses of the
people who did the respective ports.

* Menu:

* Gawk Distribution::           What is in the `gawk' distribution.
* Unix Installation::           Installing `gawk' under various
                                versions of Unix.
* Non-Unix Installation::       Installation on Other Operating Systems.
* Bugs::                        Reporting Problems and Bugs.
* Other Versions::              Other freely available `awk'
                                implementations.


File: gawk.info,  Node: Gawk Distribution,  Next: Unix Installation,  Up: Installation

B.1 The `gawk' Distribution
===========================

This minor node describes how to get the `gawk' distribution, how to
extract it, and then what is in the various files and subdirectories.

* Menu:

* Getting::                     How to get the distribution.
* Extracting::                  How to extract the distribution.
* Distribution contents::       What is in the distribution.


File: gawk.info,  Node: Getting,  Next: Extracting,  Up: Gawk Distribution

B.1.1 Getting the `gawk' Distribution
-------------------------------------

There are three ways to get GNU software:

   * Copy it from someone else who already has it.

   * Retrieve `gawk' from the Internet host `ftp.gnu.org', in the
     directory `/gnu/gawk'.  Both anonymous `ftp' and `http' access are
     supported.  If you have the `wget' program, you can use a command
     like the following:

          wget http://ftp.gnu.org/gnu/gawk/gawk-4.0.0.tar.gz

   The GNU software archive is mirrored around the world.  The
up-to-date list of mirror sites is available from the main FSF web site
(http://www.gnu.org/order/ftp.html).  Try to use one of the mirrors;
they will be less busy, and you can usually find one closer to your
site.


File: gawk.info,  Node: Extracting,  Next: Distribution contents,  Prev: Getting,  Up: Gawk Distribution

B.1.2 Extracting the Distribution
---------------------------------

`gawk' is distributed as several `tar' files compressed with different
compression programs: `gzip', `bzip2', and `xz'. For simplicity, the
rest of these instructions assume you are using the one compressed with
the GNU Zip program, `gzip'.

   Once you have the distribution (for example, `gawk-4.0.0.tar.gz'),
use `gzip' to expand the file and then use `tar' to extract it.  You
can use the following pipeline to produce the `gawk' distribution:

     # Under System V, add 'o' to the tar options
     gzip -d -c gawk-4.0.0.tar.gz | tar -xvpf -

   On a system with GNU `tar', you can let `tar' do the decompression
for you:

     tar -xvpzf gawk-4.0.0.tar.gz

Extracting the archive creates a directory named `gawk-4.0.0' in the
current directory.

   The distribution file name is of the form `gawk-V.R.P.tar.gz'.  The
V represents the major version of `gawk', the R represents the current
release of version V, and the P represents a "patch level", meaning
that minor bugs have been fixed in the release.  The current patch
level is 0, but when retrieving distributions, you should get the
version with the highest version, release, and patch level.  (Note,
however, that patch levels greater than or equal to 70 denote "beta" or
nonproduction software; you might not want to retrieve such a version
unless you don't mind experimenting.)  If you are not on a Unix or
GNU/Linux system, you need to make other arrangements for getting and
extracting the `gawk' distribution.  You should consult a local expert.


File: gawk.info,  Node: Distribution contents,  Prev: Extracting,  Up: Gawk Distribution

B.1.3 Contents of the `gawk' Distribution
-----------------------------------------

The `gawk' distribution has a number of C source files, documentation
files, subdirectories, and files related to the configuration process
(*note Unix Installation::), as well as several subdirectories related
to different non-Unix operating systems:

Various `.c', `.y', and `.h' files
     The actual `gawk' source code.

`README'
`README_d/README.*'
     Descriptive files: `README' for `gawk' under Unix and the rest for
     the various hardware and software combinations.

`INSTALL'
     A file providing an overview of the configuration and installation
     process.

`ChangeLog'
     A detailed list of source code changes as bugs are fixed or
     improvements made.

`ChangeLog.0'
     An older list of source code changes.

`NEWS'
     A list of changes to `gawk' since the last release or patch.

`NEWS.0'
     An older list of changes to `gawk'.

`COPYING'
     The GNU General Public License.

`FUTURES'
     A brief list of features and changes being contemplated for future
     releases, with some indication of the time frame for the feature,
     based on its difficulty.

`LIMITATIONS'
     A list of those factors that limit `gawk''s performance.  Most of
     these depend on the hardware or operating system software and are
     not limits in `gawk' itself.

`POSIX.STD'
     A description of behaviors in the POSIX standard for `awk' which
     are left undefined, or where `gawk' may not comply fully, as well
     as a list of things that the POSIX standard should describe but
     does not.

`doc/awkforai.txt'
     A short article describing why `gawk' is a good language for
     Artificial Intelligence (AI) programming.

`doc/bc_notes'
     A brief description of `gawk''s "byte code" internals.

`doc/README.card'
`doc/ad.block'
`doc/awkcard.in'
`doc/cardfonts'
`doc/colors'
`doc/macros'
`doc/no.colors'
`doc/setter.outline'
     The `troff' source for a five-color `awk' reference card.  A
     modern version of `troff' such as GNU `troff' (`groff') is needed
     to produce the color version. See the file `README.card' for
     instructions if you have an older `troff'.

`doc/gawk.1'
     The `troff' source for a manual page describing `gawk'.  This is
     distributed for the convenience of Unix users.

`doc/gawk.texi'
     The Texinfo source file for this Info file.  It should be
     processed with TeX (via `texi2dvi' or `texi2pdf') to produce a
     printed document, and with `makeinfo' to produce an Info or HTML
     file.

`doc/gawk.info'
     The generated Info file for this Info file.

`doc/gawkinet.texi'
     The Texinfo source file for *note (General Introduction)Top::
     gawkinet, TCP/IP Internetworking with `gawk'.  It should be
     processed with TeX (via `texi2dvi' or `texi2pdf') to produce a
     printed document and with `makeinfo' to produce an Info or HTML
     file.

`doc/gawkinet.info'
     The generated Info file for `TCP/IP Internetworking with `gawk''.

`doc/igawk.1'
     The `troff' source for a manual page describing the `igawk'
     program presented in *note Igawk Program::.

`doc/Makefile.in'
     The input file used during the configuration process to generate
     the actual `Makefile' for creating the documentation.

`Makefile.am'
`*/Makefile.am'
     Files used by the GNU `automake' software for generating the
     `Makefile.in' files used by `autoconf' and `configure'.

`Makefile.in'
`aclocal.m4'
`configh.in'
`configure.ac'
`configure'
`custom.h'
`missing_d/*'
`m4/*'
     These files and subdirectories are used when configuring `gawk'
     for various Unix systems.  They are explained in *note Unix
     Installation::.

`po/*'
     The `po' library contains message translations.

`awklib/extract.awk'
`awklib/Makefile.am'
`awklib/Makefile.in'
`awklib/eg/*'
     The `awklib' directory contains a copy of `extract.awk' (*note
     Extract Program::), which can be used to extract the sample
     programs from the Texinfo source file for this Info file. It also
     contains a `Makefile.in' file, which `configure' uses to generate
     a `Makefile'.  `Makefile.am' is used by GNU Automake to create
     `Makefile.in'.  The library functions from *note Library
     Functions::, and the `igawk' program from *note Igawk Program::,
     are included as ready-to-use files in the `gawk' distribution.
     They are installed as part of the installation process.  The rest
     of the programs in this Info file are available in appropriate
     subdirectories of `awklib/eg'.

`posix/*'
     Files needed for building `gawk' on POSIX-compliant systems.

`pc/*'
     Files needed for building `gawk' under MS-Windows and OS/2 (*note
     PC Installation::, for details).

`vms/*'
     Files needed for building `gawk' under VMS (*note VMS
     Installation::, for details).

`test/*'
     A test suite for `gawk'.  You can use `make check' from the
     top-level `gawk' directory to run your version of `gawk' against
     the test suite.  If `gawk' successfully passes `make check', then
     you can be confident of a successful port.


File: gawk.info,  Node: Unix Installation,  Next: Non-Unix Installation,  Prev: Gawk Distribution,  Up: Installation

B.2 Compiling and Installing `gawk' on Unix-like Systems
========================================================

Usually, you can compile and install `gawk' by typing only two
commands.  However, if you use an unusual system, you may need to
configure `gawk' for your system yourself.

* Menu:

* Quick Installation::               Compiling `gawk' under Unix.
* Additional Configuration Options:: Other compile-time options.
* Configuration Philosophy::         How it's all supposed to work.


File: gawk.info,  Node: Quick Installation,  Next: Additional Configuration Options,  Up: Unix Installation

B.2.1 Compiling `gawk' for Unix-like Systems
--------------------------------------------

The normal installation steps should work on all modern commercial
Unix-derived systems, GNU/Linux, BSD-based systems, and the Cygwin
environment for MS-Windows.

   After you have extracted the `gawk' distribution, `cd' to
`gawk-4.0.0'.  Like most GNU software, `gawk' is configured
automatically for your system by running the `configure' program.  This
program is a Bourne shell script that is generated automatically using
GNU `autoconf'.  (The `autoconf' software is described fully starting
with *note (Autoconf)Top:: autoconf,Autoconf--Generating Automatic
Configuration Scripts.)

   To configure `gawk', simply run `configure':

     sh ./configure

   This produces a `Makefile' and `config.h' tailored to your system.
The `config.h' file describes various facts about your system.  You
might want to edit the `Makefile' to change the `CFLAGS' variable,
which controls the command-line options that are passed to the C
compiler (such as optimization levels or compiling for debugging).

   Alternatively, you can add your own values for most `make' variables
on the command line, such as `CC' and `CFLAGS', when running
`configure':

     CC=cc CFLAGS=-g sh ./configure

See the file `INSTALL' in the `gawk' distribution for all the details.

   After you have run `configure' and possibly edited the `Makefile',
type:

     make

Shortly thereafter, you should have an executable version of `gawk'.
That's all there is to it!  To verify that `gawk' is working properly,
run `make check'.  All of the tests should succeed.  If these steps do
not work, or if any of the tests fail, check the files in the
`README_d' directory to see if you've found a known problem.  If the
failure is not described there, please send in a bug report (*note
Bugs::).


File: gawk.info,  Node: Additional Configuration Options,  Next: Configuration Philosophy,  Prev: Quick Installation,  Up: Unix Installation

B.2.2 Additional Configuration Options
--------------------------------------

There are several additional options you may use on the `configure'
command line when compiling `gawk' from scratch, including:

`--disable-lint'
     Disable all lint checking within `gawk'.  The `--lint' and
     `--lint-old' options (*note Options::) are accepted, but silently
     do nothing.  Similarly, setting the `LINT' variable (*note
     User-modified::) has no effect on the running `awk' program.

     When used with GCC's automatic dead-code-elimination, this option
     cuts almost 200K bytes off the size of the `gawk' executable on
     GNU/Linux x86 systems.  Results on other systems and with other
     compilers are likely to vary.  Using this option may bring you
     some slight performance improvement.

     Using this option will cause some of the tests in the test suite
     to fail.  This option may be removed at a later date.

`--disable-nls'
     Disable all message-translation facilities.  This is usually not
     desirable, but it may bring you some slight performance
     improvement.

`--with-whiny-user-strftime'
     Force use of the included version of the `strftime()' function for
     deficient systems.

   Use the command `./configure --help' to see the full list of options
that `configure' supplies.


File: gawk.info,  Node: Configuration Philosophy,  Prev: Additional Configuration Options,  Up: Unix Installation

B.2.3 The Configuration Process
-------------------------------

This minor node is of interest only if you know something about using
the C language and Unix-like operating systems.

   The source code for `gawk' generally attempts to adhere to formal
standards wherever possible.  This means that `gawk' uses library
routines that are specified by the ISO C standard and by the POSIX
operating system interface standard.  The `gawk' source code requires
using an ISO C compiler (the 1990 standard).

   Many Unix systems do not support all of either the ISO or the POSIX
standards.  The `missing_d' subdirectory in the `gawk' distribution
contains replacement versions of those functions that are most likely
to be missing.

   The `config.h' file that `configure' creates contains definitions
that describe features of the particular operating system where you are
attempting to compile `gawk'.  The three things described by this file
are: what header files are available, so that they can be correctly
included, what (supposedly) standard functions are actually available
in your C libraries, and various miscellaneous facts about your
operating system.  For example, there may not be an `st_blksize'
element in the `stat' structure.  In this case, `HAVE_ST_BLKSIZE' is
undefined.

   It is possible for your C compiler to lie to `configure'. It may do
so by not exiting with an error when a library function is not
available.  To get around this, edit the file `custom.h'.  Use an
`#ifdef' that is appropriate for your system, and either `#define' any
constants that `configure' should have defined but didn't, or `#undef'
any constants that `configure' defined and should not have.  `custom.h'
is automatically included by `config.h'.

   It is also possible that the `configure' program generated by
`autoconf' will not work on your system in some other fashion.  If you
do have a problem, the file `configure.ac' is the input for `autoconf'.
You may be able to change this file and generate a new version of
`configure' that works on your system (*note Bugs::, for information on
how to report problems in configuring `gawk').  The same mechanism may
be used to send in updates to `configure.ac' and/or `custom.h'.


File: gawk.info,  Node: Non-Unix Installation,  Next: Bugs,  Prev: Unix Installation,  Up: Installation

B.3 Installation on Other Operating Systems
===========================================

This minor node describes how to install `gawk' on various non-Unix
systems.

* Menu:

* PC Installation::             Installing and Compiling `gawk' on
                                MS-DOS and OS/2.
* VMS Installation::            Installing `gawk' on VMS.


File: gawk.info,  Node: PC Installation,  Next: VMS Installation,  Up: Non-Unix Installation

B.3.1 Installation on PC Operating Systems
------------------------------------------

This minor node covers installation and usage of `gawk' on x86 machines
running MS-DOS, any version of MS-Windows, or OS/2.  In this minor
node, the term "Windows32" refers to any of Microsoft
Windows-95/98/ME/NT/2000/XP/Vista/7.

   The limitations of MS-DOS (and MS-DOS shells under Windows32 or
OS/2) has meant that various "DOS extenders" are often used with
programs such as `gawk'.  The varying capabilities of Microsoft Windows
3.1 and Windows32 can add to the confusion.  For an overview of the
considerations, please refer to `README_d/README.pc' in the
distribution.

* Menu:

* PC Binary Installation::      Installing a prepared distribution.
* PC Compiling::                Compiling `gawk' for MS-DOS,
                                Windows32, and OS/2.
* PC Testing::                  Testing `gawk' on PC systems.
* PC Using::                    Running `gawk' on MS-DOS, Windows32
                                and OS/2.
* Cygwin::                      Building and running `gawk' for
                                Cygwin.
* MSYS::                        Using `gawk' In The MSYS Environment.


File: gawk.info,  Node: PC Binary Installation,  Next: PC Compiling,  Up: PC Installation

B.3.1.1 Installing a Prepared Distribution for PC Systems
.........................................................

If you have received a binary distribution prepared by the MS-DOS
maintainers, then `gawk' and the necessary support files appear under
the `gnu' directory, with executables in `gnu/bin', libraries in
`gnu/lib/awk', and manual pages under `gnu/man'.  This is designed for
easy installation to a `/gnu' directory on your drive--however, the
files can be installed anywhere provided `AWKPATH' is set properly.
Regardless of the installation directory, the first line of `igawk.cmd'
and `igawk.bat' (in `gnu/bin') may need to be edited.

   The binary distribution contains a separate file describing the
contents. In particular, it may include more than one version of the
`gawk' executable.

   OS/2 (32 bit, EMX) binary distributions are prepared for the `/usr'
directory of your preferred drive. Set `UNIXROOT' to your installation
drive (e.g., `e:') if you want to install `gawk' onto another drive
than the hardcoded default `c:'. Executables appear in `/usr/bin',
libraries under `/usr/share/awk', manual pages under `/usr/man',
Texinfo documentation under `/usr/info', and NLS files under
`/usr/share/locale'.  Note that the files can be installed anywhere
provided `AWKPATH' is set properly.

   If you already have a file `/usr/info/dir' from another package _do
not overwrite it!_ Instead enter the following commands at your prompt
(replace `x:' by your installation drive):

     install-info --info-dir=x:/usr/info x:/usr/info/gawk.info
     install-info --info-dir=x:/usr/info x:/usr/info/gawkinet.info

   The binary distribution may contain a separate file containing
additional or more detailed installation instructions.


File: gawk.info,  Node: PC Compiling,  Next: PC Testing,  Prev: PC Binary Installation,  Up: PC Installation

B.3.1.2 Compiling `gawk' for PC Operating Systems
.................................................

`gawk' can be compiled for MS-DOS, Windows32, and OS/2 using the GNU
development tools from DJ Delorie (DJGPP: MS-DOS only) or Eberhard
Mattes (EMX: MS-DOS, Windows32 and OS/2).  The file
`README_d/README.pc' in the `gawk' distribution contains additional
notes, and `pc/Makefile' contains important information on compilation
options.

   To build `gawk' for MS-DOS and Windows32, copy the files in the `pc'
directory (_except_ for `ChangeLog') to the directory with the rest of
the `gawk' sources, then invoke `make' with the appropriate target name
as an argument to build `gawk'.  The `Makefile' copied from the `pc'
directory contains a configuration section with comments and may need
to be edited in order to work with your `make' utility.

   The `Makefile' supports a number of targets for building various
MS-DOS and Windows32 versions.  A list of targets is printed if the
`make' command is given without a target.  As an example, to build
`gawk' using the DJGPP tools, enter `make djgpp'.  (The DJGPP tools
needed for the build may be found at
`ftp://ftp.delorie.com/pub/djgpp/current/v2gnu/'.)  To build a native
MS-Windows binary of `gawk', type `make mingw32'.

   The 32 bit EMX version of `gawk' works "out of the box" under OS/2.
However, it is highly recommended to use GCC 2.95.3 for the compilation.
In principle, it is possible to compile `gawk' the following way:

     $ ./configure
     $ make

   This is not recommended, though.  To get an OMF executable you should
use the following commands at your `sh' prompt:

     $ CFLAGS="-O2 -Zomf -Zmt"
     $ export CFLAGS
     $ LDFLAGS="-s -Zcrtdll -Zlinker /exepack:2 -Zlinker /pm:vio -Zstack 0x6000"
     $ export LDFLAGS
     $ RANLIB="echo"
     $ export RANLIB
     $ ./configure --prefix=c:/usr
     $ make AR=emxomfar

   These are just suggestions for use with GCC 2.x.  You may use any
other set of (self-consistent) environment variables and compiler flags.

   If you use GCC 2.95 it is recommended to use also:

     $ LIBS="-lgcc"
     $ export LIBS

   You can also get an `a.out' executable if you prefer:

     $ CFLAGS="-O2 -Zmt"
     $ export CFLAGS
     $ LDFLAGS="-s -Zstack 0x6000"
     $ LIBS="-lgcc"
     $ unset RANLIB
     $ ./configure --prefix=c:/usr
     $ make

     NOTE: Compilation of `a.out' executables also works with GCC 3.2.
     Versions later than GCC 3.2 have not been tested successfully.

   `make install' works as expected with the EMX build.

     NOTE: Ancient OS/2 ports of GNU `make' are not able to handle the
     Makefiles of this package.  If you encounter any problems with
     `make', try GNU Make 3.79.1 or later versions.  You should find
     the latest version on `ftp://hobbes.nmsu.edu/pub/os2/'.


File: gawk.info,  Node: PC Testing,  Next: PC Using,  Prev: PC Compiling,  Up: PC Installation

B.3.1.3 Testing `gawk' on PC Operating Systems
..............................................

Using `make' to run the standard tests and to install `gawk' requires
additional Unix-like tools, including `sh', `sed', and `cp'. In order
to run the tests, the `test/*.ok' files may need to be converted so
that they have the usual MS-DOS-style end-of-line markers.
Alternatively, run `make check CMP="diff -a"' to use GNU `diff' in text
mode instead of `cmp' to compare the resulting files.

   Most of the tests work properly with Stewartson's shell along with
the companion utilities or appropriate GNU utilities.  However, some
editing of `test/Makefile' is required. It is recommended that you copy
the file `pc/Makefile.tst' over the file `test/Makefile' as a
replacement. Details can be found in `README_d/README.pc' and in the
file `pc/Makefile.tst'.

   On OS/2 the `pid' test fails because `spawnl()' is used instead of
`fork()'/`execl()' to start child processes.  Also the `mbfw1' and
`mbprintf1' tests fail because the needed multibyte functionality is
not available.


File: gawk.info,  Node: PC Using,  Next: Cygwin,  Prev: PC Testing,  Up: PC Installation

B.3.1.4 Using `gawk' on PC Operating Systems
............................................

With the exception of the Cygwin environment, the `|&' operator and
TCP/IP networking (*note TCP/IP Networking::) are not supported for
MS-DOS or MS-Windows.  EMX (OS/2 only) does support at least the `|&'
operator.

   The MS-DOS and MS-Windows versions of `gawk' search for program
files as described in *note AWKPATH Variable::.  However, semicolons
(rather than colons) separate elements in the `AWKPATH' variable.  If
`AWKPATH' is not set or is empty, then the default search path for
MS-Windows and MS-DOS versions is `".;c:/lib/awk;c:/gnu/lib/awk"'.

   The search path for OS/2 (32 bit, EMX) is determined by the prefix
directory (most likely `/usr' or `c:/usr') that has been specified as
an option of the `configure' script like it is the case for the Unix
versions.  If `c:/usr' is the prefix directory then the default search
path contains `.' and `c:/usr/share/awk'.  Additionally, to support
binary distributions of `gawk' for OS/2 systems whose drive `c:' might
not support long file names or might not exist at all, there is a
special environment variable.  If `UNIXROOT' specifies a drive then
this specific drive is also searched for program files.  E.g., if
`UNIXROOT' is set to `e:' the complete default search path is
`".;c:/usr/share/awk;e:/usr/share/awk"'.

   An `sh'-like shell (as opposed to `command.com' under MS-DOS or
`cmd.exe' under MS-Windows or OS/2) may be useful for `awk' programming.
The DJGPP collection of tools includes an MS-DOS port of Bash, and
several shells are available for OS/2, including `ksh'.

   Under MS-Windows, OS/2 and MS-DOS, `gawk' (and many other text
programs) silently translate end-of-line `"\r\n"' to `"\n"' on input
and `"\n"' to `"\r\n"' on output.  A special `BINMODE' variable
(c.e.)  allows control over these translations and is interpreted as
follows:

   * If `BINMODE' is `"r"', or one, then binary mode is set on read
     (i.e., no translations on reads).

   * If `BINMODE' is `"w"', or two, then binary mode is set on write
     (i.e., no translations on writes).

   * If `BINMODE' is `"rw"' or `"wr"' or three, binary mode is set for
     both read and write.

   * `BINMODE=NON-NULL-STRING' is the same as `BINMODE=3' (i.e., no
     translations on reads or writes).  However, `gawk' issues a warning
     message if the string is not one of `"rw"' or `"wr"'.

The modes for standard input and standard output are set one time only
(after the command line is read, but before processing any of the `awk'
program).  Setting `BINMODE' for standard input or standard output is
accomplished by using an appropriate `-v BINMODE=N' option on the
command line.  `BINMODE' is set at the time a file or pipe is opened
and cannot be changed mid-stream.

   The name `BINMODE' was chosen to match `mawk' (*note Other
Versions::).  `mawk' and `gawk' handle `BINMODE' similarly; however,
`mawk' adds a `-W BINMODE=N' option and an environment variable that
can set `BINMODE', `RS', and `ORS'.  The files `binmode[1-3].awk'
(under `gnu/lib/awk' in some of the prepared distributions) have been
chosen to match `mawk''s `-W BINMODE=N' option.  These can be changed
or discarded; in particular, the setting of `RS' giving the fewest
"surprises" is open to debate.  `mawk' uses `RS = "\r\n"' if binary
mode is set on read, which is appropriate for files with the
MS-DOS-style end-of-line.

   To illustrate, the following examples set binary mode on writes for
standard output and other files, and set `ORS' as the "usual"
MS-DOS-style end-of-line:

     gawk -v BINMODE=2 -v ORS="\r\n" ...

or:

     gawk -v BINMODE=w -f binmode2.awk ...

These give the same result as the `-W BINMODE=2' option in `mawk'.  The
following changes the record separator to `"\r\n"' and sets binary mode
on reads, but does not affect the mode on standard input:

     gawk -v RS="\r\n" --source "BEGIN { BINMODE = 1 }" ...

or:

     gawk -f binmode1.awk ...

With proper quoting, in the first example the setting of `RS' can be
moved into the `BEGIN' rule.


File: gawk.info,  Node: Cygwin,  Next: MSYS,  Prev: PC Using,  Up: PC Installation

B.3.1.5 Using `gawk' In The Cygwin Environment
..............................................

`gawk' can be built and used "out of the box" under MS-Windows if you
are using the Cygwin environment (http://www.cygwin.com).  This
environment provides an excellent simulation of Unix, using the GNU
tools, such as Bash, the GNU Compiler Collection (GCC), GNU Make, and
other GNU programs.  Compilation and installation for Cygwin is the
same as for a Unix system:

     tar -xvpzf gawk-4.0.0.tar.gz
     cd gawk-4.0.0
     ./configure
     make

   When compared to GNU/Linux on the same system, the `configure' step
on Cygwin takes considerably longer.  However, it does finish, and then
the `make' proceeds as usual.

     NOTE: The `|&' operator and TCP/IP networking (*note TCP/IP
     Networking::) are fully supported in the Cygwin environment.  This
     is not true for any other environment on MS-Windows.


File: gawk.info,  Node: MSYS,  Prev: Cygwin,  Up: PC Installation

B.3.1.6 Using `gawk' In The MSYS Environment
............................................

In the MSYS environment under MS-Windows, `gawk' automatically uses
binary mode for reading and writing files.  Thus there is no need to
use the `BINMODE' variable.

   This can cause problems with other Unix-like components that have
been ported to MS-Windows that expect `gawk' to do automatic
translation of `"\r\n"', since it won't.  Caveat Emptor!


File: gawk.info,  Node: VMS Installation,  Prev: PC Installation,  Up: Non-Unix Installation

B.3.2 How to Compile and Install `gawk' on VMS
----------------------------------------------

This node describes how to compile and install `gawk' under VMS.  The
older designation "VMS" is used throughout to refer to OpenVMS.

* Menu:

* VMS Compilation::             How to compile `gawk' under VMS.
* VMS Installation Details::    How to install `gawk' under VMS.
* VMS Running::                 How to run `gawk' under VMS.
* VMS Old Gawk::                An old version comes with some VMS systems.


File: gawk.info,  Node: VMS Compilation,  Next: VMS Installation Details,  Up: VMS Installation

B.3.2.1 Compiling `gawk' on VMS
...............................

To compile `gawk' under VMS, there is a `DCL' command procedure that
issues all the necessary `CC' and `LINK' commands. There is also a
`Makefile' for use with the `MMS' utility.  From the source directory,
use either:

     $ @[.VMS]VMSBUILD.COM

or:

     $ MMS/DESCRIPTION=[.VMS]DESCRIP.MMS GAWK

   Older versions of `gawk' could be built with VAX C or GNU C on
VAX/VMS, as well as with DEC C, but that is no longer supported.  DEC C
(also briefly known as "Compaq C" and now known as "HP C," but referred
to here as "DEC C") is required.  Both `VMSBUILD.COM' and `DESCRIP.MMS'
contain some obsolete support for the older compilers but are set up to
use DEC C by default.

   `gawk' has been tested under Alpha/VMS 7.3-1 using Compaq C V6.4,
and on Alpha/VMS 7.3, Alpha/VMS 7.3-2, and IA64/VMS 8.3.(1)

   ---------- Footnotes ----------

   (1) The IA64 architecture is also known as "Itanium."


File: gawk.info,  Node: VMS Installation Details,  Next: VMS Running,  Prev: VMS Compilation,  Up: VMS Installation

B.3.2.2 Installing `gawk' on VMS
................................

To install `gawk', all you need is a "foreign" command, which is a
`DCL' symbol whose value begins with a dollar sign. For example:

     $ GAWK :== $disk1:[gnubin]GAWK

Substitute the actual location of `gawk.exe' for `$disk1:[gnubin]'. The
symbol should be placed in the `login.com' of any user who wants to run
`gawk', so that it is defined every time the user logs on.
Alternatively, the symbol may be placed in the system-wide
`sylogin.com' procedure, which allows all users to run `gawk'.

   Optionally, the help entry can be loaded into a VMS help library:

     $ LIBRARY/HELP SYS$HELP:HELPLIB [.VMS]GAWK.HLP

(You may want to substitute a site-specific help library rather than
the standard VMS library `HELPLIB'.)  After loading the help text, the
command:

     $ HELP GAWK

provides information about both the `gawk' implementation and the `awk'
programming language.

   The logical name `AWK_LIBRARY' can designate a default location for
`awk' program files.  For the `-f' option, if the specified file name
has no device or directory path information in it, `gawk' looks in the
current directory first, then in the directory specified by the
translation of `AWK_LIBRARY' if the file is not found.  If, after
searching in both directories, the file still is not found, `gawk'
appends the suffix `.awk' to the filename and retries the file search.
If `AWK_LIBRARY' has no definition, a default value of `SYS$LIBRARY:'
is used for it.


File: gawk.info,  Node: VMS Running,  Next: VMS Old Gawk,  Prev: VMS Installation Details,  Up: VMS Installation

B.3.2.3 Running `gawk' on VMS
.............................

Command-line parsing and quoting conventions are significantly different
on VMS, so examples in this Info file or from other sources often need
minor changes.  They _are_ minor though, and all `awk' programs should
run correctly.

   Here are a couple of trivial tests:

     $ gawk -- "BEGIN {print ""Hello, World!""}"
     $ gawk -"W" version
     ! could also be -"W version" or "-W version"

Note that uppercase and mixed-case text must be quoted.

   The VMS port of `gawk' includes a `DCL'-style interface in addition
to the original shell-style interface (see the help entry for details).
One side effect of dual command-line parsing is that if there is only a
single parameter (as in the quoted string program above), the command
becomes ambiguous.  To work around this, the normally optional `--'
flag is required to force Unix-style parsing rather than `DCL' parsing.
If any other dash-type options (or multiple parameters such as data
files to process) are present, there is no ambiguity and `--' can be
omitted.

   The default search path, when looking for `awk' program files
specified by the `-f' option, is `"SYS$DISK:[],AWK_LIBRARY:"'.  The
logical name `AWKPATH' can be used to override this default.  The format
of `AWKPATH' is a comma-separated list of directory specifications.
When defining it, the value should be quoted so that it retains a single
translation and not a multitranslation `RMS' searchlist.


File: gawk.info,  Node: VMS Old Gawk,  Prev: VMS Running,  Up: VMS Installation

B.3.2.4 Some VMS Systems Have An Old Version of `gawk'
......................................................

Some versions of VMS have an old version of `gawk'.  To access it,
define a symbol, as follows:

     $ gawk :== $sys$common:[syshlp.examples.tcpip.snmp]gawk.exe

   This is apparently version 2.15.6, which is extremely old. We
recommend compiling and using the current version.


File: gawk.info,  Node: Bugs,  Next: Other Versions,  Prev: Non-Unix Installation,  Up: Installation

B.4 Reporting Problems and Bugs
===============================

     There is nothing more dangerous than a bored archeologist.
     The Hitchhiker's Guide to the Galaxy

   If you have problems with `gawk' or think that you have found a bug,
please report it to the developers; we cannot promise to do anything
but we might well want to fix it.

   Before reporting a bug, make sure you have actually found a real bug.
Carefully reread the documentation and see if it really says you can do
what you're trying to do.  If it's not clear whether you should be able
to do something or not, report that too; it's a bug in the
documentation!

   Before reporting a bug or trying to fix it yourself, try to isolate
it to the smallest possible `awk' program and input data file that
reproduces the problem.  Then send us the program and data file, some
idea of what kind of Unix system you're using, the compiler you used to
compile `gawk', and the exact results `gawk' gave you.  Also say what
you expected to occur; this helps us decide whether the problem is
really in the documentation.

   Please include the version number of `gawk' you are using.  You can
get this information with the command `gawk --version'.

   Once you have a precise problem, send email to <bug-gawk@gnu.org>.

   Using this address automatically sends a copy of your mail to me.
If necessary, I can be reached directly at <arnold@skeeve.com>.  The
bug reporting address is preferred since the email list is archived at
the GNU Project.  _All email should be in English, since that is my
native language._

     CAUTION: Do _not_ try to report bugs in `gawk' by posting to the
     Usenet/Internet newsgroup `comp.lang.awk'.  While the `gawk'
     developers do occasionally read this newsgroup, there is no
     guarantee that we will see your posting.  The steps described
     above are the official recognized ways for reporting bugs.  Really.

     NOTE: Many distributions of GNU/Linux and the various BSD-based
     operating systems have their own bug reporting systems.  If you
     report a bug using your distribution's bug reporting system,
     _please_ also send a copy to <bug-gawk@gnu.org>.

     This is for two reasons.  First, while some distributions forward
     bug reports "upstream" to the GNU mailing list, many don't, so
     there is a good chance that the `gawk'  maintainer won't even see
     the bug report!  Second, mail to the GNU list is archived, and
     having everything at the GNU project keeps things self-contained
     and not dependant on other web sites.

   Non-bug suggestions are always welcome as well.  If you have
questions about things that are unclear in the documentation or are
just obscure features, ask me; I will try to help you out, although I
may not have the time to fix the problem.  You can send me electronic
mail at the Internet address noted previously.

   If you find bugs in one of the non-Unix ports of `gawk', please send
an electronic mail message to the person who maintains that port.  They
are named in the following list, as well as in the `README' file in the
`gawk' distribution.  Information in the `README' file should be
considered authoritative if it conflicts with this Info file.

   The people maintaining the non-Unix ports of `gawk' are as follows:

MS-DOS with DJGPP       Scott Deifik, <scottd.mail@sbcglobal.net>.
MS-Windows with MINGW   Eli Zaretskii, <eliz@gnu.org>.
OS/2                    Andreas Buening, <andreas.buening@nexgo.de>.
VMS                     Pat Rankin, <rankin@pactechdata.com>.
z/OS (OS/390)           Dave Pitts, <dpitts@cozx.com>.

   If your bug is also reproducible under Unix, please send a copy of
your report to the <bug-gawk@gnu.org> email list as well.


File: gawk.info,  Node: Other Versions,  Prev: Bugs,  Up: Installation

B.5 Other Freely Available `awk' Implementations
================================================

     It's kind of fun to put comments like this in your awk code.
     `// Do C++ comments work? answer: yes! of course'
     Michael Brennan

   There are a number of other freely available `awk' implementations.
This minor node briefly describes where to get them:

Unix `awk'
     Brian Kernighan, one of the original designers of Unix `awk', has
     made his implementation of `awk' freely available.  You can
     retrieve this version via the World Wide Web from his home page
     (http://www.cs.princeton.edu/~bwk).  It is available in several
     archive formats:

    Shell archive
          `http://www.cs.princeton.edu/~bwk/btl.mirror/awk.shar'

    Compressed `tar' file
          `http://www.cs.princeton.edu/~bwk/btl.mirror/awk.tar.gz'

    Zip file
          `http://www.cs.princeton.edu/~bwk/btl.mirror/awk.zip'

     This version requires an ISO C (1990 standard) compiler; the C
     compiler from GCC (the GNU Compiler Collection) works quite nicely.

     *Note Common Extensions::, for a list of extensions in this `awk'
     that are not in POSIX `awk'.

`mawk'
     Michael Brennan wrote an independent implementation of `awk',
     called `mawk'.  It is available under the GPL (*note Copying::),
     just as `gawk' is.

     The original distribution site for the `mawk' source code no
     longer has it.  A copy is available at
     `http://www.skeeve.com/gawk/mawk1.3.3.tar.gz'.

     In 2009, Thomas Dickey took on `mawk' maintenance.  Basic
     information is available on the project's web page
     (http://www.invisible-island.net/mawk/mawk.html).  The download
     URL is `http://invisible-island.net/datafiles/release/mawk.tar.gz'.

     Once you have it, `gunzip' may be used to decompress this file.
     Installation is similar to `gawk''s (*note Unix Installation::).

     *Note Common Extensions::, for a list of extensions in `mawk' that
     are not in POSIX `awk'.

`awka'
     Written by Andrew Sumner, `awka' translates `awk' programs into C,
     compiles them, and links them with a library of functions that
     provides the core `awk' functionality.  It also has a number of
     extensions.

     The `awk' translator is released under the GPL, and the library is
     under the LGPL.

     To get `awka', go to `http://sourceforge.net/projects/awka'.

     The project seems to be frozen; no new code changes have been made
     since approximately 2003.

`pawk'
     Nelson H.F. Beebe at the University of Utah has modified Brian
     Kernighan's `awk' to provide timing and profiling information.  It
     is different from `pgawk' (*note Profiling::), in that it uses
     CPU-based profiling, not line-count profiling.  You may find it at
     either `ftp://ftp.math.utah.edu/pub/pawk/pawk-20030606.tar.gz' or
     `http://www.math.utah.edu/pub/pawk/pawk-20030606.tar.gz'.

Busybox Awk
     Busybox is a GPL-licensed program providing small versions of many
     applications within a single executable. It is aimed at embedded
     systems.  It includes a full implementation of POSIX `awk'.  When
     building it, be careful not to do `make install' as it will
     overwrite copies of other applications in your `/usr/local/bin'.
     For more information, see the project's home page
     (http://busybox.net).

The OpenSolaris POSIX `awk'
     The version of `awk' in `/usr/xpg4/bin' on Solaris is more-or-less
     POSIX-compliant. It is based on the `awk' from Mortice Kern
     Systems for PCs.  The source code can be downloaded from the
     OpenSolaris web site (http://www.opensolaris.org).  This author
     was able to make it compile and work under GNU/Linux with 1-2
     hours of work.  Making it more generally portable (using GNU
     Autoconf and/or Automake) would take more work, and this has not
     been done, at least to our knowledge.

`jawk'
     This is an interpreter for `awk' written in Java. It claims to be
     a full interpreter, although because it uses Java facilities for
     I/O and for regexp matching, the language it supports is different
     from POSIX `awk'.  More information is available on the project's
     home page (http://jawk.sourceforge.net).

Libmawk
     This is an embeddable `awk' interpreter derived from `mawk'. For
     more information see `http://repo.hu/projects/libmawk/'.

QSE Awk
     This is an embeddable `awk' interpreter. For more information see
     `http://code.google.com/p/qse/' and `http://awk.info/?tools/qse'.

`QTawk'
     This is an independent implementation of `awk' distributed under
     the GPL. It has a large number of extensions over standard `awk'
     and may not be 100% syntactically compatible with it.  See
     `http://www.quiktrim.org/QTawk.html' for more information,
     including the manual and a download link.

`xgawk'
     XML `gawk'.  This is a fork of the `gawk' 3.1.6 source base to
     support processing XML files. It has a number of interesting
     extensions which should one day be integrated into the main `gawk'
     code base.  For more information, see the XMLgawk project web site
     (http://xmlgawk.sourceforge.net).



File: gawk.info,  Node: Notes,  Next: Basic Concepts,  Prev: Installation,  Up: Top

Appendix C Implementation Notes
*******************************

This appendix contains information mainly of interest to implementers
and maintainers of `gawk'.  Everything in it applies specifically to
`gawk' and not to other implementations.

* Menu:

* Compatibility Mode::          How to disable certain `gawk'
                                extensions.
* Additions::                   Making Additions To `gawk'.
* Dynamic Extensions::          Adding new built-in functions to
                                `gawk'.
* Future Extensions::           New features that may be implemented one day.


File: gawk.info,  Node: Compatibility Mode,  Next: Additions,  Up: Notes

C.1 Downward Compatibility and Debugging
========================================

*Note POSIX/GNU::, for a summary of the GNU extensions to the `awk'
language and program.  All of these features can be turned off by
invoking `gawk' with the `--traditional' option or with the `--posix'
option.

   If `gawk' is compiled for debugging with `-DDEBUG', then there is
one more option available on the command line:

`-Y'
`--parsedebug'
     Prints out the parse stack information as the program is being
     parsed.

   This option is intended only for serious `gawk' developers and not
for the casual user.  It probably has not even been compiled into your
version of `gawk', since it slows down execution.


File: gawk.info,  Node: Additions,  Next: Dynamic Extensions,  Prev: Compatibility Mode,  Up: Notes

C.2 Making Additions to `gawk'
==============================

If you find that you want to enhance `gawk' in a significant fashion,
you are perfectly free to do so.  That is the point of having free
software; the source code is available and you are free to change it as
you want (*note Copying::).

   This minor node discusses the ways you might want to change `gawk'
as well as any considerations you should bear in mind.

* Menu:

* Accessing The Source::        Accessing the Git repository.
* Adding Code::                 Adding code to the main body of
                                `gawk'.
* New Ports::                   Porting `gawk' to a new operating
                                system.


File: gawk.info,  Node: Accessing The Source,  Next: Adding Code,  Up: Additions

C.2.1 Accessing The `gawk' Git Repository
-----------------------------------------

As `gawk' is Free Software, the source code is always available.  *note
Gawk Distribution::, describes how to get and build the formal,
released versions of `gawk'.

   However, if you want to modify `gawk' and contribute back your
changes, you will probably wish to work with the development version.
To do so, you will need to access the `gawk' source code repository.
The code is maintained using the Git distributed version control system
(http://git-scm.com/).  You will need to install it if your system
doesn't have it.  Once you have done so, use the command:

     git clone git://git.savannah.gnu.org/gawk.git

This will clone the `gawk' repository.  If you are behind a firewall
that will not allow you to use the Git native protocol, you can still
access the repository using:

     git clone http://git.savannah.gnu.org/r/gawk.git

   Once you have made changes, you can use `git diff' to produce a
patch, and send that to the `gawk' maintainer; see *note Bugs:: for how
to do that.

   Finally, if you cannot install Git (e.g., if it hasn't been ported
yet to your operating system), you can use the Git-CVS gateway to check
out a copy using CVS, as follows:

     cvs -d:pserver:anonymous@pserver.git.sv.gnu.org:/gawk.git co -d gawk master


File: gawk.info,  Node: Adding Code,  Next: New Ports,  Prev: Accessing The Source,  Up: Additions

C.2.2 Adding New Features
-------------------------

You are free to add any new features you like to `gawk'.  However, if
you want your changes to be incorporated into the `gawk' distribution,
there are several steps that you need to take in order to make it
possible to include your changes:

  1. Before building the new feature into `gawk' itself, consider
     writing it as an extension module (*note Dynamic Extensions::).
     If that's not possible, continue with the rest of the steps in
     this list.

  2. Be prepared to sign the appropriate paperwork.  In order for the
     FSF to distribute your changes, you must either place those
     changes in the public domain and submit a signed statement to that
     effect, or assign the copyright in your changes to the FSF.  Both
     of these actions are easy to do and _many_ people have done so
     already. If you have questions, please contact me (*note Bugs::),
     or <assign@gnu.org>.

  3. Get the latest version.  It is much easier for me to integrate
     changes if they are relative to the most recent distributed
     version of `gawk'.  If your version of `gawk' is very old, I may
     not be able to integrate them at all.  (*Note Getting::, for
     information on getting the latest version of `gawk'.)

  4. See *note (Version)Top:: standards, GNU Coding Standards.  This
     document describes how GNU software should be written. If you
     haven't read it, please do so, preferably _before_ starting to
     modify `gawk'.  (The `GNU Coding Standards' are available from the
     GNU Project's web site
     (http://www.gnu.org/prep/standards_toc.html).  Texinfo, Info, and
     DVI versions are also available.)

  5. Use the `gawk' coding style.  The C code for `gawk' follows the
     instructions in the `GNU Coding Standards', with minor exceptions.
     The code is formatted using the traditional "K&R" style,
     particularly as regards to the placement of braces and the use of
     TABs.  In brief, the coding rules for `gawk' are as follows:

        * Use ANSI/ISO style (prototype) function headers when defining
          functions.

        * Put the name of the function at the beginning of its own line.

        * Put the return type of the function, even if it is `int', on
          the line above the line with the name and arguments of the
          function.

        * Put spaces around parentheses used in control structures
          (`if', `while', `for', `do', `switch', and `return').

        * Do not put spaces in front of parentheses used in function
          calls.

        * Put spaces around all C operators and after commas in
          function calls.

        * Do not use the comma operator to produce multiple side
          effects, except in `for' loop initialization and increment
          parts, and in macro bodies.

        * Use real TABs for indenting, not spaces.

        * Use the "K&R" brace layout style.

        * Use comparisons against `NULL' and `'\0'' in the conditions of
          `if', `while', and `for' statements, as well as in the `case's
          of `switch' statements, instead of just the plain pointer or
          character value.

        * Use the `TRUE', `FALSE' and `NULL' symbolic constants and the
          character constant `'\0'' where appropriate, instead of `1'
          and `0'.

        * Provide one-line descriptive comments for each function.

        * Do not use the `alloca()' function for allocating memory off
          the stack.  Its use causes more portability trouble than is
          worth the minor benefit of not having to free the storage.
          Instead, use `malloc()' and `free()'.

        * Do not use comparisons of the form `! strcmp(a, b)' or
          similar.  As Henry Spencer once said, "`strcmp()' is not a
          boolean!"  Instead, use `strcmp(a, b) == 0'.

        * If adding new bit flag values, use explicit hexadecimal
          constants (`0x001', `0x002', `0x004', and son on) instead of
          shifting one left by successive amounts (`(1<<0)', `(1<<1)',
          and so on).

          NOTE: If I have to reformat your code to follow the coding
          style used in `gawk', I may not bother to integrate your
          changes at all.

  6. Update the documentation.  Along with your new code, please supply
     new sections and/or chapters for this Info file.  If at all
     possible, please use real Texinfo, instead of just supplying
     unformatted ASCII text (although even that is better than no
     documentation at all).  Conventions to be followed in `GAWK:
     Effective AWK Programming' are provided after the `@bye' at the
     end of the Texinfo source file.  If possible, please update the
     `man' page as well.

     You will also have to sign paperwork for your documentation
     changes.

  7. Submit changes as unified diffs.  Use `diff -u -r -N' to compare
     the original `gawk' source tree with your version.  I recommend
     using the GNU version of `diff'.  Send the output produced by
     either run of `diff' to me when you submit your changes.  (*Note
     Bugs::, for the electronic mail information.)

     Using this format makes it easy for me to apply your changes to the
     master version of the `gawk' source code (using `patch').  If I
     have to apply the changes manually, using a text editor, I may not
     do so, particularly if there are lots of changes.

  8. Include an entry for the `ChangeLog' file with your submission.
     This helps further minimize the amount of work I have to do,
     making it easier for me to accept patches.

   Although this sounds like a lot of work, please remember that while
you may write the new code, I have to maintain it and support it. If it
isn't possible for me to do that with a minimum of extra work, then I
probably will not.


File: gawk.info,  Node: New Ports,  Prev: Adding Code,  Up: Additions

C.2.3 Porting `gawk' to a New Operating System
----------------------------------------------

If you want to port `gawk' to a new operating system, there are several
steps:

  1. Follow the guidelines in *note Adding Code::, concerning coding
     style, submission of diffs, and so on.

  2. Be prepared to sign the appropriate paperwork.  In order for the
     FSF to distribute your code, you must either place your code in
     the public domain and submit a signed statement to that effect, or
     assign the copyright in your code to the FSF.  Both of these
     actions are easy to do and _many_ people have done so already. If
     you have questions, please contact me, or <gnu@gnu.org>.

  3. When doing a port, bear in mind that your code must coexist
     peacefully with the rest of `gawk' and the other ports. Avoid
     gratuitous changes to the system-independent parts of the code. If
     at all possible, avoid sprinkling `#ifdef's just for your port
     throughout the code.

     If the changes needed for a particular system affect too much of
     the code, I probably will not accept them.  In such a case, you
     can, of course, distribute your changes on your own, as long as
     you comply with the GPL (*note Copying::).

  4. A number of the files that come with `gawk' are maintained by other
     people.  Thus, you should not change them unless it is for a very
     good reason; i.e., changes are not out of the question, but
     changes to these files are scrutinized extra carefully.  The files
     are `dfa.c', `dfa.h', `getopt1.c', `getopt.c', `getopt.h',
     `install-sh', `mkinstalldirs', `regcomp.c', `regex.c',
     `regexec.c', `regexex.c', `regex.h', `regex_internal.c', and
     `regex_internal.h'.

  5. Be willing to continue to maintain the port.  Non-Unix operating
     systems are supported by volunteers who maintain the code needed
     to compile and run `gawk' on their systems. If noone volunteers to
     maintain a port, it becomes unsupported and it may be necessary to
     remove it from the distribution.

  6. Supply an appropriate `gawkmisc.???' file.  Each port has its own
     `gawkmisc.???' that implements certain operating system specific
     functions. This is cleaner than a plethora of `#ifdef's scattered
     throughout the code.  The `gawkmisc.c' in the main source
     directory includes the appropriate `gawkmisc.???' file from each
     subdirectory.  Be sure to update it as well.

     Each port's `gawkmisc.???' file has a suffix reminiscent of the
     machine or operating system for the port--for example,
     `pc/gawkmisc.pc' and `vms/gawkmisc.vms'. The use of separate
     suffixes, instead of plain `gawkmisc.c', makes it possible to move
     files from a port's subdirectory into the main subdirectory,
     without accidentally destroying the real `gawkmisc.c' file.
     (Currently, this is only an issue for the PC operating system
     ports.)

  7. Supply a `Makefile' as well as any other C source and header files
     that are necessary for your operating system.  All your code
     should be in a separate subdirectory, with a name that is the same
     as, or reminiscent of, either your operating system or the
     computer system.  If possible, try to structure things so that it
     is not necessary to move files out of the subdirectory into the
     main source directory.  If that is not possible, then be sure to
     avoid using names for your files that duplicate the names of files
     in the main source directory.

  8. Update the documentation.  Please write a section (or sections)
     for this Info file describing the installation and compilation
     steps needed to compile and/or install `gawk' for your system.

   Following these steps makes it much easier to integrate your changes
into `gawk' and have them coexist happily with other operating systems'
code that is already there.

   In the code that you supply and maintain, feel free to use a coding
style and brace layout that suits your taste.


File: gawk.info,  Node: Dynamic Extensions,  Next: Future Extensions,  Prev: Additions,  Up: Notes

C.3 Adding New Built-in Functions to `gawk'
===========================================

     Danger Will Robinson!  Danger!!
     Warning! Warning!
     The Robot

   It is possible to add new built-in functions to `gawk' using
dynamically loaded libraries. This facility is available on systems
(such as GNU/Linux) that support the C `dlopen()' and `dlsym()'
functions.  This minor node describes how to write and use dynamically
loaded extensions for `gawk'.  Experience with programming in C or C++
is necessary when reading this minor node.

     CAUTION: The facilities described in this minor node are very much
     subject to change in a future `gawk' release.  Be aware that you
     may have to re-do everything, at some future time.

     If you have written your own dynamic extensions, be sure to
     recompile them for each new `gawk' release.  There is no guarantee
     of binary compatibility between different releases, nor will there
     ever be such a guarantee.

     NOTE: When `--sandbox' is specified, extensions are disabled
     (*note Options::.

* Menu:

* Internals::                   A brief look at some `gawk' internals.
* Plugin License::              A note about licensing.
* Sample Library::              A example of new functions.


File: gawk.info,  Node: Internals,  Next: Plugin License,  Up: Dynamic Extensions

C.3.1 A Minimal Introduction to `gawk' Internals
------------------------------------------------

The truth is that `gawk' was not designed for simple extensibility.
The facilities for adding functions using shared libraries work, but
are something of a "bag on the side."  Thus, this tour is brief and
simplistic; would-be `gawk' hackers are encouraged to spend some time
reading the source code before trying to write extensions based on the
material presented here.  Of particular note are the files `awk.h',
`builtin.c', and `eval.c'.  Reading `awkgram.y' in order to see how the
parse tree is built would also be of use.

   With the disclaimers out of the way, the following types, structure
members, functions, and macros are declared in `awk.h' and are of use
when writing extensions.  The next minor node shows how they are used:

`AWKNUM'
     An `AWKNUM' is the internal type of `awk' floating-point numbers.
     Typically, it is a C `double'.

`NODE'
     Just about everything is done using objects of type `NODE'.  These
     contain both strings and numbers, as well as variables and arrays.

`AWKNUM force_number(NODE *n)'
     This macro forces a value to be numeric. It returns the actual
     numeric value contained in the node.  It may end up calling an
     internal `gawk' function.

`void force_string(NODE *n)'
     This macro guarantees that a `NODE''s string value is current.  It
     may end up calling an internal `gawk' function.  It also
     guarantees that the string is zero-terminated.

`void force_wstring(NODE *n)'
     Similarly, this macro guarantees that a `NODE''s wide-string value
     is current.  It may end up calling an internal `gawk' function.
     It also guarantees that the wide string is zero-terminated.

`size_t get_curfunc_arg_count(void)'
     This function returns the actual number of parameters passed to
     the current function.  Inside the code of an extension this can be
     used to determine the maximum index which is safe to use with
     `get_actual_argument'.  If this value is greater than `nargs', the
     function was called incorrectly from the `awk' program.

`nargs'
     Inside an extension function, this is the maximum number of
     expected parameters, as set by the `make_builtin()' function.

`n->stptr'
`n->stlen'
     The data and length of a `NODE''s string value, respectively.  The
     string is _not_ guaranteed to be zero-terminated.  If you need to
     pass the string value to a C library function, save the value in
     `n->stptr[n->stlen]', assign `'\0'' to it, call the routine, and
     then restore the value.

`n->wstptr'
`n->wstlen'
     The data and length of a `NODE''s wide-string value, respectively.
     Use `force_wstring()' to make sure these values are current.

`n->type'
     The type of the `NODE'. This is a C `enum'. Values should be one
     of `Node_var', `Node_var_new', or `Node_var_array' for function
     parameters.

`n->vname'
     The "variable name" of a node.  This is not of much use inside
     externally written extensions.

`void assoc_clear(NODE *n)'
     Clears the associative array pointed to by `n'.  Make sure that
     `n->type == Node_var_array' first.

`NODE **assoc_lookup(NODE *symbol, NODE *subs, int reference)'
     Finds, and installs if necessary, array elements.  `symbol' is the
     array, `subs' is the subscript.  This is usually a value created
     with `make_string()' (see below).  `reference' should be `TRUE' if
     it is an error to use the value before it is created. Typically,
     `FALSE' is the correct value to use from extension functions.

`NODE *make_string(char *s, size_t len)'
     Take a C string and turn it into a pointer to a `NODE' that can be
     stored appropriately.  This is permanent storage; understanding of
     `gawk' memory management is helpful.

`NODE *make_number(AWKNUM val)'
     Take an `AWKNUM' and turn it into a pointer to a `NODE' that can
     be stored appropriately.  This is permanent storage; understanding
     of `gawk' memory management is helpful.

`NODE *dupnode(NODE *n)'
     Duplicate a node.  In most cases, this increments an internal
     reference count instead of actually duplicating the entire `NODE';
     understanding of `gawk' memory management is helpful.

`void unref(NODE *n)'
     This macro releases the memory associated with a `NODE' allocated
     with `make_string()' or `make_number()'.  Understanding of `gawk'
     memory management is helpful.

`void make_builtin(const char *name, NODE *(*func)(NODE *), int count)'
     Register a C function pointed to by `func' as new built-in
     function `name'. `name' is a regular C string. `count' is the
     maximum number of arguments that the function takes.  The function
     should be written in the following manner:

          /* do_xxx --- do xxx function for gawk */

          NODE *
          do_xxx(int nargs)
          {
              ...
          }

`NODE *get_argument(int i)'
     This function is called from within a C extension function to get
     the `i'-th argument from the function call.  The first argument is
     argument zero.

`NODE *get_actual_argument(int i,'
`                          int optional, int wantarray);'
     This function retrieves a particular argument `i'.  `wantarray' is
     `TRUE' if the argument should be an array, `FALSE' otherwise. If
     `optional' is `TRUE', the argument need not have been supplied.
     If it wasn't, the return value is `NULL'.  It is a fatal error if
     `optional' is `TRUE' but the argument was not provided.

`get_scalar_argument(i, opt)'
     This is a convenience macro that calls `get_actual_argument()'.

`get_array_argument(i, opt)'
     This is a convenience macro that calls `get_actual_argument()'.

`void update_ERRNO(void)'
     This function is called from within a C extension function to set
     the value of `gawk''s `ERRNO' variable, based on the current value
     of the C `errno' global variable.  It is provided as a convenience.

`void update_ERRNO_saved(int errno_saved)'
     This function is called from within a C extension function to set
     the value of `gawk''s `ERRNO' variable, based on the error value
     provided as the argument.  It is provided as a convenience.

`void register_deferred_variable(const char *name, NODE *(*load_func)(void))'
     This function is called to register a function to be called when a
     reference to an undefined variable with the given name is
     encountered.  The callback function will never be called if the
     variable exists already, so, unless the calling code is running at
     program startup, it should first check whether a variable of the
     given name already exists.  The argument function must return a
     pointer to a `NODE' containing the newly created variable.  This
     function is used to implement the builtin `ENVIRON' and `PROCINFO'
     arrays, so you can refer to them for examples.

`void register_open_hook(void *(*open_func)(IOBUF *))'
     This function is called to register a function to be called
     whenever a new data file is opened, leading to the creation of an
     `IOBUF' structure in `iop_alloc()'.  After creating the new
     `IOBUF', `iop_alloc()' will call (in reverse order of
     registration, so the last function registered is called first)
     each open hook until one returns non-`NULL'.  If any hook returns
     a non-`NULL' value, that value is assigned to the `IOBUF''s
     `opaque' field (which will presumably point to a structure
     containing additional state associated with the input processing),
     and no further open hooks are called.

     The function called will most likely want to set the `IOBUF''s
     `get_record' method to indicate that future input records should
     be retrieved by calling that method instead of using the standard
     `gawk' input processing.

     And the function will also probably want to set the `IOBUF''s
     `close_func' method to be called when the file is closed to clean
     up any state associated with the input.

     Finally, hook functions should be prepared to receive an `IOBUF'
     structure where the `fd' field is set to `INVALID_HANDLE', meaning
     that `gawk' was not able to open the file itself. In this case,
     the hook function must be able to successfully open the file and
     place a valid file descriptor there.

     Currently, for example, the hook function facility is used to
     implement the XML parser shared library extension.  For more info,
     please look in `awk.h' and in `io.c'.

   An argument that is supposed to be an array needs to be handled with
some extra code, in case the array being passed in is actually from a
function parameter.

   The following boilerplate code shows how to do this:

     NODE *the_arg;

     /* assume need 3rd arg, 0-based */
     the_arg = get_array_argument(2, FALSE);

   Again, you should spend time studying the `gawk' internals; don't
just blindly copy this code.


File: gawk.info,  Node: Plugin License,  Next: Sample Library,  Prev: Internals,  Up: Dynamic Extensions

C.3.2 Extension Licensing
-------------------------

Every dynamic extension should define the global symbol
`plugin_is_GPL_compatible' to assert that it has been licensed under a
GPL-compatible license.  If this symbol does not exist, `gawk' will
emit a fatal error and exit.

   The declared type of the symbol should be `int'.  It does not need
to be in any allocated section, though.  The code merely asserts that
the symbol exists in the global scope.  Something like this is enough:

     int plugin_is_GPL_compatible;


File: gawk.info,  Node: Sample Library,  Prev: Plugin License,  Up: Dynamic Extensions

C.3.3 Example: Directory and File Operation Built-ins
-----------------------------------------------------

Two useful functions that are not in `awk' are `chdir()' (so that an
`awk' program can change its directory) and `stat()' (so that an `awk'
program can gather information about a file).  This minor node
implements these functions for `gawk' in an external extension library.

* Menu:

* Internal File Description::   What the new functions will do.
* Internal File Ops::           The code for internal file operations.
* Using Internal File Ops::     How to use an external extension.


File: gawk.info,  Node: Internal File Description,  Next: Internal File Ops,  Up: Sample Library

C.3.3.1 Using `chdir()' and `stat()'
....................................

This minor node shows how to use the new functions at the `awk' level
once they've been integrated into the running `gawk' interpreter.
Using `chdir()' is very straightforward. It takes one argument, the new
directory to change to:

     ...
     newdir = "/home/arnold/funstuff"
     ret = chdir(newdir)
     if (ret < 0) {
         printf("could not change to %s: %s\n",
                        newdir, ERRNO) > "/dev/stderr"
         exit 1
     }
     ...

   The return value is negative if the `chdir' failed, and `ERRNO'
(*note Built-in Variables::) is set to a string indicating the error.

   Using `stat()' is a bit more complicated.  The C `stat()' function
fills in a structure that has a fair amount of information.  The right
way to model this in `awk' is to fill in an associative array with the
appropriate information:

     file = "/home/arnold/.profile"
     fdata[1] = "x"    # force `fdata' to be an array
     ret = stat(file, fdata)
     if (ret < 0) {
         printf("could not stat %s: %s\n",
                  file, ERRNO) > "/dev/stderr"
         exit 1
     }
     printf("size of %s is %d bytes\n", file, fdata["size"])

   The `stat()' function always clears the data array, even if the
`stat()' fails.  It fills in the following elements:

`"name"'
     The name of the file that was `stat()''ed.

`"dev"'
`"ino"'
     The file's device and inode numbers, respectively.

`"mode"'
     The file's mode, as a numeric value. This includes both the file's
     type and its permissions.

`"nlink"'
     The number of hard links (directory entries) the file has.

`"uid"'
`"gid"'
     The numeric user and group ID numbers of the file's owner.

`"size"'
     The size in bytes of the file.

`"blocks"'
     The number of disk blocks the file actually occupies. This may not
     be a function of the file's size if the file has holes.

`"atime"'
`"mtime"'
`"ctime"'
     The file's last access, modification, and inode update times,
     respectively.  These are numeric timestamps, suitable for
     formatting with `strftime()' (*note Built-in::).

`"pmode"'
     The file's "printable mode."  This is a string representation of
     the file's type and permissions, such as what is produced by `ls
     -l'--for example, `"drwxr-xr-x"'.

`"type"'
     A printable string representation of the file's type.  The value
     is one of the following:

    `"blockdev"'
    `"chardev"'
          The file is a block or character device ("special file").

    `"directory"'
          The file is a directory.

    `"fifo"'
          The file is a named-pipe (also known as a FIFO).

    `"file"'
          The file is just a regular file.

    `"socket"'
          The file is an `AF_UNIX' ("Unix domain") socket in the
          filesystem.

    `"symlink"'
          The file is a symbolic link.

   Several additional elements may be present depending upon the
operating system and the type of the file.  You can test for them in
your `awk' program by using the `in' operator (*note Reference to
Elements::):

`"blksize"'
     The preferred block size for I/O to the file. This field is not
     present on all POSIX-like systems in the C `stat' structure.

`"linkval"'
     If the file is a symbolic link, this element is the name of the
     file the link points to (i.e., the value of the link).

`"rdev"'
`"major"'
`"minor"'
     If the file is a block or character device file, then these values
     represent the numeric device number and the major and minor
     components of that number, respectively.


File: gawk.info,  Node: Internal File Ops,  Next: Using Internal File Ops,  Prev: Internal File Description,  Up: Sample Library

C.3.3.2 C Code for `chdir()' and `stat()'
.........................................

Here is the C code for these extensions.  They were written for
GNU/Linux.  The code needs some more work for complete portability to
other POSIX-compliant systems:(1)

     #include "awk.h"

     #include <sys/sysmacros.h>

     int plugin_is_GPL_compatible;

     /*  do_chdir --- provide dynamically loaded chdir() builtin for gawk */

     static NODE *
     do_chdir(int nargs)
     {
         NODE *newdir;
         int ret = -1;

         if (do_lint && get_curfunc_arg_count() != 1)
             lintwarn("chdir: called with incorrect number of arguments");

         newdir = get_scalar_argument(0, FALSE);

   The file includes the `"awk.h"' header file for definitions for the
`gawk' internals.  It includes `<sys/sysmacros.h>' for access to the
`major()' and `minor'() macros.

   By convention, for an `awk' function `foo', the function that
implements it is called `do_foo'.  The function should take a `int'
argument, usually called `nargs', that represents the number of defined
arguments for the function.  The `newdir' variable represents the new
directory to change to, retrieved with `get_scalar_argument()'.  Note
that the first argument is numbered zero.

   This code actually accomplishes the `chdir()'. It first forces the
argument to be a string and passes the string value to the `chdir()'
system call. If the `chdir()' fails, `ERRNO' is updated.

         (void) force_string(newdir);
         ret = chdir(newdir->stptr);
         if (ret < 0)
             update_ERRNO();

   Finally, the function returns the return value to the `awk' level:

         return make_number((AWKNUM) ret);
     }

   The `stat()' built-in is more involved.  First comes a function that
turns a numeric mode into a printable representation (e.g., 644 becomes
`-rw-r--r--'). This is omitted here for brevity:

     /* format_mode --- turn a stat mode field into something readable */

     static char *
     format_mode(unsigned long fmode)
     {
         ...
     }

   Next comes the `do_stat()' function. It starts with variable
declarations and argument checking:

     /* do_stat --- provide a stat() function for gawk */

     static NODE *
     do_stat(int nargs)
     {
         NODE *file, *array, *tmp;
         struct stat sbuf;
         int ret;
         NODE **aptr;
         char *pmode;    /* printable mode */
         char *type = "unknown";

         if (do_lint && get_curfunc_arg_count() > 2)
             lintwarn("stat: called with too many arguments");

   Then comes the actual work. First, the function gets the arguments.
Then, it always clears the array.  The code use `lstat()' (instead of
`stat()') to get the file information, in case the file is a symbolic
link.  If there's an error, it sets `ERRNO' and returns:

         /* file is first arg, array to hold results is second */
         file = get_scalar_argument(0, FALSE);
         array = get_array_argument(1, FALSE);

         /* empty out the array */
         assoc_clear(array);

         /* lstat the file, if error, set ERRNO and return */
         (void) force_string(file);
         ret = lstat(file->stptr, & sbuf);
         if (ret < 0) {
             update_ERRNO();
             return make_number((AWKNUM) ret);
         }

   Now comes the tedious part: filling in the array.  Only a few of the
calls are shown here, since they all follow the same pattern:

         /* fill in the array */
         aptr = assoc_lookup(array, tmp = make_string("name", 4), FALSE);
         *aptr = dupnode(file);
         unref(tmp);

         aptr = assoc_lookup(array, tmp = make_string("mode", 4), FALSE);
         *aptr = make_number((AWKNUM) sbuf.st_mode);
         unref(tmp);

         aptr = assoc_lookup(array, tmp = make_string("pmode", 5), FALSE);
         pmode = format_mode(sbuf.st_mode);
         *aptr = make_string(pmode, strlen(pmode));
         unref(tmp);

   When done, return the `lstat()' return value:


         return make_number((AWKNUM) ret);
     }

   Finally, it's necessary to provide the "glue" that loads the new
function(s) into `gawk'.  By convention, each library has a routine
named `dlload()' that does the job:

     /* dlload --- load new builtins in this library */

     NODE *
     dlload(NODE *tree, void *dl)
     {
         make_builtin("chdir", do_chdir, 1);
         make_builtin("stat", do_stat, 2);
         return make_number((AWKNUM) 0);
     }

   And that's it!  As an exercise, consider adding functions to
implement system calls such as `chown()', `chmod()', and `umask()'.

   ---------- Footnotes ----------

   (1) This version is edited slightly for presentation.  See
`extension/filefuncs.c' in the `gawk' distribution for the complete
version.


File: gawk.info,  Node: Using Internal File Ops,  Prev: Internal File Ops,  Up: Sample Library

C.3.3.3 Integrating the Extensions
..................................

Now that the code is written, it must be possible to add it at runtime
to the running `gawk' interpreter.  First, the code must be compiled.
Assuming that the functions are in a file named `filefuncs.c', and IDIR
is the location of the `gawk' include files, the following steps create
a GNU/Linux shared library:

     $ gcc -fPIC -shared -DHAVE_CONFIG_H -c -O -g -IIDIR filefuncs.c
     $ ld -o filefuncs.so -shared filefuncs.o

   Once the library exists, it is loaded by calling the `extension()'
built-in function.  This function takes two arguments: the name of the
library to load and the name of a function to call when the library is
first loaded. This function adds the new functions to `gawk'.  It
returns the value returned by the initialization function within the
shared library:

     # file testff.awk
     BEGIN {
         extension("./filefuncs.so", "dlload")

         chdir(".")  # no-op

         data[1] = 1 # force `data' to be an array
         print "Info for testff.awk"
         ret = stat("testff.awk", data)
         print "ret =", ret
         for (i in data)
             printf "data[\"%s\"] = %s\n", i, data[i]
         print "testff.awk modified:",
             strftime("%m %d %y %H:%M:%S", data["mtime"])

         print "\nInfo for JUNK"
         ret = stat("JUNK", data)
         print "ret =", ret
         for (i in data)
             printf "data[\"%s\"] = %s\n", i, data[i]
         print "JUNK modified:", strftime("%m %d %y %H:%M:%S", data["mtime"])
     }

   Here are the results of running the program:

     $ gawk -f testff.awk
     -| Info for testff.awk
     -| ret = 0
     -| data["size"] = 607
     -| data["ino"] = 14945891
     -| data["name"] = testff.awk
     -| data["pmode"] = -rw-rw-r--
     -| data["nlink"] = 1
     -| data["atime"] = 1293993369
     -| data["mtime"] = 1288520752
     -| data["mode"] = 33204
     -| data["blksize"] = 4096
     -| data["dev"] = 2054
     -| data["type"] = file
     -| data["gid"] = 500
     -| data["uid"] = 500
     -| data["blocks"] = 8
     -| data["ctime"] = 1290113572
     -| testff.awk modified: 10 31 10 12:25:52
     -|
     -| Info for JUNK
     -| ret = -1
     -| JUNK modified: 01 01 70 02:00:00


File: gawk.info,  Node: Future Extensions,  Prev: Dynamic Extensions,  Up: Notes

C.4 Probable Future Extensions
==============================

     AWK is a language similar to PERL, only considerably more elegant.
     Arnold Robbins

     Hey!
     Larry Wall

   This minor node briefly lists extensions and possible improvements
that indicate the directions we are currently considering for `gawk'.
The file `FUTURES' in the `gawk' distribution lists these extensions as
well.

   Following is a list of probable future changes visible at the `awk'
language level:

Loadable module interface
     It is not clear that the `awk'-level interface to the modules
     facility is as good as it should be.  The interface needs to be
     redesigned, particularly taking namespace issues into account, as
     well as possibly including issues such as library search path order
     and versioning.

`RECLEN' variable for fixed-length records
     Along with `FIELDWIDTHS', this would speed up the processing of
     fixed-length records.  `PROCINFO["RS"]' would be `"RS"' or
     `"RECLEN"', depending upon which kind of record processing is in
     effect.

Databases
     It may be possible to map a GDBM/NDBM/SDBM file into an `awk'
     array.

More `lint' warnings
     There are more things that could be checked for portability.

   Following is a list of probable improvements that will make `gawk''s
source code easier to work with:

Loadable module mechanics
     The current extension mechanism works (*note Dynamic Extensions::),
     but is rather primitive. It requires a fair amount of manual work
     to create and integrate a loadable module.  Nor is the current
     mechanism as portable as might be desired.  The GNU `libtool'
     package provides a number of features that would make using
     loadable modules much easier.  `gawk' should be changed to use
     `libtool'.

Loadable module internals
     The API to its internals that `gawk' "exports" should be revised.
     Too many things are needlessly exposed.  A new API should be
     designed and implemented to make module writing easier.

Better array subscript management
     `gawk''s management of array subscript storage could use revamping,
     so that using the same value to index multiple arrays only stores
     one copy of the index value.

   Finally, the programs in the test suite could use documenting in
this Info file.

   *Note Additions::, if you are interested in tackling any of these
projects.


File: gawk.info,  Node: Basic Concepts,  Next: Glossary,  Prev: Notes,  Up: Top

Appendix D Basic Programming Concepts
*************************************

This major node attempts to define some of the basic concepts and terms
that are used throughout the rest of this Info file.  As this Info file
is specifically about `awk', and not about computer programming in
general, the coverage here is by necessity fairly cursory and
simplistic.  (If you need more background, there are many other
introductory texts that you should refer to instead.)

* Menu:

* Basic High Level::            The high level view.
* Basic Data Typing::           A very quick intro to data types.
* Floating Point Issues::       Stuff to know about floating-point numbers.

